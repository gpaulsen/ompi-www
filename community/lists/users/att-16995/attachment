<div><div><div>Dear all,</div><div><br></div><div>I have encounted a problem concerns running large jobs on SMP cluster with Open MPI 1.4.</div><div>The application need all-to-all communication, each process send messages to all other processes via MPI_Isend. It goes fine when running 256 processes, the problems occurs when process number &gt;=512.</div>
<div><br></div><div>The error message is:</div><div>        mpirun -np 512 -machinefile machinefile.512 ./my_app</div><div>        [gh30][[23246,1],311][connect/btl_openib_connect_oob.c:463:qp_create_one] error creating qp errno says Cannot allocate memory</div>
<div>        ...</div><div>        [gh26][[23246,1],106][connect/btl_openib_connect_oob.c:809:rml_recv_cb] error in endpoint reply start connect</div><div>        [gh26][[23246,1],117][connect/btl_openib_connect_oob.c:463:qp_create_one] error creating qp errno says Cannot allocate memory</div>
<div>        ...</div><div>        mpirun has exited due to process rank 424 with PID 26841 on</div><div>        node gh31 exiting without calling &quot;finalize&quot;.</div><div><br></div><div>Related post (<a href="http://www.open-mpi.org/community/lists/users/2009/07/9786.php">http://www.open-mpi.org/community/lists/users/2009/07/9786.php</a>) suggests it may run out of HCA QP resources. So I checked my system configuration with &#39;ibv_devinfo -v&#39; and get: &#39;max_qp: 261056&#39;. In my case, running with 256 processes would be under the limit: 256^2 = 65536 &lt; 261056, but 512^2 = 262144 &gt; 261056. </div>
<div>My question is: how to increase the max_qp number of InfiniBand or how to get around this problem in MPI?</div><div><br></div><div>Thanks in advance for any help you may give!</div><div><br></div><div>Huiwei Lv</div>
<div>PhD Student at Institute of Computing Technology</div><div><br></div><div>-------------------------</div><div>p.s. The system informantion is provided below:</div><div>$ ompi_info -v ompi full --parsable</div><div>ompi:version:full:1.4</div>
<div>ompi:version:svn:r22285</div><div>ompi:version:release_date:Dec 08, 2009</div><div>$ uname -a</div><div>Linux gh26 2.6.18-128.el5 #1 SMP Wed Jan 21 10:41:14 EST 2009 x86_64 x86_64 x86_64 GNU/Linux</div><div>$ ulimit -l</div>
<div>unlimited</div><div>$ ibv_devinfo -v</div><div>hca_id: mlx4_0</div><div>        transport:                      InfiniBand (0)</div><div>        fw_ver:                         2.7.000</div><div>        node_guid:                      00d2:c910:0001:b6c0</div>
<div>        sys_image_guid:                 00d2:c910:0001:b6c3</div><div>        vendor_id:                      0x02c9</div><div>        vendor_part_id:                 26428</div><div>        hw_ver:                         0xB0</div>
<div>        board_id:                       MT_0D20110009</div><div>        phys_port_cnt:                  1</div><div>        max_mr_size:                    0xffffffffffffffff</div><div>        page_size_cap:                  0xfffffe00</div>
<div>        max_qp:                         261056</div><div>        max_qp_wr:                      16351</div><div>        device_cap_flags:               0x00fc9c76</div><div>        max_sge:                        32</div>
<div>        max_sge_rd:                     0</div><div>        max_cq:                         65408</div><div>        max_cqe:                        4194303</div><div>        max_mr:                         524272</div>
<div>        max_pd:                         32764</div><div>        max_qp_rd_atom:                 16</div><div>        max_ee_rd_atom:                 0</div><div>        max_res_rd_atom:                4176896</div><div>
        max_qp_init_rd_atom:            128</div><div>        max_ee_init_rd_atom:            0</div><div>        atomic_cap:                     ATOMIC_HCA (1)</div><div>        max_ee:                         0</div><div>
        max_rdd:                        0</div><div>        max_mw:                         0</div><div>        max_raw_ipv6_qp:                0</div><div>        max_raw_ethy_qp:                1</div><div>        max_mcast_grp:                  8192</div>
<div>        max_mcast_qp_attach:            56</div><div>        max_total_mcast_qp_attach:      458752</div><div>        max_ah:                         0</div><div>        max_fmr:                        0</div><div>        max_srq:                        65472</div>
<div>        max_srq_wr:                     16383</div><div>        max_srq_sge:                    31</div><div>        max_pkeys:                      128</div><div>        local_ca_ack_delay:             15</div><div>
                port:   1</div><div>                        state:                  PORT_ACTIVE (4)</div><div>                        max_mtu:                2048 (4)</div><div>                        active_mtu:             2048 (4)</div>
<div>                        sm_lid:                 86</div><div>                        port_lid:               73</div><div>                        port_lmc:               0x00</div><div>                        link_layer:             IB</div>
<div>                        max_msg_sz:             0x40000000</div><div>                        port_cap_flags:         0x02510868</div><div>                        max_vl_num:             8 (4)</div><div>                        bad_pkey_cntr:          0x0</div>
<div>                        qkey_viol_cntr:         0x0</div><div>                        sm_sl:                  0</div><div>                        pkey_tbl_len:           128</div><div>                        gid_tbl_len:            128</div>
<div>                        subnet_timeout:         18</div><div>                        init_type_reply:        0</div><div>                        active_width:           4X (2)</div><div>                        active_speed:           10.0 Gbps (4)</div>
<div>                        phys_state:             LINK_UP (5)</div><div>                        GID[  0]:               fe80:0000:0000:0000:00d2:c910:0001:b6c1</div><div><br></div><div>Related threads in the list: </div>
<div><a href="http://www.open-mpi.org/community/lists/users/2009/07/9786.php">http://www.open-mpi.org/community/lists/users/2009/07/9786.php</a></div><div><a href="http://www.open-mpi.org/community/lists/users/2009/08/10456.php">http://www.open-mpi.org/community/lists/users/2009/08/10456.php</a></div>
<div style="font-size: 12px; "><br></div></div></div>

