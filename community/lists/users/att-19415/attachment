<div class="gmail_quote">On Fri, Jun 1, 2012 at 5:00 AM, Jeff Squyres <span dir="ltr">&lt;<a href="mailto:jsquyres@cisco.com" target="_blank">jsquyres@cisco.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
<div id=":bn">Try running:<br>
<br>
which mpirun<br>
ssh cl2n022 which mpirun<br>
ssh cl2n010 which mpirun<br>
<br>
and<br>
<br>
ldd your_mpi_executable<br>
ssh cl2n022 which mpirun<br>
ssh cl2n010 which mpirun<br>
<br>
Compare the results and ensure that you&#39;re finding the same mpirun on all nodes, and the same libmpi.so on all nodes.  There may well be another Open MPI installed in some non-default location of which you&#39;re unaware.</div>
</blockquote></div><br>I&#39;ll try that Jeff (results given below). However, I suspect there must be something goofy about this (brand new) cluster itself because among the countless jobs that failed, I got one job that ran without error, and all I ever did was to rearrange the echo and which commands. We&#39;ve also observed some peculiar behaviour on this cluster using Intel MPI that seemed to be associated with the number of tasks requested. And after more experimentation, the Open MPI version of the program also seems to be sensitive to the number of tasks (e.g., works with 48, fails with 64).<br>
<br>Thanks for the feedback Jeff, but I think the ball is firmly in my court.<br><br><br><br>I ran the following PBS script with &quot;qsub -l procs=128 job.pbs&quot;. Environment variables are set using the Environment Modules packages.<br>
<br><div style="margin-left:40px"><span style="font-family:courier new,monospace">echo $HOSTNAME</span><br><span style="font-family:courier new,monospace">which mpiexec<br>module load library/openmpi/1.6-intel</span><br><span style="font-family:courier new,monospace">which mpiexec</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">echo $PATH</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">echo $LD_LIBRARY_PATH</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">ldd test-ompi16</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">mpiexec --prefix /lustre/jasper/software/openmpi/openmpi-1.6-intel ./test-ompi16</span><br style="font-family:courier new,monospace">
</div><br>Standard output gave<br><br><div style="margin-left:40px"><span style="font-family:courier new,monospace">cl2n011</span><br><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">/lustre/jasper/software/openmpi/openmpi-1.6-intel/bin/mpiexec</span><br style="font-family:courier new,monospace"><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">/lustre/jasper/software/openmpi/openmpi-1.6-intel/bin:/lustre/jasper/software/intel//l_ics_2012.0.032/composer_xe_2011_sp1.6.233/mpirt/bin/intel64:/lustre/jasper/software/intel//l_ics_2012.0.032/composer_xe_2011_sp1.6.233/bin/intel64:/home/esumbar/local/bin:/home/esumbar/bin:/usr/kerberos/bin:/bin:/usr/bin:/opt/sgi/sgimc/bin:/usr/local/torque/sbin:/usr/local/torque/bin</span><br style="font-family:courier new,monospace">
<br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">/lustre/jasper/software/openmpi/openmpi-1.6-intel/lib:/lustre/jasper/software/intel//l_ics_2012.0.032/composer_xe_2011_sp1.6.233/ipp/lib/intel64:/lustre/jasper/software/intel//l_ics_2012.0.032/composer_xe_2011_sp1.6.233/mkl/lib/intel64:/lustre/jasper/software/intel//l_ics_2012.0.032/composer_xe_2011_sp1.6.233/compiler/lib/intel64:/lustre/jasper/software/intel//l_ics_2012.0.032/composer_xe_2011_sp1.6.233/tbb/lib/intel64:/home/esumbar/local/lib:/usr/lib/jvm/jre-1.6.0-sun/lib/amd64/server:/usr/lib/jvm/jre-1.6.0-sun/lib/amd64:/opt/sgi/sgimc/lib:/lustre/jasper/software/intel//l_ics_2012.0.032/composer_xe_2011_sp1.6.233/debugger/lib/intel64:/lustre/jasper/software/intel//l_ics_2012.0.032/composer_xe_2011_sp1.6.233/mpirt/lib/intel64</span><br>
<br><span style="font-family:courier new,monospace">    linux-vdso.so.1 =&gt;  (0x00007fffb5358000)</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">    libmpi.so.1 =&gt; /lustre/jasper/software/openmpi/openmpi-1.6-intel/lib/libmpi.so.1 (0x00002b3968d1d000)</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">    libdl.so.2 =&gt; /lib64/libdl.so.2 (0x000000329ce00000)</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">    libimf.so =&gt; /lustre/jasper/software/intel//l_ics_2012.0.032/composer_xe_2011_sp1.6.233/compiler/lib/intel64/libimf.so (0x00002b3969137000)</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">    libm.so.6 =&gt; /lib64/libm.so.6 (0x000000329d200000)</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">    librt.so.1 =&gt; /lib64/librt.so.1 (0x000000329da00000)</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">    libnsl.so.1 =&gt; /lib64/libnsl.so.1 (0x00000032a6400000)</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">    libutil.so.1 =&gt; /lib64/libutil.so.1 (0x00000032a8400000)</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">    libsvml.so =&gt; /lustre/jasper/software/intel//l_ics_2012.0.032/composer_xe_2011_sp1.6.233/compiler/lib/intel64/libsvml.so (0x00002b3969504000)</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">    libgcc_s.so.1 =&gt; /lib64/libgcc_s.so.1 (0x00000032a4c00000)</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">    libintlc.so.5 =&gt; /lustre/jasper/software/intel//l_ics_2012.0.032/composer_xe_2011_sp1.6.233/compiler/lib/intel64/libintlc.so.5 (0x00002b3969c77000)</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">    libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x000000329d600000)</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">    libc.so.6 =&gt; /lib64/libc.so.6 (0x000000329ca00000)</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">    /lib64/ld-linux-x86-64.so.2 (0x000000329c200000)</span><br><br></div><br>Standard error gave<br><br><div style="margin-left:40px"><span style="font-family:courier new,monospace">which: no mpiexec in (/home/esumbar/local/bin:/home/esumbar/bin:/usr/kerberos/bin:/bin:/usr/bin:/opt/sgi/sgimc/bin:/usr/local/torque/sbin:/usr/local/torque/bin)</span><br>
<br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">[cl2n005:05142] *** Process received signal ***</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">[cl2n005:05142] Signal: Segmentation fault (11)</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n005:05142] Signal code: Address not mapped (1)</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">[cl2n005:05142] Failing at address: 0x10</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n005:05142] [ 0] /lib64/libpthread.so.0 [0x373180ebe0]</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">[cl2n005:05142] [ 1] /lustre/jasper/software/openmpi/openmpi-1.6-intel/lib/libmpi.so.1(opal_memory_ptmalloc2_int_malloc+0x4b3) [0x2aff9aad5113]</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n005:05142] [ 2] /lustre/jasper/software/openmpi/openmpi-1.6-intel/lib/libmpi.so.1(opal_memory_ptmalloc2_malloc+0x59) [0x2aff9aad78a9]</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n005:05142] [ 3] /lustre/jasper/software/openmpi/openmpi-1.6-intel/lib/libmpi.so.1 [0x2aff9aad7596]</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">[cl2n005:05142] [ 4] /lustre/jasper/software/openmpi/openmpi-1.6-intel/lib/libmpi.so.1(ompi_free_list_grow+0x89) [0x2aff9aa0fa59]</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n005:05142] [ 5] /lustre/jasper/software/openmpi/openmpi-1.6-intel/lib/libmpi.so.1(ompi_free_list_init_ex+0x9c) [0x2aff9aa0fd8c]</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n005:05142] [ 6] /lustre/jasper/software/openmpi/openmpi-1.6-intel/lib/openmpi/mca_btl_openib.so [0x2aff9e94561c]</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">[cl2n005:05142] [ 7] /lustre/jasper/software/openmpi/openmpi-1.6-intel/lib/libmpi.so.1(mca_btl_base_select+0x130) [0x2aff9aa57930]</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n005:05142] [ 8] /lustre/jasper/software/openmpi/openmpi-1.6-intel/lib/openmpi/mca_bml_r2.so(mca_bml_r2_component_init+0xe) [0x2aff9e52bc1e]</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n005:05142] [ 9] /lustre/jasper/software/openmpi/openmpi-1.6-intel/lib/libmpi.so.1(mca_bml_base_init+0x72) [0x2aff9aa570b2]</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n005:05142] [10] /lustre/jasper/software/openmpi/openmpi-1.6-intel/lib/openmpi/mca_pml_ob1.so [0x2aff9e1107e9]</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">[cl2n005:05142] [11] /lustre/jasper/software/openmpi/openmpi-1.6-intel/lib/libmpi.so.1(mca_pml_base_select+0x43e) [0x2aff9aa6592e]</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n005:05142] [12] /lustre/jasper/software/openmpi/openmpi-1.6-intel/lib/libmpi.so.1(ompi_mpi_init+0x782) [0x2aff9aa276a2]</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n005:05142] [13] /lustre/jasper/software/openmpi/openmpi-1.6-intel/lib/libmpi.so.1(MPI_Init+0xf4) [0x2aff9aa3f884]</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">[cl2n005:05142] [14] ./test-ompi16(main+0x4c) [0x400b5c]</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n005:05142] [15] /lib64/libc.so.6(__libc_start_main+0xf4) [0x3730c1d994]</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">[cl2n005:05142] [16] ./test-ompi16 [0x400a59]</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n005:05142] *** End of error message ***</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">[cl2n006:32362] [[58962,0],5] ORTE_ERROR_LOG: Data unpack would read past end of buffer in file util/nidmap.c at line 776</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n006:32362] [[58962,0],5] ORTE_ERROR_LOG: Data unpack would read past end of buffer in file ess_tm_module.c at line 310</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n006:32362] [[58962,0],5] ORTE_ERROR_LOG: Data unpack would read past end of buffer in file base/odls_base_default_fns.c at line 2342</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n003:04157] [[58962,0],8] ORTE_ERROR_LOG: Data unpack would read past end of buffer in file util/nidmap.c at line 776</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n003:04157] [[58962,0],8] ORTE_ERROR_LOG: Data unpack would read past end of buffer in file ess_tm_module.c at line 310</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">[cl2n003:04157] [[58962,0],8] ORTE_ERROR_LOG: Data unpack would read past end of buffer in file base/odls_base_default_fns.c at line 2342</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">--------------------------------------------------------------------------</span><br style="font-family:courier new,monospace"><span style="font-family:courier new,monospace">mpiexec noticed that process rank 77 with PID 5142 on node cl2n005 exited on signal 11 (Segmentation fault).</span><br style="font-family:courier new,monospace">
<span style="font-family:courier new,monospace">--------------------------------------------------------------------------</span><br></div><br clear="all"><br>-- <br><div><div></div><div>Edmund Sumbar<font color="#999999"><br>
University of Alberta<br></font></div><div><font color="#999999">+1 780 492 9360</font></div></div><br>

