I see. Thank you both for the prompt replies. <br><br><div class="gmail_quote">On Thu, Jul 26, 2012 at 8:21 PM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div style="word-wrap:break-word">Application processes will *only* be placed on nodes included in the allocation. The -nolocal flag is intended to ensure that no application processes are started on the same node as mpirun in the case where that node is included in the allocation. This happens, for example, with Torque, where mpirun is executed on one of the allocated nodes.<div>
<br></div><div>I believe SGE doesn&#39;t do that - and so the allocation won&#39;t include the submit host, in which case you don&#39;t need -nolocal.</div><div><div class="h5"><div><br></div><div><br><div><div>On Jul 26, 2012, at 5:58 PM, Erik Nelson wrote:</div>
<br><blockquote type="cite">I was under the impression that the -nolocal option keeps processes off the submit<br>host (since there may be hundreds or thousands of jobs submitted at any time, <br>and we don&#39;t want this host to be overloaded).<br>

<br>My understanding of what you said in you last email is that, by listing the hosts,  I<br>automatically send all processes (parent and child, or master and slave if you <br>prefer) to the specified list of hosts. <br>
<br>
Reading your email below, it looks like this was the correct understanding.<br><br><br><div class="gmail_quote">On Thu, Jul 26, 2012 at 5:20 PM, Reuti <span dir="ltr">&lt;<a href="mailto:reuti@staff.uni-marburg.de" target="_blank">reuti@staff.uni-marburg.de</a>&gt;</span> wrote:<br>

<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Am 26.07.2012 um 23:58 schrieb Erik Nelson:<br>
<div><br>
&gt; Reuti,<br>
&gt;<br>
&gt; Thank you. Our queue is backed up, so it will take a little while before I can try this.<br>
&gt;<br>
&gt; I assume that by specifying the nodes this way, I don&#39;t need (and it would confuse<br>
&gt; the system) to add -nolocal. In other words, qsub will try to put the parent node<br>
&gt; somewhere in this set.<br>
&gt;<br>
&gt; Is this the idea?<br>
<br>
</div>Depends what you refer to by &quot;parent node&quot;. I assume you mean the submit host. This is never included in any created selection of SGE unless it&#39;s an execution host too.<br>
<br>
The master host of the parallel job (i.e. the one where the jobscript with the `mpiexec` is running) will be used as a normal machine from MPI&#39;s point of view.<br>
<span><font color="#888888"><br>
-- Reuti<br>
</font></span><div><div><br>
<br>
&gt; Erik<br>
&gt;<br>
&gt;<br>
&gt; On Thu, Jul 26, 2012 at 4:48 PM, Reuti &lt;<a href="mailto:reuti@staff.uni-marburg.de" target="_blank">reuti@staff.uni-marburg.de</a>&gt; wrote:<br>
&gt; Am 26.07.2012 um 23:33 schrieb Erik Nelson:<br>
&gt;<br>
&gt; &gt; I have a purely parallel job that runs ~100 processes. Each process has ~identical<br>
&gt; &gt; overhead so the speed of the program is dominated by the slowest processor.<br>
&gt; &gt;<br>
&gt; &gt; For this reason, I would like to restrict the job to a specific set of identical (fast)<br>
&gt; &gt; processors on our cluster.<br>
&gt; &gt;<br>
&gt; &gt; I read the FAQ on -hosts and -hostfile, but it is still unclear to me what affect these<br>
&gt; &gt; directives will have in a queuing environment.<br>
&gt; &gt;<br>
&gt; &gt; Currently, I submit the job using the &quot;qsub&quot; command in the &quot;sge&quot; environment as :<br>
&gt; &gt;<br>
&gt; &gt;             qsub -pe mpich 101 jobfile.job<br>
&gt; &gt;<br>
&gt; &gt; where jobfile contains the command<br>
&gt; &gt;<br>
&gt; &gt;             mpirun -np 101 -nolocal ./executable<br>
&gt;<br>
&gt; I would leave -nolocal out here.<br>
&gt;<br>
&gt; $ qsub -l &quot;h=compute-5-[1-9]|compute-5-1[0-9]|compute-5-2[0-9]|compute-5-3[0-2]&quot; -pe mpich 101 jobfile.job<br>
&gt;<br>
&gt; -- Reuti<br>
&gt;<br>
&gt;<br>
&gt; &gt; I would like to restrict the job to nodes compute-5-1 to compute-5-32 on our machine,<br>
&gt; &gt; each containing 8 cpu&#39;s (slots). How do I go about this?<br>
&gt; &gt;<br>
&gt; &gt; Thanks, Erik<br>
&gt; &gt;<br>
&gt; &gt; --<br>
&gt; &gt; Erik Nelson<br>
&gt; &gt;<br>
&gt; &gt; Howard Hughes Medical Institute<br>
&gt; &gt; 6001 Forest Park Blvd., Room ND10.124<br>
&gt; &gt; Dallas, Texas 75235-9050<br>
&gt; &gt;<br>
&gt; &gt; p : <a href="tel:214%20645%205981" value="+12146455981" target="_blank">214 645 5981</a><br>
&gt; &gt; f : <a href="tel:214%20645%205948" value="+12146455948" target="_blank">214 645 5948</a><br>
&gt; &gt; _______________________________________________<br>
&gt; &gt; users mailing list<br>
&gt; &gt; <a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
&gt; &gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt;<br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; --<br>
&gt; Erik Nelson<br>
&gt;<br>
&gt; Howard Hughes Medical Institute<br>
&gt; 6001 Forest Park Blvd., Room ND10.124<br>
&gt; Dallas, Texas 75235-9050<br>
&gt;<br>
&gt; p : <a href="tel:214%20645%205981" value="+12146455981" target="_blank">214 645 5981</a><br>
&gt; f : <a href="tel:214%20645%205948" value="+12146455948" target="_blank">214 645 5948</a><br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</div></div></blockquote></div><br><br clear="all"><br>-- <br>Erik Nelson<br><br>Howard Hughes Medical Institute<br>6001 Forest Park Blvd., Room ND10.124<br>Dallas, Texas 75235-9050<br><br>p : <a href="tel:214%20645%205981" value="+12146455981" target="_blank">214 645 5981</a><br>
f : <a href="tel:214%20645%205948" value="+12146455948" target="_blank">214 645 5948</a><br>

_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></blockquote>
</div><br></div></div></div></div><br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></div><br><br clear="all"><br>-- <br>Erik Nelson<br><br>Howard Hughes Medical Institute<br>
6001 Forest Park Blvd., Room ND10.124<br>Dallas, Texas 75235-9050<br><br>p : 214 645 5981<br>f : 214 645 5948<br>

