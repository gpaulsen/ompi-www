Dear Jeff, thanks for the information.<div><br></div><div>&gt;Open MPI currently has very limited cartesian support -- it actually doesn&#39;t remap anything.<div><div><br></div><div>I see, OpenMPI doesn&#39;t remap anything; this explains probably why my runtime of my simulation varies sometimes between 30% for the same setup.</div>
<div><br></div><div>&gt;Would you have any interest in writing a partitioning algorithm for your needs within the context of a plugin?  I&#39;d be happy to walk &gt;you through the process; it&#39;s not too complicated (although we should probably move the discussion off to the Open MPI devel &gt;mailing list).<br>
<div><div></div></div></div><div><br></div><div><div>I guess after using for more than a decade Open Source Software, it&#39;s time to give something back :). ... so yes, I am willing to do that !!</div><div><br></div><div>
Because I am not yet experienced with OpenMPI internals, I would really appreciate your advice, if you could tell me where exactly I have to dig into.. I guess it should be around ompi_topo_create function, but how to write MPI_Cart_Create as a plugin, I will rely on you information. And do you know if MPICH, LAM etc. have an efficient implementation of MPI_Cart_Create ? so I can borrow some ideas from them....</div>
<div><br></div><div>best wishes,</div><div><br></div><div>Paul Hilscher</div><div><br></div><div> </div><div><div><div><br><div class="gmail_quote">On Tue, Jun 29, 2010 at 8:17 PM, Jeff Squyres <span dir="ltr">&lt;<a href="mailto:jsquyres@cisco.com" target="_blank">jsquyres@cisco.com</a>&gt;</span> wrote:<br>

<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Open MPI currently has very limited cartesian support -- it actually doesn&#39;t remap anything.<br>
<br>
That being said, it is *very* easy to extend Open MPI&#39;s algorithms for cartesian partitioning.  As you probably already know, Open MPI is all about its plugins -- finding and selecting a good set of plugins to use at run-time.  Open MPI has many different types of plugins.  One of these types of plugins performs the cartesian/graph mapping behind MPI_Cart_create (and friends) function(s).<br>


<br>
Would you have any interest in writing a partitioning algorithm for your needs within the context of a plugin?  I&#39;d be happy to walk you through the process; it&#39;s not too complicated (although we should probably move the discussion off to the Open MPI devel mailing list).<br>


<div><div></div><div><br>
<br>
On Jun 29, 2010, at 4:50 AM, Paul Hilscher wrote:<br>
<br>
&gt; Dear OpenMPI list,<br>
&gt;<br>
&gt; I am using  a MPI-parallelized simulation program,  with a domain-decomposition in 6-Dimensions.<br>
&gt; In order to improve the scalability of my program I would like to know according to what preferences<br>
&gt; is MPI distributing the ranks when using MPI_Cart_create( reorder allowed).<br>
&gt;<br>
&gt; To explain my inquiry, imagine a 3-dimensional solver in  X-Y-M and 4 computing<br>
&gt; nodes, each nodes consist of 4 Quad-Core CPUs (4(Node)x[ 4(CPUs) x 4(Cores))] CPUs=64CPUs).<br>
&gt;<br>
&gt; Now I decompose  all 3 dimensions by 4 (4x4x4 = 64) using  MPI_Cart_create.<br>
&gt; MPI has now several  possibilities to map the problem e.g. X-M (locally) on a node and<br>
&gt; Y across the nodes, or Y-M (locally) and X across the nodes.<br>
&gt;<br>
&gt; Now my question is, how can I tell MPI that I want to distribute X-Y locally while<br>
&gt; M is distributed across nodes. The reason is that X-Y<br>
&gt; communication ratio is much large (FFT) compared to M where we have only<br>
&gt; 2 communications per time-step via an Allreduce.<br>
&gt; An MPI implementation for the BlueGENE for example has an option<br>
&gt; called mapfile where on can tell MPI how to map the dimensions onto<br>
&gt; the Nodes. I did not found somethings similar for openmpi.<br>
&gt;<br>
&gt; Does anybody know how to achieve this mapping or could anybody<br>
&gt; tell me where I could find some examples or tutorials ?<br>
&gt;<br>
&gt; Thank you very much for your help and best wishes<br>
&gt;<br>
&gt; Paul Hilscher<br>
</div></div><div>&gt; _______________________________________________<br>
&gt; </div></blockquote></div><br></div>
</div></div></div></div></div>

