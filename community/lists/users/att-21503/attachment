Hi, <br><br>Thank for your reply. But this is not the case that you mentioned, everything is correct with the program.<br><br><div class="gmail_quote">On Tue, Mar 5, 2013 at 12:40 PM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Check your code - it looks like you called MPI_Init and failed to call MPI_Finalize before exiting<br>
<div><div class="h5"><br>
On Mar 5, 2013, at 9:07 AM, Chintu &lt;<a href="mailto:chintudcy@gmail.com">chintudcy@gmail.com</a>&gt; wrote:<br>
<br>
&gt; Hi,<br>
&gt;<br>
&gt; I am running my jobs on openmpi linux platform. I am getting the following errors:<br>
&gt;<br>
&gt; [compute-12-23.local:10203] *** An error occurred in MPI_Comm_rank<br>
&gt; [compute-12-23.local:10203] *** on communicator MPI_COMM_WORLD<br>
&gt; [compute-12-23.local:10203] *** MPI_ERR_COMM: invalid communicator<br>
&gt; [compute-12-23.local:10203] *** MPI_ERRORS_ARE_FATAL: your MPI job will now abort<br>
&gt; --------------------------------------------------------------------------<br>
&gt; mpirun has exited due to process rank 11 with PID 10211 on<br>
&gt; node compute-12-23.local exiting improperly. There are two reasons this could occur:<br>
&gt;<br>
&gt; 1. this process did not call &quot;init&quot; before exiting, but others in<br>
&gt; the job did. This can cause a job to hang indefinitely while it waits<br>
&gt; for all processes to call &quot;init&quot;. By rule, if one process calls &quot;init&quot;,<br>
&gt; then ALL processes must call &quot;init&quot; prior to termination.<br>
&gt;<br>
&gt; 2. this process called &quot;init&quot;, but exited without calling &quot;finalize&quot;.<br>
&gt; By rule, all processes that call &quot;init&quot; MUST call &quot;finalize&quot; prior to<br>
&gt; exiting or it will be considered an &quot;abnormal termination&quot;<br>
&gt;<br>
&gt; This may have caused other processes in the application to be<br>
&gt; terminated by signals sent by mpirun (as reported here).<br>
&gt; --------------------------------------------------------------------------<br>
&gt; [compute-12-23.local:10199] 11 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal<br>
&gt; [compute-12-23.local:10199] Set MCA parameter &quot;orte_base_help_aggregate&quot; to 0 to see all help / error messages<br>
&gt; rm: cannot remove `/tmp/145890.1.normal/rsh&#39;: No such file or directory<br>
&gt;<br>
&gt;<br>
&gt; Any help or suggestion will be appreciated.<br>
&gt;<br>
&gt; Thanks,<br>
&gt; Praveen<br>
</div></div>&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</blockquote></div><br>

