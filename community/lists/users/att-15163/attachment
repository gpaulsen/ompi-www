<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta content="text/html; charset=ISO-8859-1"
      http-equiv="Content-Type">
  </head>
  <body text="#000000" bgcolor="#ffffff">
    Bonjour Jeff,<br>
    <br>
    Le 16/12/2010 01:40, Jeff Squyres a &eacute;crit&nbsp;:
    <blockquote
      cite="mid:47376C68-1526-4DA3-B31C-0ECF114D6299@cisco.com"
      type="cite">
      <pre wrap="">On Dec 15, 2010, at 3:24 PM, Ralph Castain wrote:

</pre>
      <blockquote type="cite">
        <blockquote type="cite">
          <pre wrap="">I am not using the TCP BTL, only OPENIB one. Does this change the number of sockets in use per node, please ?
</pre>
        </blockquote>
        <pre wrap="">
I believe the openib btl opens sockets for connection purposes, so the count is likely the same. An IB person can confirm that...
</pre>
      </blockquote>
      <pre wrap="">
Nope -- the openib BTL uses the daemon-based communication mechanism.  So it should only use the TCP ports that are already open.

Does this problem *always* happen, or does it only happen once in a great while?
</pre>
    </blockquote>
    gg= No, this problem happens rather often, almost every other time.<br>
    Seems to happen more often as the number of cores increases.<br>
    <br>
    <blockquote
      cite="mid:47376C68-1526-4DA3-B31C-0ECF114D6299@cisco.com"
      type="cite">
      <pre wrap="">
I've seen a similar problem with the TCP BTL every once in a great while -- where a random, errant (non-Open MPI) process connects to a socket that Open MPI is listening on (regardless of whether it's the TCP BTL or TCP OOB).  This causes badness in Open MPI because we don't verify the connector properly, and more importantly, don't handle it nicely when the connector is not Open MPI.  I've seen this happen with network malware scanners, for example -- they try to connect to large swaths of TCP ports and sometimes unluckily hit an open Open MPI TCP port.
</pre>
    </blockquote>
    gg= Is there a way with the <b>current</b> code, to direct OpenMPI
    to use a restricted range of TCP ports,<br>
    that I can choose at launch time ?<br>
    Or, conversely, which routine should I patch in my private OpenMPI
    install to aim at the same result ?<br>
    <br>
    &nbsp;Usually, on the cluster I use, workers are not shared with any
    other tasks ... ;;-((<br>
    <br>
    &nbsp;Thanks,&nbsp;&nbsp; Best,&nbsp;&nbsp;&nbsp; G.<br>
    <br>
    <blockquote
      cite="mid:47376C68-1526-4DA3-B31C-0ECF114D6299@cisco.com"
      type="cite">
      <pre wrap="">
We have a fix for this coming in a future version of the TCP BTL; looks like we should also harden this up for the TCP OOB as well...
</pre>
    </blockquote>
    <br>
  </body>
</html>

