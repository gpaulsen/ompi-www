thanks for your reply jeff<div><br></div><div>so i tried following</div><div><br></div><div><br></div><div><br></div><div><span class="Apple-style-span" style="border-collapse: collapse; ">#include &lt;stdio.h&gt;<br>#include &lt;mpi.h&gt;<br>
<br>int main(int argc, char **argv) {<br>&nbsp;int np, me, sbuf = -1, rbuf = -2,mbuf=1000;<br>int data[2];<br>&nbsp;MPI_Init(&amp;argc,&amp;argv);<br>&nbsp;MPI_Comm_size(MPI_COMM_WORLD,&amp;np);<br>&nbsp;MPI_Comm_rank(MPI_COMM_WORLD,&amp;me);<br>
&nbsp;if ( np &lt; 2 ) MPI_Abort(MPI_COMM_WORLD,-1);<br><br>&nbsp;if ( me == 1 ) MPI_Send(&amp;sbuf,1,MPI_INT,0,344,MPI_COMM_WORLD);<br>if(me==2) MPI_Send( &amp;mbuf,1,MPI_INT,0,344,MPI_COMM_WORLD);</span></div><div><span class="Apple-style-span" style="border-collapse: collapse; ">if ( me == 0 ) {<br>
&nbsp; MPI_Recv(data,2,MPI_INT,MPI_ANY_SOURCE,344,MPI_COMM_WORLD,MPI_STATUS_IGNORE);<br>&nbsp;}<br></span></div><div><span class="Apple-style-span" style="border-collapse: collapse; "><br>&nbsp;MPI_Finalize();<br><br>&nbsp;return 0;<br>}</span><br>
</div><div><br>it can successfuly receive the one sent from processor 1(me==1) but it failed to receive the one sent from processor 2(me==2)</div><div>mpirun -np 3 hello</div><div><br></div><div><br></div><div>thanks</div>
<div>winthan<br><div class="gmail_quote">On Tue, Dec 23, 2008 at 1:15 PM, Jeff Squyres <span dir="ltr">&lt;<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;">
This looks like a question for the MPICH2 developers.<br>
<br>
Specifically, it looks like you are using MPICH2, not Open MPI. &nbsp;They are entirely different software packages maintained by different people -- we&#39;re not really qualified to answer questions about MPICH2. &nbsp;The top-level API is the same between the two (meaning that you can compile and run your app in either Open MPI or MPICH2), but that&#39;s where the similarities end.<div>
<div></div><div class="Wj3C7c"><br>
<br>
<br>
On Dec 23, 2008, at 2:07 PM, Win Than Aung wrote:<br>
<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
PS： extra question<br>
qsub -I -q standby -l select=1:ncpus=8<br>
mpirun -np 4 ./hello<br>
running mpdallexit on <a href="http://steele-a137.rcac.purdue.edu" target="_blank">steele-a137.rcac.purdue.edu</a><br>
LAUNCHED mpd on <a href="http://steele-a137.rcac.purdue.edu" target="_blank">steele-a137.rcac.purdue.edu</a> &nbsp;via<br>
RUNNING: mpd on <a href="http://steele-a137.rcac.purdue.edu" target="_blank">steele-a137.rcac.purdue.edu</a><br>
steele-a137.rcac.purdue.edu_36959 (172.18.24.147)<br>
time for 100 loops = 2.98023223877e-05 seconds<br>
too few entries in machinefile<br>
<br>
the mpi program supposed to print 4 hello msg since there r four processors.<br>
but for some reasons, it doesn&#39;t print<br>
thanks<br>
winthan<br>
<br>
<br>
On Tue, Dec 23, 2008 at 1:23 PM, Eugene Loh &lt;<a href="mailto:Eugene.Loh@sun.com" target="_blank">Eugene.Loh@sun.com</a>&gt; wrote:<br>
Win Than Aung wrote:<br>
<br>
MPI_Recv(....) &lt;&lt; is it possible to receive the message sent from other sources? I tried MPI_ANY_SOURCE in place of source but it doesn&#39;t work out<br>
<br>
Yes of course. &nbsp;Can you send a short example of what doesn&#39;t work? &nbsp;The example should presumably be less than about 20 lines. &nbsp;Here is an example that works:<br>
<br>
% cat a.c<br>
#include &lt;stdio.h&gt;<br>
#include &lt;mpi.h&gt;<br>
<br>
int main(int argc, char **argv) {<br>
&nbsp;int np, me, sbuf = -1, rbuf = -2;<br>
<br>
&nbsp;MPI_Init(&amp;argc,&amp;argv);<br>
&nbsp;MPI_Comm_size(MPI_COMM_WORLD,&amp;np);<br>
&nbsp;MPI_Comm_rank(MPI_COMM_WORLD,&amp;me);<br>
&nbsp;if ( np &lt; 2 ) MPI_Abort(MPI_COMM_WORLD,-1);<br>
<br>
&nbsp;if ( me == 1 ) MPI_Send(&amp;sbuf,1,MPI_INT,0,344,MPI_COMM_WORLD);<br>
&nbsp;if ( me == 0 ) {<br>
 &nbsp;MPI_Recv(&amp;rbuf,1,MPI_INT,MPI_ANY_SOURCE,344,MPI_COMM_WORLD,MPI_STATUS_IGNORE);<br>
 &nbsp;if ( rbuf == sbuf ) printf(&quot;Send/Recv self passed\n&quot;);<br>
 &nbsp;else &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;printf(&quot;Send/Recv self FAILED\n&quot;);<br>
&nbsp;}<br>
<br>
&nbsp;MPI_Finalize();<br>
<br>
&nbsp;return 0;<br>
}<br>
% mpicc a.c<br>
% mpirun -np 2 a.out<br>
Send/Recv self passed<br>
%<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</blockquote>
<br>
<br></div></div><font color="#888888">
-- <br>
Jeff Squyres<br>
Cisco Systems</font><div><div></div><div class="Wj3C7c"><br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</div></div></blockquote></div><br></div>

