I&#39;m afraid I&#39;m confused - I don&#39;t understand what is and isn&#39;t working. What &quot;next process&quot; isn&#39;t starting?<br><br><br><div class="gmail_quote">On Thu, Oct 11, 2012 at 9:41 AM, Michael Di Domenico <span dir="ltr">&lt;<a href="mailto:mdidomenico4@gmail.com" target="_blank">mdidomenico4@gmail.com</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">adding some additional info<br>
<br>
did an strace on an orted process where xhpl failed to start, i did<br>
this after the mpirun execution, so i probably missed some output, but<br>
it keeps scrolling<br>
<br>
poll([{fd=4, events=POLLIN},{fd=7, events=POLLIN},{fd=8,<br>
events=POLLIN},{fd=10, events=POLLIN},{fd=12, events=POLLIN},{fd=13,<br>
events=POLLIN},{fd=14, events=POLLIN},{fd=15, events=POLLIN},{fd=16,<br>
events=POLLIN}], 9, 1000) = 0 (Timeout)<br>
<br>
i didn&#39;t see anything useful in /proc under those file descriptors,<br>
but perhaps i missed something i don&#39;t know to look for<br>
<br>
On Thu, Oct 11, 2012 at 12:06 PM, Michael Di Domenico<br>
<div class="HOEnZb"><div class="h5">&lt;<a href="mailto:mdidomenico4@gmail.com">mdidomenico4@gmail.com</a>&gt; wrote:<br>
&gt; too add a little more detail, it looks like xhpl is not actually<br>
&gt; starting on all nodes when i kick off the mpirun<br>
&gt;<br>
&gt; each time i cancel and restart the job, the nodes that do not start<br>
&gt; change, so i can&#39;t call it a bad node<br>
&gt;<br>
&gt; if i disable infiniband with --mca btl self,sm,tcp on occasion i can<br>
&gt; get xhpl to actually run, but it&#39;s not consistent<br>
&gt;<br>
&gt; i&#39;m going to check my ethernet network and make sure there&#39;s no<br>
&gt; problems there (could this be an OOB error with mpirun?), on the nodes<br>
&gt; that fail to start xhpl, i do see the orte process, but nothing in the<br>
&gt; logs about why it failed to launch xhpl<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; On Thu, Oct 11, 2012 at 11:49 AM, Michael Di Domenico<br>
&gt; &lt;<a href="mailto:mdidomenico4@gmail.com">mdidomenico4@gmail.com</a>&gt; wrote:<br>
&gt;&gt; I&#39;m trying to diagnose an MPI job (in this case xhpl), that fails to<br>
&gt;&gt; start when the rank count gets fairly high into the thousands.<br>
&gt;&gt;<br>
&gt;&gt; My symptom is the jobs fires up via slurm, and I can see all the xhpl<br>
&gt;&gt; processes on the nodes, but it never kicks over to the next process.<br>
&gt;&gt;<br>
&gt;&gt; My question is, what debugs should I turn on to tell me what the<br>
&gt;&gt; system might be waiting on?<br>
&gt;&gt;<br>
&gt;&gt; I&#39;ve checked a bunch of things, but I&#39;m probably overlooking something<br>
&gt;&gt; trivial (which is par for me).<br>
&gt;&gt;<br>
&gt;&gt; I&#39;m using the Openmpi 1.6.1, Slurm 2.4.2 on CentOS 6.3, with Infiniband/PSM<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</div></div></blockquote></div><br>

