<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  </head>
  <body bgcolor="#ffffff" text="#000000">
    Thank you Jed, sounds like the log_summary should be sufficient for
    my needs!<br>
    <br>
    I appreciate your help :)<br>
    <br>
    Have a great weekend!<br>
    <br>
    Paul Monday<br>
    <br>
    On 5/6/11 3:38 AM, Jed Brown wrote:
    <blockquote
      cite="mid:BANLkTinKQ-C8XsPS=wZcYP7ExLq3d369aA@mail.gmail.com"
      type="cite">
      <div class="gmail_quote">On Thu, May 5, 2011 at 23:15, Paul Monday
        (Parallel Scientific) <span dir="ltr">&lt;<a
            moz-do-not-send="true" href="mailto:paul.monday@parsci.com">paul.monday@parsci.com</a>&gt;</span>
        wrote:<br>
        <blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt
          0.8ex; border-left: 1px solid rgb(204, 204, 204);
          padding-left: 1ex;">
          <div style="word-wrap: break-word;">Hi, I'm hoping someone can
            help me locate a SpMV benchmark that runs w/ Open MPI so I
            can benchmark how my systems are interacting with the
            network as I add nodes / cores to the pool of systems.  I
            can find SpMV benchmarks for single processor / OpenMP all
            over, but these networked ones are proving harder to come
            by.  I located Lis (<a moz-do-not-send="true"
              href="http://www.ssisc.org/lis/" target="_blank">http://www.ssisc.org/lis/</a>)
            but it seems more of a solver then a benchmarking program.</div>
        </blockquote>
      </div>
      <br>
      <div>I would suggest using PETSc. It is a solvers library rather
        than a contrived benchmark suite, but the examples give you
        access to many different matrices and you can use many different
        formats without changing the code. If you run with -log_summary,
        you will get a useful table showing the performance of different
        operations (time/balance/communication/reductions/flops/etc).
        Also note that SpMV is usually not an end in its own right,
        usually it is part of a preconditioned Krylov iteration, so the
        performance of all the pieces matter.</div>
      <div><br>
      </div>
      <div>If you are concerned with absolute performance then you
        should consider using petsc-dev since it tends to have better
        memory performance due to software prefetch. This is important
        for good reuse of high-level caches since otherwise the matrix
        entries flush out the useful stuff. It usually makes between a
        20 and 30% improvement, a bit more for some symmetric and
        triangular kernels. Many of the sparse matrix kernels did not
        have software prefetch as of the 3.1 release. Remember:</div>
      <div><br>
      </div>
      <div>"The easiest way to make software scalable is to make it
        sequentially inefficient." (Gropp, 1999)</div>
      <pre wrap="">
<fieldset class="mimeAttachmentHeader"></fieldset>
_______________________________________________
users mailing list
<a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
<a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></pre>
    </blockquote>
    <br>
  </body>
</html>

