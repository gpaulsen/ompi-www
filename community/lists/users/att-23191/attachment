<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" xmlns="http://www.w3.org/TR/REC-html40"><head><meta http-equiv=Content-Type content="text/html; charset=utf-8"><meta name=Generator content="Microsoft Word 14 (filtered medium)"><style><!--
/* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0in;
	margin-bottom:.0001pt;
	font-size:12.0pt;
	font-family:"Times New Roman","serif";}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-priority:99;
	color:purple;
	text-decoration:underline;}
span.hoenzb
	{mso-style-name:hoenzb;}
span.EmailStyle18
	{mso-style-type:personal-reply;
	font-family:"Calibri","sans-serif";
	color:#1F497D;}
.MsoChpDefault
	{mso-style-type:export-only;
	font-family:"Calibri","sans-serif";}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
--></style><!--[if gte mso 9]><xml>
<o:shapedefaults v:ext="edit" spidmax="1026" />
</xml><![endif]--><!--[if gte mso 9]><xml>
<o:shapelayout v:ext="edit">
<o:idmap v:ext="edit" data="1" />
</o:shapelayout></xml><![endif]--></head><body lang=EN-US link=blue vlink=purple><div class=WordSection1><p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>Yes, this was a bug with Open MPI 1.7.3.  I could not reproduce it, but it was definitely an issue in certain configurations.<o:p></o:p></span></p><p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>Here was the fix.</span>   <span style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>https://svn.open-mpi.org/trac/ompi/changeset/29762<o:p></o:p></span></p><p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>We fixed it in Open MPI 1.7.4 and the trunk version, so as you have seen, they do not have the problem.<o:p></o:p></span></p><p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>Rolf<o:p></o:p></span></p><p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'><o:p>&nbsp;</o:p></span></p><div style='border:none;border-left:solid blue 1.5pt;padding:0in 0in 0in 4.0pt'><div><div style='border:none;border-top:solid #B5C4DF 1.0pt;padding:3.0pt 0in 0in 0in'><p class=MsoNormal><b><span style='font-size:10.0pt;font-family:"Tahoma","sans-serif"'>From:</span></b><span style='font-size:10.0pt;font-family:"Tahoma","sans-serif"'> users [mailto:users-bounces@open-mpi.org] <b>On Behalf Of </b>Özgür Pekçagliyan<br><b>Sent:</b> Friday, December 13, 2013 8:03 AM<br><b>To:</b> users@open-mpi.org<br><b>Subject:</b> Re: [OMPI users] Cuda Aware MPI Problem<o:p></o:p></span></p></div></div><p class=MsoNormal><o:p>&nbsp;</o:p></p><div><p class=MsoNormal>Hello again,<br><br>I have compiled openmpi--1.9a1r29873 from nightly build trunk and so far everything looks alright. But I have not test the cuda support yet.<o:p></o:p></p></div><div><p class=MsoNormal style='margin-bottom:12.0pt'><o:p>&nbsp;</o:p></p><div><p class=MsoNormal>On Fri, Dec 13, 2013 at 2:38 PM, Özgür Pekçağlıyan &lt;<a href="mailto:ozgur.pekcagliyan@gmail.com" target="_blank">ozgur.pekcagliyan@gmail.com</a>&gt; wrote:<o:p></o:p></p><div><p class=MsoNormal>Hello,<br><br>I am having difficulties with compiling openMPI with CUDA support. I have followed this (<a href="http://www.open-mpi.org/faq/?category=building#build-cuda" target="_blank">http://www.open-mpi.org/faq/?category=building#build-cuda</a>) faq entry. As below;<br><br>$ cd openmpi-1.7.3/<o:p></o:p></p><div><p class=MsoNormal>$ ./configure --with-cuda=/urs/local/cuda-5.5<br>$ make all install<br><br>everything goes perfect during compilation. But when I try to execute simplest mpi hello world application I got following error;<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>$ mpicc hello.c -o hello<br>$ mpirun -np 2 hello<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><div><p class=MsoNormal>hello: symbol lookup error: /usr/local/lib/openmpi/mca_pml_ob1.so: undefined symbol: progress_one_cuda_htod_event<o:p></o:p></p></div><div><p class=MsoNormal>hello: symbol lookup error: /usr/local/lib/openmpi/mca_pml_ob1.so: undefined symbol: progress_one_cuda_htod_event<o:p></o:p></p></div><div><p class=MsoNormal>--------------------------------------------------------------------------<o:p></o:p></p></div><div><p class=MsoNormal>mpirun has exited due to process rank 0 with PID 30329 on<o:p></o:p></p></div><div><p class=MsoNormal>node cudalab1 exiting improperly. There are three reasons this could occur:<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>1. this process did not call &quot;init&quot; before exiting, but others in<o:p></o:p></p></div><div><p class=MsoNormal>the job did. This can cause a job to hang indefinitely while it waits<o:p></o:p></p></div><div><p class=MsoNormal>for all processes to call &quot;init&quot;. By rule, if one process calls &quot;init&quot;,<o:p></o:p></p></div><div><p class=MsoNormal>then ALL processes must call &quot;init&quot; prior to termination.<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>2. this process called &quot;init&quot;, but exited without calling &quot;finalize&quot;.<o:p></o:p></p></div><div><p class=MsoNormal>By rule, all processes that call &quot;init&quot; MUST call &quot;finalize&quot; prior to<o:p></o:p></p></div><div><p class=MsoNormal>exiting or it will be considered an &quot;abnormal termination&quot;<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>3. this process called &quot;MPI_Abort&quot; or &quot;orte_abort&quot; and the mca parameter<o:p></o:p></p></div><div><p class=MsoNormal>orte_create_session_dirs is set to false. In this case, the run-time cannot<o:p></o:p></p></div><div><p class=MsoNormal>detect that the abort call was an abnormal termination. Hence, the only<o:p></o:p></p></div><div><p class=MsoNormal>error message you will receive is this one.<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>This may have caused other processes in the application to be<o:p></o:p></p></div><div><p class=MsoNormal>terminated by signals sent by mpirun (as reported here).<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>You can avoid this message by specifying -quiet on the mpirun command line.<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>--------------------------------------------------------------------------<o:p></o:p></p></div></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>$ mpirun -np 1 hello<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p><div><p class=MsoNormal>hello: symbol lookup error: /usr/local/lib/openmpi/mca_pml_ob1.so: undefined symbol: progress_one_cuda_htod_event<o:p></o:p></p></div><div><p class=MsoNormal>--------------------------------------------------------------------------<o:p></o:p></p></div><div><p class=MsoNormal>mpirun has exited due to process rank 0 with PID 30327 on<o:p></o:p></p></div><div><p class=MsoNormal>node cudalab1 exiting improperly. There are three reasons this could occur:<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>1. this process did not call &quot;init&quot; before exiting, but others in<o:p></o:p></p></div><div><p class=MsoNormal>the job did. This can cause a job to hang indefinitely while it waits<o:p></o:p></p></div><div><p class=MsoNormal>for all processes to call &quot;init&quot;. By rule, if one process calls &quot;init&quot;,<o:p></o:p></p></div><div><p class=MsoNormal>then ALL processes must call &quot;init&quot; prior to termination.<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>2. this process called &quot;init&quot;, but exited without calling &quot;finalize&quot;.<o:p></o:p></p></div><div><p class=MsoNormal>By rule, all processes that call &quot;init&quot; MUST call &quot;finalize&quot; prior to<o:p></o:p></p></div><div><p class=MsoNormal>exiting or it will be considered an &quot;abnormal termination&quot;<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>3. this process called &quot;MPI_Abort&quot; or &quot;orte_abort&quot; and the mca parameter<o:p></o:p></p></div><div><p class=MsoNormal>orte_create_session_dirs is set to false. In this case, the run-time cannot<o:p></o:p></p></div><div><p class=MsoNormal>detect that the abort call was an abnormal termination. Hence, the only<o:p></o:p></p></div><div><p class=MsoNormal>error message you will receive is this one.<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>This may have caused other processes in the application to be<o:p></o:p></p></div><div><p class=MsoNormal>terminated by signals sent by mpirun (as reported here).<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>You can avoid this message by specifying -quiet on the mpirun command line.<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>--------------------------------------------------------------------------<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>Any suggestions?<o:p></o:p></p></div><p class=MsoNormal style='margin-bottom:12.0pt'>I have two PCs with Intel I3 CPUs and Geforce GTX 480 GPUs.<br><br><br>And here is the hello.c file;<o:p></o:p></p><div><p class=MsoNormal>#include &lt;stdio.h&gt;<o:p></o:p></p></div><div><p class=MsoNormal>#include &lt;mpi.h&gt;<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>int main (int argc, char **argv)<o:p></o:p></p></div><div><p class=MsoNormal>{<o:p></o:p></p></div><div><p class=MsoNormal>&nbsp; int rank, size;<o:p></o:p></p></div><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><div><p class=MsoNormal>&nbsp; MPI_Init (&amp;argc, &amp;argv); /* starts MPI */<o:p></o:p></p></div><div><p class=MsoNormal>&nbsp; MPI_Comm_rank (MPI_COMM_WORLD, &amp;rank); /* get current process id */<o:p></o:p></p></div><div><p class=MsoNormal>&nbsp; MPI_Comm_size (MPI_COMM_WORLD, &amp;size); /* get number of processes */<o:p></o:p></p></div><div><p class=MsoNormal>&nbsp; printf( &quot;Hello world from process %d of %d\n&quot;, rank, size );<o:p></o:p></p></div><div><p class=MsoNormal>&nbsp; MPI_Finalize();<o:p></o:p></p></div><div><p class=MsoNormal>&nbsp; return 0;<o:p></o:p></p></div><div><p class=MsoNormal>}<o:p></o:p></p></div><div><p class=MsoNormal><span style='color:#888888'><o:p>&nbsp;</o:p></span></p></div><p class=MsoNormal style='margin-bottom:12.0pt'><span class=hoenzb><o:p>&nbsp;</o:p></span></p><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><p class=MsoNormal><span class=hoenzb><span style='color:#888888'>-- </span><o:p></o:p></span></p><div><p class=MsoNormal><span style='color:#888888'>Özgür Pekçağlıyan</span><o:p></o:p></p><div><p class=MsoNormal><span style='color:#888888'>B.Sc. in Computer Engineering<o:p></o:p></span></p></div><div><p class=MsoNormal><span style='color:#888888'>M.Sc. in&nbsp;Computer Engineering<o:p></o:p></span></p></div></div></div></div></div><p class=MsoNormal><br><br clear=all><o:p></o:p></p><div><p class=MsoNormal><o:p>&nbsp;</o:p></p></div><p class=MsoNormal>-- <o:p></o:p></p><div><p class=MsoNormal>Özgür Pekçağlıyan<o:p></o:p></p><div><p class=MsoNormal>B.Sc. in Computer Engineering<o:p></o:p></p></div><div><p class=MsoNormal>M.Sc. in&nbsp;Computer Engineering<o:p></o:p></p></div></div></div></div></div>
<DIV>
<HR>
</DIV>
<DIV>This email message is for the sole use of the intended recipient(s) and may 
contain confidential information.&nbsp; Any unauthorized review, use, disclosure 
or distribution is prohibited.&nbsp; If you are not the intended recipient, 
please contact the sender by reply email and destroy all copies of the original 
message. </DIV>
<DIV>
<HR>
</DIV>
</body></html>