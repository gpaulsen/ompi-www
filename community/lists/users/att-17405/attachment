Hi,<br>I want to know if anybody is having problems with fault tolerant job using infiniband. When I run my job with tcp if anything happens with one node, my job keeps running, but if I change my job to use infiniband if anything happens with the infiniband (i.e cable problems) my job fails.<br>
<br>Anybody knows if there is something different that need to be done when using openib instead tcp?  <br><br>Bellow a example of the message I&#39;m receiving from the mpi.<br><br>Regards,<br>Guilherme<br><br>--------------------------------------------------------------------------                                                                                                <br>
The OpenFabrics stack has reported a network error event.  Open MPI                                                                                                       <br>will try to continue, but your job may end up failing.                                                                                                                    <br>
<br>  Local host:        XXXXX<br>  MPI process PID:   23341                         <br>  Error number:      10 (IBV_EVENT_PORT_ERR)       <br><br>This error may indicate connectivity problems within the fabric;<br>please contact your system administrator.                       <br>
--------------------------------------------------------------------------<br>[ZZZZ:23320] 15 more processes have sent help message help-mpi-btl-openib.txt / of error event<br>[WWW:23320] Set MCA parameter &quot;orte_base_help_aggregate&quot; to 0 to see all help / error messages<br>
[[4089,1],144][btl_openib_component.c:3227:handle_wc] from XXXXX to: YYYYY error polling LP CQ with status RETRY EXCEEDED ERROR status number 12 for wr_id 214283560 opcode 51  vendor error 129 qp_idx 3<br>[[4089,1],147][btl_openib_component.c:3227:handle_wc] from XXXXX to: YYYYY error polling LP CQ with status RETRY EXCEEDED ERROR status number 12 for wr_id 490884096 opcode 1  vendor error 129 qp_idx 0<br>
--------------------------------------------------------------------------<br>The InfiniBand retry count between two MPI processes has been<br>exceeded.  &quot;Retry count&quot; is defined in the InfiniBand spec 1.2<br>(section 12.7.38):<br>
<br>    The total number of times that the sender wishes the receiver to<br>    retry timeout, packet sequence, etc. errors before posting a<br>    completion error.<br><br>This error typically means that there is something awry within the<br>
InfiniBand fabric itself.  You should note the hosts on which this<br>error has occurred; it has been observed that rebooting or removing a<br>particular host from the job can sometimes resolve this issue.<br><br>Two MCA parameters can be used to control Open MPI&#39;s behavior with<br>
respect to the retry count:<br><br>* btl_openib_ib_retry_count - The number of times the sender will<br>  attempt to retry (defaulted to 7, the maximum value).<br>* btl_openib_ib_timeout - The local ACK timeout parameter (defaulted<br>
  to 10).  The actual timeout value used is calculated as:<br><br>     4.096 microseconds * (2^btl_openib_ib_timeout)<br><br>  See the InfiniBand spec 1.2 (section 12.7.34) for more details.<br><br>Below is some information about the host that raised the error and the<br>
peer to which it was connected:<br><br>  Local host:   XXXX<br>  Local device: mlx4_0<br>  Peer host:    YYYY<br><br>You may need to consult with your system administrator to get this<br>problem fixed.<br>--------------------------------------------------------------------------<br>
<br>

