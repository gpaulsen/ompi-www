<div dir="ltr"><div><div>Hi,<br><br></div>I am facing problem in running Open MPI using TCP (on 1G Ethernet). In practice the bandwidth must not exceed 1000 Mbps but for some data points (for point-to-point ping pong) it exceeds this limit. I checked with MPICH it works as desired. <br>

<br></div>Following is the command I issue to run my program on TCP. Am I missing something?<br><br><b>-bash-3.2$ mpirun -np 2  -machinefile machines -N 1 --mca btl tcp,self ./bandwidth.ompi </b><br>--------------------------------------------------------------------------<br>

The following command line options and corresponding MCA parameter have<br>been deprecated and replaced as follows:<br><br>  Command line options:<br>    Deprecated:  --npernode, -npernode<br>    Replacement: --map-by ppr:N:node<br>

<br>  Equivalent MCA parameter:<br>    Deprecated:  rmaps_base_n_pernode, rmaps_ppr_n_pernode<br>    Replacement: rmaps_base_mapping_policy=ppr:N:node<br><br>The deprecated forms *will* disappear in a future version of Open MPI.<br>

Please update to the new syntax.<br>--------------------------------------------------------------------------<br>Hello, world.  I am 1 on compute-0-16.local<br>Hello, world.  I am 0 on compute-0-15.local<br>1    25.66    0.30<br>

2    25.54    0.60<br>4    25.34    1.20<br>8    25.27    2.42<br>16    25.24    4.84<br>32    25.49    9.58<br>64    26.44    18.47<br>128    26.85    36.37<br>256    29.43    66.37<br>512    36.02    108.44<br>1024    42.03    185.86<br>

2048    194.30    80.42<br>4096    255.21    122.45<br>8192    258.85    241.45<br>16384    307.96    405.90<br>32768    422.78    591.32<br>65536    790.11    632.83<br>131072    1054.08    948.70<br><b>262144    1618.20    1235.94<br>

524288    3126.65    1279.33</b><br><br style="color:rgb(0,0,0)"><div><div><div><div><span style="color:rgb(0,0,0)">-Bibrak<br></span></div><div dir="ltr"><font color="#888888"></font></div></div>
</div></div></div>

