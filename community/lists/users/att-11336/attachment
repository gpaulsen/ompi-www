<br><br><div class="gmail_quote">On Tue, Dec 1, 2009 at 16:28, Abhishek Kulkarni <span dir="ltr">&lt;<a href="mailto:abbyzcool@gmail.com">abbyzcool@gmail.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">

<div class="im">On Tue, Dec 1, 2009 at 6:15 PM, Nicolas Bock &lt;<a href="mailto:nicolasbock@gmail.com">nicolasbock@gmail.com</a>&gt; wrote:<br>
&gt; After reading Anthony&#39;s question again, I am not sure now that we are having<br>
&gt; the same problem, but we might. In any case, the attached example programs<br>
&gt; trigger the issue of running out of pipes. I don&#39;t see how orted could, even<br>
&gt; if it was reused. There is only a very limited number of processes running<br>
&gt; at any given time. Once slave terminates, how would it still have open<br>
&gt; pipes? Shouldn&#39;t the total number of open files, or pipes, be very limited<br>
&gt; in this situation? And yet, after maybe 20 or so iterations in master.c,<br>
&gt; orted complains about running out of pipes.<br>
&gt;<br>
&gt; nick<br>
&gt;<br>
<br>
</div>What version of OMPI are you trying it with? I can easily run it up to more<br>
than 200 iterations.<br>
<br></blockquote><div><br>openmpi-1.3.3<br><br>Â <br></div><blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
Also, how many nodes are you running this on?<br>
<div class="im"><br></div></blockquote><div>This is on one node with 4 cores. I am using<br><br>mpirun -np 1<br><br></div></div><br>

