<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" xmlns="http://www.w3.org/TR/REC-html40">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="Generator" content="Microsoft Word 14 (filtered medium)">
<style><!--
/* Font Definitions */
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0in;
	margin-bottom:.0001pt;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-priority:99;
	color:purple;
	text-decoration:underline;}
span.EmailStyle17
	{mso-style-type:personal-compose;
	font-family:"Calibri","sans-serif";
	color:windowtext;}
.MsoChpDefault
	{mso-style-type:export-only;
	font-family:"Calibri","sans-serif";}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
--></style><!--[if gte mso 9]><xml>
<o:shapedefaults v:ext="edit" spidmax="1026" />
</xml><![endif]--><!--[if gte mso 9]><xml>
<o:shapelayout v:ext="edit">
<o:idmap v:ext="edit" data="1" />
</o:shapelayout></xml><![endif]-->
</head>
<body lang="EN-US" link="blue" vlink="purple">
<div class="WordSection1">
<p class="MsoNormal">My institute recently purchased a linux cluster with 20 nodes; 2 sockets per node; 6 cores per socket. OpenMPI v 1.8.1 is installed. I want to run 15 jobs. Each job requires 16 MPI processes. &nbsp;For each job, I want to use two cores on each
 node, mapping by socket. If I use these options:<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;">#PBS -l nodes=8:ppn=2<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;">mpirun --report-bindings --bind-to core --map-by socket:PE=1 -np 16 &lt;executable file name&gt;<o:p></o:p></span></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">The reported bindings are: <o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;">[burn001:09186] MCW rank 0 bound to socket 0[core 0[hwt 0]]: [B/././././.][./././././.]<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;">[burn001:09186] MCW rank 1 bound to socket 1[core 6[hwt 0]]: [./././././.][B/././././.]<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;">[burn004:07113] MCW rank 6 bound to socket 0[core 0[hwt 0]]: [B/././././.][./././././.]<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;">[burn004:07113] MCW rank 7 bound to socket 1[core 6[hwt 0]]: [./././././.][B/././././.]<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;">and so on&#8230;<o:p></o:p></span></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">These bindings appear to be OK, but when I do a &#8220;top &#8211;H&#8221; on each node, I see that all 15 jobs use core 0 and core 6 on each node. This means, I believe, that I am only using 1/6 or my resources. I want to use 100%. So I try this:<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;">#PBS -l nodes=8:ppn=2<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;">mpirun --report-bindings --bind-to socket --map-by socket:PE=1 -np 16 &lt;executable file name&gt;<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;"><o:p>&nbsp;</o:p></span></p>
<p class="MsoNormal">Now it appears that I am getting 100% usage of all cores on all nodes. The bindings are:<o:p></o:p></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;"><o:p>&nbsp;</o:p></span></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;">[burn004:07244] MCW rank 0 bound to socket 0[core 0[hwt 0]], socket 0[core 1[hwt 0]], socket 0[core 2[hwt 0]], socket 0[core 3[hwt 0]], socket 0[core 4[hwt 0]], socket 0[core 5[hwt 0]]: [B/B/B/B/B/B][./././././.]<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;">[burn004:07244] MCW rank 1 bound to socket 1[core 6[hwt 0]], socket 1[core 7[hwt 0]], socket 1[core 8[hwt 0]], socket 1[core 9[hwt 0]], socket 1[core 10[hwt 0]], socket 1[core 11[hwt 0]]: [./././././.][B/B/B/B/B/B]<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;">[burn008:07256] MCW rank 3 bound to socket 1[core 6[hwt 0]], socket 1[core 7[hwt 0]], socket 1[core 8[hwt 0]], socket 1[core 9[hwt 0]], socket 1[core 10[hwt 0]], socket 1[core 11[hwt 0]]: [./././././.][B/B/B/B/B/B]<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-family:&quot;Courier New&quot;">[burn008:07256] MCW rank 2 bound to socket 0[core 0[hwt 0]], socket 0[core 1[hwt 0]], socket 0[core 2[hwt 0]], socket 0[core 3[hwt 0]], socket 0[core 4[hwt 0]], socket 0[core 5[hwt 0]]: [B/B/B/B/B/B][./././././.]<o:p></o:p></span></p>
<p class="MsoNormal">and so on&#8230;<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">The problem now is that some of my jobs are hanging. They all start running fine, and produce output. But at some point I lose about 4 out of 15 jobs due to hanging. I suspect that an MPI message is passed and not received. The number of
 jobs that hang and the time when they hang varies from test to test. We have run these cases successfully on our old cluster dozens of times &#8211; they are part of our benchmark suite.
<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">When I run these jobs using a map by core strategy (that is, the MPI processes are just mapped by core, and each job only uses 16 cores on two nodes), I do not see as much hanging. It still occurs, but less often. This leads me to suspect
 that there is something about the increased network traffic due to the map-by-socket approach that is the cause of the problem. But I do not know what to do about it. I think that the map-by-socket approach is the right one, but I do not know if I have my
 OpenMPI options just right.<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">Can you tell me what OpenMPI options to use, and can you tell me how I might debug the hanging issue.<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">Kevin McGrattan<o:p></o:p></p>
<p class="MsoNormal">National Institute of Standards and Technology<o:p></o:p></p>
<p class="MsoNormal">100 Bureau Drive, Mail Stop 8664<o:p></o:p></p>
<p class="MsoNormal">Gaithersburg, Maryland 20899<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">301 975 2712<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
</body>
</html>

