<div dir="ltr"><br><div class="gmail_extra"><br><div class="gmail_quote">On Wed, Feb 10, 2016 at 8:44 AM, Peter Wind <span dir="ltr">&lt;<a href="mailto:peter.wind@met.no" target="_blank">peter.wind@met.no</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div><div style="font-family:arial,helvetica,sans-serif;font-size:12pt;color:#000000"><div>I agree that in practice the best practice would be to use Win_shared_query.<br></div><div><br></div><div>Still I am confused by this part in the documentation:<br></div><div>&quot;The allocated memory is contiguous across process ranks unless the info key <i>alloc_shared_noncontig</i> is specified. Contiguous across process ranks means that the first address in the memory segment of process i is consecutive with the last address in the memory segment of process i - 1. This may enable the user to calculate remote address offsets with local information only.&quot;</div><div><br></div><div>Isn&#39;t this an encouragement to use the pointer of Win_allocate_shared directly?<br></div><div><br></div></div></div></blockquote><div><br></div><div>No, it is not.  Win_allocate_shared only gives you the pointer to the portion of the allocation that is owned by the calling process.  If you want to access the whole slab, call Win_shared_query(..,rank=0,..) and use the resulting baseptr.</div><div><br></div><div>I attempted to modify your code to be more correct, but I don&#39;t know enough Fortran to get it right.  If you can parse C examples, I&#39;ll provide some of those.</div><div><br></div><div>Jeff</div><div> </div><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div><div style="font-family:arial,helvetica,sans-serif;font-size:12pt;color:#000000"><div></div><div>Peter<br></div><div><br></div><hr><blockquote style="border-left:2px solid #1010ff;margin-left:5px;padding-left:5px;color:#000;font-weight:normal;font-style:normal;text-decoration:none;font-family:Helvetica,Arial,sans-serif;font-size:12pt"><div><div class="h5"><div dir="ltr">I don&#39;t know about bulletproof, but Win_shared_query is the *only* valid way to get the addresses of memory in other processes associated with a window.<div><br></div><div>The default for Win_allocate_shared is contiguous memory, but it can and likely will be mapped differently into each process, in which case only relative offsets are transferrable.<br><div><br>Jeff<br><div><div class="gmail_extra"><br><div class="gmail_quote">On Wed, Feb 10, 2016 at 4:19 AM, Gilles Gouaillardet <span dir="ltr">&lt;<a href="mailto:gilles.gouaillardet@gmail.com" target="_blank">gilles.gouaillardet@gmail.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Peter,<div><br></div><div>The bulletproof way is to use MPI_Win_shared_query after MPI_Win_allocate_shared.</div><div>I do not know if current behavior is a bug or a feature...</div><div><br></div><div>Cheers,</div><div><br></div><div>Gilles<div><div><br><div><br></div>On Wednesday, February 10, 2016, Peter Wind &lt;<a href="mailto:peter.wind@met.no" target="_blank">peter.wind@met.no</a>&gt; wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Hi,<br>
<br>
Under fortran, MPI_Win_allocate_shared is called with a window size of zero for some processes.<br>
The output pointer is then not valid for these processes (null pointer).<br>
Did I understood this wrongly? shouldn&#39;t the pointers be contiguous, so that for a zero sized window, the pointer should point to the start of the segment of the next rank?<br>
The documentation explicitly specifies &quot;size = 0 is valid&quot;.<br>
<br>
Attached a small code, where rank=0 allocate a window of size zero. All the other ranks get valid pointers, except rank 0.<br>
<br>
Best regards,<br>
Peter<br>
_______________________________________________<br>
users mailing list<br>
<a>users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2016/02/28485.php" target="_blank">http://www.open-mpi.org/community/lists/users/2016/02/28485.php</a><br>
</blockquote></div></div></div>
<br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" rel="noreferrer" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2016/02/28493.php" rel="noreferrer" target="_blank">http://www.open-mpi.org/community/lists/users/2016/02/28493.php</a><br></blockquote></div><br><br clear="all"><div><br></div>-- <br><div>Jeff Hammond<br><a href="mailto:jeff.science@gmail.com" target="_blank">jeff.science@gmail.com</a><br><a href="http://jeffhammond.github.io/" target="_blank">http://jeffhammond.github.io/</a><br></div>
</div></div></div></div></div>
<br>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></div></div>Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2016/02/28496.php" target="_blank">http://www.open-mpi.org/community/lists/users/2016/02/28496.php</a></blockquote><div><br></div></div></div><br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" rel="noreferrer" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2016/02/28497.php" rel="noreferrer" target="_blank">http://www.open-mpi.org/community/lists/users/2016/02/28497.php</a><br></blockquote></div><br><br clear="all"><div><br></div>-- <br><div class="gmail_signature">Jeff Hammond<br><a href="mailto:jeff.science@gmail.com" target="_blank">jeff.science@gmail.com</a><br><a href="http://jeffhammond.github.io/" target="_blank">http://jeffhammond.github.io/</a></div>
</div></div>

