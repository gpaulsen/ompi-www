<html>
<head>
<style><!--
.hmmessage P
{
margin:0px;
padding:0px
}
body.hmmessage
{
font-size: 10pt;
font-family:Verdana
}
--></style>
</head>
<body class='hmmessage'>
Thanks a lot Gus for you help again. I only have one CPU per node. <br>The -n X option (no matter what the value of X is) shows X processes running on one node only (the other one is free).<br>If I add the machinefile option with WN1 and WN2 in it, the right behavior is manifested. According to the documentation,<br>mpirun should get the PBS_NODEFILE automatically from the PBS. So, I do not need to use machinefile.<br><br>Any ideas?<br><br>Thanks a lot in advance.<br>~Belaid. <br><br><br>&gt; Date: Tue, 1 Dec 2009 15:42:30 -0500<br>&gt; From: gus@ldeo.columbia.edu<br>&gt; To: users@open-mpi.org<br>&gt; Subject: Re: [OMPI users] mpirun is using one PBS node only<br>&gt; <br>&gt; Hi Belaid Moa<br>&gt; <br>&gt; Belaid MOA wrote:<br>&gt; &gt; Hi everyone,<br>&gt; &gt;  Here is another elementary question. I tried the following steps found <br>&gt; &gt; in the FAQ section of www.open-mpi.org with a simple hello world example <br>&gt; &gt; (with PBS/torque):<br>&gt; &gt;  $  qsub -l nodes=2 my_script.sh<br>&gt; &gt; <br>&gt; &gt; my_script.sh is pasted below:<br>&gt; &gt; ========================<br>&gt; &gt; #!/bin/sh -l<br>&gt; &gt; #PBS -N helloTest<br>&gt; &gt; #PBS -j eo<br>&gt; &gt; echo `cat $PBS_NODEFILE` # shows two nodes: WN1 WN2<br>&gt; &gt; cd $PBS_O_WORKDIR<br>&gt; &gt; /usr/local/bin/mpirun hello<br>&gt; &gt; ========================<br>&gt; &gt; <br>&gt; &gt; When the job is submitted, only one process is ran. When I add the -n 2 <br>&gt; &gt; option to the mpirun command,<br>&gt; &gt; two processes are ran but on one node only. <br>&gt; <br>&gt; Do you have a single CPU/core per node?<br>&gt; Or are they multi-socket/multi-core?<br>&gt; <br>&gt; Check "man mpiexec" for the options that control on which nodes and<br>&gt; slots, etc your program will run.<br>&gt; ("Man mpiexec" will tell you more than I possibly can.)<br>&gt; <br>&gt; The default option is "-byslot",<br>&gt; which will use all "slots" (actually cores<br>&gt; or CPUs) available on a node before it moves to the next node.<br>&gt; Reading your question and your surprise with the result,<br>&gt; I would guess what you want is "-bynode" (not the default).<br>&gt; <br>&gt; Also, if you have more than one CPU/core per node,<br>&gt; you need to put this information in your Torque/PBS "nodes" file<br>&gt; (and restart your pbs_server daemon).<br>&gt; Something like this (for 2 CPUs/cores per node):<br>&gt; <br>&gt; WN1 np=2<br>&gt; WN2 np=2<br>&gt; <br>&gt; I hope this helps,<br>&gt; Gus Correa<br>&gt; ---------------------------------------------------------------------<br>&gt; Gustavo Correa<br>&gt; Lamont-Doherty Earth Observatory - Columbia University<br>&gt; Palisades, NY, 10964-8000 - USA<br>&gt; ---------------------------------------------------------------------<br>&gt; <br>&gt; <br>&gt; &gt; Note that  echo `cat <br>&gt; &gt; $PBS_NODEFILE` outputs<br>&gt; &gt; the two nodes I am using: WN1 and WN2.<br>&gt; &gt; <br>&gt; &gt; The output from ompi_info is shown below:<br>&gt; &gt; <br>&gt; &gt; $ ompi_info | grep tm<br>&gt; &gt;               MCA memory: ptmalloc2 (MCA v2.0, API v2.0, Component v1.3.3)<br>&gt; &gt;                  MCA ras: tm (MCA v2.0, API v2.0, Component v1.3.3)<br>&gt; &gt;                  MCA plm: tm (MCA v2.0, API v2.0, Component v1.3.3)<br>&gt; &gt; <br>&gt; &gt;  Any help on why openMPI/mpirun is using only one PBS node is very <br>&gt; &gt; appreciated.<br>&gt; &gt; <br>&gt; &gt; Thanks a lot in advance and sorry for bothering you guys with my <br>&gt; &gt; elementary questions!<br>&gt; &gt; <br>&gt; &gt; ~Belaid. <br>&gt; &gt; <br>&gt; &gt; <br>&gt; &gt; <br>&gt; &gt; ------------------------------------------------------------------------<br>&gt; &gt; Windows Live: Keep your friends up to date with what you do online. <br>&gt; &gt; &lt;http://go.microsoft.com/?linkid=9691810&gt;<br>&gt; &gt; <br>&gt; &gt; <br>&gt; &gt; ------------------------------------------------------------------------<br>&gt; &gt; <br>&gt; &gt; _______________________________________________<br>&gt; &gt; users mailing list<br>&gt; &gt; users@open-mpi.org<br>&gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<br>&gt; <br>&gt; _______________________________________________<br>&gt; users mailing list<br>&gt; users@open-mpi.org<br>&gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<br> 		 	   		  <br /><hr />Windows Live: Keep your friends up to date <a href='http://go.microsoft.com/?linkid=9691810' target='_new'>with what you do online.</a></body>
</html>
