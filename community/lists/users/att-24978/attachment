<div dir="ltr"><div class="gmail_extra"><div class="gmail_quote">On Mon, Aug 11, 2014 at 10:41 AM, Rob Latham <span dir="ltr">&lt;<a href="mailto:robl@mcs.anl.gov" target="_blank">robl@mcs.anl.gov</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div class=""><br>
<br>
On 08/11/2014 08:54 AM, George Bosilca wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
The patch related to ticket #4597 is zapping only the datatypes where<br>
the user explicitly provided a zero count.<br>
<br>
We can argue about LB and UB, but I have a hard time understanding the<br>
rationale of allowing zero count only for LB and UB. If it is required<br>
by the standard we can easily support it (the line in the patch has to<br>
move a little down in the code).<br>
</blockquote>
<br></div>
ROMIO&#39;s type flattening code is primitive: the zero-length blocks for UB and LB were the only way to encode the extent of the type, without calling back into the MPI implementation&#39;s type-inquiry routines.<br>
<br>
<br>
*I* don&#39;t  care how OpenMPI deals with UB and LB.  It was *you* who suggested one might need to look a bit more closely at how OpenMPI type processing handles those markers:<br>
<br>
<a href="http://www.open-mpi.org/community/lists/users/2014/05/24325.php" target="_blank">http://www.open-mpi.org/<u></u>community/lists/users/2014/05/<u></u>24325.php</a></blockquote><div><br></div><div>I have absolutely no issue with this approach. I was basically trying to figure out if the ticket was closed too early or not.</div>
<div><br></div><div>  George.</div><div><br></div><div> </div><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><br>
<br>
==rob<br>
<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div class="">
<br>
   George.<br>
<br>
<br>
<br>
On Mon, Aug 11, 2014 at 9:44 AM, Rob Latham &lt;<a href="mailto:robl@mcs.anl.gov" target="_blank">robl@mcs.anl.gov</a><br></div><div class="">
&lt;mailto:<a href="mailto:robl@mcs.anl.gov" target="_blank">robl@mcs.anl.gov</a>&gt;&gt; wrote:<br>
<br>
<br>
<br>
    On 08/10/2014 07:32 PM, Mohamad Chaarawi wrote:<br>
<br>
        Update:<br>
<br>
        George suggested that I try with the 1.8.2 rc3 and that one<br>
        resolves the<br>
        hindexed_block segfault that I was seeing with ompi. the I/O<br>
        part now<br>
        works with ompio, but needs the patches from Rob in ROMIO to<br>
        work correctly.<br>
<br>
        The 2nd issue with collective I/O where some processes<br>
        participate with<br>
        0 sized datatypes created with hindexed and hvector, is still<br>
        unresolved.<br>
<br>
<br>
    I think this ticket was closed a bit too early:<br>
<br></div>
    <a href="https://svn.open-mpi.org/trac/__ompi/ticket/4597" target="_blank">https://svn.open-mpi.org/trac/<u></u>__ompi/ticket/4597</a><div class=""><br>
    &lt;<a href="https://svn.open-mpi.org/trac/ompi/ticket/4597" target="_blank">https://svn.open-mpi.org/<u></u>trac/ompi/ticket/4597</a>&gt;<br>
<br>
    I don&#39;t know OpenMPI&#39;s type processing at all, but if it&#39;s like<br>
    ROMIO, you cannot simply zap blocks of zero length:  some zero<br>
    length blocks indicate upper bound and lower bound.<br>
<br>
    or maybe it&#39;s totally unrelated.  There were a flurry of datatype<br>
    bugs reported against both MPICH and OpenMPI in may of this year and<br>
    I am sure I am confusing several issues.<br>
<br>
    ==rob<br>
<br>
<br>
        Thanks,<br>
        Mohamad<br>
<br>
        On 8/6/2014 11:50 AM, Mohamad Chaarawi wrote:<br>
<br>
            Hi all,<br>
<br>
            I&#39;m seeing some problems with dervided datatype construction<br>
            and I/O<br>
            with OpenMPI 1.8.1.<br>
<br>
            I have replicated them in the attached program.<br></div>
            The first issue is that MPI_Type_create_hindexed___<u></u>block()<div class=""><br>
            always<br>
            sefgaults. Usage of this routine is commented out in the<br>
            program. (I<br>
            have a separate email thread with George and Edgar about this).<br>
<br>
            The other issue is a segfault in MPI_File_set_view, when I<br>
            have ranks<br>
             &gt; 0 creating the derived datatypes with count 0, and rank 0<br>
            creating a<br>
            derived datatype of count NUM_BLOCKS. If I use<br>
            MPI_Type_contiguous to<br>
            create the 0 sized file and memory datatypes (instead of<br>
            hindexed and<br>
            hvector) it works fine.<br>
            To replicate, run the program with 2 or more procs:<br>
<br>
            mpirun -np 2 ./hindexed_io mpi_test_file<br>
<br>
            [jam:15566] *** Process received signal ***<br>
            [jam:15566] Signal: Segmentation fault (11)<br>
            [jam:15566] Signal code: Address not mapped (1)<br>
            [jam:15566] Failing at address: (nil)<br>
            [jam:15566] [ 0] [0xfcd440]<br>
            [jam:15566] [ 1]<br></div>
            /scr/chaarawi/install/ompi/__<u></u>lib/libmpi.so.1(ADIOI_Flatten_<u></u>__datatype+0x17a)[0xc80f2a]<br>
            [jam:15566] [ 2]<br>
            /scr/chaarawi/install/ompi/__<u></u>lib/libmpi.so.1(ADIO_Set_view+<u></u>__0x1c1)[0xc72a6d]<br>
            [jam:15566] [ 3]<br>
            /scr/chaarawi/install/ompi/__<u></u>lib/libmpi.so.1(mca_io_romio__<u></u>_dist_MPI_File_set_view+0x69b)<u></u>[__0xc8d11b]<br>
            [jam:15566] [ 4]<br>
            /scr/chaarawi/install/ompi/__<u></u>lib/libmpi.so.1(mca_io_romio__<u></u>_file_set_view+0x7c)[0xc4f7c5]<br>
            [jam:15566] [ 5]<br>
            /scr/chaarawi/install/ompi/__<u></u>lib/libmpi.so.1(PMPI_File_set_<u></u>__view+0x1e6)[0xb32f7e]<div class=""><br>
            [jam:15566] [ 6] ./hindexed_io[0x8048aa6]<br>
            [jam:15566] [ 7]<br></div>
            /lib/libc.so.6(__libc_start___<u></u>main+0xdc)[0x7d5ebc]<div class=""><br>
            [jam:15566] [ 8] ./hindexed_io[0x80487e1]<br>
            [jam:15566] *** End of error message ***<br>
<br>
            If I use --mca io ompio with 2 or more procs, the program<br>
            segfaults in<br>
            write_at_all (regardless of what routine is used to<br>
            construct a 0<br>
            sized datatype):<br>
<br>
            [jam:15687] *** Process received signal ***<br>
            [jam:15687] Signal: Floating point exception (8)<br>
            [jam:15687] Signal code: Integer divide-by-zero (1)<br>
            [jam:15687] Failing at address: 0x3e29b7<br>
            [jam:15687] [ 0] [0xe56440]<br>
            [jam:15687] [ 1]<br></div>
            /scr/chaarawi/install/ompi/__<u></u>lib/libmpi.so.1(ompi_io_ompio_<u></u>__set_explicit_offset+0x9d)[__<u></u>0x3513bc]<br>
            [jam:15687] [ 2]<br>
            /scr/chaarawi/install/ompi/__<u></u>lib/libmpi.so.1(ompio_io___<u></u>ompio_file_write_at_all+0x3e)[<u></u>__0x35869a]<br>
            [jam:15687] [ 3]<br>
            /scr/chaarawi/install/ompi/__<u></u>lib/libmpi.so.1(mca_io_ompio__<u></u>_file_write_at_all+0x66)[__<u></u>0x358650]<br>
            [jam:15687] [ 4]<br>
            /scr/chaarawi/install/ompi/__<u></u>lib/libmpi.so.1(MPI_File___<u></u>write_at_all+0x1b3)[0x1f46f3]<div class=""><br>
            [jam:15687] [ 5] ./hindexed_io[0x8048b07]<br>
            [jam:15687] [ 6]<br></div>
            /lib/libc.so.6(__libc_start___<u></u>main+0xdc)[0x7d5ebc]<div class=""><br>
            [jam:15687] [ 7] ./hindexed_io[0x80487e1]<br>
            [jam:15687] *** End of error message ***<br>
<br>
            If I use mpich 3.1.2 , I don&#39;t see those issues.<br>
<br>
            Thanks,<br>
            Mohamad<br>
<br>
<br></div>
            ______________________________<u></u>___________________<br>
            users mailing list<br>
            <a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a> &lt;mailto:<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a>&gt;<br>
            Subscription:<a href="http://www.open-__mpi.org/mailman/listinfo.cgi/__users" target="_blank">http://www.open-_<u></u>_mpi.org/mailman/listinfo.cgi/<u></u>__users</a><div class=""><br>
            &lt;<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/<u></u>mailman/listinfo.cgi/users</a>&gt;<br>
            Link to this<br></div>
            post:<a href="http://www.open-mpi.org/__community/lists/users/2014/08/__24931.php" target="_blank">http://www.open-mpi.org/_<u></u>_community/lists/users/2014/<u></u>08/__24931.php</a><br>
            &lt;<a href="http://www.open-mpi.org/community/lists/users/2014/08/24931.php" target="_blank">http://www.open-mpi.org/<u></u>community/lists/users/2014/08/<u></u>24931.php</a>&gt;<br>
<br>
<br>
<br>
<br>
        ______________________________<u></u>___________________<br>
        users mailing list<br>
        <a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a> &lt;mailto:<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a>&gt;<br>
        Subscription:<br>
        <a href="http://www.open-mpi.org/__mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/__<u></u>mailman/listinfo.cgi/users</a><div class=""><br>
        &lt;<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/<u></u>mailman/listinfo.cgi/users</a>&gt;<br>
        Link to this post:<br></div>
        <a href="http://www.open-mpi.org/__community/lists/users/2014/08/__24963.php" target="_blank">http://www.open-mpi.org/__<u></u>community/lists/users/2014/08/<u></u>__24963.php</a><div class=""><br>
        &lt;<a href="http://www.open-mpi.org/community/lists/users/2014/08/24963.php" target="_blank">http://www.open-mpi.org/<u></u>community/lists/users/2014/08/<u></u>24963.php</a>&gt;<br>
<br>
<br>
    --<br>
    Rob Latham<br>
    Mathematics and Computer Science Division<br>
    Argonne National Lab, IL USA<br></div>
    ______________________________<u></u>___________________<br>
    users mailing list<br>
    <a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a> &lt;mailto:<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a>&gt;<br>
    Subscription: <a href="http://www.open-mpi.org/__mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/__<u></u>mailman/listinfo.cgi/users</a><div class=""><br>
    &lt;<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/<u></u>mailman/listinfo.cgi/users</a>&gt;<br>
    Link to this post:<br></div>
    <a href="http://www.open-mpi.org/__community/lists/users/2014/08/__24971.php" target="_blank">http://www.open-mpi.org/__<u></u>community/lists/users/2014/08/<u></u>__24971.php</a><br>
    &lt;<a href="http://www.open-mpi.org/community/lists/users/2014/08/24971.php" target="_blank">http://www.open-mpi.org/<u></u>community/lists/users/2014/08/<u></u>24971.php</a>&gt;<div class=""><br>
<br>
<br>
<br>
<br>
______________________________<u></u>_________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/<u></u>mailman/listinfo.cgi/users</a><br></div>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/08/24973.php" target="_blank">http://www.open-mpi.org/<u></u>community/lists/users/2014/08/<u></u>24973.php</a><br>
<br>
</blockquote><div class="">
<br>
-- <br>
Rob Latham<br>
Mathematics and Computer Science Division<br>
Argonne National Lab, IL USA<br>
______________________________<u></u>_________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/<u></u>mailman/listinfo.cgi/users</a><br></div>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/08/24974.php" target="_blank">http://www.open-mpi.org/<u></u>community/lists/users/2014/08/<u></u>24974.php</a><br>
</blockquote></div><br></div></div>

