<table cellspacing="0" cellpadding="0" border="0" ><tr><td valign="top" style="font: inherit;">Got it. &nbsp;&nbsp;Building a new openMPI solved it.<br><div><br></div><div>I don't know if the standard Ubuntu install was the problem or if it just didn't like the slightly later kernel.</div><div><br></div><div>Seems to be reason to be suspicious of Ubuntu 10.10 OpenMPI builds if you have anything unusual in your system.</div><div><br></div><div>Thanks.</div><div><br>--- On <b>Tue, 12/7/11, Jeff Squyres <i>&lt;jsquyres@cisco.com&gt;</i></b> wrote:<br><blockquote style="border-left: 2px solid rgb(16, 16, 255); margin-left: 5px; padding-left: 5px;"><br>From: Jeff Squyres &lt;jsquyres@cisco.com&gt;<br>Subject: Re: [OMPI users] Mpirun only works when n&lt; 3<br>To: randolph_pullen@yahoo.com.au<br>Cc: "Open MPI Users" &lt;users@open-mpi.org&gt;<br>Received: Tuesday, 12 July, 2011, 10:29 PM<br><br><div class="plainMail">On Jul 11, 2011, at 11:31 AM, Randolph
 Pullen wrote:<br><br>&gt; There are no firewalls by default.&nbsp; I can ssh between both nodes without a password so I assumed that all is good with the comms.<br><br>FWIW, ssh'ing is different than "comms" (which I assume you mean opening random TCP sockets between two servers).<br><br>&gt; I can also get both nodes to participate in the ring program at the same time.<br>&gt; Its just that I am limited to inly 2 processes if they are split between the nodes<br>&gt; ie:<br>&gt; mpirun -H A,B ring&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;(works)<br>&gt; mpirun -H A,A,A,A,A,A,A&nbsp; ring&nbsp; &nbsp;&nbsp;&nbsp;(works)<br>&gt; mpirun -H B,B,B,B ring&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;(works)<br>&gt; mpirun -H A,B,A&nbsp; ring&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (hangs)<br><br>It is odd that A,B works and A,B,A does not.<br><br>&gt; I have
 discovered slightly more information:<br>&gt; When I replace node 'B' from the new cluster with node 'C' from the old cluster<br>&gt; I get the similar behavior but with an error message:<br>&gt; mpirun -H A,A,A,A,A,A,A&nbsp; ring&nbsp; &nbsp;&nbsp;&nbsp;(works from either node)<br>&gt; mpirun -H C,C,C&nbsp; ring&nbsp; &nbsp;&nbsp;&nbsp;(works from either node)<br>&gt; mpirun -H A,C&nbsp; ring&nbsp; &nbsp;&nbsp;&nbsp;(Fails from either node:)<br>&gt; Process 0 sending 10 to 1, tag 201 (3 processes in ring)<br>&gt; [C:23465] ***&nbsp; An error occurred in MPI_Recv<br>&gt; [C:23465] ***&nbsp; on communicator MPI_COMM_WORLD<br>&gt; [C:23465] ***&nbsp; MPI_ERRORS_ARE FATAL (your job will now abort)<br>&gt; Process 0 sent to 1<br>&gt; ----------------------------------<br>&gt; Running this on either node A or C produces the same result<br>&gt; Node C runs openMPI 1.4.1 and is an ordinary dual core on FC10 , not an i5 2400 like the others.<br>&gt; all the
 binaries are compiled on FC10 with gcc 4.3.2<br><br><br>Are you sure that all the versions of Open MPI being used on all nodes are exactly the same?&nbsp; I.e., are you finding/using Open MPI v1.4.1 on all nodes?<br><br>Are the nodes homogeneous in terms of software?&nbsp; If they're heterogeneous in terms of hardware, you *might* need to have separate OMPI installations on each machine (vs., for example, a network-filesystem-based install shared to all 3) because the compiler's optimizer may produce code tailored for one of the machines, and it may therefore fail in unexpected ways on the other(s).&nbsp; The same is true for your executable.<br><br>See this FAQ entry about heterogeneous setups:<br><br>&nbsp; &nbsp; <a href="http://www.open-mpi.org/faq/?category=building#where-to-install" target="_blank">http://www.open-mpi.org/faq/?category=building#where-to-install</a><br><br>...hmm.&nbsp; I could have sworn we had more on the FAQ about heterogeneity,
 but perhaps not.&nbsp; The old LAM/MPI FAQ on heterogeneity is somewhat outdated, but most of its concepts are directly relevant to Open MPI as well:<br><br>&nbsp; &nbsp; <a href="http://www.lam-mpi.org/faq/category11.php3" target="_blank">http://www.lam-mpi.org/faq/category11.php3</a><br><br>I should probably copy most of that LAM/MPI heterogeneous FAQ to the Open MPI FAQ, but it'll be waaay down on my priority list.&nbsp; :-(&nbsp; If anyone could help out here, I'd be happy to point them in the right direction to convert the LAM/MPI FAQ PHP to Open MPI FAQ PHP...&nbsp; <br><br>To be clear: the PHP conversion will be pretty trivial; I stole heavily from the LAM/MPI FAQ PHP to create the Open MPI FAQ PHP -- but there are points where the LAM/MPI heterogeneity text needs to be updated; that'll take an hour or two to update all that content.<br><br>-- <br>Jeff Squyres<br><a ymailto="mailto:jsquyres@cisco.com"
 href="/mc/compose?to=jsquyres@cisco.com">jsquyres@cisco.com</a><br>For corporate legal information go to:<br><a href="http://www.cisco.com/web/about/doing_business/legal/cri/" target="_blank">http://www.cisco.com/web/about/doing_business/legal/cri/</a><br><br></div></blockquote></div></td></tr></table>
