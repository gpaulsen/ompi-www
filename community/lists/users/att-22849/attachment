<html><head><meta http-equiv="Content-Type" content="text/html charset=iso-8859-1"></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;">It's the same situation as with any of the bindings - we don't really support it at this time. All the bindings ultimately funnel down into the C implementation, so when that becomes fully thread safe, then so will the rest of the bindings.<div><br></div><div><br><div><div>On Oct 26, 2013, at 6:39 PM, Saliya Ekanayake &lt;<a href="mailto:esaliya@gmail.com">esaliya@gmail.com</a>&gt; wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><div dir="ltr">Hi,<div><br></div><div>Since this is a conversation on thread support, I have a quick related question. Is&nbsp;<span style="font-family:arial,sans-serif;font-size:13px">MPI_THREAD_MULTIPLE supported with OpenMPI's Java binding?</span></div>
<div><span style="font-family:arial,sans-serif;font-size:13px"><br></span></div><div><span style="font-family:arial,sans-serif;font-size:13px">Thank you,<br>Saliya</span></div></div><div class="gmail_extra"><br><br><div class="gmail_quote">
On Wed, Oct 23, 2013 at 2:40 PM, Jeff Hammond <span dir="ltr">&lt;<a href="mailto:jeff.science@gmail.com" target="_blank">jeff.science@gmail.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
And in practice the difference between FUNNELED and SERIALIZED will be<br>
very small. &nbsp;The differences might emerge from thread-local state and<br>
thread-specific network registration, but I don't see this being<br>
required. &nbsp;Hence, for most purposes SINGLE=FUNNELED=SERIALIZED is<br>
equivalent to NOMUTEX and MULTIPLE is MUTEX, where MUTEX refers to the<br>
internal mutex required to make MPI reentrant.<br>
<span class="HOEnZb"><font color="#888888"><br>
Jeff<br>
</font></span><div class="HOEnZb"><div class="h5"><br>
On Wed, Oct 23, 2013 at 1:18 PM, Tim Prince &lt;<a href="mailto:n8tm@aol.com">n8tm@aol.com</a>&gt; wrote:<br>
&gt; On 10/23/2013 01:02 PM, Barrett, Brian W wrote:<br>
&gt;<br>
&gt; On 10/22/13 10:23 AM, "Jai Dayal" &lt;<a href="mailto:dayalsoap@gmail.com">dayalsoap@gmail.com</a>&gt; wrote:<br>
&gt;<br>
&gt; I, for the life of me, can't understand the difference between these two<br>
&gt; init_thread modes.<br>
&gt;<br>
&gt; MPI_THREAD_SINGLE states that "only one thread will execute", but<br>
&gt; MPI_THREAD_FUNNELED states "The process may be multi-threaded, but only the<br>
&gt; main thread will make MPI calls (all MPI calls are funneled to the main<br>
&gt; thread)."<br>
&gt;<br>
&gt; If I use MPI_THREAD_SINGLE, and just create a bunch of pthreads that dumbly<br>
&gt; loop in the background, the MPI library will have no way of detecting this,<br>
&gt; nor should this have any affects on the machine.<br>
&gt;<br>
&gt; This is exactly the same as MPI_THREAD_FUNNELED. What exactly does it mean<br>
&gt; with "only one thread will execute?" The openmpi library has absolutely zero<br>
&gt; way of knowng I've spawned other pthreads, and since these pthreads aren't<br>
&gt; actually doing MPI communication, I fail to see how this would interfere.<br>
&gt;<br>
&gt;<br>
&gt; Technically, if you call MPI_INIT_THREAD with MPI_THREAD_SINGLE, you have<br>
&gt; made a promise that you will not create any other threads in your<br>
&gt; application. &nbsp;There was a time where OSes shipped threaded and non-threaded<br>
&gt; malloc, for example, so knowing that might be important for that last bit of<br>
&gt; performance. &nbsp;There are also some obscure corner cases of the memory model<br>
&gt; of some architectures where you might get unexpected results if you made an<br>
&gt; MPI Receive call in an thread and accessed that buffer later from another<br>
&gt; thread, which may require memory barriers inside the implementation, so<br>
&gt; there could be some differences between SINGLE and FUNNELED due to those<br>
&gt; barriers.<br>
&gt;<br>
&gt; In Open MPI, we'll handle those corner cases whether you init for SINGLE or<br>
&gt; FUNNELED, so there's really no practical difference for Open MPI, but you're<br>
&gt; then slightly less portable.<br>
&gt;<br>
&gt; I'm asking because I'm using an open_mpi build ontop of infiniband, and the<br>
&gt; maximum thread mode is MPI_THREAD_SINGLE.<br>
&gt;<br>
&gt;<br>
&gt; That doesn't seem right; which version of Open MPI are you using?<br>
&gt;<br>
&gt; Brian<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; As Brian said, you aren't likely to be running on a system like Windows 98<br>
&gt; where non-thread-safe libraries were preferred. &nbsp;My colleagues at NASA<br>
&gt; insist that any properly built MPI will support MPI_THREAD_FUNNELED by<br>
&gt; default, even when the documentation says explicit setting in<br>
&gt; MPI_Init_thread() is mandatory. &nbsp;The statement which I see in OpenMPI doc<br>
&gt; says all MPI calls must be made by the thread which calls MPI_Init_thread.<br>
&gt; Apparently it will work if plain MPI_Init is used instead. &nbsp;This theory<br>
&gt; appears to hold up for all the MPI implementations of interest. &nbsp;The<br>
&gt; additional threads referred to are "inside the MPI rank," although I suppose<br>
&gt; additional application threads not involved with MPI are possible.<br>
&gt;<br>
&gt;<br>
</div></div><div class="HOEnZb"><div class="h5">&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
<br>
<br>
--<br>
Jeff Hammond<br>
<a href="mailto:jeff.science@gmail.com">jeff.science@gmail.com</a><br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</div></div></blockquote></div><br><br clear="all"><div><br></div>-- <br><div dir="ltr"><span style="color:rgb(136,136,136)">Saliya Ekanayake <a href="mailto:esaliya@gmail.com" target="_blank">esaliya@gmail.com</a></span><span style="color:rgb(136,136,136)">&nbsp;</span><br style="color:rgb(136,136,136)">
<span style="color:rgb(136,136,136)">Cell 812-391-4914 Home 812-961-6383</span><br style="color:rgb(136,136,136)"><font color="#888888"><a href="http://saliya.org/" target="_blank">http://saliya.org</a></font></div>
</div>
_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>http://www.open-mpi.org/mailman/listinfo.cgi/users</blockquote></div><br></div></body></html>
