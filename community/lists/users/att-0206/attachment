<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type">
  <title></title>
</head>
<body bgcolor="#ffffff" text="#000000">
<pre wrap=""><div class="moz-txt-sig">Message: 2
Date: Tue, 18 Oct 2005 08:48:45 -0600
From: "Tim S. Woodall" <a class="moz-txt-link-rfc2396E"
 href="mailto:twoodall@lanl.gov">&lt;twoodall@lanl.gov&gt;</a>
Subject: Re: [O-MPI users] Hpl Bench mark and Openmpi rc3 (Jeff
	Squyres)
To: Open MPI Users <a class="moz-txt-link-rfc2396E"
 href="mailto:users@open-mpi.org">&lt;users@open-mpi.org&gt;</a>
Message-ID: <a class="moz-txt-link-rfc2396E"
 href="mailto:43550B4D.6080509@lanl.gov">&lt;43550B4D.6080509@lanl.gov&gt;</a>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

</div></pre>
<blockquote type="cite">
  <pre wrap=""><span class="moz-txt-citetags">&gt; </span>
<span class="moz-txt-citetags">&gt; </span>Hi Jeff,
<span class="moz-txt-citetags">&gt; </span>   I installed two versions of open mpi slightly different. One on 
<span class="moz-txt-citetags">&gt; </span>/opt/openmpi or I would get the gfortran error and the other in 
<span class="moz-txt-citetags">&gt; </span>/home/allan/openmpi
<span class="moz-txt-citetags">&gt; </span>However I do not think that is the problem as the path names are 
<span class="moz-txt-citetags">&gt; </span>specified in the bahrc and bash_profile files of the /home/allan directory.
<span class="moz-txt-citetags">&gt; </span>I also log into user allan who is not a superuser.On running the open 
<span class="moz-txt-citetags">&gt; </span>mpi with HPL I use the following command line:
<span class="moz-txt-citetags">&gt; </span>a1&gt; mpirun -mca pls_rsh_orted /home/allan/openmpi/bin/orted -hostfile aa 
<span class="moz-txt-citetags">&gt; </span>-np 16 ./xhpl
<span class="moz-txt-citetags">&gt; </span>from the directory where xhpl resides such as /homer/open/bench and I 
<span class="moz-txt-citetags">&gt; </span>use the -mca command pls_rsh_orted as it otherwise comes up with an 
<span class="moz-txt-citetags">&gt; </span>error that it cannot find the ORTED daemon on machines a1, a2 etc. That 
<span class="moz-txt-citetags">&gt; </span>is probaly aconfiguration error. However the commands above and the 
<span class="moz-txt-citetags">&gt; </span>setup described works fine and there are no errors in the HPL.out file, 
<span class="moz-txt-citetags">&gt; </span>except that it is slow.
<span class="moz-txt-citetags">&gt; </span>I use an atlas BLAS library for creating xhpl from hpl.tar.gz. The make 
<span class="moz-txt-citetags">&gt; </span>file for hpl uses the atlas libs and the open mpi mpicc compiler for 
<span class="moz-txt-citetags">&gt; </span>both compilation and linking. and I have zeroed out the MPI macro paths 
<span class="moz-txt-citetags">&gt; </span>in Make.open(that's what I reanmed the hpl makefile) for make arch=open 
<span class="moz-txt-citetags">&gt; </span>in hpl directory. Please find attached the ompi_info -all file as 
<span class="moz-txt-citetags">&gt; </span>requested. Thank you very much:
<span class="moz-txt-citetags">&gt; </span>Allan
<span class="moz-txt-citetags">&gt; </span>
<span class="moz-txt-citetags">&gt; </span>
  </pre>
</blockquote>
<pre wrap=""><!---->
We've done linpack runs recently w/ Infiniband, which result in performance
comparable to mvapich, but not w/ the tcp port. Can you try running w/ an
earlier version, specify on the command line:

-mca pml teg

I'm interested in seeing if there is any performance difference.

Thanks,
Tim


------------------------------

_______________________________________________
users mailing list
<a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
<a class="moz-txt-link-freetext"
 href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>

End of users Digest, Vol 112, Issue 1
*************************************

Hi Tim,
  I tried the same cluster (16 node x86) with the switches -mca pml teg and I get good performance of 24.52Gflops at N=22500
and Block size NB=120.
My command line now looks like :
a1&gt; mpirun -mca pls_rsh_orted /home/allan/openmpi/bin/orted -mca pml teg -hostile aa -np 16 ./xhpl
hostfile = aa, containing the addresses of the 16 machines.
I am using a GS116 16 port netgear Gigabit ethernet switch with Gnet realtek gig ethernet cards
Why, PLEASE, do these switches pml teg make such a difference? It's 2.6 times more performance in GFlops than what I was getting without them.
I tried version rc3 and not an earlier version.
Thank you very much for your assistance!
Best wishes
Allan
</pre>
</body>
</html>

