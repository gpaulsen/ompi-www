Hi,<br>I haven&#39;t used the more mpi process also but still am still unable to reduce my exection time.Here is my code <u><span style="color:rgb(153,0,0)"><a href="http://seshendramln.blogspot.se/">http://seshendramln.blogspot.se/</a></span></u>  <br>
and please help me in solving.  <br>In this code iam getting the same execution time in i increase or decrease the no.of nodes.<br><br>thanking you<br><br><br>With regards <br>seshendra<br><br><br><div class="gmail_quote">
On Fri, May 4, 2012 at 12:55 PM, Jeff Squyres <span dir="ltr">&lt;<a href="mailto:jsquyres@cisco.com" target="_blank">jsquyres@cisco.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
You probably need to be more fine-grained in your timing.  Find out exactly what is increasing in time.  This is a common symptom for codes that do not scale well -- i.e., adding more MPI processes actually causes it to slow down.<br>

<div class="HOEnZb"><div class="h5"><br>
<br>
On May 3, 2012, at 7:48 AM, seshendra seshu wrote:<br>
<br>
&gt; Hi,<br>
&gt; I have written an parallel program and when i run my program on 4,8,16 nodes and calculated the execution time at master using MPI_Wtime in master node. The problem the execution time is increasing rapidly like NON parallel program-55 sec, and for parallel program 2-nodes--60sec , 4-nodes 74sec, 8-node--120 sec and for 16 nodes---for 180 sec. can i know my problem in parallel version actually the time needs to be decreased but it is increasing i dont the reason. i have calculated my time as shown below<br>

&gt;<br>
&gt;<br>
&gt; main(argv,argc)<br>
&gt; {<br>
&gt; double start,end;<br>
&gt; start= MPI_Wtime;<br>
&gt; // done some work<br>
&gt; {<br>
&gt; // start send from master node and receiving it<br>
&gt; end =MPI_Wtime;<br>
&gt; cout&lt;&lt;&quot;execution time&quot;&lt;&lt;end-start;<br>
&gt; }<br>
&gt; //in slave nodes done some work<br>
&gt;  MPI_Finalize;<br>
&gt; }<br>
&gt;<br>
&gt; Please help me in solving this problem.<br>
&gt;<br>
&gt; --<br>
&gt;  WITH REGARDS<br>
&gt; M.L.N.Seshendra<br>
</div></div><div class="HOEnZb"><div class="h5">&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
<br>
--<br>
Jeff Squyres<br>
<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a><br>
For corporate legal information go to: <a href="http://www.cisco.com/web/about/doing_business/legal/cri/" target="_blank">http://www.cisco.com/web/about/doing_business/legal/cri/</a><br>
<br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</div></div></blockquote></div><br><br clear="all"><br>-- <br> WITH REGARDS<br>M.L.N.Seshendra<br>

