<html><head><meta http-equiv=Content-Type content="text/html; charset=iso-8859-1"><META name="Author" content="Novell GroupWise WebAccess"></head><body style='font-family: Tahoma, sans-serif; font-size: 13px; '><br><br>&gt;&gt;&gt; Ralph Castain <rhc@open-mpi.org> 11/17/09 4:04 PM &gt;&gt;&gt;<br>
&gt;Your cmd line is telling OMPI to run 17 processes. Since your hostfile indicates that only 16 of them are to &gt;run on 10.4.23.107 (which I assume is your PS3 node?), 1 process is going to be run on 10.4.1.23 (I assume &gt;this is node1?).<br>node1 has 16 Cores (4 x AMD Quad Core Processors)<br><br>node2 is the ps3 with two processors (slots)<br><div><br></div><div>&gt;I would guess that the executable is compiled to run on the PS3 given your specified path, so I would &gt;expect it to bomb on node1 - which is exactly what appears to be happening.</div><div>the executable is compiled on each node separately and lies at each node in the same directory<br> /mnt/projects/PS3Cluster/Benchmark/pi<br>on each node different directories are mounted. so there exists a separate executable file compiled at each node.<br><br>in the end i want to ran R on this cluster with Rmpi - as i get a similar problem there i rist wanted to try with an c programm.<br><br>with r happens the same thing it works when i start it on each node but if i want to start more than 16 processes on node one in exits.<br><br></div><div><br><div><div>On Nov 17, 2009, at 1:59 AM, Laurin Müller wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><div style="margin: 4px 4px 1px; font-family: Tahoma; font-style: normal; font-variant: normal; font-weight: normal; font-size: 10pt; line-height: normal; font-size-adjust: none; font-stretch: normal;">
<div>Hi,</div>
<div>&nbsp;</div>
<div>i want to build a cluster with openmpi.</div>
<div>&nbsp;</div>
<div>2 nodes:</div>
<div>node 1: 4 x Amd Quad Core, ubuntu 9.04, openmpi 1.3.2</div>
<div>node 2: Sony PS3, ubuntu 9.04, openmpi 1.3</div>
<div>&nbsp;</div>
<div>both can connect with ssh to each other and to itself without passwd.</div>
<div>&nbsp;</div>
<div>I can run the sample proramm pi.c on both nodes seperatly (see below). But if i try to start it on node1 with --hostfile option to use node 2 "remote" i got this error:</div>
<div>&nbsp;</div>
<div><a href="mailto:cluster@bioclust:%7E$">cluster@bioclust:~$</a> mpirun --hostfile /etc/openmpi/openmpi-default-hostfile -np 17 /mnt/projects/PS3Cluster/Benchmark/pi<br>--------------------------------------------------------------------------<br>mpirun noticed that the job aborted, but has no info as to the process<br>that caused that situation.<br>--------------------------------------------------------------------------<br></div>
<div>my hostfile:</div>
<div><a href="mailto:cluster@bioclust:%7E$">cluster@bioclust:~$</a> cat /etc/openmpi/openmpi-default-hostfile</div>
<div>10.4.23.107 slots=16<br>10.4.1.23 slots=2<br></div>
<div>i can see with top that the processors of node2 begin to work shortly, then it apports on node1.</div>
<div>&nbsp;</div>
<div>I use this sample/test program:</div>
<div>#include &lt;stdio.h&gt;<br>#include &lt;stdlib.h&gt;</div>
<div>#include "mpi.h"</div>
<div>int main(int argc, char *argv[])<br>{<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int&nbsp;&nbsp;&nbsp; i, n;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double h, pi, x;</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int&nbsp;&nbsp;&nbsp; me, nprocs;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; double piece;</div>
<div>/* --------------------------------------------------- */</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Init (&amp;argc, &amp;argv);</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Comm_size (MPI_COMM_WORLD, &amp;nprocs);<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Comm_rank (MPI_COMM_WORLD, &amp;me);</div>
<div>/* --------------------------------------------------- */</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (me == 0)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; printf("%s", "Input number of intervals:\n");<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; scanf ("%d", &amp;n);<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</div>
<div>/* --------------------------------------------------- */</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Bcast (&amp;n, 1, MPI_INT, 0, MPI_COMM_WORLD);</div>
<div>/* --------------------------------------------------- */</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; h&nbsp;&nbsp;&nbsp;&nbsp; = 1. / (double) n;</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; piece = 0.;</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (i=me+1; i &lt;= n; i+=nprocs)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x&nbsp;&nbsp;&nbsp;&nbsp; = (i-1)*h;</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; piece = piece + ( 4/(1+(x)*(x)) + 4/(1+(x+h)*(x+h))) / 2 * h;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; printf("%d: pi = %25.15f\n", me, piece);</div>
<div>/* --------------------------------------------------- */</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Reduce (&amp;piece, &amp;pi, 1, MPI_DOUBLE,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_SUM, 0, MPI_COMM_WORLD);</div>
<div>/* --------------------------------------------------- */</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (me == 0)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; printf("pi = %25.15f\n", pi);<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</div>
<div>/* --------------------------------------------------- */</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp; MPI_Finalize();</div>
<div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return 0;<br>}<br></div>
<div>it works on each node.</div>
<div>node1:</div>
<div><a href="mailto:cluster@bioclust:%7E$">cluster@bioclust:~$</a> mpirun -np 4 /mnt/projects/PS3Cluster/Benchmark/piInput number of intervals:<br>20<br>0: pi =&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.822248040052981<br>2: pi =&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.773339953424083<br>3: pi =&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.747089984650041<br>1: pi =&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.798498008827023<br>pi =&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.141175986954128</div>
<div>&nbsp;</div>
<div>node2:</div>
<div><a href="mailto:cluster@kasimir:%7E$">cluster@kasimir:~$</a> mpirun -np 2 /mnt/projects/PS3Cluster/Benchmark/pi<br>Input number of intervals:<br>5<br>1: pi =&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.267463056905495<br>0: pi =&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.867463056905495<br>pi =&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.134926113810990<br><a href="mailto:cluster@kasimir:%7E$">cluster@kasimir:~$</a> </div>
<div>&nbsp;</div>
<div>Thx in advance,</div>
<div>Laurin<br></div>
<div><br>&nbsp;</div>
<div>&nbsp;</div></div>
_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>http://www.open-mpi.org/mailman/listinfo.cgi/users</blockquote></div><br></div></rhc@open-mpi.org></body></html>

