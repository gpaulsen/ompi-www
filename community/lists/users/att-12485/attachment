<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
<HEAD>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="Generator" CONTENT="MS Exchange Server version 6.5.7655.10">
<TITLE>Re: [OMPI users] Problem in remote nodes</TITLE>
</HEAD>
<BODY>
<!-- Converted from text/plain format -->

<P><FONT SIZE=2>Those are normal ssh messages, I think - an ssh session may try mulktiple auth methods before one succeeds.<BR>
<BR>
You're absolutely sure that there's no firewalling software and selinux is disabled?&nbsp; Ompi is behaving as if it is trying to communicate and failing (e.g., its hanging while trying to open some tcp sockets back).<BR>
<BR>
Can you open random tcp sockets between your nodes?&nbsp; (E.g., in non-mpi processes)<BR>
<BR>
-jms<BR>
Sent from my PDA.&nbsp; No type good.<BR>
<BR>
----- Original Message -----<BR>
From: users-bounces@open-mpi.org &lt;users-bounces@open-mpi.org&gt;<BR>
To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>
Sent: Wed Mar 31 06:25:43 2010<BR>
Subject: Re: [OMPI users] Problem in remote nodes<BR>
<BR>
I've been checking the /var/log/messages on the compute node and there is<BR>
nothing new after executing ' mpirun --host itanium2 -np 2<BR>
helloworld.out',<BR>
but in the /var/log/messages file on the remote node it appears the<BR>
following messages, nothing about unix_chkpwd.<BR>
<BR>
Mar 31 11:56:51 itanium2 sshd(pam_unix)[15349]: authentication failure;<BR>
logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=itanium1&nbsp; user=otro<BR>
Mar 31 11:56:53 itanium2 sshd[15349]: Accepted publickey for otro from<BR>
192.168.3.1 port 40999 ssh2<BR>
Mar 31 11:56:53 itanium2 sshd(pam_unix)[15351]: session opened for user<BR>
otro by (uid=500)<BR>
Mar 31 11:56:53 itanium2 sshd(pam_unix)[15351]: session closed for user otro<BR>
<BR>
It seems that the authentication fails at first, but in the next message<BR>
it connects with the node...<BR>
<BR>
El Mar, 30 de Marzo de 2010, 20:02, Robert Collyer escribió:<BR>
&gt; I've been having similar problems using Fedora core 9.&nbsp; I believe the<BR>
&gt; issue may be with SELinux, but this is just an educated guess.&nbsp; In my<BR>
&gt; setup, shortly after a login via mpi, there is a notation in the<BR>
&gt; /var/log/messages on the compute node as follows:<BR>
&gt;<BR>
&gt; Mar 30 12:39:45 &lt;node_name&gt; kernel: type=1400 audit(1269970785.534:588):<BR>
&gt; avc:&nbsp; denied&nbsp; { read } for&nbsp; pid=8047 comm=&quot;unix_chkpwd&quot; name=&quot;hosts&quot;<BR>
&gt; dev=dm-0 ino=24579<BR>
&gt; scontext=system_u:system_r:system_chkpwd_t:s0-s0:c0.c1023<BR>
&gt; tcontext=unconfined_u:object_r:etc_runtime_t:s0 tclass=file<BR>
&gt;<BR>
&gt; which says SELinux denied unix_chkpwd read access to hosts.<BR>
&gt;<BR>
&gt; Are you getting anything like this?<BR>
&gt;<BR>
&gt; In the meantime, I'll check if allowing unix_chkpwd read access to hosts<BR>
&gt; eliminates the problem on my system, and if it works, I'll post the<BR>
&gt; steps involved.<BR>
&gt;<BR>
&gt; uriz.49949@e.unavarra.es wrote:<BR>
&gt;&gt; I've benn investigating and there is no firewall that could stop TCP<BR>
&gt;&gt; traffic in the cluster. With the option --mca plm_base_verbose 30 I get<BR>
&gt;&gt; the following output:<BR>
&gt;&gt;<BR>
&gt;&gt; [itanium1] /home/otro &gt; mpirun --mca plm_base_verbose 30 --host itanium2<BR>
&gt;&gt; helloworld.out<BR>
&gt;&gt; [itanium1:08311] mca: base: components_open: Looking for plm components<BR>
&gt;&gt; [itanium1:08311] mca: base: components_open: opening plm components<BR>
&gt;&gt; [itanium1:08311] mca: base: components_open: found loaded component rsh<BR>
&gt;&gt; [itanium1:08311] mca: base: components_open: component rsh has no<BR>
&gt;&gt; register<BR>
&gt;&gt; function<BR>
&gt;&gt; [itanium1:08311] mca: base: components_open: component rsh open function<BR>
&gt;&gt; successful<BR>
&gt;&gt; [itanium1:08311] mca: base: components_open: found loaded component<BR>
&gt;&gt; slurm<BR>
&gt;&gt; [itanium1:08311] mca: base: components_open: component slurm has no<BR>
&gt;&gt; register function<BR>
&gt;&gt; [itanium1:08311] mca: base: components_open: component slurm open<BR>
&gt;&gt; function<BR>
&gt;&gt; successful<BR>
&gt;&gt; [itanium1:08311] mca:base:select: Auto-selecting plm components<BR>
&gt;&gt; [itanium1:08311] mca:base:select:(&nbsp; plm) Querying component [rsh]<BR>
&gt;&gt; [itanium1:08311] mca:base:select:(&nbsp; plm) Query of component [rsh] set<BR>
&gt;&gt; priority to 10<BR>
&gt;&gt; [itanium1:08311] mca:base:select:(&nbsp; plm) Querying component [slurm]<BR>
&gt;&gt; [itanium1:08311] mca:base:select:(&nbsp; plm) Skipping component [slurm].<BR>
&gt;&gt; Query<BR>
&gt;&gt; failed to return a module<BR>
&gt;&gt; [itanium1:08311] mca:base:select:(&nbsp; plm) Selected component [rsh]<BR>
&gt;&gt; [itanium1:08311] mca: base: close: component slurm closed<BR>
&gt;&gt; [itanium1:08311] mca: base: close: unloading component slurm<BR>
&gt;&gt;<BR>
&gt;&gt; --Hangs here<BR>
&gt;&gt;<BR>
&gt;&gt; It seems a slurm problem??<BR>
&gt;&gt;<BR>
&gt;&gt; Thanks to any idea<BR>
&gt;&gt;<BR>
&gt;&gt; El Vie, 19 de Marzo de 2010, 17:57, Ralph Castain escribió:<BR>
&gt;&gt;<BR>
&gt;&gt;&gt; Did you configure OMPI with --enable-debug? You should do this so that<BR>
&gt;&gt;&gt; more diagnostic output is available.<BR>
&gt;&gt;&gt;<BR>
&gt;&gt;&gt; You can also add the following to your cmd line to get more info:<BR>
&gt;&gt;&gt;<BR>
&gt;&gt;&gt; --debug --debug-daemons --leave-session-attached<BR>
&gt;&gt;&gt;<BR>
&gt;&gt;&gt; Something is likely blocking proper launch of the daemons and processes<BR>
&gt;&gt;&gt; so<BR>
&gt;&gt;&gt; you aren't getting to the btl's at all.<BR>
&gt;&gt;&gt;<BR>
&gt;&gt;&gt;<BR>
&gt;&gt;&gt; On Mar 19, 2010, at 9:42 AM, uriz.49949@e.unavarra.es wrote:<BR>
&gt;&gt;&gt;<BR>
&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt; The processes are running on the remote nodes but they don't give the<BR>
&gt;&gt;&gt;&gt; response to the origin node. I don't know why.<BR>
&gt;&gt;&gt;&gt; With the option --mca btl_base_verbose 30, I have the same problems<BR>
&gt;&gt;&gt;&gt; and<BR>
&gt;&gt;&gt;&gt; it<BR>
&gt;&gt;&gt;&gt; doesn't show any message.<BR>
&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt; Thanks<BR>
&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt;&gt; On Wed, Mar 17, 2010 at 1:41 PM, Jeff Squyres &lt;jsquyres@cisco.com&gt;<BR>
&gt;&gt;&gt;&gt;&gt; wrote:<BR>
&gt;&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt;&gt;&gt; On Mar 17, 2010, at 4:39 AM, &lt;uriz.49949@e.unavarra.es&gt; wrote:<BR>
&gt;&gt;&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi everyone I'm a new Open MPI user and I have just installed Open<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; MPI<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; in<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; a 6 nodes cluster with Scientific Linux. When I execute it in local<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; it<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; works perfectly, but when I try to execute it on the remote nodes<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; with<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; the<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; --host&nbsp; option it hangs and gives no message. I think that the<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; problem<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; could be with the shared libraries but i'm not sure. In my opinion<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; the<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; problem is not ssh because i can access to the nodes with no<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; password<BR>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt;&gt;&gt; You might want to check that Open MPI processes are actually running<BR>
&gt;&gt;&gt;&gt;&gt;&gt; on<BR>
&gt;&gt;&gt;&gt;&gt;&gt; the remote nodes -- check with ps if you see any &quot;orted&quot; or other<BR>
&gt;&gt;&gt;&gt;&gt;&gt; MPI-related processes (e.g., your processes).<BR>
&gt;&gt;&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt;&gt;&gt; Do you have any TCP firewall software running between the nodes?&nbsp; If<BR>
&gt;&gt;&gt;&gt;&gt;&gt; so,<BR>
&gt;&gt;&gt;&gt;&gt;&gt; you'll need to disable it (at least for Open MPI jobs).<BR>
&gt;&gt;&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt;&gt; I also recommend running mpirun with the option --mca<BR>
&gt;&gt;&gt;&gt;&gt; btl_base_verbose<BR>
&gt;&gt;&gt;&gt;&gt; 30 to troubleshoot tcp issues.<BR>
&gt;&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt;&gt; In some environments, you need to explicitly tell mpirun what network<BR>
&gt;&gt;&gt;&gt;&gt; interfaces it can use to reach the hosts. Read the following FAQ<BR>
&gt;&gt;&gt;&gt;&gt; section for more information:<BR>
&gt;&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt;&gt; <A HREF="http://www.open-mpi.org/faq/?category=tcp">http://www.open-mpi.org/faq/?category=tcp</A><BR>
&gt;&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt;&gt; Item 7 of the FAQ might be of special interest.<BR>
&gt;&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt;&gt; Regards,<BR>
&gt;&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt;&gt; _______________________________________________<BR>
&gt;&gt;&gt;&gt;&gt; users mailing list<BR>
&gt;&gt;&gt;&gt;&gt; users@open-mpi.org<BR>
&gt;&gt;&gt;&gt;&gt; <A HREF="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</A><BR>
&gt;&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt;&gt; _______________________________________________<BR>
&gt;&gt;&gt;&gt; users mailing list<BR>
&gt;&gt;&gt;&gt; users@open-mpi.org<BR>
&gt;&gt;&gt;&gt; <A HREF="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</A><BR>
&gt;&gt;&gt;&gt;<BR>
&gt;&gt;&gt; _______________________________________________<BR>
&gt;&gt;&gt; users mailing list<BR>
&gt;&gt;&gt; users@open-mpi.org<BR>
&gt;&gt;&gt; <A HREF="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</A><BR>
&gt;&gt;&gt;<BR>
&gt;&gt;&gt;<BR>
&gt;&gt;<BR>
&gt;&gt;<BR>
&gt;&gt; _______________________________________________<BR>
&gt;&gt; users mailing list<BR>
&gt;&gt; users@open-mpi.org<BR>
&gt;&gt; <A HREF="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</A><BR>
&gt;&gt;<BR>
&gt;&gt;<BR>
&gt; _______________________________________________<BR>
&gt; users mailing list<BR>
&gt; users@open-mpi.org<BR>
&gt; <A HREF="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</A><BR>
&gt;<BR>
<BR>
<BR>
_______________________________________________<BR>
users mailing list<BR>
users@open-mpi.org<BR>
<A HREF="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</A><BR>
</FONT>
</P>

</BODY>
</HTML>