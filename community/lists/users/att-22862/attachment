<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" xmlns="http://www.w3.org/TR/REC-html40"><head><meta http-equiv=Content-Type content="text/html; charset=us-ascii"><meta name=Generator content="Microsoft Word 14 (filtered medium)"><style><!--
/* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:Consolas;
	panose-1:2 11 6 9 2 2 4 3 2 4;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0in;
	margin-bottom:.0001pt;
	font-size:12.0pt;
	font-family:"Times New Roman","serif";}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-priority:99;
	color:purple;
	text-decoration:underline;}
p
	{mso-style-priority:99;
	margin:0in;
	margin-bottom:.0001pt;
	font-size:12.0pt;
	font-family:"Times New Roman","serif";}
pre
	{mso-style-priority:99;
	mso-style-link:"HTML Preformatted Char";
	margin:0in;
	margin-bottom:.0001pt;
	font-size:10.0pt;
	font-family:"Courier New";}
span.HTMLPreformattedChar
	{mso-style-name:"HTML Preformatted Char";
	mso-style-priority:99;
	mso-style-link:"HTML Preformatted";
	font-family:Consolas;}
span.EmailStyle20
	{mso-style-type:personal-reply;
	font-family:"Calibri","sans-serif";
	color:#1F497D;}
.MsoChpDefault
	{mso-style-type:export-only;
	font-size:10.0pt;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
--></style><!--[if gte mso 9]><xml>
<o:shapedefaults v:ext="edit" spidmax="1026" />
</xml><![endif]--><!--[if gte mso 9]><xml>
<o:shapelayout v:ext="edit">
<o:idmap v:ext="edit" data="1" />
</o:shapelayout></xml><![endif]--></head><body lang=EN-US link=blue vlink=purple><div class=WordSection1><p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>Let me try this out and see what happens for me.&nbsp; But yes, please go ahead and send me the complete backtrace.<o:p></o:p></span></p><p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>Rolf<o:p></o:p></span></p><p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'><o:p>&nbsp;</o:p></span></p><div style='border:none;border-left:solid blue 1.5pt;padding:0in 0in 0in 4.0pt'><div><div style='border:none;border-top:solid #B5C4DF 1.0pt;padding:3.0pt 0in 0in 0in'><p class=MsoNormal><b><span style='font-size:10.0pt;font-family:"Tahoma","sans-serif"'>From:</span></b><span style='font-size:10.0pt;font-family:"Tahoma","sans-serif"'> users [mailto:users-bounces@open-mpi.org] <b>On Behalf Of </b>KESTENER Pierre<br><b>Sent:</b> Wednesday, October 30, 2013 11:34 AM<br><b>To:</b> users@open-mpi.org<br><b>Cc:</b> KESTENER Pierre<br><b>Subject:</b> [OMPI users] OpenMPI-1.7.3 - cuda support<o:p></o:p></span></p></div></div><p class=MsoNormal><o:p>&nbsp;</o:p></p><div><p class=MsoNormal><span style='font-size:10.0pt;font-family:"Tahoma","sans-serif";color:black'>Hello, &nbsp;&nbsp;&nbsp; <o:p></o:p></span></p><div><p class=MsoNormal style='margin-bottom:12.0pt'><span style='font-size:10.0pt;font-family:"Tahoma","sans-serif";color:black'><br>I'm having problems running a simple cuda-aware mpi application; the one found at<br><a href="https://github.com/parallel-forall/code-samples/tree/master/posts/cuda-aware-mpi-example" target="_blank">https://github.com/parallel-forall/code-samples/tree/master/posts/cuda-aware-mpi-example</a><br><br>I have modified symbol ENV_LOCAL_RANK into OMPI_COMM_WORLD_LOCAL_RANK<br>My cluster has 2 K20m GPUs per node, with QLogic IB stack.<br><br>The normal CUDA/MPI application works fine;<br>&nbsp;but the cuda-ware mpi app is crashing when using 2 MPI proc over the 2 GPUs of the same node:<br>the error message is:<br>&nbsp;&nbsp;&nbsp; Assertion failure at ptl.c:200: nbytes == msglen<br>I can send the complete backtrace from cuda-gdb if needed.<br><br>The same app when running on 2 GPUs on 2 different nodes give another error:<br>&nbsp;&nbsp;&nbsp; jacobi_cuda_aware_mpi:28280 terminated with signal 11 at PC=2aae9d7c9f78 SP=7fffc06c21f8.&nbsp; &nbsp;&nbsp;&nbsp; Backtrace:<br>&nbsp;&nbsp;&nbsp; /gpfslocal/pub/local/lib64/libinfinipath.so.4(+0x8f78)[0x2aae9d7c9f78]<br><br><br>Can someone give me hints where to look to track this problem ?<br>Thank you.<br><br>Pierre Kestener.<o:p></o:p></span></p><div><div><div><div><pre><span style='color:black'><o:p>&nbsp;</o:p></span></pre></div></div></div></div></div></div></div></div>
<DIV>
<HR>
</DIV>
<DIV>This email message is for the sole use of the intended recipient(s) and may 
contain confidential information.&nbsp; Any unauthorized review, use, disclosure 
or distribution is prohibited.&nbsp; If you are not the intended recipient, 
please contact the sender by reply email and destroy all copies of the original 
message. </DIV>
<DIV>
<HR>
</DIV>
</body></html>

