<div dir="ltr">Dear <span style="font-size:12.8000001907349px">Andrew Burns,</span><div><span style="font-size:12.8000001907349px">Thank you for your ideas. Your guess is partly correct, I am trying to merge two sets of programs into one executable and then run in mpi.</span></div><div><span style="font-size:12.8000001907349px">As per your suggestion, I have omitted the MPI_Finalize from of one set. And also commented the MPI_Barrier in some parts. </span></div><div><span style="font-size:12.8000001907349px">But still it is serial.</span></div><div><span style="font-size:12.8000001907349px">For your idea: attached here Makefile.</span></div><div><span style="font-size:12.8000001907349px"><br></span></div><div><span style="font-size:12.8000001907349px">Regards</span></div><div><span style="font-size:12.8000001907349px">Ashfaq</span></div><div><span style="font-size:12.8000001907349px"> </span></div></div><div class="gmail_extra"><br><div class="gmail_quote">On Tue, Feb 3, 2015 at 6:26 PM, Burns, Andrew J CTR (US) <span dir="ltr">&lt;<a href="mailto:andrew.j.burns35.ctr@mail.mil" target="_blank">andrew.j.burns35.ctr@mail.mil</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Classification: UNCLASSIFIED<br>
Caveats: NONE<br>
<br>
If I could venture a guess, it sounds like you are trying to merge two separate programs into one executable and run them in parallel<br>
via MPI.<br>
<br>
The problem sounds like an issue where your program starts in parallel but then changes back to serial while the program is still<br>
executing.<br>
<br>
I can&#39;t be entirely sure without looking at the code itself.<br>
<br>
One guess is that MPI_Finalize is in the wrong location. Finalize should be called to end the parallel section and move the program<br>
back to serial. Typically this means that Finalize will be very close to the last line of the program.<br>
<br>
It may also be possible that with the way your program is structured, the effect is effectively serial since only one core is<br>
processing at any given moment. This may be due to extensive use of barrier or similar functions.<br>
<br>
Andrew Burns<br>
Lockheed Martin<br>
Software Engineer<br>
410-306-0409<br>
ARL DSRC<br>
<a href="mailto:andrew.j.burns2@us.army.mil">andrew.j.burns2@us.army.mil</a><br>
<a href="mailto:andrew.j.burns35.ctr@mail.mil">andrew.j.burns35.ctr@mail.mil</a><br>
<br>
-----Original Message-----<br>
From: users [mailto:<a href="mailto:users-bounces@open-mpi.org">users-bounces@open-mpi.org</a>] On Behalf Of Ralph Castain<br>
Sent: Tuesday, February 03, 2015 9:05 AM<br>
To: Open MPI Users<br>
Subject: Re: [OMPI users] prob in running two mpi merged program<br>
<br>
I&#39;m afraid I don&#39;t quite understand what you are saying, so let&#39;s see if I can clarify. You have two fortran MPI programs. You start<br>
one using &quot;mpiexec&quot;. You then start the other one as a singleton - i.e., you just run &quot;myapp&quot; without using mpiexec. The two apps are<br>
attempting to execute an MPI_Connect/accept so they can &quot;join&quot;.<br>
<br>
Is that correct? You mention MPICH in your statement about one of the procs - are you using MPICH or Open MPI? If the latter, which<br>
version are you using?<br>
<br>
Ralph<br>
<br>
<br>
On Mon, Feb 2, 2015 at 11:35 PM, Muhammad Ashfaqur Rahman &lt;<a href="mailto:ashfaq226@gmail.com">ashfaq226@gmail.com</a>&gt; wrote:<br>
<br>
<br>
        Dear All,<br>
        Take my greetings. I am new in mpi usage. I have problems in parallel run, when two fortran mpi programs are merged to one<br>
executable. If these two are separate, then they are running parallel.<br>
<br>
        One program has used spmd and another one  has used mpich header directly.<br>
<br>
        Other issue is that while trying to run the above mentioned merged program in mpi, it&#39;s first started with separate parallel<br>
instances of same step and then after some steps it becomes serial.<br>
<br>
        Please help me in this regards<br>
<br>
        Ashfaq<br>
        Ph.D Student<br>
        Dept. of Meteorology<br>
<br>
        _______________________________________________<br>
        users mailing list<br>
        <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
        Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
        Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2015/02/26264.php" target="_blank">http://www.open-mpi.org/community/lists/users/2015/02/26264.php</a><br>
<br>
<br>
<br>
<br>
Classification: UNCLASSIFIED<br>
Caveats: NONE<br>
<br>
<br>
<br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2015/02/26266.php" target="_blank">http://www.open-mpi.org/community/lists/users/2015/02/26266.php</a><br></blockquote></div><br></div>

