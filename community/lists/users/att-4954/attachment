<html><body>
<p>Is what George says accurate?  If so, it sounds to me like OpenMPI does not comply with the MPI standard on the behavior of eager protocol. MPICH is getting dinged in this discussion because they have complied with the requirements of the MPI standard.  IBM MPI also complies with the standard. <br>
<br>
If there is any debate about whether the MPI standard does (or should) require the behavior I describe below then we should move the discussion to the MPI 2.1 Forum and get a clarification.<br>
<br>
To me, the MPI standard is clear that a program like this:<br>
<br>
task 0:<br>
MPI_Init<br>
sleep(3000);<br>
start receiving messages<br>
<br>
each of tasks 1 to n-1:<br>
MPI_Init<br>
loop 5000 times<br>
   MPI_Send(small message to 0)<br>
end loop<br>
<br>
May send some small messages eagerly if there is space at task 0 but must block each task 1 to  n-1 before allowing task 0 to run out of eager buffer space.  Doing this requires a token or credit management system in which each task has credits for known buffer space at task 0. Each task will send eagerly to task 0 until the sender runs out of credits and then must switch to rendezvous protocol.  Tasks 1to n-1 might each do 3 MPI_Sends or 300 MPI_Sends before blocking, depending on how much buffer space there is at task 0 but they would need to block in some MPI_Send before task 0 blows up. <br>
<br>
When task 0 wakes up and begins receiving the early arrivals, tasks 1 to n-1 will unblock and resume looping..  Allowing the user to shut off eager protocol by setting eager size to 0 does not fix the standards compliance issue.  You must either have no eager protocol at all or must have a eager message token/credit strategy.<br>
<br>
                 Dick <br>
<br>
Dick Treumann  -  MPI Team/TCEM            <br>
IBM Systems &amp; Technology Group<br>
Dept 0lva / MS P963 -- 2455 South Road -- Poughkeepsie, NY 12601<br>
Tele (845) 433-7846         Fax (845) 433-8363<br>
<br>
<br>
<tt>users-bounces@open-mpi.org wrote on 02/03/2008 06:59:38 PM:<br>
<br>
&gt; Well ... this is exactly the kind of behavior a high performance &nbsp;<br>
&gt; application try to achieve isn't it ?<br>
&gt; <br>
&gt; The problem here is not the flow control. What you need is to avoid &nbsp;<br>
&gt; buffering the messages on the receiver side. Luckily, Open MPI is &nbsp;<br>
&gt; entirely configurable at runtime, so this situation is really easy to &nbsp;<br>
&gt; deal with even at the user level. Set the eager size to zero, and no &nbsp;<br>
&gt; buffering on the receiver side will be made. Your program will survive &nbsp;<br>
&gt; as long as there is some available memory on the receiver.<br>
&gt; <br>
&gt; &nbsp; &nbsp;Thanks,<br>
&gt; &nbsp; &nbsp; &nbsp;George.<br>
&gt; <br>
&gt; On Feb 1, 2008, at 6:32 PM, 8mj6tc902@sneakemail.com wrote:<br>
&gt; <br>
&gt; &gt; That would make sense. I able to break OpenMPI by having Node A wait &nbsp;<br>
&gt; &gt; for<br>
&gt; &gt; messages from Node B. Node B is in fact sleeping while Node C bombards<br>
&gt; &gt; Node A with a few thousand messages. After a while Node B wakes up and<br>
&gt; &gt; sends Node A the message it's been waiting on, but Node A has long &nbsp;<br>
&gt; &gt; since<br>
&gt; &gt; been buried and seg faults. If I decrease the number of messages C is<br>
&gt; &gt; sending, it works properly. This was on OpenMPI 1.2.4 (using I think &nbsp;<br>
&gt; &gt; the<br>
&gt; &gt; SM BTL (might have been MX or TCP, but certainly not infiniband. I &nbsp;<br>
&gt; &gt; could<br>
&gt; &gt; dig up the test and try again if anyone is seriously curious).<br>
&gt; &gt;<br>
&gt; &gt; Trying the same test on MPICH/MX went very very slow (I don't think &nbsp;<br>
&gt; &gt; they<br>
&gt; &gt; have any clever buffer management) but it didn't crash.<br>
&gt; &gt;<br>
&gt; &gt; Sacerdoti, Federico Federico.Sacerdoti-at-deshaw.com<br>
&gt; &gt; |openmpi-users/Allow| wrote:<br>
&gt; &gt;&gt; Hi,<br>
&gt; &gt;&gt;<br>
&gt; &gt;&gt; I am readying an openmpi 1.2.5 software stack for use with a<br>
&gt; &gt;&gt; many-thousand core cluster. I have a question about sending small<br>
&gt; &gt;&gt; messages that I hope can be answered on this list.<br>
&gt; &gt;&gt;<br>
&gt; &gt;&gt; I was under the impression that if node A wants to send a small MPI<br>
&gt; &gt;&gt; message to node B, it must have a credit to do so. The credit &nbsp;<br>
&gt; &gt;&gt; assures A<br>
&gt; &gt;&gt; that B has enough buffer space to accept the message. Credits are<br>
&gt; &gt;&gt; required by the mpi layer regardless of the BTL transport layer used.<br>
&gt; &gt;&gt;<br>
&gt; &gt;&gt; I have been told by a Voltaire tech that this is not so, the &nbsp;<br>
&gt; &gt;&gt; credits are<br>
&gt; &gt;&gt; used by the infiniband transport layer to reliably send a message, &nbsp;<br>
&gt; &gt;&gt; and<br>
&gt; &gt;&gt; is not an openmpi feature.<br>
&gt; &gt;&gt;<br>
&gt; &gt;&gt; Thanks,<br>
&gt; &gt;&gt; Federico<br>
&gt; &gt;&gt;<br>
&gt; &gt;&gt; _______________________________________________<br>
&gt; &gt;&gt; users mailing list<br>
&gt; &gt;&gt; users@open-mpi.org<br>
&gt; &gt;&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; &gt;<br>
&gt; &gt;<br>
&gt; &gt; -- <br>
&gt; &gt; --Kris<br>
&gt; &gt;<br>
&gt; &gt; 叶ってしまう夢は本当の夢と言えん。<br>
&gt; &gt; [A dream that comes true can't really be called a dream.]<br>
&gt; &gt; _______________________________________________<br>
&gt; &gt; users mailing list<br>
&gt; &gt; users@open-mpi.org<br>
&gt; &gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; <br>
&gt; [attachment &quot;smime.p7s&quot; deleted by Richard <br>
&gt; Treumann/Poughkeepsie/IBM] _______________________________________________<br>
&gt; users mailing list<br>
&gt; users@open-mpi.org<br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></tt></body></html>
