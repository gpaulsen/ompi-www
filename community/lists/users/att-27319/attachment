<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=Windows-1252">
<style type="text/css" style="display:none;"><!-- P {margin-top:0;margin-bottom:0;} --></style>
</head>
<body dir="ltr">
<div id="divtagdefaultwrapper" style="font-size:12pt;color:#000000;background-color:#FFFFFF;font-family:Calibri,Arial,Helvetica,sans-serif;">
<p>Hi,&nbsp;</p>
<p><br>
</p>
<p>Thanks a lot, it seems to be working using the --prefix on mpirun.</p>
<p>I have trouble understanding why using the right flags or exporting &quot;by hand&quot; with -x PATH -x LD_LIBRARY_PATH do not work.</p>
<p>In any case, the --prefix option works so that's a good starting point.</p>
<p><br>
</p>
<p>Thank you again,&nbsp;</p>
<p><br>
</p>
<p>MD</p>
<br>
<br>
<div style="color: rgb(0, 0, 0);">
<hr tabindex="-1" style="display:inline-block; width:98%">
<div id="divRplyFwdMsg" dir="ltr"><font face="Calibri, sans-serif" color="#000000" style="font-size:11pt"><b>From:</b> users &lt;users-bounces@open-mpi.org&gt; on behalf of Ralph Castain &lt;rhc@open-mpi.org&gt;<br>
<b>Sent:</b> Friday, July 24, 2015 1:51 AM<br>
<b>To:</b> Open MPI Users<br>
<b>Subject:</b> Re: [OMPI users] SGE segfaulting with OpenMPI 1.8.6</font>
<div>&nbsp;</div>
</div>
<div>I believe qrsh will execute a simple env command across the allocated nodes - have you looked into that?
<div class=""><br class="">
</div>
<div class="">The bottom line is that you simply are not getting the right orted on the remote nodes - you are getting the old one, which doesn’t recognize the new command line option that mpirun is giving.</div>
<div class=""><br class="">
</div>
<div class="">Try adding —prefix=&lt;install-point&gt; to your mpirun cmd line. This will force the path and ld_library_path to the correct value when executing the orted</div>
<div class=""><br class="">
</div>
<div class="">Also, you should probably add —enable-orterun-prefix-by-default to your configure line to avoid having to add anything to the mpirun cmd line</div>
<div class=""><br class="">
</div>
<div class=""><br class="">
<div>
<blockquote type="cite" class="">
<div class="">On Jul 23, 2015, at 8:08 AM, <a href="mailto:m.delorme@surrey.ac.uk" class="">
m.delorme@surrey.ac.uk</a> wrote:</div>
<br class="Apple-interchange-newline">
<div class="">
<div dir="ltr" class="">
<div id="divtagdefaultwrapper" class="" style="font-size:12pt; background-color:rgb(255,255,255); font-family:Calibri,Arial,Helvetica,sans-serif">
<p class="">hi,&nbsp;</p>
<p class=""><br class="">
</p>
<p class="">Thanks for the quick answer.</p>
<p class="">I am actually using the module environment, and made my own module for openmpi-1.8.6 prepending the paths.</p>
<p class=""><br class="">
</p>
<p class="">I was so desperate to get the env right that I doubled everything : my script is running with the -V flag, I am loading the modules, and printing the env. This returns the right PATH and LD_LIBRARY_PATH</p>
<p class="">The problem is that printing the env before mpirun will give me the environment of the master node running mpirun but not the nodes where the program will really be executed.</p>
<p class="">On the other hand, if I just try to put the env in a mpirun, then the whole thing segfaults as previously.</p>
<p class=""><br class="">
</p>
<p class="">So I am not sure I have a proper way to ensure my env variable are right.</p>
<p class=""><br class="">
</p>
MD<br class="">
<br class="">
<div class="" style="">
<hr tabindex="-1" class="" style="display:inline-block; width:98%">
<div id="divRplyFwdMsg" dir="ltr" class=""><font face="Calibri, sans-serif" class="" style="font-size:11pt"><b class="">From:</b> users &lt;<a href="mailto:users-bounces@open-mpi.org" class="">users-bounces@open-mpi.org</a>&gt; on behalf of John Hearns &lt;<a href="mailto:hearnsj@googlemail.com" class="">hearnsj@googlemail.com</a>&gt;<br class="">
<b class="">Sent:</b> Thursday, July 23, 2015 3:53 PM<br class="">
<b class="">To:</b> Open MPI Users<br class="">
<b class="">Subject:</b> Re: [OMPI users] SGE segfaulting with OpenMPI 1.8.6</font>
<div class="">&nbsp;</div>
</div>
<div class="">
<div dir="ltr" class="">You say that you can run the code OK 'by hand' with an mpirun.
<div class=""><br class="">
</div>
<div class="">Are you assuming somehow that the Gridengine jobs will inherit your environment variables, paths etc?</div>
<div class="">If I remember correctly, you should submit wiht the &nbsp;-V &nbsp;option to pass over environment settings.</div>
<div class="">Even better, make sure that the job script itself sets all the paths and variables.</div>
<div class="">Have you looked at using the 'modules' environment?</div>
<div class=""><br class="">
</div>
<div class="">Also submit a job script and put the 'env' command in as the first command.</div>
<div class="">Look at your output closely.</div>
<div class=""><br class="">
</div>
<div class=""><br class="">
</div>
<div class=""><br class="">
</div>
</div>
<div class="gmail_extra"><br class="">
<div class="gmail_quote">On 23 July 2015 at 15:45, <span dir="ltr" class="">&lt;<a href="mailto:m.delorme@surrey.ac.uk" target="_blank" title="mailto:m.delorme@surrey.ac.uk
Ctrl&#43;Click or tap to follow the link" class="">m.delorme@surrey.ac.uk</a>&gt;</span> wrote:<br class="">
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex; border-left:1px #ccc solid; padding-left:1ex">
<div dir="ltr" class="">
<div class="" style="font-size:12pt; background-color:rgb(255,255,255); font-family:Calibri,Arial,Helvetica,sans-serif">
<p class="">Hello,&nbsp;</p>
<p class=""><br class="">
</p>
<p class="">I have been working on this problem for the last week, browsing the help and the mailing list with no success.</p>
<p class="">While&nbsp;trying to run MPI programs using SGE, I end up with seg faults every time.</p>
<p class=""><br class="">
</p>
<p class="">A bit of information on the system :</p>
<p class=""><br class="">
</p>
<p class="">I am working on a 14 nodes cluster. Every node is an Intel Xeon, each composed of 2 sockets with 10 cores each (so 20 cores per node). The nodes are Infiniband&nbsp;connected. The job scheduler is Grid Engine as mentioned before.</p>
<p class="">Since I don't have the hand on the cluster administration, and the &quot;default&quot; installation of openMPI is an old one, I compiled and installed myself Open-MPI 1.8.6 and prepended paths (general and library) to ensure the use of my version of mpi.</p>
<p class=""><br class="">
</p>
<p class="">Open MPI has been configured with the flags --with-sge, and grepping grid engine in ompi_info returns something that looks correct :</p>
<p class=""><br class="">
</p>
<p class="">MCA ras: gridengine (MCA v2.0, API v2.0, Component v1.8.6)<br class="">
</p>
<p class=""><br class="">
</p>
<p class=""><br class="">
</p>
<p class="">Now when running a simple script, displaying the hostname, on two slots binded on one single node, I get the following message :</p>
<p class=""><br class="">
</p>
<p class="">[galaxy1:44361] Error: unknown option &quot;--hnp-topo-sig&quot;</p>
<p class="">Segmentation fault</p>
<p class="">--------------------------------------------------------------------------</p>
<p class="">ORTE was unable to reliably start one or more daemons.</p>
<p class="">This usually is caused by:</p>
<p class=""><br class="">
</p>
<p class="">* not finding the required libraries and/or binaries on</p>
<p class="">&nbsp; one or more nodes. Please check your PATH and LD_LIBRARY_PATH</p>
<p class="">&nbsp; settings, or configure OMPI with --enable-orterun-prefix-by-default</p>
<p class=""><br class="">
</p>
<p class="">* lack of authority to execute on one or more specified nodes.</p>
<p class="">&nbsp; Please verify your allocation and authorities.</p>
<p class=""><br class="">
</p>
<p class="">* the inability to write startup files into /tmp (--tmpdir/orte_tmpdir_base).</p>
<p class="">&nbsp; Please check with your sys admin to determine the correct location to use.</p>
<p class=""><br class="">
</p>
<p class="">* &nbsp;compilation of the orted with dynamic libraries when static are required</p>
<p class="">&nbsp; (e.g., on Cray). Please check your configure cmd line and consider using</p>
<p class="">&nbsp; one of the contrib/platform definitions for your system type.</p>
<p class=""><br class="">
</p>
<p class="">* an inability to create a connection back to mpirun due to a</p>
<p class="">&nbsp; lack of common network interfaces and/or no route found between</p>
<p class="">&nbsp; them. Please check network connectivity (including firewalls</p>
<p class="">&nbsp; and network routing requirements).</p>
<p class="">--------------------------------------------------------------------------</p>
<div class=""><br class="">
</div>
<div class=""><br class="">
</div>
<div class="">When I connect to the specific host crashing and try to run the program by hand with mpirun, the whole thing executes without problem.</div>
<div class="">I made sure the libraries and path are right, that I have the rights on the node, that /tmp is accessible. I don't think the fourth point of the list is the problem, as for the last one, I suppose that if I can access the node by sshing it, SGE
 shouldn't have a problem with it as well ...</div>
<div class=""><br class="">
</div>
<div class="">My guess is then a problem from SGE or the integration of OpenMPI with SGE ...&nbsp;</div>
<div class=""><br class="">
</div>
<div class="">I googled with no real success the &quot;hnp-topo-sig&quot;, and only got to a stackoverflow page indicating that the problem should be nodes running a different version of OpenMPI.&nbsp;</div>
<div class="">I know that there is an old OpenMPI version by default on the nodes, but shouldn't&nbsp;prepending the paths and exporting the environment (using the -V flag in the script) be sufficient to ensure the right version of openMPI is used ?</div>
<div class=""><br class="">
</div>
<div class="">A bit of additional information,&nbsp;</div>
<div class=""><br class="">
</div>
<div class="">qconf -se orte :</div>
<div class=""><br class="">
</div>
<div class="">
<div class="">pe_name &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;orte</div>
<div class="">slots &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2000</div>
<div class="">user_lists &nbsp; &nbsp; &nbsp; &nbsp; NONE</div>
<div class="">xuser_lists &nbsp; &nbsp; &nbsp; &nbsp;NONE</div>
<div class="">start_proc_args &nbsp; &nbsp;/bin/true</div>
<div class="">stop_proc_args &nbsp; &nbsp; /bin/true</div>
<div class="">allocation_rule &nbsp; &nbsp;$fill_up</div>
<div class="">control_slaves &nbsp; &nbsp; TRUE</div>
<div class="">job_is_first_task &nbsp;FALSE</div>
<div class="">urgency_slots &nbsp; &nbsp; &nbsp;min</div>
<div class="">accounting_summary FALSE</div>
<div class="">qsort_args &nbsp; &nbsp; &nbsp; &nbsp; NONE</div>
</div>
<div class=""><br class="">
</div>
<div class=""><br class="">
</div>
<div class="">You will find attached the compressed log&nbsp;of ompi_info -a --parsable</div>
<div class=""><br class="">
</div>
<div class=""><br class="">
</div>
<div class=""><br class="">
</div>
<div class="">Thank you very much in advance for any suggestion,&nbsp;</div>
<div class=""><br class="">
</div>
<div class=""><br class="">
</div>
<div class="">MD</div>
<div class=""><br class="">
</div>
<div class=""><br class="">
</div>
</div>
</div>
<br class="">
_______________________________________________<br class="">
users mailing list<br class="">
<a href="mailto:users@open-mpi.org" class="">users@open-mpi.org</a><br class="">
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" rel="noreferrer" target="_blank" class="">
http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br class="">
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2015/07/27312.php" rel="noreferrer" target="_blank" class="">
http://www.open-mpi.org/community/lists/users/2015/07/27312.php</a><br class="">
</blockquote>
</div>
<br class="">
</div>
</div>
</div>
</div>
</div>
_______________________________________________<br class="">
users mailing list<br class="">
<a href="mailto:users@open-mpi.org" class="">users@open-mpi.org</a><br class="">
Subscription: http://www.open-mpi.org/mailman/listinfo.cgi/users<br class="">
Link to this post: http://www.open-mpi.org/community/lists/users/2015/07/27314.php</div>
</blockquote>
</div>
<br class="">
</div>
</div>
</div>
</div>
</body>
</html>

