<table cellspacing="0" cellpadding="0" border="0" ><tr><td valign="top" style="font: inherit;"><br>I have a mpi program that aggregates data from multiple sql systems.&nbsp; It all runs fine.&nbsp; To test fault tolerance I switch one of the machines off while it is running.&nbsp; The result is always a hang, ie mpirun never completes.<br>&nbsp;<br>To try and avoid this I have replaced the send and receive calls with immediate calls (ie MPI_Isend, MPI_Irecv) to try and trap long waiting sends and receives but it makes no difference.<br>My requirement is that all complete or mpirun exits with an error - no matter where they are in their execution when a failure occurs.&nbsp; This system must continue (ie fail)&nbsp; if a machine dies, regroup and re-cast the job over the remaining nodes.<br><br>I am running FC10, gcc 4.3.2 and openMPI 1.4.1<br>4G RAM, dual core intel all
 x86_64<br><br><br>===============================================================================================================<br>The commands I have tried:<br>mpirun&nbsp; -hostfile ~/mpd.hosts -np 6&nbsp; ./ingsprinkle&nbsp; test t3&nbsp; "select * from tab"&nbsp;&nbsp; <br><br>mpirun -mca <span class="quotelev1">btl ^sm</span> -hostfile ~/mpd.hosts -np 6&nbsp; ./ingsprinkle&nbsp; test t3&nbsp; "select * from tab"&nbsp; &nbsp;<br>
<br>mpirun -mca orte_forward_job_control 1&nbsp; -hostfile ~/mpd.hosts -np 6&nbsp; ./ingsprinkle&nbsp; test t3&nbsp; "select * from tab"&nbsp; &nbsp;<br>
<br><br>===============================================================================================================<br><br>The results:<br>recv returned 0 with status 0<br>waited&nbsp; # 2000002 tiumes - now status is&nbsp; 0 flag is -1976147192<br>--------------------------------------------------------------------------<br>MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD <br>with errorcode 5.<br><br>NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.<br>You may or may not see output from other processes, depending on<br>exactly when Open MPI kills them.<br>--------------------------------------------------------------------------<br>--------------------------------------------------------------------------<br>mpirun has exited due to process rank 0 with PID 29141 on<br>node bd01 exiting without calling "finalize". This may<br>have caused other processes in the application to be<br>terminated by signals sent by mpirun
 (as reported here).<br>--------------------------------------------------------------------------<br><br>[*** wait a long time ***]<br>[bd01:29136] [[55293,0],0]-[[55293,0],1] mca_oob_tcp_msg_recv: readv failed: Connection reset by peer (104)<br><br>^Cmpirun: abort is already in progress...hit ctrl-c again to forcibly terminate<br><br><br>===============================================================================================================<br><br>As you can see, my trap can signal an abort, the tcp layer can time out but mpirun just keeps on running...<br><br>Any help greatly appreciated..<br>Vlad<br><br><br></td></tr></table><br>



      &nbsp;
