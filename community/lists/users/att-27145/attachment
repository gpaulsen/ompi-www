<div dir="ltr"><div>Hi,<br><br></div>While checking for memory issues related with CGNS 2.5.5, on a test machine, the following output is display when just opening and closing CGNS file.<br><div><div><div><br></div><div>Can anybody please help me on this?<br>This machine is Centos 7 (minimal installation) with GCC 4.8.3 and CentOS 7. The gcc compiler is used. The CGNS library is statically compiled locally with default configuration option.<br><br></div><div>===================<br>before open:files 0/0: memory 0/0<br>after  open:files 1/1: memory 969250618/969250618<br>no CGNS error reported<br>no CGNS error reported<br>before close:files 1/1: memory 969250618/969250618<br>after  close:files 0/0: memory 969250618/969250618<br>no CGNS error reported<br>===================<br><div><br>I am still not able to conclude on whether it is a OS/machine/CGNSLib problem? Should I compile with dynamic option?<br><br></div>If I use MPI and open CGNS file only for reading, should it occupy whole memory on each processor? Ideally it should free memory after cg_close(), but it is not freeing.<br><br></div><div>Also, in major cases, the CGNS file would be of size of more than 2GB. Do I need to compile with any specific flags? <br><br></div><div>Please help.<br></div><div>Thanks.<br><br>--<br></div><div>regards,<br></div><div>Manoj<br></div><div><br></div></div></div></div><div class="gmail_extra"><br><div class="gmail_quote">On Tue, Jun 2, 2015 at 2:19 AM, Manoj Vaghela <span dir="ltr">&lt;<a href="mailto:manoj.vaghela@gmail.com" target="_blank">manoj.vaghela@gmail.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir="ltr"><div><div><div><div><div><div>Dear Nathan,<br><br></div>After some initial debugging procedure, I found that the problem is with the CGNS (v 2.5) file which I am reading by each processor. The CGNS file which has 3-levels of userdefined data of descriptors/arrays is just read by each processor only for getting some texts, which in turn takes 1% of memory (totally to 5GB). I have no idea of why it is happening. I have asked this memory related issue to the CGNS forum for help.<br><br></div>I am checking memory of each processor (process) using &quot;top&quot; command. Each process shows its % memory usage, so in my case for 16 processors, it is 16 * 1% = 16% (5GB) of total memory (=32GB) which is very huge for just extracting only text data from the file.<br><br></div>Any comments are welcome.<br></div>Thanks.<br><br>--<br></div>regards,<br></div>Manoj B Vaghela<br></div><div class="gmail_extra"><br><div class="gmail_quote"><div><div class="h5">On Mon, Jun 1, 2015 at 3:14 PM, Nathan Hjelm <span dir="ltr">&lt;<a href="mailto:hjelmn@lanl.gov" target="_blank">hjelmn@lanl.gov</a>&gt;</span> wrote:<br></div></div><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div><div class="h5"><br>
Just to be sure. How are you measuring the memory usage? If you are<br>
using /proc/meminfo are you subracting out the Cached memory usage?<br>
<br>
-Nathan<br>
<div><div><br>
On Mon, Jun 01, 2015 at 04:54:45AM -0400, Manoj Vaghela wrote:<br>
&gt;    Hi OpenMPI users,<br>
&gt;<br>
&gt;    I have been using OpenMPI for quite a few years now. Recently I figured<br>
&gt;    out some memory related issues which are quite bothering me.<br>
&gt;<br>
&gt;    I have OpenMPI 1.8.3 version installed on different machines. All machines<br>
&gt;    are SMPs and linux x86_64. The Machine one and one-1 are installed with<br>
&gt;    Red Hat Enterprise Linux Server release 5.4 and others are CentOS 7.<br>
&gt;<br>
&gt;    I am using 16 cores on each machine. If I see memory consumption for a<br>
&gt;    finite volume problem of 3 million cells, it should take nearly 3GB of<br>
&gt;    memory on each machine for 16 cores usage. The following are some of the<br>
&gt;    values of memory consumption which I got.<br>
&gt;<br>
&gt;    machine       mem used(GB)       total memory(GB)           per<br>
&gt;    core<br>
&gt;<br>
&gt;    memory usage(%)<br>
&gt;    ==========================================================<br>
&gt;    one            2.114413568                  66.075424<br>
&gt;    0.2<br>
&gt;    one-1         2.368967808                 24.676748<br>
&gt;    0.6<br>
&gt;    two             7.362867456                 32.869944<br>
&gt;    1.4<br>
&gt;    three          7.333295872                 16.368964<br>
&gt;    2.8<br>
&gt;    four            7.356667136                 32.842264<br>
&gt;    1.4<br>
&gt;    five             7.350758912<br>
&gt;    32.815888                      1.4<br>
&gt;<br>
&gt;    I am wondering why machines two to five are taking high memory against the<br>
&gt;    machines one and one-1 for the same setup files for this problem.<br>
&gt;<br>
&gt;    I have compiled OpenMPI with its default options on all machines.<br>
&gt;<br>
&gt;    It will help if somebody has any idea on this problem. Is there anything<br>
&gt;    to be set while building OpenMPI ? or it is OS problem?<br>
&gt;    Thanks.<br>
&gt;<br>
&gt;    Manoj<br>
&gt;<br>
<br>
</div></div>&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
&gt; Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; Searchable archives: <a href="http://www.open-mpi.org/community/lists/users/2015/06/27006.php" target="_blank">http://www.open-mpi.org/community/lists/users/2015/06/27006.php</a><br>
<br>
<br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></div></div>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2015/06/27015.php" target="_blank">http://www.open-mpi.org/community/lists/users/2015/06/27015.php</a><br></blockquote></div><br></div>
</blockquote></div><br></div>

