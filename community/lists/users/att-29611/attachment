<p dir="ltr"><br>
On Jul 8, 2016 4:04 PM, &quot;Juan Francisco Martínez&quot; &lt;<a href="mailto:juan.francisco.martinez@est.fib.upc.edu">juan.francisco.martinez@est.fib.upc.edu</a>&gt; wrote:<br>
&gt;<br>
&gt; George,<br>
&gt;<br>
&gt; Thanks for your rapid answer.<br>
&gt;<br>
&gt; I just ask for &quot;simple synchronized reduction implementation&quot; because I<br>
&gt; am using a simple (and therefore really rapid) mpi communications<br>
&gt; simulator that models all collectives as synchronized collectives and I<br>
&gt; appreciate a huge differences between the real and the simulated<br>
&gt; execution because the reductions.<br>
&gt;<br>
&gt; After note that in reallity there is no case where the mpi_reductions<br>
&gt; syncrhonizes, then maybe could be a good idea to try to model an<br>
&gt; approximation to the real behaviour.</p>
<p dir="ltr">Then maybe you want to take a look into the sync collective module, which does exactly what you want /need,  i.e. automatically adds a barrier every X collective per communicator. I&#39;m away from my computer and I can&#39;t check if we still have this module in the repo, if not you should be able to resurrect it from an older version. </p>
<p dir="ltr">&gt;<br>
&gt; There is any place where I can found documentation about the different<br>
&gt; algorithms that are implemented for mpi_reduction?</p>
<p dir="ltr">Not that I know of. Ompi_info should be good enough no? </p>
<p dir="ltr">George <br>
&gt;<br>
&gt; - Fran<br>
&gt;<br>
&gt; On Fri, 2016-07-08 at 15:40 +0200, George Bosilca wrote:<br>
&gt; &gt;<br>
&gt; &gt; On Jul 8, 2016 3:16 PM, &quot;Juan Francisco Martínez&quot; &lt;<br>
&gt; &gt; <a href="mailto:juan.francisco.martinez@est.fib.upc.edu">juan.francisco.martinez@est.fib.upc.edu</a>&gt; wrote:<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; Hi everybody!<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; First of all I want to congratulate all of you because the quality<br>
&gt; &gt; of<br>
&gt; &gt; &gt; the community, I have solved a lot of doubts just reading the<br>
&gt; &gt; mailing<br>
&gt; &gt; &gt; list.<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; However I have a question that I can not solve... Until now I<br>
&gt; &gt; though<br>
&gt; &gt; &gt; that all the collective operations have an implicit sincronization,<br>
&gt; &gt; but<br>
&gt; &gt; &gt; I can see that this is not true at all (because optimizations?).<br>
&gt; &gt; Then,<br>
&gt; &gt; &gt; after searching a little bit on the web I saw that there are<br>
&gt; &gt; several<br>
&gt; &gt; &gt; implementations of the reduction in openmpi, in fact there are 6<br>
&gt; &gt; &gt; possible algorithm (at least on OMPI 1.6) that you can use by mean<br>
&gt; &gt; of<br>
&gt; &gt; &gt; the mca parameters...<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; I thought that one of them behaves as a synchronization but after<br>
&gt; &gt; &gt; execute a test with each one, no one behaves as it. Then my<br>
&gt; &gt; question<br>
&gt; &gt; &gt; is, there is any possibility, by tuning ompi, the reduce operation<br>
&gt; &gt; &gt; syncrhonize all the ranks that are involved at the end of the<br>
&gt; &gt; &gt; operation?<br>
&gt; &gt; The straightforward answer is that the reduction provides a logical<br>
&gt; &gt; synchronization only between the root of the reduction and each one<br>
&gt; &gt; of the participants individually.<br>
&gt; &gt; As you already noticed this is not the case from a practical<br>
&gt; &gt; perspective because different underlying algorithms can be used,  and<br>
&gt; &gt; they use different communication patterns. Thus, you cannot,  and you<br>
&gt; &gt; should not, make a parallel between a reduction and a<br>
&gt; &gt; synchronization.<br>
&gt; &gt; If you really need the synchronization behavior why don&#39;t you use<br>
&gt; &gt; allreduce instead? Or at least a bcast of a single byte after the<br>
&gt; &gt; reduction (it also works with a barrier but as already have 1/2 of<br>
&gt; &gt; the synchronization, aka. all-to-root, this will be an overkill).<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; Also I would like to know if there is any mechanism to know at<br>
&gt; &gt; runtime<br>
&gt; &gt; &gt; which algorithm is being used.<br>
&gt; &gt; Again,  there is no simple answer. Even if the tuned collective<br>
&gt; &gt; module could expose the algorithm, how do you know that a particular<br>
&gt; &gt; collective will be using the tuned module? We order the collective<br>
&gt; &gt; modules by priority,  and the decision of which module will handle<br>
&gt; &gt; each collective is dynamic, based on the many factors.<br>
&gt; &gt; George<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; Thanks for all!<br>
&gt; &gt; &gt; - Fran<br>
&gt; &gt; &gt; _______________________________________________<br>
&gt; &gt; &gt; users mailing list<br>
&gt; &gt; &gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; &gt; &gt; Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/users">https://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; &gt; &gt; Link to this post:<br>
&gt; &gt; <a href="http://www.open-mpi.org/community/lists/users/2016/07/29606.php">http://www.open-mpi.org/community/lists/users/2016/07/29606.php</a><br>
&gt; &gt; _______________________________________________<br>
&gt; &gt; users mailing list<br>
&gt; &gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; &gt; Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/users">https://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; &gt; Link to this post:<br>
&gt; &gt; <a href="http://www.open-mpi.org/community/lists/users/2016/07/29607.php">http://www.open-mpi.org/community/lists/users/2016/07/29607.php</a><br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/users">https://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2016/07/29609.php">http://www.open-mpi.org/community/lists/users/2016/07/29609.php</a></p>

