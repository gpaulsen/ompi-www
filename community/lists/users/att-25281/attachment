<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" xmlns="http://www.w3.org/TR/REC-html40">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="Generator" content="Microsoft Word 14 (filtered medium)">
<!--[if !mso]><style>v\:* {behavior:url(#default#VML);}
o\:* {behavior:url(#default#VML);}
w\:* {behavior:url(#default#VML);}
.shape {behavior:url(#default#VML);}
</style><![endif]--><style><!--
/* Font Definitions */
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0in;
	margin-bottom:.0001pt;
	font-size:12.0pt;
	font-family:"Times New Roman","serif";}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-priority:99;
	color:purple;
	text-decoration:underline;}
p.MsoAcetate, li.MsoAcetate, div.MsoAcetate
	{mso-style-priority:99;
	mso-style-link:"Balloon Text Char";
	margin:0in;
	margin-bottom:.0001pt;
	font-size:8.0pt;
	font-family:"Tahoma","sans-serif";}
span.EmailStyle17
	{mso-style-type:personal-reply;
	font-family:"Calibri","sans-serif";
	color:#1F497D;}
span.BalloonTextChar
	{mso-style-name:"Balloon Text Char";
	mso-style-priority:99;
	mso-style-link:"Balloon Text";
	font-family:"Tahoma","sans-serif";}
.MsoChpDefault
	{mso-style-type:export-only;
	font-size:10.0pt;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
--></style><!--[if gte mso 9]><xml>
<o:shapedefaults v:ext="edit" spidmax="1026" />
</xml><![endif]--><!--[if gte mso 9]><xml>
<o:shapelayout v:ext="edit">
<o:idmap v:ext="edit" data="1" />
</o:shapelayout></xml><![endif]-->
</head>
<body lang="EN-US" link="blue" vlink="purple">
<div class="WordSection1">
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">I am testing a new cluster that we just bought, which is why I am loading things this way. I am deliberately increasing network traffic. But in general, we
 submit jobs intermittently with various numbers of MPI processes. I have read that a good strategy is to map by socket, which in our case means that we assign 2 MPI processes to node1, which has two sockets, 2 MPI processes to node2, and so on. For my test
 cases, each has 16 MPI processes, which means that each job is spread out over 8 nodes. Yes, if I were to always load up the entire cluster, I could map the way you suggest, but I am looking for a strategy that gives me optimum performance for small cluster
 loads and for large too.<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D"><o:p>&nbsp;</o:p></span></p>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">Can anyone confirm whether or not it is best to map by socket in cases where you have a light load on your cluster?<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D"><o:p>&nbsp;</o:p></span></p>
<div>
<div style="border:none;border-top:solid #B5C4DF 1.0pt;padding:3.0pt 0in 0in 0in">
<p class="MsoNormal"><b><span style="font-size:10.0pt;font-family:&quot;Tahoma&quot;,&quot;sans-serif&quot;">From:</span></b><span style="font-size:10.0pt;font-family:&quot;Tahoma&quot;,&quot;sans-serif&quot;"> users [mailto:users-bounces@open-mpi.org]
<b>On Behalf Of </b>Jeff Squyres (jsquyres)<br>
<b>Sent:</b> Friday, September 05, 2014 10:37 AM<br>
<b>To:</b> Open MPI User's List<br>
<b>Subject:</b> Re: [OMPI users] How does binding option affect network traffic?<o:p></o:p></span></p>
</div>
</div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">I'm confused, then: why you wouldn't want to minimize the number of servers that a single job runs on?
<o:p></o:p></p>
<div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
<div>
<p class="MsoNormal">I ask because it sounds to me like you're running 12 jobs, each with 1 process per server. &nbsp;And therefore all 12 jobs are running on each server, like this:<o:p></o:p></p>
</div>
<div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
<div>
<p class="MsoNormal"><img width="720" height="540" id="_x0030_6621144-D40A-4E73-A2A1-1169A890A863" src="cid:image001.jpg@01CFC90F.89614760"><o:p></o:p></p>
</div>
<div>
<p class="MsoNormal">With this layout, you're thrashing the server networking resources -- you're forcing the maximum use of the network.<o:p></o:p></p>
</div>
<div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
<div>
<p class="MsoNormal">Why don't you pack the jobs in to as few servers as possible, and therefore use shared memory as much as possible, and as little network as possible? &nbsp;This is the conventional wisdom. &nbsp;...perhaps I'm missing something in your setup?<o:p></o:p></p>
</div>
<div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
<div>
<p class="MsoNormal"><img width="720" height="540" id="_x0038_B69DFDE-A756-4375-A382-9CA8CC49B2B3" src="cid:image002.jpg@01CFC90F.89614760"><o:p></o:p></p>
</div>
<div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
<div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<div>
<p class="MsoNormal"><br>
On Sep 3, 2014, at 10:02 AM, McGrattan, Kevin B. Dr. &lt;<a href="mailto:kevin.mcgrattan@nist.gov">kevin.mcgrattan@nist.gov</a>&gt;&nbsp;wrote:<br>
<br>
<br>
<o:p></o:p></p>
<p class="MsoNormal">No, there are 12 cores per node, and 12 MPI processes are assigned to each node. The&nbsp;total RAM usage is about 10% of available. We suspect that the problem might be the&nbsp;combination of MPI message passing and disk I/O to the master node,
 both of which&nbsp;are handled by Infiniband. But I do not know how to monitor the traffic, and I do&nbsp;not know how much is too much. Ganglia reports Gigabit Ethernet usage, but we're&nbsp;primarily using IB.&nbsp;<br>
<br>
-----Original Message-----<br>
From: users [<a href="mailto:users-bounces@open-mpi.org">mailto:users-bounces@open-mpi.org</a>] On Behalf Of Jeff Squyres (jsquyres)<br>
Sent: Tuesday, September 02, 2014 5:41 PM<br>
To: Open MPI User's List<br>
Subject: Re: [OMPI users] How does binding option affect network traffic?<br>
<br>
Ah, ok -- I think I missed this part of the thread: each of your individual MPI&nbsp;processes suck up huge gobbs of memory.<br>
<br>
So just to be clear, in general: you don't intend to run more MPI processes than&nbsp;cores per server, *and* you intend to run fewer MPI processes per server than would&nbsp;consume the entire amount of RAM.<br>
<br>
Are both of those always correct (at the same time)?<br>
<br>
If so, it sounds like the first runs that you posted about were heavily overloading&nbsp;the servers in terms of RAM usage. &nbsp;Specifically: if you were running out of&nbsp;(registered) RAM, I can understand why Open MPI would hang. &nbsp;We have a few known&nbsp;issues that the
 openib BTL will hang if it runs out of registered memory -- but this&nbsp;is such a small corner case (because no one runs that way) that we've honestly never&nbsp;bothered to fix the issue (it's actually a really complicated resource exhaustion&nbsp;issue -- it's kinda
 hard to know what the Right Thing is to do when you've run out&nbsp;of memory...).<br>
<br>
<br>
<br>
On Sep 2, 2014, at 9:37 AM, McGrattan, Kevin B. Dr. &lt;<a href="mailto:kevin.mcgrattan@nist.gov">kevin.mcgrattan@nist.gov</a>&gt;&nbsp;wrote:<br>
<br>
<br>
<o:p></o:p></p>
<p class="MsoNormal">Thanks for the advice. Our jobs vary in size, from just a few MPI processes to&nbsp;about 64. Jobs are submitted at random, which is why I want to map by socket. If&nbsp;the cluster is empty, and someone submits a job with 16 MPI processes, I would&nbsp;think
 it would run most efficiently if it used 8 nodes, 2 processes per node. If we&nbsp;just fill up two nodes as you suggest, we overload the RAM on those two nodes.<br>
<br>
-----Original Message-----<br>
From: users [<a href="mailto:users-bounces@open-mpi.org">mailto:users-bounces@open-mpi.org</a>] On Behalf Of&nbsp;<a href="mailto:tmishima@jcity.maeda.co.jp">tmishima@jcity.maeda.co.jp</a><br>
Sent: Friday, August 29, 2014 5:24 PM<br>
To: Open MPI Users<br>
Subject: Re: [OMPI users] How does binding option affect network traffic?<br>
<br>
Hi,<br>
<br>
Your cluster is very similar to ours where Torque and OpenMPI is installed.<br>
<br>
I would use this cmd line:<br>
<br>
#PBS -l nodes=2:ppn=12<br>
mpirun --report-bindings -np 16 &lt;executable file name&gt;<br>
<br>
Here --map-by socket:pe=1 and -bind-to core is assumed as default setting.<br>
Then, you can run 10 jobs independently and simultaneously beacause you have 20&nbsp;nodes totally.<br>
<br>
While each node in your cluser has 12 cores, the nprocs per node running on a node&nbsp;is 8, which means 66.666 % use, not 100%.<br>
I think this loss can not be avoided as long as you use 16*N MPI per job.<br>
It's a kind of mismatch with your cluster which has 12 cores per node.<br>
If you can use 12*N MPI per job, then it's most effective.<br>
Is there any reason why you use 16*N MPI per job?<br>
<br>
Tetsuya<br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/08/25201.php">
http://www.open-mpi.org/community/lists/users/2014/08/25201.php</a><br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/09/25220.php">
http://www.open-mpi.org/community/lists/users/2014/09/25220.php</a><o:p></o:p></p>
<p class="MsoNormal"><br>
<br>
--&nbsp;<br>
Jeff Squyres<br>
<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a><br>
For corporate legal information go to:&nbsp;<a href="http://www.cisco.com/web/about/doing_business/legal/cri/">http://www.cisco.com/web/about/doing_business/legal/cri/</a><br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/09/25233.php">
http://www.open-mpi.org/community/lists/users/2014/09/25233.php</a><br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/09/25249.php">
http://www.open-mpi.org/community/lists/users/2014/09/25249.php</a><o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<div>
<p class="MsoNormal"><br>
--&nbsp;<br>
Jeff Squyres<br>
<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a><br>
For corporate legal information go to:&nbsp;<a href="http://www.cisco.com/web/about/doing_business/legal/cri/">http://www.cisco.com/web/about/doing_business/legal/cri/</a><o:p></o:p></p>
</div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
</div>
</div>
</body>
</html>

