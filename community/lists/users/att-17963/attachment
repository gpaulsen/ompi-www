Hi Gustavo, <br><br>Here is the output of : <br>barells@ip-10-17-153-123:~&gt; /opt/openmpi/intel/bin/mpif90 -showme<br>gfortran -I/usr/lib64/mpi/gcc/openmpi/include -pthread -I/usr/lib64/mpi/gcc/openmpi/lib64 -L/usr/lib64/mpi/gcc/openmpi/lib64 -lmpi_f90 -lmpi_f77 -lmpi -lopen-rte -lopen-pal -ldl -Wl,--export-dynamic -lnsl -lutil -lm -ldl<br>
<br>This points to gfortran. <br><br>I do see what you are saying about the 1.4.2 and 1.4.4 components. <br>I&#39;m not sure why that is, but there seems to be some conflict with the existing openmpi, before recently installed 1.4.4 and trying to install with ifort. <br>
<br><br><div class="gmail_quote">On Wed, Dec 14, 2011 at 12:43 PM, Gustavo Correa <span dir="ltr">&lt;<a href="mailto:gus@ldeo.columbia.edu">gus@ldeo.columbia.edu</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
How about the output of this?<br>
<br>
/opt/openmpi/intel/bin/mpif90 -showme<br>
<br>
Anyway, something seems to be wrong with your OpenMPI installation.<br>
Just read the output of your ompi_info in your email below.<br>
You will see that the OpenMPI version is 1.4.4.<br>
However, most components are version 1.4.2.<br>
Do you agree?<br>
<br>
I would download the OpenMPI 1.4.4 tarball again and start fresh.<br>
Untar the tarball in a brand new directory, don&#39;t overwrite old stuff.<br>
Also, every time your OpenMPI build fails, or if you want to change compilers<br>
[say from gfortran to ifort],<br>
do a &#39;make distclean&#39; to cleanup any leftovers of previous builds,<br>
and change the destination directory in --prefix= , to install in a different location.<br>
<div class="im HOEnZb"><br>
I hope this helps,<br>
Gus Correa<br>
<br>
</div><div class="HOEnZb"><div class="h5">On Dec 14, 2011, at 12:21 PM, Micah Sklut wrote:<br>
<br>
&gt; Hi Gustav,<br>
&gt;<br>
&gt; I did read Price&#39;s email:<br>
&gt;<br>
&gt; When I do &quot;which mpif90&quot;, i get:<br>
&gt; /opt/openmpi/intel/bin/mpif90<br>
&gt; which is the desired directory/binary<br>
&gt;<br>
&gt; As I mentioned, the config log file indicated it was using ifort, and had no mention of gfortran.<br>
&gt; Below is the output from ompi_info. It shows reference to the correct ifort compiler. But, yet the mpif90 compiler, still yeilds a gfortran compiler.<br>
&gt; --&gt;<br>
&gt; barells@ip-10-17-153-123:~&gt; ompi_info<br>
&gt;                  Package: Open MPI barells@ip-10-17-148-204 Distribution<br>
&gt;                 Open MPI: 1.4.4<br>
&gt;    Open MPI SVN revision: r25188<br>
&gt;    Open MPI release date: Sep 27, 2011<br>
&gt;                 Open RTE: 1.4.4<br>
&gt;    Open RTE SVN revision: r25188<br>
&gt;    Open RTE release date: Sep 27, 2011<br>
&gt;                     OPAL: 1.4.4<br>
&gt;        OPAL SVN revision: r25188<br>
&gt;        OPAL release date: Sep 27, 2011<br>
&gt;             Ident string: 1.4.4<br>
&gt;                   Prefix: /usr/lib64/mpi/gcc/openmpi<br>
&gt;  Configured architecture: x86_64-unknown-linux-gnu<br>
&gt;           Configure host: ip-10-17-148-204<br>
&gt;            Configured by: barells<br>
&gt;            Configured on: Wed Dec 14 14:22:43 UTC 2011<br>
&gt;           Configure host: ip-10-17-148-204<br>
&gt;                 Built by: barells<br>
&gt;                 Built on: Wed Dec 14 14:27:56 UTC 2011<br>
&gt;               Built host: ip-10-17-148-204<br>
&gt;               C bindings: yes<br>
&gt;             C++ bindings: yes<br>
&gt;       Fortran77 bindings: yes (all)<br>
&gt;       Fortran90 bindings: yes<br>
&gt;  Fortran90 bindings size: small<br>
&gt;               C compiler: gcc<br>
&gt;      C compiler absolute: /usr/bin/gcc<br>
&gt;             C++ compiler: g++<br>
&gt;    C++ compiler absolute: /usr/bin/g++<br>
&gt;       Fortran77 compiler: ifort<br>
&gt;   Fortran77 compiler abs: /opt/intel/fce/9.1.040/bin/ifort<br>
&gt;       Fortran90 compiler: ifort<br>
&gt;   Fortran90 compiler abs: /opt/intel/fce/9.1.040/bin/ifort<br>
&gt;              C profiling: yes<br>
&gt;            C++ profiling: yes<br>
&gt;      Fortran77 profiling: yes<br>
&gt;      Fortran90 profiling: yes<br>
&gt;           C++ exceptions: no<br>
&gt;           Thread support: posix (mpi: no, progress: no)<br>
&gt;            Sparse Groups: no<br>
&gt;   Internal debug support: no<br>
&gt;      MPI parameter check: runtime<br>
&gt; Memory profiling support: no<br>
&gt; Memory debugging support: no<br>
&gt;          libltdl support: yes<br>
&gt;    Heterogeneous support: no<br>
&gt;  mpirun default --prefix: no<br>
&gt;          MPI I/O support: yes<br>
&gt;        MPI_WTIME support: gettimeofday<br>
&gt; Symbol visibility support: yes<br>
&gt;    FT Checkpoint support: no  (checkpoint thread: no)<br>
&gt;            MCA backtrace: execinfo (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;               MCA memory: ptmalloc2 (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;            MCA paffinity: linux (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                MCA carto: auto_detect (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                MCA carto: file (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;            MCA maffinity: first_use (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                MCA timer: linux (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;          MCA installdirs: env (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;          MCA installdirs: config (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA dpm: orte (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;               MCA pubsub: orte (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;            MCA allocator: basic (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;            MCA allocator: bucket (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                 MCA coll: basic (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                 MCA coll: hierarch (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                 MCA coll: inter (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                 MCA coll: self (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                 MCA coll: sm (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                 MCA coll: sync (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                 MCA coll: tuned (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                   MCA io: romio (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                MCA mpool: fake (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                MCA mpool: rdma (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                MCA mpool: sm (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA pml: cm (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA pml: csum (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA pml: ob1 (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA pml: v (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA bml: r2 (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;               MCA rcache: vma (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA btl: ofud (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA btl: openib (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA btl: self (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA btl: sm (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA btl: tcp (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA btl: udapl (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                 MCA topo: unity (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA osc: pt2pt (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA osc: rdma (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA iof: hnp (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA iof: orted (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA iof: tool (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA oob: tcp (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                 MCA odls: default (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA ras: slurm (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                MCA rmaps: load_balance (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                MCA rmaps: rank_file (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                MCA rmaps: round_robin (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                MCA rmaps: seq (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA rml: oob (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;               MCA routed: binomial (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;               MCA routed: direct (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;               MCA routed: linear (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA plm: rsh (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA plm: slurm (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                MCA filem: rsh (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;               MCA errmgr: default (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA ess: env (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA ess: hnp (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA ess: singleton (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA ess: slurm (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;                  MCA ess: tool (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;              MCA grpcomm: bad (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;              MCA grpcomm: basic (MCA v2.0, API v2.0, Component v1.4.2)<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; On Wed, Dec 14, 2011 at 12:11 PM, Gustavo Correa &lt;<a href="mailto:gus@ldeo.columbia.edu">gus@ldeo.columbia.edu</a>&gt; wrote:<br>
&gt; Hi Micah<br>
&gt;<br>
&gt; Did you read Tim Prince&#39;s email to you?  Check it out.<br>
&gt;<br>
&gt; Best thing is to set your environment variables [PATH, LD_LIBRARY_PATH, intel setup]<br>
&gt; in your initialization file, .profile/.bashrc or .[t]cshrc.<br>
&gt;<br>
&gt; What is the output of &#39;ompi_info&#39;? [From your ifort-built OpenMPI.]<br>
&gt; Does it show ifort or gfortran?<br>
&gt;<br>
&gt; I hope this helps,<br>
&gt; Gus Correa<br>
&gt;<br>
&gt; On Dec 14, 2011, at 11:21 AM, Micah Sklut wrote:<br>
&gt;<br>
&gt; &gt; Thanks for your thoughts,<br>
&gt; &gt;<br>
&gt; &gt; It would certainly appear that it is a PATH issue, but I still haven&#39;t figured it out.<br>
&gt; &gt;<br>
&gt; &gt; When I type the ifort command, ifort does run.<br>
&gt; &gt; The intel path is in my PATH and is the first directory listed.<br>
&gt; &gt;<br>
&gt; &gt; Looking at the configure.log, there is nothing indicating use or mentioning of &quot;gfortran&quot;.<br>
&gt; &gt;<br>
&gt; &gt; gfortran is in the /usr/bin directory, which is in the PATH as well.<br>
&gt; &gt;<br>
&gt; &gt; Any other suggestions of things to look for?<br>
&gt; &gt;<br>
&gt; &gt; Thank you,<br>
&gt; &gt;<br>
&gt; &gt; On Wed, Dec 14, 2011 at 11:05 AM, Gustavo Correa &lt;<a href="mailto:gus@ldeo.columbia.edu">gus@ldeo.columbia.edu</a>&gt; wrote:<br>
&gt; &gt; Hi Micah<br>
&gt; &gt;<br>
&gt; &gt; Is  ifort in your PATH?<br>
&gt; &gt; If not, the OpenMPI configure script will use any fortran compiler it finds first, which may be gfortran.<br>
&gt; &gt; You need to run the Intel compiler startup script before you run the OpenMPI configure.<br>
&gt; &gt; The easy thing to do is to source the Intel script inside your .profile/.bashrc or .[t]cshrc file.<br>
&gt; &gt; I hope this helps,<br>
&gt; &gt;<br>
&gt; &gt; Gus Correa<br>
&gt; &gt;<br>
&gt; &gt; On Dec 14, 2011, at 9:49 AM, Micah Sklut wrote:<br>
&gt; &gt;<br>
&gt; &gt; &gt; Hi All,<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; I have installed openmpi for gfortran, but am now attempting to install openmpi as ifort.<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; I have run the following configuration:<br>
&gt; &gt; &gt; ./configure --prefix=/opt/openmpi/intel CC=gcc CXX=g++ F77=ifort FC=ifort<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; The install works successfully, but when I run /opt/openmpi/intel/bin/mpif90, it runs as gfortran.<br>
&gt; &gt; &gt; Oddly, when I am user: root, the same mpif90 runs as ifort.<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; Can someone please alleviate my confusion as to why I mpif90 is not running as ifort?<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; Thank you for your suggestions,<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; --<br>
&gt; &gt; &gt; Micah<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; _______________________________________________<br>
&gt; &gt; &gt; users mailing list<br>
&gt; &gt; &gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; &gt; &gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; &gt;<br>
&gt; &gt;<br>
&gt; &gt; _______________________________________________<br>
&gt; &gt; users mailing list<br>
&gt; &gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; &gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; &gt;<br>
&gt; &gt;<br>
&gt; &gt;<br>
&gt; &gt; --<br>
&gt; &gt; Micah Sklut<br>
&gt; &gt;<br>
&gt; &gt;<br>
&gt; &gt; _______________________________________________<br>
&gt; &gt; users mailing list<br>
&gt; &gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; &gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt;<br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; --<br>
&gt; Micah Sklut<br>
&gt;<br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</div></div></blockquote></div><br><br clear="all"><br>-- <br>Micah Sklut<br><br><br>

