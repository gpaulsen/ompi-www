<html><head><style type="text/css"><!-- DIV {margin:0px;} --></style></head><body><div style="font-family:'times new roman', 'new york', times, serif;font-size:12pt"><div>But, exactly the same program gets different result in another cluster.</div><div>I mean the result doent have any spike at all.</div><div>Second cluster is almost the same features with the previous one except little </div><div>small memory capacity and little low frequency.</div><div>First cluster: 3.0 GHz Intel Xeon, 4GB memory, centOS 4.6, </div><div>Second cluster: 2.8 GHz Intel Xeon, 3GBmemory, Fedora core5</div><div>Openmpi1.3 is used in both cluster.</div><div><br></div><div><br></div><div><br></div><div style="font-family:times new roman, new york, times, serif;font-size:12pt"><br><div style="font-family:times new roman, new york, times, serif;font-size:12pt"><font size="2" face="Tahoma"><hr size="1"><b><span style="font-weight: bold;">From:</span></b> Eugene Loh
 &lt;Eugene.Loh@Sun.COM><br><b><span style="font-weight: bold;">To:</span></b> Open MPI Users &lt;users@open-mpi.org><br><b><span style="font-weight: bold;">Sent:</span></b> Friday, April 24, 2009 1:26:14 AM<br><b><span style="font-weight: bold;">Subject:</span></b> Re: [OMPI users] MPI_Bcast from OpenMPI<br></font><br>



  
  


Okay.  So, going back to Jeff's second surprise, we have 256 Mbyte/2.5
sec = 100 Mbyte/sec = 1 Gbit/sec (sloppy math).  So, without getting
into details of what we're measuring/reporting here, there doesn't on
the face of it appear to be anything wrong with the baseline
performance.  Jeff was right that 256K doubles should have been faster,
but 256 Mbyte... seems reasonable.<br>
<br>
So, the remaining mystery is the 6x or so spike at 128 Mbyte.  Dunno. 
How important is it to resolve that mystery?<br>
<br>
shan axida wrote:
<blockquote type="cite">
  
  <div style="font-family:'times new roman', 'new york', times, serif;font-size:12pt;">
  <div>Sorry, I had a mistake in calculation.</div>
  <div>Not 131072 (double) but 131072 KB.</div>
  <div>It means around 128 MB.</div>
  <div> </div>
  <div style="font-family:times new roman, new york, times, serif;font-size:12pt;"><b><span style="font-weight:bold;">From:</span></b> Jeff Squyres
<a rel="nofollow" class="moz-txt-link-rfc2396E" ymailto="mailto:jsquyres@cisco.com" target="_blank" href="mailto:jsquyres@cisco.com">&lt;jsquyres@cisco.com></a><b><span style="font-weight:bold;"><br>
To:</span></b> Open MPI Users <a rel="nofollow" class="moz-txt-link-rfc2396E" ymailto="mailto:users@open-mpi.org" target="_blank" href="mailto:users@open-mpi.org">&lt;users@open-mpi.org></a><b><span style="font-weight:bold;"><br>
Sent:</span></b> Thursday, April 23, 2009 8:23:52 PM<b><span style="font-weight:bold;"><br>
Subject:</span></b> Re: [OMPI users] MPI_Bcast from OpenMPI<br>
  <div style="font-family:arial, helvetica, sans-serif;font-size:13px;"><br>
Very strange; 6 seconds for a 1MB broadcast over 64 processes is *way*
too long.  Even 2.5 sec at 2MB seems too long</div>
  </div>
  </div>
</blockquote>


</div></div><div style="position:fixed"></div></div><br>

      </body></html>
