<div dir="ltr">Thank you and one last question. Is it possible to avoid a core and instruct OMPI to use only the other cores?</div><div class="gmail_extra"><br><div class="gmail_quote">On Mon, Dec 22, 2014 at 2:08 PM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div style="word-wrap:break-word"><br><div><span class=""><blockquote type="cite"><div>On Dec 22, 2014, at 10:45 AM, Saliya Ekanayake &lt;<a href="mailto:esaliya@gmail.com" target="_blank">esaliya@gmail.com</a>&gt; wrote:</div><br><div><div dir="ltr">Hi Ralph,<div><br></div><div>Yes the report bindings show the correct binding as expected for the processes. The doubt I am having is, say I spawn a thread within my process. If I don&#39;t specify affinity for it, is it possible for it to get scheduled to run in a core outside that of the process? </div></div></div></blockquote><div><br></div></span>It shouldn’t, unless you deliberately unbind it.</div><div><span class=""><br><blockquote type="cite"><div><div dir="ltr"><div><br></div><div>Second question is, does MPI provides an API such that I can retrieve the binding info from program to take decisions on setting thread affinity?</div></div></div></blockquote><div><br></div></span>Nothing specifically in the standard, no. There has been some discussion on this list about ways of getting the info, though they all involve a collective operation. I’m working on an MPI extension for OMPI to access it as each proc already has binding/location info for every proc in the job - just no MPI standard way of providing it to you.</div><div><br></div><div><br><blockquote type="cite"><div><div><div class="h5"><div dir="ltr"><div><br></div><div>Thank you,<br>Saliya</div></div><div class="gmail_extra"><br><div class="gmail_quote">On Mon, Dec 22, 2014 at 1:18 PM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div style="word-wrap:break-word">FWIW: it looks like we are indeed binding to core if PE is set, so if you are seeing something different, then we may have a bug somewhere.<div><br></div><div>If you add —report-bindings to your cmd line, you should see where we bound the procs - does that look correct?</div><div><div><div><br></div><div><br><div><blockquote type="cite"><div>On Dec 22, 2014, at 9:49 AM, Ralph Castain &lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt; wrote:</div><br><div><div style="word-wrap:break-word">They will be bound to whatever level you specified - I believe by default we bind to socket when mapping by socket. If you want them bound to core, you might need to add —bind-to core.<div><br></div><div>I can take a look at it - I *thought* we had reset that to bind-to core when PE=N was specified, but maybe that got lost.</div><div><br><div><br><div><blockquote type="cite"><div>On Dec 22, 2014, at 8:32 AM, Saliya Ekanayake &lt;<a href="mailto:esaliya@gmail.com" target="_blank">esaliya@gmail.com</a>&gt; wrote:</div><br><div><div dir="ltr">Hi,<div><br></div><div>I&#39;ve been using --map-by socket:PE=N, where N is used to control the number of cores a proc gets mapped to. Does this also guarantee that a proc is bound to N cores in the socket? I am asking this because I see some threads spawned by the process run outside the given N cores in the socket.</div><div><br></div><div>Is this expected or I guess I am missing some binding parameter here? Also, is there some documentation on these different choices? Are the options in [1] available in current release?</div><div><br></div><div>[1] <a href="http://www.slideshare.net/jsquyres/open-mpi-explorations-in-process-affinity-eurompi13-presentation" target="_blank">http://www.slideshare.net/jsquyres/open-mpi-explorations-in-process-affinity-eurompi13-presentation</a></div><div><br></div><div>Thank you,<br>Saliya<br clear="all"><div><br></div>-- <br><div><div dir="ltr"><div><div dir="ltr"><div><div dir="ltr"><span style="color:rgb(136,136,136)">Saliya Ekanayake</span></div><div dir="ltr">Ph.D. Candidate | Research Assistant</div><div dir="ltr">School of Informatics and Computing | Digital Science Center</div><div dir="ltr">Indiana University, Bloomington<br><span style="color:rgb(136,136,136)">Cell <a href="tel:812-391-4914" value="+18123914914" target="_blank">812-391-4914</a></span><br style="color:rgb(136,136,136)"><font color="#888888"><a href="http://saliya.org/" target="_blank">http://saliya.org</a></font></div></div></div></div></div></div>
</div></div>
_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/12/26051.php" target="_blank">http://www.open-mpi.org/community/lists/users/2014/12/26051.php</a></div></blockquote></div><br></div></div></div></div></blockquote></div><br></div></div></div></div><br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/12/26054.php" target="_blank">http://www.open-mpi.org/community/lists/users/2014/12/26054.php</a><br></blockquote></div><br><br clear="all"><div><br></div>-- <br><div><div dir="ltr"><div><div dir="ltr"><div><div dir="ltr"><span style="color:rgb(136,136,136)">Saliya Ekanayake</span></div><div dir="ltr">Ph.D. Candidate | Research Assistant</div><div dir="ltr">School of Informatics and Computing | Digital Science Center</div><div dir="ltr">Indiana University, Bloomington<br><span style="color:rgb(136,136,136)">Cell <a href="tel:812-391-4914" value="+18123914914" target="_blank">812-391-4914</a></span><br style="color:rgb(136,136,136)"><font color="#888888"><a href="http://saliya.org/" target="_blank">http://saliya.org</a></font></div></div></div></div></div></div>
</div>
_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></div></div>Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/12/26056.php" target="_blank">http://www.open-mpi.org/community/lists/users/2014/12/26056.php</a></div></blockquote></div><br></div><br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/12/26057.php" target="_blank">http://www.open-mpi.org/community/lists/users/2014/12/26057.php</a><br></blockquote></div><br><br clear="all"><div><br></div>-- <br><div class="gmail_signature"><div dir="ltr"><div><div dir="ltr"><div><div dir="ltr"><span style="color:rgb(136,136,136)">Saliya Ekanayake</span></div><div dir="ltr">Ph.D. Candidate | Research Assistant</div><div dir="ltr">School of Informatics and Computing | Digital Science Center</div><div dir="ltr">Indiana University, Bloomington<br><span style="color:rgb(136,136,136)">Cell 812-391-4914</span><br style="color:rgb(136,136,136)"><font color="#888888"><a href="http://saliya.org" target="_blank">http://saliya.org</a></font></div></div></div></div></div></div>
</div>

