Thanks for your response. The program that I have been using for testing purposes is a simple hello:<br><br><br>#include &lt;stdio.h&gt;<br>&nbsp;<br>#include &lt;mpi.h&gt; <br>&nbsp;<br><br>#include &lt;sys/time.h&gt; <br>#include &lt;sys/resource.h&gt; 
<br>#include &lt;unistd.h&gt; <br>#include &lt;stdio.h&gt;<br>main(int argc, char *argv) <br>{<br>&nbsp; char name[BUFSIZ];<br>&nbsp; int length;<br>&nbsp; int rank;<br>&nbsp; struct rlimit rlim; <br>&nbsp; FILE *output;<br><br>&nbsp; MPI_Init(&amp;argc, &amp;argv);
<br>&nbsp; MPI_Get_processor_name(name, &amp;length);<br>&nbsp; MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);<br>&nbsp; rank = 0;<br>&nbsp; MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank); <br><br>// while(1) {<br>&nbsp; printf(&quot;%s: hello world from rank %d\n&quot;, name, rank);
<br>&nbsp; sleep(1);<br>// }<br>&nbsp; MPI_Finalize();<br>} <br><br>If I run this program not in a slurm environment I get the following<br><br>mpirun -np 4 -mca btl tcp,self -host wolf1,master ./hello<br><br>master: hello world from rank 1
<br>wolf1: hello world from rank 0<br>wolf1: hello world from rank 2<br>master: hello world from rank 3<br><br>This is&nbsp; exactly what I expect. Now if I create a slurm environment using the following:<br><br>srun -n 4 -A<br>
<br>The output of printenv|grep SLRUM gives me:<br><br>SLURM_NODELIST=master,wolf1<br>SLURM_SRUN_COMM_PORT=58929<br>SLURM_MEM_BIND_TYPE=<br>SLURM_CPU_BIND_VERBOSE=quiet<br>SLURM_MEM_BIND_LIST=<br>SLURM_CPU_BIND_LIST=<br>SLURM_NNODES=2
<br>SLURM_JOBID=66135<br>SLURM_TASKS_PER_NODE=2(x2)<br>SLURM_SRUN_COMM_HOST=master<br>SLURM_CPU_BIND_TYPE=<br>SLURM_MEM_BIND_VERBOSE=quiet<br>SLURM_NPROCS=4<br><br>This seems to indicate that both master and wolf1 have been allocated and that each node should run 2 tasks, which is correct since both master and wolf1 are dual processor machines.
<br><br>Now if I run:<br><br>mpirun -np 4 -mca btl tcp,self ./hello<br><br>The output is:<br><br>master: hello world from rank 1<br>master: hello world from rank 2<br>master: hello world from rank 3<br>master: hello world from rank 0
<br><br><br>All four processes are running on master and none on wolf1.<br><br>If I try the following and specify the hosts. I get the following error message.<br><br>mpirun -np 4 -host wolf1,master -mca btl tcp,self ./hello
<br><br>--------------------------------------------------------------------------<br>Some of the requested hosts are not included in the current allocation for the<br>application:<br>&nbsp; ./hello<br>The requested hosts were:
<br>&nbsp; wolf1,master<br><br>Verify that you have mapped the allocated resources properly using the<br>--host specification.<br>--------------------------------------------------------------------------<br>[master:28022] [0,0,0] ORTE_ERROR_LOG: Out of resource in file rmgr_urm.c at line 377
<br>[master:28022] mpirun: spawn failed with errno=-2<br><br><br>I&#39;m at a loss to figure out how to get this working correctly. Any help would be greatly appreciated.<br><br>Bob<br><br><div><span class="gmail_quote">On 1/19/07, 
<b class="gmail_sendername">Ralph Castain</b> &lt;<a href="mailto:rhc@lanl.gov">rhc@lanl.gov</a>&gt; wrote:</span><blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
Open MPI and SLURM should work together just fine right out-of-the-box. The<br>typical command progression is:<br><br>srun -n x -A<br>mpirun -n y .....<br><br><br>If you are doing those commands and still see everything running on the head
<br>node, then two things could be happening:<br><br>(a) you really aren&#39;t getting an allocation from slurm. Perhaps you don&#39;t<br>have slurm setup correctly and aren&#39;t actually seeing the allocation in your<br>
environment. Do a &quot;printenv | grep SLURM&quot; and see if you find the following<br>variables:<br>SLURM_NPROCS=8<br>SLURM_CPU_BIND_VERBOSE=quiet<br>SLURM_CPU_BIND_TYPE=<br>SLURM_CPU_BIND_LIST=<br>SLURM_MEM_BIND_VERBOSE=quiet
<br>SLURM_MEM_BIND_TYPE=<br>SLURM_MEM_BIND_LIST=<br>SLURM_JOBID=47225<br>SLURM_NNODES=2<br>SLURM_NODELIST=odin[013-014]<br>SLURM_TASKS_PER_NODE=4(x2)<br>SLURM_SRUN_COMM_PORT=43206<br>SLURM_SRUN_COMM_HOST=odin<br><br>Obviously, the values will be different, but we really need the
<br>TASKS_PER_NODE and NODELIST ones to be there<br><br>(b) the master node is being included in your nodelist and you aren&#39;t<br>running enough mpi processes to need more nodes (i.e., the number of slots<br>on the master node is greater than or equal to the num procs you requested).
<br>You can force Open MPI to not run on your master node by including<br>&quot;--nolocal&quot; on your command line.<br><br>Of course, if the master node is the only thing on the nodelist, this will<br>cause mpirun to abort as there is nothing else for us to use.
<br><br>Hope that helps<br>Ralph<br><br><br>On 1/18/07 11:03 PM, &quot;Robert Bicknell&quot; &lt;<a href="mailto:robbicknell@gmail.com">robbicknell@gmail.com</a>&gt; wrote:<br><br>&gt; I&#39;m trying to get slurm and openmpi to work together on a debian, two
<br>&gt; node cluster.&nbsp;&nbsp;Slurm and openmpi seem to work fine seperately, but when<br>&gt; I try to run a mpi program in a slurm allocation, all the processes get<br>&gt; run on the master node, and not distributed to the second node. What am
<br>&gt; I doing wrong?<br>&gt;<br>&gt; Bob<br>&gt; _______________________________________________<br>&gt; users mailing list<br>&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">
http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br><br><br>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">
http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></div><br>

