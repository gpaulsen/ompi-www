<table cellspacing="0" cellpadding="0" border="0" ><tr><td valign="top" style="font: inherit;">OK, I think I got things sorted out.&nbsp; Thanx for your inputs.<br><br>Ted<br><br>--- On <b>Fri, 2/6/09, Jeff Squyres <i>&lt;jsquyres@cisco.com&gt;</i></b> wrote:<br><blockquote style="border-left: 2px solid rgb(16, 16, 255); margin-left: 5px; padding-left: 5px;">From: Jeff Squyres &lt;jsquyres@cisco.com&gt;<br>Subject: Re: [OMPI users] Global Communicator<br>To: "Open MPI Users" &lt;users@open-mpi.org&gt;<br>Cc: tedhyu@wag.caltech.edu<br>Date: Friday, February 6, 2009, 2:46 PM<br><br><pre>On Feb 6, 2009, at 11:59 AM, McCalla, Mac wrote:<br><br>&gt; Does the "default mpirun command" implementation match the build<br>environment for quest_ompi.x ?<br>&gt; ie., what mpi implementation (mpich, LAM/MPI, OPENMPI, or other) was<br>quest_ompi.x  compiled/linked with? and does that match the result of<br>"which mpirun"?  You might try running a job using your PBS
 system<br>that simply executes the which mpirun command and see what you get.<br><br>Mac is dead-on in his analysis.<br><br>You must compile your MPI application with exactly the same MPI implementation<br>that you run it -- there is currently no binary compatibility between MPI<br>implementations.  So if you compile your MPI application with Open MPI, then you<br>must run it with Open MPI's mpirun/mpiexec (which, as the man page notes,<br>are exact synonyms of each other in Open MPI -- this is not necessarily true in<br>other MPI implementations).<br><br>If you compile your application with MPICH, then you must use MPICH's<br>mpirun/mpiexec -- and you'll need to ask them for help if things don't<br>work (i.e., it's an entirely different project and we're not qualified<br>to give you help with their software).<br><br>Finally, note that Open MPI "understands" PBS/Torque.  If your system<br>administrator build Open MPI with PBS/Torque support, you don't
 need to list<br>the hostfile on Open MPI's mpirun/mpiexec command line -- Open MPI will<br>"just figure it out" and know a) what hosts to use and b) how many<br>processes to launch.  Specifically, you can use this:<br><br>     mpiexec ${CODE} &gt;/ul/tedhyu/fuelcell/HOH/test/HH.out<br><br>(or, as Mac suggests, you might want to provide a full path name to mpiexec to<br>ensure that you're getting the "Right" mpiexec)<br><br>You can check your Open MPI installation to see if it has PBS/Torque support<br>with the following:<br><br>    ompi_info | grep tm<br><br>If you see anything in the output like this (although the exact version numbers<br>may be different):<br><br>                 MCA ras: tm (MCA v2.0, API v2.0, Component v1.4)<br><br>then your Open MPI has this native PBS/Torque support built-in and you can<br>avoid specifying a hostfile and -np arguments.<br><br>--Jeff Squyres<br>Cisco Systems<br><br></pre></blockquote></td></tr></table><br>

      
