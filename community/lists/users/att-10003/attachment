
<br><font size=2 face="sans-serif">I think it unlikely that its a time
limit thing. Firstly, slurm is set up with no time limit on jobs, and we
get the same behaviour whether or not slurm is in the picture.</font>
<br><font size=2 face="sans-serif">In addition, we've run several other
much larger jobs with a greater number of permutations and they complete
fine.</font>
<br>
<br><font size=2 face="sans-serif">This job takes about 5-10 minutes to
run. We've run jobs that take a week or more and the indivdual R process
can be seen to run for days at a time and they run fine.</font>
<br>
<br><font size=2 face="sans-serif">In addition, I'd find it hard to believe
(although I concede the possibility) that jobs entirely self-contained
within the same box run slower that jobs which span 2 boxes over the network.
(14 cpus vs 17 cpus for example).</font>
<br>
<br>
<br><font size=2 face="sans-serif">____________________<br>
Steve Dale<br>
Senior Platform Analyst<br>
Health Canada<br>
Phone: (613)-948-4910<br>
E-mail: steven_dale@hc-sc.gc.ca</font>
<br>
<br>
<br>
<table width=100%>
<tr valign=top>
<td width=40%><font size=1 face="sans-serif"><b>Ralph Castain &lt;rhc@open-mpi.org&gt;</b>
</font>
<br><font size=1 face="sans-serif">Sent by: users-bounces@open-mpi.org</font>
<p><font size=1 face="sans-serif">07/17/2009 01:13 AM</font>
<table border>
<tr valign=top>
<td bgcolor=white>
<div align=center><font size=1 face="sans-serif">Please respond to<br>
Open MPI Users &lt;users@open-mpi.org&gt;</font></div></table>
<br>
<td width=59%>
<table width=100%>
<tr valign=top>
<td>
<div align=right><font size=1 face="sans-serif">To</font></div>
<td><font size=1 face="sans-serif">Open MPI Users &lt;users@open-mpi.org&gt;</font>
<tr valign=top>
<td>
<div align=right><font size=1 face="sans-serif">cc</font></div>
<td>
<tr valign=top>
<td>
<div align=right><font size=1 face="sans-serif">Subject</font></div>
<td><font size=1 face="sans-serif">Re: [OMPI users] Possible openmpi bug?</font></table>
<br>
<table>
<tr valign=top>
<td>
<td></table>
<br></table>
<br>
<br>
<br><font size=3>From what I can see, it looks like your job is being terminated
- something is killing mpirun. Is it possible that the job runs slowly
enough on 14 or less cpus that it simply isn't completing within your specified
time limit?</font>
<br>
<br><font size=3>The lifeline message simply indicates that a process self-aborted
because it lost contact with its local daemon - in this case, mpirun (as
that is always daemon 0) - which means that the daemon was terminated for
some reason.</font>
<br>
<br>
<br><font size=3>On Jul 16, 2009, at 11:15 AM, Steven Dale wrote:</font>
<br>
<br><font size=2 face="sans-serif"><br>
Here is my situation:</font><font size=3> <br>
</font><font size=2 face="sans-serif"><br>
2 Dell R900's with 16 cpus each and 64 GB RAM</font><font size=3> </font><font size=2 face="sans-serif"><br>
OS: SuSE SLES 10 SP2 patched up to date</font><font size=3> </font><font size=2 face="sans-serif"><br>
R version 2.9.1</font><font size=3> </font><font size=2 face="sans-serif"><br>
Rmpi version 0.5-7</font><font size=3> </font><font size=2 face="sans-serif"><br>
snow version 0.3-3</font><font size=3> </font><font size=2 face="sans-serif"><br>
maanova library version 1.14.0</font><font size=3> </font><font size=2 face="sans-serif"><br>
openmpi version 1.3.3</font><font size=3> </font><font size=2 face="sans-serif"><br>
slurm version 2.0.3</font><font size=3> <br>
</font><font size=2 face="sans-serif"><br>
With a given set of R code, we get abnormal exits when using 14 or less
cpus. When using 15 or more, the job completes normally. <br>
error is a variation on: </font><font size=3><br>
</font><font size=2 face="sans-serif"><br>
[pdp-dev-r01:22618] [[15549,1],0] routed:binomial: Connection to lifeline
[[15549,0],0] lost</font><font size=3> <br>
</font><font size=2 face="sans-serif"><br>
during the array permutations.</font><font size=3> <br>
</font><font size=2 face="sans-serif"><br>
Increasing the number of permutations above 200 also produces similar results.
</font><font size=3><br>
</font><font size=2 face="sans-serif"><br>
The R code is executed with a typical command line for 14 cpus being:</font><font size=3>
<br>
</font><font size=2 face="sans-serif"><br>
sbatch -n 14 -i ./Rtest.txt --mail-type=ALL </font><a href="mailto:--mail-user=steven_dale@hc-sc.gc.ca"><font size=2 color=blue face="sans-serif"><u>--mail-user=steven_dale@hc-sc.gc.ca</u></font></a><font size=2 face="sans-serif">
/usr/local/bin/R --no-save</font><font size=3> <br>
<br>
</font><font size=2 face="sans-serif"><br>
Config.log, ompi_info, Rscript.txt and slurm outputs are attached. Network
is GB Ethernet copper tcp/ip.</font><font size=3> <br>
<br>
</font><font size=2 face="sans-serif"><br>
I think this to be an openmpi error/bug due to the routed:binomial message.
This also had the same results with openmpi-1.3.2, R 2.9.0, maanova 1.12
and slurm 2.0.1.</font><font size=3> <br>
<br>
</font><font size=2 face="sans-serif"><br>
No non-default MCA parameters are set.</font><font size=3> <br>
</font><font size=2 face="sans-serif"><br>
LD_LIBRARY_PATH=/usr/local/lib.</font><font size=3> <br>
</font><font size=2 face="sans-serif"><br>
Configuration done with defaults.</font><font size=3> <br>
</font><font size=2 face="sans-serif"><br>
Any ideas are welcome.</font><font size=3> <br>
<br>
<br>
<br>
</font><font size=2 face="sans-serif"><br>
____________________<br>
Steve Dale</font><font size=3><br>
&lt;bugrep.tar.bz2&gt;_______________________________________________<br>
users mailing list</font><font size=3 color=blue><u><br>
</u></font><a href="mailto:users@open-mpi.org"><font size=3 color=blue><u>users@open-mpi.org</u></font></a><font size=3><br>
http://www.open-mpi.org/mailman/listinfo.cgi/users</font>
<br><font size=2><tt>_______________________________________________<br>
users mailing list<br>
users@open-mpi.org<br>
http://www.open-mpi.org/mailman/listinfo.cgi/users</tt></font>
<br>
