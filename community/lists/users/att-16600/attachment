<html>
<head>
<style><!--
.hmmessage P
{
margin:0px;
padding:0px
}
body.hmmessage
{
font-size: 10pt;
font-family:Tahoma
}
--></style>
</head>
<body class='hmmessage'>
"MPI can get through your firewall, right?"<BR><BR>
As far as I can tell the firewall is not the problem - have tried it with firewalls disabled, automatic fw polices based on port requests from MPI, and with manual exception policies.&nbsp;<BR>&nbsp;<BR>
&gt; From: users-request@open-mpi.org<BR>&gt; Subject: users Digest, Vol 1911, Issue 4<BR>&gt; To: users@open-mpi.org<BR>&gt; Date: Fri, 20 May 2011 14:58:40 -0400<BR>&gt; <BR>&gt; Send users mailing list submissions to<BR>&gt; users@open-mpi.org<BR>&gt; <BR>&gt; To subscribe or unsubscribe via the World Wide Web, visit<BR>&gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; or, via email, send a message with subject or body 'help' to<BR>&gt; users-request@open-mpi.org<BR>&gt; <BR>&gt; You can reach the person managing the list at<BR>&gt; users-owner@open-mpi.org<BR>&gt; <BR>&gt; When replying, please edit your Subject line so it is more specific<BR>&gt; than "Re: Contents of users digest..."<BR>&gt; <BR>&gt; <BR>&gt; Today's Topics:<BR>&gt; <BR>&gt; 1. Re: v1.5.3-x64 does not work on Windows 7 workgroup (Damien)<BR>&gt; <BR>&gt; <BR>&gt; ----------------------------------------------------------------------<BR>&gt; <BR>&gt; Message: 1<BR>&gt; Date: Fri, 20 May 2011 12:58:21 -0600<BR>&gt; From: Damien &lt;damien@khubla.com&gt;<BR>&gt; Subject: Re: [OMPI users] v1.5.3-x64 does not work on Windows 7<BR>&gt; workgroup<BR>&gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; Message-ID: &lt;4DD6B9CD.8060505@khubla.com&gt;<BR>&gt; Content-Type: text/plain; charset="iso-8859-1"; Format="flowed"<BR>&gt; <BR>&gt; MPI can get through your firewall, right?<BR>&gt; <BR>&gt; Damien<BR>&gt; <BR>&gt; On 20/05/2011 12:53 PM, Jason Mackay wrote:<BR>&gt; &gt; I have verified that disabling UAC does not fix the problem. xhlp.exe <BR>&gt; &gt; starts, threads spin up on both machines, CPU usage is at 80-90% but <BR>&gt; &gt; no progress is ever made.<BR>&gt; &gt;<BR>&gt; &gt; &gt;From this state, Ctrl-break on the head node yields the following output:<BR>&gt; &gt;<BR>&gt; &gt; [REMOTEMACHINE:02032] [[20816,1],0]-[[20816,0],0] <BR>&gt; &gt; mca_oob_tcp_msg_recv: readv failed: Unknown error (108)<BR>&gt; &gt; [REMOTEMACHINE:05064] [[20816,1],1]-[[20816,0],0] <BR>&gt; &gt; mca_oob_tcp_msg_recv: readv failed: Unknown error (108)<BR>&gt; &gt; [REMOTEMACHINE:05420] [[20816,1],2]-[[20816,0],0] <BR>&gt; &gt; mca_oob_tcp_msg_recv: readv failed: Unknown error (108)<BR>&gt; &gt; [REMOTEMACHINE:03852] [[20816,1],3]-[[20816,0],0] <BR>&gt; &gt; mca_oob_tcp_msg_recv: readv failed: Unknown error (108)<BR>&gt; &gt; [REMOTEMACHINE:05436] [[20816,1],4]-[[20816,0],0] <BR>&gt; &gt; mca_oob_tcp_msg_recv: readv failed: Unknown error (108)<BR>&gt; &gt; [REMOTEMACHINE:04416] [[20816,1],5]-[[20816,0],0] <BR>&gt; &gt; mca_oob_tcp_msg_recv: readv failed: Unknown error (108)<BR>&gt; &gt; [REMOTEMACHINE:02032] [[20816,1],0] routed:binomial: Connection to <BR>&gt; &gt; lifeline [[20816,0],0] lost<BR>&gt; &gt; [REMOTEMACHINE:05064] [[20816,1],1] routed:binomial: Connection to <BR>&gt; &gt; lifeline [[20816,0],0] lost<BR>&gt; &gt; [REMOTEMACHINE:05420] [[20816,1],2] routed:binomial: Connection to <BR>&gt; &gt; lifeline [[20816,0],0] lost<BR>&gt; &gt; [REMOTEMACHINE:03852] [[20816,1],3] routed:binomial: Connection to <BR>&gt; &gt; lifeline [[20816,0],0] lost<BR>&gt; &gt; [REMOTEMACHINE:05436] [[20816,1],4] routed:binomial: Connection to <BR>&gt; &gt; lifeline [[20816,0],0] lost<BR>&gt; &gt; [REMOTEMACHINE:04416] [[20816,1],5] routed:binomial: Connection to <BR>&gt; &gt; lifeline [[20816,0],0] lost<BR>&gt; &gt;<BR>&gt; &gt;<BR>&gt; &gt;<BR>&gt; &gt; &gt; From: users-request@open-mpi.org<BR>&gt; &gt; &gt; Subject: users Digest, Vol 1911, Issue 1<BR>&gt; &gt; &gt; To: users@open-mpi.org<BR>&gt; &gt; &gt; Date: Fri, 20 May 2011 08:14:13 -0400<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Send users mailing list submissions to<BR>&gt; &gt; &gt; users@open-mpi.org<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; To subscribe or unsubscribe via the World Wide Web, visit<BR>&gt; &gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt; or, via email, send a message with subject or body 'help' to<BR>&gt; &gt; &gt; users-request@open-mpi.org<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; You can reach the person managing the list at<BR>&gt; &gt; &gt; users-owner@open-mpi.org<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; When replying, please edit your Subject line so it is more specific<BR>&gt; &gt; &gt; than "Re: Contents of users digest..."<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Today's Topics:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; 1. Re: Error: Entry Point Not Found (Zhangping Wei)<BR>&gt; &gt; &gt; 2. Re: Problem with MPI_Request, MPI_Isend/recv and<BR>&gt; &gt; &gt; MPI_Wait/Test (George Bosilca)<BR>&gt; &gt; &gt; 3. Re: v1.5.3-x64 does not work on Windows 7 workgroup (Jeff Squyres)<BR>&gt; &gt; &gt; 4. Re: Error: Entry Point Not Found (Jeff Squyres)<BR>&gt; &gt; &gt; 5. Re: openmpi (1.2.8 or above) and Intel composer XE 2011 (aka<BR>&gt; &gt; &gt; 12.0) (Jeff Squyres)<BR>&gt; &gt; &gt; 6. Re: Openib with &gt; 32 cores per node (Jeff Squyres)<BR>&gt; &gt; &gt; 7. Re: MPI_COMM_DUP freeze with OpenMPI 1.4.1 (Jeff Squyres)<BR>&gt; &gt; &gt; 8. Re: Trouble with MPI-IO (Jeff Squyres)<BR>&gt; &gt; &gt; 9. Re: Trouble with MPI-IO (Tom Rosmond)<BR>&gt; &gt; &gt; 10. Re: Problem with MPI_Request, MPI_Isend/recv and<BR>&gt; &gt; &gt; MPI_Wait/Test (David B?ttner)<BR>&gt; &gt; &gt; 11. Re: Trouble with MPI-IO (Jeff Squyres)<BR>&gt; &gt; &gt; 12. Re: MPI_Alltoallv function crashes when np &gt; 100 (Jeff Squyres)<BR>&gt; &gt; &gt; 13. Re: MPI_ERR_TRUNCATE with MPI_Allreduce() error, but only<BR>&gt; &gt; &gt; sometimes... (Jeff Squyres)<BR>&gt; &gt; &gt; 14. Re: Trouble with MPI-IO (Jeff Squyres)<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ----------------------------------------------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 1<BR>&gt; &gt; &gt; Date: Thu, 19 May 2011 09:13:53 -0700 (PDT)<BR>&gt; &gt; &gt; From: Zhangping Wei &lt;zhangping_wei@yahoo.com&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] Error: Entry Point Not Found<BR>&gt; &gt; &gt; To: users@open-mpi.org<BR>&gt; &gt; &gt; Message-ID: &lt;101342.7961.qm@web111818.mail.gq1.yahoo.com&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset="gb2312"<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Dear Paul,<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; I checked the way 'mpirun -np N &lt;cmd&gt;' you mentioned, but it was the <BR>&gt; &gt; same<BR>&gt; &gt; &gt; problem.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; I guess it may related to the system I used, because I have used it <BR>&gt; &gt; correctly in<BR>&gt; &gt; &gt; another XP 32 bit system.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; I look forward to more advice.Thanks.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Zhangping<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ________________________________<BR>&gt; &gt; &gt; ???????? "users-request@open-mpi.org" &lt;users-request@open-mpi.org&gt;<BR>&gt; &gt; &gt; ???????? users@open-mpi.org<BR>&gt; &gt; &gt; ?????????? 2011/5/19 (????) 11:00:02 ????<BR>&gt; &gt; &gt; ?? ???? users Digest, Vol 1910, Issue 2<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Send users mailing list submissions to<BR>&gt; &gt; &gt; users@open-mpi.org<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; To subscribe or unsubscribe via the World Wide Web, visit<BR>&gt; &gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt; or, via email, send a message with subject or body 'help' to<BR>&gt; &gt; &gt; users-request@open-mpi.org<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; You can reach the person managing the list at<BR>&gt; &gt; &gt; users-owner@open-mpi.org<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; When replying, please edit your Subject line so it is more specific<BR>&gt; &gt; &gt; than "Re: Contents of users digest..."<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Today's Topics:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; 1. Re: Error: Entry Point Not Found (Paul van der Walt)<BR>&gt; &gt; &gt; 2. Re: Openib with &gt; 32 cores per node (Robert Horton)<BR>&gt; &gt; &gt; 3. Re: Openib with &gt; 32 cores per node (Samuel K. Gutierrez)<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ----------------------------------------------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 1<BR>&gt; &gt; &gt; Date: Thu, 19 May 2011 16:14:02 +0100<BR>&gt; &gt; &gt; From: Paul van der Walt &lt;paul@denknerd.nl&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] Error: Entry Point Not Found<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;BANLkTinjZ0CNtchQJCZYhfGSnR51jPuP7w@mail.gmail.com&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset=UTF-8<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Hi,<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On 19 May 2011 15:54, Zhangping Wei &lt;zhangping_wei@yahoo.com&gt; wrote:<BR>&gt; &gt; &gt; &gt; 4, I use command window to run it in this way: ?mpirun ?n 4 <BR>&gt; &gt; ?**.exe ?,then I<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Probably not the problem, but shouldn't that be 'mpirun -np N &lt;cmd&gt;' ?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Paul<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; --<BR>&gt; &gt; &gt; O&lt; ascii ribbon campaign - stop html mail - www.asciiribbon.org<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 2<BR>&gt; &gt; &gt; Date: Thu, 19 May 2011 16:37:56 +0100<BR>&gt; &gt; &gt; From: Robert Horton &lt;r.horton@qmul.ac.uk&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] Openib with &gt; 32 cores per node<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;1305819476.9663.148.camel@moelwyn&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset="UTF-8"<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On Thu, 2011-05-19 at 08:27 -0600, Samuel K. Gutierrez wrote:<BR>&gt; &gt; &gt; &gt; Hi,<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Try the following QP parameters that only use shared receive queues.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; -mca btl_openib_receive_queues S,12288,128,64,32:S,65536,128,64,32<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Thanks for that. If I run the job over 2 x 48 cores it now works and the<BR>&gt; &gt; &gt; performance seems reasonable (I need to do some more tuning) but when I<BR>&gt; &gt; &gt; go up to 4 x 48 cores I'm getting the same problem:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; <BR>&gt; &gt; [compute-1-7.local][[14383,1],86][../../../../../ompi/mca/btl/openib/connect/btl_openib_connect_oob.c:464:qp_create_one]<BR>&gt; &gt; &gt; error creating qp errno says Cannot allocate memory<BR>&gt; &gt; &gt; [compute-1-7.local:18106] *** An error occurred in MPI_Isend<BR>&gt; &gt; &gt; [compute-1-7.local:18106] *** on communicator MPI_COMM_WORLD<BR>&gt; &gt; &gt; [compute-1-7.local:18106] *** MPI_ERR_OTHER: known error not in list<BR>&gt; &gt; &gt; [compute-1-7.local:18106] *** MPI_ERRORS_ARE_FATAL (your MPI job <BR>&gt; &gt; will now abort)<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Any thoughts?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Thanks,<BR>&gt; &gt; &gt; Rob<BR>&gt; &gt; &gt; --<BR>&gt; &gt; &gt; Robert Horton<BR>&gt; &gt; &gt; System Administrator (Research Support) - School of Mathematical <BR>&gt; &gt; Sciences<BR>&gt; &gt; &gt; Queen Mary, University of London<BR>&gt; &gt; &gt; r.horton@qmul.ac.uk - +44 (0) 20 7882 7345<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 3<BR>&gt; &gt; &gt; Date: Thu, 19 May 2011 09:59:13 -0600<BR>&gt; &gt; &gt; From: "Samuel K. Gutierrez" &lt;samuel@lanl.gov&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] Openib with &gt; 32 cores per node<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;B3E83138-9AF0-48C0-871C-DBBB2E712E12@lanl.gov&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset=us-ascii<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Hi,<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On May 19, 2011, at 9:37 AM, Robert Horton wrote<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; On Thu, 2011-05-19 at 08:27 -0600, Samuel K. Gutierrez wrote:<BR>&gt; &gt; &gt; &gt;&gt; Hi,<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; Try the following QP parameters that only use shared receive queues.<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; -mca btl_openib_receive_queues S,12288,128,64,32:S,65536,128,64,32<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Thanks for that. If I run the job over 2 x 48 cores it now works <BR>&gt; &gt; and the<BR>&gt; &gt; &gt; &gt; performance seems reasonable (I need to do some more tuning) but <BR>&gt; &gt; when I<BR>&gt; &gt; &gt; &gt; go up to 4 x 48 cores I'm getting the same problem:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; <BR>&gt; &gt; &gt;[compute-1-7.local][[14383,1],86][../../../../../ompi/mca/btl/openib/connect/btl_openib_connect_oob.c:464:qp_create_one]<BR>&gt; &gt; &gt; &gt;] error creating qp errno says Cannot allocate memory<BR>&gt; &gt; &gt; &gt; [compute-1-7.local:18106] *** An error occurred in MPI_Isend<BR>&gt; &gt; &gt; &gt; [compute-1-7.local:18106] *** on communicator MPI_COMM_WORLD<BR>&gt; &gt; &gt; &gt; [compute-1-7.local:18106] *** MPI_ERR_OTHER: known error not in list<BR>&gt; &gt; &gt; &gt; [compute-1-7.local:18106] *** MPI_ERRORS_ARE_FATAL (your MPI job <BR>&gt; &gt; will now<BR>&gt; &gt; &gt; &gt;abort)<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Any thoughts?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; How much memory does each node have? Does this happen at startup?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Try adding:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; -mca btl_openib_cpc_include rdmacm<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; I'm not sure if your version of OFED supports this feature, but <BR>&gt; &gt; maybe using XRC<BR>&gt; &gt; &gt; may help. I **think** other tweaks are needed to get this going, but <BR>&gt; &gt; I'm not<BR>&gt; &gt; &gt; familiar with the details.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Hope that helps,<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Samuel K. Gutierrez<BR>&gt; &gt; &gt; Los Alamos National Laboratory<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Thanks,<BR>&gt; &gt; &gt; &gt; Rob<BR>&gt; &gt; &gt; &gt; --<BR>&gt; &gt; &gt; &gt; Robert Horton<BR>&gt; &gt; &gt; &gt; System Administrator (Research Support) - School of Mathematical <BR>&gt; &gt; Sciences<BR>&gt; &gt; &gt; &gt; Queen Mary, University of London<BR>&gt; &gt; &gt; &gt; r.horton@qmul.ac.uk - +44 (0) 20 7882 7345<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; _______________________________________________<BR>&gt; &gt; &gt; &gt; users mailing list<BR>&gt; &gt; &gt; &gt; users@open-mpi.org<BR>&gt; &gt; &gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; _______________________________________________<BR>&gt; &gt; &gt; users mailing list<BR>&gt; &gt; &gt; users@open-mpi.org<BR>&gt; &gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; End of users Digest, Vol 1910, Issue 2<BR>&gt; &gt; &gt; **************************************<BR>&gt; &gt; &gt; -------------- next part --------------<BR>&gt; &gt; &gt; HTML attachment scrubbed and removed<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 2<BR>&gt; &gt; &gt; Date: Thu, 19 May 2011 08:48:03 -0800<BR>&gt; &gt; &gt; From: George Bosilca &lt;bosilca@eecs.utk.edu&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] Problem with MPI_Request, MPI_Isend/recv and<BR>&gt; &gt; &gt; MPI_Wait/Test<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;FCAC66F9-FDB5-48BB-A800-263D8A4F9337@eecs.utk.edu&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset=iso-8859-1<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; David,<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; I do not see any mechanism for protecting the accesses to the <BR>&gt; &gt; requests to a single thread? What is the thread model you're using?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;From an implementation perspective, your code is correct only if <BR>&gt; &gt; you initialize the MPI library with MPI_THREAD_MULTIPLE and if the <BR>&gt; &gt; library accepts. Otherwise, there is an assumption that the <BR>&gt; &gt; application is single threaded, or that the MPI behavior is <BR>&gt; &gt; implementation dependent. Please read the MPI standard regarding to <BR>&gt; &gt; MPI_Init_thread for more details.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Regards,<BR>&gt; &gt; &gt; george.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On May 19, 2011, at 02:34 , David B?ttner wrote:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Hello,<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I am working on a hybrid MPI (OpenMPI 1.4.3) and Pthread code. I <BR>&gt; &gt; am using MPI_Isend and MPI_Irecv for communication and <BR>&gt; &gt; MPI_Test/MPI_Wait to check if it is done. I do this repeatedly in the <BR>&gt; &gt; outer loop of my code. The MPI_Test is used in the inner loop to check <BR>&gt; &gt; if some function can be called which depends on the received data.<BR>&gt; &gt; &gt; &gt; The program regularly crashed (only when not using printf...) and <BR>&gt; &gt; after debugging it I figured out the following problem:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; In MPI_Isend I have an invalid read of memory. I fixed the problem <BR>&gt; &gt; with not re-using a<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; MPI_Request req_s, req_r;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; but by using<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; MPI_Request* req_s;<BR>&gt; &gt; &gt; &gt; MPI_Request* req_r<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; and re-allocating them before the MPI_Isend/recv.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; The documentation says, that in MPI_Wait and MPI_Test (if <BR>&gt; &gt; successful) the request-objects are deallocated and set to <BR>&gt; &gt; MPI_REQUEST_NULL.<BR>&gt; &gt; &gt; &gt; It also says, that in MPI_Isend and MPI_Irecv, it allocates the <BR>&gt; &gt; Objects and associates it with the request object.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; As I understand this, this either means I can use a pointer to <BR>&gt; &gt; MPI_Request which I don't have to initialize for this (it doesn't work <BR>&gt; &gt; but crashes), or that I can use a MPI_Request pointer which I have <BR>&gt; &gt; initialized with malloc(sizeof(MPI_REQUEST)) (or passing the address <BR>&gt; &gt; of a MPI_Request req), which is set and unset in the functions. But <BR>&gt; &gt; this version crashes, too.<BR>&gt; &gt; &gt; &gt; What works is using a pointer, which I allocate before the <BR>&gt; &gt; MPI_Isend/recv and which I free after MPI_Wait in every iteration. In <BR>&gt; &gt; other words: It only uses if I don't reuse any kind of MPI_Request. <BR>&gt; &gt; Only if I recreate one every time.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Is this, what is should be like? I believe that a reuse of the <BR>&gt; &gt; memory would be a lot more efficient (less calls to malloc...). Am I <BR>&gt; &gt; missing something here? Or am I doing something wrong?<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Let me provide some more detailed information about my problem:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I am running the program on a 30 node infiniband cluster. Each <BR>&gt; &gt; node has 4 single core Opteron CPUs. I am running 1 MPI Rank per node <BR>&gt; &gt; and 4 threads per rank (-&gt; one thread per core).<BR>&gt; &gt; &gt; &gt; I am compiling with mpicc of OpenMPI using gcc below.<BR>&gt; &gt; &gt; &gt; Some pseudo-code of the program can be found at the end of this <BR>&gt; &gt; e-mail.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I was able to reproduce the problem using different amount of <BR>&gt; &gt; nodes and even using one node only. The problem does not arise when I <BR>&gt; &gt; put printf-debugging information into the code. This pointed me into <BR>&gt; &gt; the direction that I have some memory problem, where some write <BR>&gt; &gt; accesses some memory it is not supposed to.<BR>&gt; &gt; &gt; &gt; I ran the tests using valgrind with --leak-check=full and <BR>&gt; &gt; --show-reachable=yes, which pointed me either to MPI_Isend or MPI_Wait <BR>&gt; &gt; depending on whether I had the threads spin in a loop for MPI_Test to <BR>&gt; &gt; return success or used MPI_Wait respectively.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I would appreciate your help with this. Am I missing something <BR>&gt; &gt; important here? Is there a way to re-use the request in the different <BR>&gt; &gt; iterations other than I thought it should work?<BR>&gt; &gt; &gt; &gt; Or is there a way to re-initialize the allocated memory before the <BR>&gt; &gt; MPI_Isend/recv so that I at least don't have to call free and malloc <BR>&gt; &gt; each time?<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Thank you very much for your help!<BR>&gt; &gt; &gt; &gt; Kind regards,<BR>&gt; &gt; &gt; &gt; David B?ttner<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; _____________________<BR>&gt; &gt; &gt; &gt; Pseudo-Code of program:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; MPI_Request* req_s;<BR>&gt; &gt; &gt; &gt; MPI_Request* req_w;<BR>&gt; &gt; &gt; &gt; OUTER-LOOP<BR>&gt; &gt; &gt; &gt; if(0 == threadid)<BR>&gt; &gt; &gt; &gt; {<BR>&gt; &gt; &gt; &gt; req_s = malloc(sizeof(MPI_Request));<BR>&gt; &gt; &gt; &gt; req_r = malloc(sizeof(MPI_Request));<BR>&gt; &gt; &gt; &gt; MPI_Isend(..., req_s)<BR>&gt; &gt; &gt; &gt; MPI_Irecv(..., req_r)<BR>&gt; &gt; &gt; &gt; }<BR>&gt; &gt; &gt; &gt; pthread_barrier<BR>&gt; &gt; &gt; &gt; INNER-LOOP (while NOT_DONE or RET)<BR>&gt; &gt; &gt; &gt; if(TRYLOCK &amp;&amp; NOT_DONE)<BR>&gt; &gt; &gt; &gt; {<BR>&gt; &gt; &gt; &gt; if(MPI_TEST(req_r))<BR>&gt; &gt; &gt; &gt; {<BR>&gt; &gt; &gt; &gt; Call_Function_A;<BR>&gt; &gt; &gt; &gt; NOT_DONE = 0;<BR>&gt; &gt; &gt; &gt; }<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; }<BR>&gt; &gt; &gt; &gt; RET = Call_Function_B;<BR>&gt; &gt; &gt; &gt; }<BR>&gt; &gt; &gt; &gt; pthread_barrier_wait<BR>&gt; &gt; &gt; &gt; if(0 == threadid)<BR>&gt; &gt; &gt; &gt; {<BR>&gt; &gt; &gt; &gt; MPI_WAIT(req_s)<BR>&gt; &gt; &gt; &gt; MPI_WAIT(req_r)<BR>&gt; &gt; &gt; &gt; free(req_s);<BR>&gt; &gt; &gt; &gt; free(req_r);<BR>&gt; &gt; &gt; &gt; }<BR>&gt; &gt; &gt; &gt; _____________<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; --<BR>&gt; &gt; &gt; &gt; David B?ttner, Informatik, Technische Universit?t M?nchen<BR>&gt; &gt; &gt; &gt; TUM I-10 - FMI 01.06.059 - Tel. 089 / 289-17676<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; _______________________________________________<BR>&gt; &gt; &gt; &gt; users mailing list<BR>&gt; &gt; &gt; &gt; users@open-mpi.org<BR>&gt; &gt; &gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; "To preserve the freedom of the human mind then and freedom of the <BR>&gt; &gt; press, every spirit should be ready to devote itself to martyrdom; for <BR>&gt; &gt; as long as we may think as we will, and speak as we think, the <BR>&gt; &gt; condition of man will proceed in improvement."<BR>&gt; &gt; &gt; -- Thomas Jefferson, 1799<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 3<BR>&gt; &gt; &gt; Date: Thu, 19 May 2011 21:22:48 -0400<BR>&gt; &gt; &gt; From: Jeff Squyres &lt;jsquyres@cisco.com&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] v1.5.3-x64 does not work on Windows 7<BR>&gt; &gt; &gt; workgroup<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;278274F0-BF00-4498-950F-9779E0083C5A@cisco.com&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset=us-ascii<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Unfortunately, our Windows guy (Shiqing) is off getting married and <BR>&gt; &gt; will be out for a little while. :-(<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; All that I can cite is the README.WINDOWS.txt file in the top-level <BR>&gt; &gt; directory. I'm afraid that I don't know much else about Windows. :-(<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On May 18, 2011, at 8:17 PM, Jason Mackay wrote:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Hi all,<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; My thanks to all those involved for putting together this Windows <BR>&gt; &gt; binary release of OpenMPI! I am hoping to use it in a small Windows <BR>&gt; &gt; based OpenMPI cluster at home.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Unfortunately my experience so far has not exactly been trouble <BR>&gt; &gt; free. It seems that, due to the fact that this release is using WMI, <BR>&gt; &gt; there are a number of settings that must be configured on the machines <BR>&gt; &gt; in order to get this to work. These settings are not documented in the <BR>&gt; &gt; distribution at all. I have been experimenting with it for over a week <BR>&gt; &gt; on and off and as soon as I solve one problem, another one arises.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Currently, after much searching, reading, and tinkering with DCOM <BR>&gt; &gt; settings etc..., I can remotely start processes on all my machines <BR>&gt; &gt; using mpirun but those processes cannot access network shares (e.g. <BR>&gt; &gt; for binary distribution) and HPL (which works on any one node) does <BR>&gt; &gt; not seem to work if I run it across multiple nodes, also indicating a <BR>&gt; &gt; network issue (CPU sits at 100% in all processes with no network <BR>&gt; &gt; traffic and never terminates). To eliminate premission issues that may <BR>&gt; &gt; be caused by UAC I tried the same setup on two domain machines using <BR>&gt; &gt; an administrative account to launch and the behavior was the same. I <BR>&gt; &gt; have read that WMI processes cannot access network resources and I am <BR>&gt; &gt; at a loss for a solution to this newest of problems. If anyone knows <BR>&gt; &gt; how to make this work I would appreciate the help. I assume that <BR>&gt; &gt; someone has gotten this working and has the answers.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I have searched the mailing list archives and I found other users <BR>&gt; &gt; with similar problems but no clear guidance on the threads. Some <BR>&gt; &gt; threads make references to Microsoft KB articles but do not explicitly <BR>&gt; &gt; tell the user what needs to be done, leaving each new user to <BR>&gt; &gt; rediscover the tricks on their own. One thread made it appear that <BR>&gt; &gt; testing had only been done on Windows XP. Needless to say, security <BR>&gt; &gt; has changed dramatically in Windows since XP!<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I would like to see OpenMPI for Windows be usable by a newcomer <BR>&gt; &gt; without all of this pain.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; What would be fantastic would be:<BR>&gt; &gt; &gt; &gt; 1) a step-by-step procedure for how to get OpenMPI 1.5 working on <BR>&gt; &gt; Windows<BR>&gt; &gt; &gt; &gt; a) preferably in a bare Windows 7 workgroup environment with <BR>&gt; &gt; nothing else (i.e. no Microsoft Cluster Compute Pack, no domain etc...)<BR>&gt; &gt; &gt; &gt; 2) inclusion of these steps in the binary distribution<BR>&gt; &gt; &gt; &gt; 3) bonus points for a script which accomplishes these things <BR>&gt; &gt; automatically<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; If someone can help with (1), I would happily volunteer my time to <BR>&gt; &gt; work on (3).<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Regards,<BR>&gt; &gt; &gt; &gt; Jason<BR>&gt; &gt; &gt; &gt; _______________________________________________<BR>&gt; &gt; &gt; &gt; users mailing list<BR>&gt; &gt; &gt; &gt; users@open-mpi.org<BR>&gt; &gt; &gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; --<BR>&gt; &gt; &gt; Jeff Squyres<BR>&gt; &gt; &gt; jsquyres@cisco.com<BR>&gt; &gt; &gt; For corporate legal information go to:<BR>&gt; &gt; &gt; http://www.cisco.com/web/about/doing_business/legal/cri/<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 4<BR>&gt; &gt; &gt; Date: Thu, 19 May 2011 21:26:43 -0400<BR>&gt; &gt; &gt; From: Jeff Squyres &lt;jsquyres@cisco.com&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] Error: Entry Point Not Found<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;F830EC35-FC9B-4801-B2A3-50F54D2152A4@cisco.com&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset=windows-1252<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On May 19, 2011, at 10:54 AM, Zhangping Wei wrote:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; 4, I use command window to run it in this way: ?mpirun ?n 4 **.exe <BR>&gt; &gt; ?,then I met the error: ?entry point not found: the procedure entry <BR>&gt; &gt; point inet_pton could not be located in the dynamic link library <BR>&gt; &gt; WS2_32.dll?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Unfortunately our Windows developer/maintainer is out for a little <BR>&gt; &gt; while (he's getting married); he pretty much did the Windows stuff by <BR>&gt; &gt; himself, so none of the rest of us know much about it. :(<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; inet_pton is a standard function call relating to IP addresses that <BR>&gt; &gt; we use in the internals of OMPI; I'm not sure why it wouldn't be found <BR>&gt; &gt; on Windows XP (Shiqing did cite that the OMPI Windows port should work <BR>&gt; &gt; on Windows XP).<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; This post seems to imply that inet_ntop is only available on Vista <BR>&gt; &gt; and above:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; <BR>&gt; &gt; http://social.msdn.microsoft.com/Forums/en-US/vcgeneral/thread/e40465f2-41b7-4243-ad33-15ae9366f4e6/<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; So perhaps Shiqing needs to put in some kind of portability <BR>&gt; &gt; workaround for OMPI, and the current binaries won't actually work for <BR>&gt; &gt; XP...?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; I can't say that for sure because I really know very little about <BR>&gt; &gt; Windows; we'll unfortunately have to wait until he returns to get a <BR>&gt; &gt; definitive answer. :-(<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; --<BR>&gt; &gt; &gt; Jeff Squyres<BR>&gt; &gt; &gt; jsquyres@cisco.com<BR>&gt; &gt; &gt; For corporate legal information go to:<BR>&gt; &gt; &gt; http://www.cisco.com/web/about/doing_business/legal/cri/<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 5<BR>&gt; &gt; &gt; Date: Thu, 19 May 2011 21:37:49 -0400<BR>&gt; &gt; &gt; From: Jeff Squyres &lt;jsquyres@cisco.com&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] openmpi (1.2.8 or above) and Intel composer<BR>&gt; &gt; &gt; XE 2011 (aka 12.0)<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Cc: Giovanni Bracco &lt;giovanni.bracco@enea.it&gt;, Agostino Funel<BR>&gt; &gt; &gt; &lt;agostino.funel@enea.it&gt;, Fiorenzo Ambrosino<BR>&gt; &gt; &gt; &lt;fiorenzo.ambrosino@enea.it&gt;, Guido Guarnieri<BR>&gt; &gt; &gt; &lt;guido.guarnieri@enea.it&gt;, Roberto Ciavarella<BR>&gt; &gt; &gt; &lt;roberto.ciavarella@enea.it&gt;, Salvatore Podda<BR>&gt; &gt; &gt; &lt;salvatore.podda@enea.it&gt;, Giovanni Ponti &lt;giovanni.ponti@enea.it&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;45362608-B8B0-4ADE-9959-B35C5690A6F3@cisco.com&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset=us-ascii<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Sorry for the late reply.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Other users have seen something similar but we have never been able <BR>&gt; &gt; to reproduce it. Is this only when using IB? If you use "mpirun --mca <BR>&gt; &gt; btl_openib_cpc_if_include rdmacm", does the problem go away?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On May 11, 2011, at 6:00 PM, Marcus R. Epperson wrote:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I've seen the same thing when I build openmpi 1.4.3 with Intel 12, <BR>&gt; &gt; but only when I have -O2 or -O3 in CFLAGS. If I drop it down to -O1 <BR>&gt; &gt; then the collectives hangs go away. I don't know what, if anything, <BR>&gt; &gt; the higher optimization buys you when compiling openmpi, so I'm not <BR>&gt; &gt; sure if that's an acceptable workaround or not.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; My system is similar to yours - Intel X5570 with QDR Mellanox IB <BR>&gt; &gt; running RHEL 5, Slurm, and these openmpi btls: openib,sm,self. I'm <BR>&gt; &gt; using IMB 3.2.2 with a single iteration of Barrier to reproduce the <BR>&gt; &gt; hang, and it happens 100% of the time for me when I invoke it like this:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; # salloc -N 9 orterun -n 65 ./IMB-MPI1 -npmin 64 -iter 1 barrier<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; The hang happens on the first Barrier (64 ranks) and each of the <BR>&gt; &gt; participating ranks have this backtrace:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; __poll (...)<BR>&gt; &gt; &gt; &gt; poll_dispatch () from [instdir]/lib/libopen-pal.so.0<BR>&gt; &gt; &gt; &gt; opal_event_loop () from [instdir]/lib/libopen-pal.so.0<BR>&gt; &gt; &gt; &gt; opal_progress () from [instdir]/lib/libopen-pal.so.0<BR>&gt; &gt; &gt; &gt; ompi_request_default_wait_all () from [instdir]/lib/libmpi.so.0<BR>&gt; &gt; &gt; &gt; ompi_coll_tuned_sendrecv_actual () from [instdir]/lib/libmpi.so.0<BR>&gt; &gt; &gt; &gt; ompi_coll_tuned_barrier_intra_recursivedoubling () from <BR>&gt; &gt; [instdir]/lib/libmpi.so.0<BR>&gt; &gt; &gt; &gt; ompi_coll_tuned_barrier_intra_dec_fixed () from <BR>&gt; &gt; [instdir]/lib/libmpi.so.0<BR>&gt; &gt; &gt; &gt; PMPI_Barrier () from [instdir]/lib/libmpi.so.0<BR>&gt; &gt; &gt; &gt; IMB_barrier ()<BR>&gt; &gt; &gt; &gt; IMB_init_buffers_iter ()<BR>&gt; &gt; &gt; &gt; main ()<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; The one non-participating rank has this backtrace:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; __poll (...)<BR>&gt; &gt; &gt; &gt; poll_dispatch () from [instdir]/lib/libopen-pal.so.0<BR>&gt; &gt; &gt; &gt; opal_event_loop () from [instdir]/lib/libopen-pal.so.0<BR>&gt; &gt; &gt; &gt; opal_progress () from [instdir]/lib/libopen-pal.so.0<BR>&gt; &gt; &gt; &gt; ompi_request_default_wait_all () from [instdir]/lib/libmpi.so.0<BR>&gt; &gt; &gt; &gt; ompi_coll_tuned_sendrecv_actual () from [instdir]/lib/libmpi.so.0<BR>&gt; &gt; &gt; &gt; ompi_coll_tuned_barrier_intra_bruck () from [instdir]/lib/libmpi.so.0<BR>&gt; &gt; &gt; &gt; ompi_coll_tuned_barrier_intra_dec_fixed () from <BR>&gt; &gt; [instdir]/lib/libmpi.so.0<BR>&gt; &gt; &gt; &gt; PMPI_Barrier () from [instdir]/lib/libmpi.so.0<BR>&gt; &gt; &gt; &gt; main ()<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; If I use more nodes I can get it to hang with 1ppn, so that seems <BR>&gt; &gt; to rule out the sm btl (or interactions with it) as a culprit at least.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I can't reproduce this with openmpi 1.5.3, interestingly.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; -Marcus<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; On 05/10/2011 03:37 AM, Salvatore Podda wrote:<BR>&gt; &gt; &gt; &gt;&gt; Dear all,<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; we succeed in building several version of openmpi from 1.2.8 to <BR>&gt; &gt; 1.4.3<BR>&gt; &gt; &gt; &gt;&gt; with Intel composer XE 2011 (aka 12.0).<BR>&gt; &gt; &gt; &gt;&gt; However we found a threshold in the number of cores (depending <BR>&gt; &gt; from the<BR>&gt; &gt; &gt; &gt;&gt; application: IMB, xhpl or user applications<BR>&gt; &gt; &gt; &gt;&gt; and form the number of required cores) above which the <BR>&gt; &gt; application hangs<BR>&gt; &gt; &gt; &gt;&gt; (sort of deadlocks).<BR>&gt; &gt; &gt; &gt;&gt; The building of openmpi with 'gcc' and 'pgi' does not show the <BR>&gt; &gt; same limits.<BR>&gt; &gt; &gt; &gt;&gt; There are any known incompatibilities of openmpi with this <BR>&gt; &gt; version of<BR>&gt; &gt; &gt; &gt;&gt; intel compiilers?<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; The characteristics of our computational infrastructure are:<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; Intel processors E7330, E5345, E5530 e E5620<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; CentOS 5.3, CentOS 5.5.<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; Intel composer XE 2011<BR>&gt; &gt; &gt; &gt;&gt; gcc 4.1.2<BR>&gt; &gt; &gt; &gt;&gt; pgi 10.2-1<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; Regards<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; Salvatore Podda<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; ENEA UTICT-HPC<BR>&gt; &gt; &gt; &gt;&gt; Department for Computer Science Development and ICT<BR>&gt; &gt; &gt; &gt;&gt; Facilities Laboratory for Science and High Performace Computing<BR>&gt; &gt; &gt; &gt;&gt; C.R. Frascati<BR>&gt; &gt; &gt; &gt;&gt; Via E. Fermi, 45<BR>&gt; &gt; &gt; &gt;&gt; PoBox 65<BR>&gt; &gt; &gt; &gt;&gt; 00044 Frascati (Rome)<BR>&gt; &gt; &gt; &gt;&gt; Italy<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; Tel: +39 06 9400 5342<BR>&gt; &gt; &gt; &gt;&gt; Fax: +39 06 9400 5551<BR>&gt; &gt; &gt; &gt;&gt; Fax: +39 06 9400 5735<BR>&gt; &gt; &gt; &gt;&gt; E-mail: salvatore.podda@enea.it<BR>&gt; &gt; &gt; &gt;&gt; Home Page: www.cresco.enea.it<BR>&gt; &gt; &gt; &gt;&gt; _______________________________________________<BR>&gt; &gt; &gt; &gt;&gt; users mailing list<BR>&gt; &gt; &gt; &gt;&gt; users@open-mpi.org<BR>&gt; &gt; &gt; &gt;&gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; _______________________________________________<BR>&gt; &gt; &gt; &gt; users mailing list<BR>&gt; &gt; &gt; &gt; users@open-mpi.org<BR>&gt; &gt; &gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; --<BR>&gt; &gt; &gt; Jeff Squyres<BR>&gt; &gt; &gt; jsquyres@cisco.com<BR>&gt; &gt; &gt; For corporate legal information go to:<BR>&gt; &gt; &gt; http://www.cisco.com/web/about/doing_business/legal/cri/<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 6<BR>&gt; &gt; &gt; Date: Thu, 19 May 2011 22:01:00 -0400<BR>&gt; &gt; &gt; From: Jeff Squyres &lt;jsquyres@cisco.com&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] Openib with &gt; 32 cores per node<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;C18C4827-D305-484A-9DAE-290902D40DB3@cisco.com&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset=us-ascii<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; What Sam is alluding to is that the OpenFabrics driver code in OMPI <BR>&gt; &gt; is sucking up oodles of memory for each IB connection that you're <BR>&gt; &gt; using. The receive_queues param that he sent tells OMPI to use all <BR>&gt; &gt; shared receive queues (instead of defaulting to one per-peer receive <BR>&gt; &gt; queue and the rest shared receive queues -- the per-peer RQ sucks up <BR>&gt; &gt; all the memory when you multiple it by N peers).<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On May 19, 2011, at 11:59 AM, Samuel K. Gutierrez wrote:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Hi,<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; On May 19, 2011, at 9:37 AM, Robert Horton wrote<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;&gt; On Thu, 2011-05-19 at 08:27 -0600, Samuel K. Gutierrez wrote:<BR>&gt; &gt; &gt; &gt;&gt;&gt; Hi,<BR>&gt; &gt; &gt; &gt;&gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt;&gt; Try the following QP parameters that only use shared receive queues.<BR>&gt; &gt; &gt; &gt;&gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt;&gt; -mca btl_openib_receive_queues S,12288,128,64,32:S,65536,128,64,32<BR>&gt; &gt; &gt; &gt;&gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; Thanks for that. If I run the job over 2 x 48 cores it now works <BR>&gt; &gt; and the<BR>&gt; &gt; &gt; &gt;&gt; performance seems reasonable (I need to do some more tuning) but <BR>&gt; &gt; when I<BR>&gt; &gt; &gt; &gt;&gt; go up to 4 x 48 cores I'm getting the same problem:<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; <BR>&gt; &gt; [compute-1-7.local][[14383,1],86][../../../../../ompi/mca/btl/openib/connect/btl_openib_connect_oob.c:464:qp_create_one] <BR>&gt; &gt; error creating qp errno says Cannot allocate memory<BR>&gt; &gt; &gt; &gt;&gt; [compute-1-7.local:18106] *** An error occurred in MPI_Isend<BR>&gt; &gt; &gt; &gt;&gt; [compute-1-7.local:18106] *** on communicator MPI_COMM_WORLD<BR>&gt; &gt; &gt; &gt;&gt; [compute-1-7.local:18106] *** MPI_ERR_OTHER: known error not in list<BR>&gt; &gt; &gt; &gt;&gt; [compute-1-7.local:18106] *** MPI_ERRORS_ARE_FATAL (your MPI job <BR>&gt; &gt; will now abort)<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; Any thoughts?<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; How much memory does each node have? Does this happen at startup?<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Try adding:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; -mca btl_openib_cpc_include rdmacm<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I'm not sure if your version of OFED supports this feature, but <BR>&gt; &gt; maybe using XRC may help. I **think** other tweaks are needed to get <BR>&gt; &gt; this going, but I'm not familiar with the details.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Hope that helps,<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Samuel K. Gutierrez<BR>&gt; &gt; &gt; &gt; Los Alamos National Laboratory<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; Thanks,<BR>&gt; &gt; &gt; &gt;&gt; Rob<BR>&gt; &gt; &gt; &gt;&gt; --<BR>&gt; &gt; &gt; &gt;&gt; Robert Horton<BR>&gt; &gt; &gt; &gt;&gt; System Administrator (Research Support) - School of Mathematical <BR>&gt; &gt; Sciences<BR>&gt; &gt; &gt; &gt;&gt; Queen Mary, University of London<BR>&gt; &gt; &gt; &gt;&gt; r.horton@qmul.ac.uk - +44 (0) 20 7882 7345<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; _______________________________________________<BR>&gt; &gt; &gt; &gt;&gt; users mailing list<BR>&gt; &gt; &gt; &gt;&gt; users@open-mpi.org<BR>&gt; &gt; &gt; &gt;&gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; _______________________________________________<BR>&gt; &gt; &gt; &gt; users mailing list<BR>&gt; &gt; &gt; &gt; users@open-mpi.org<BR>&gt; &gt; &gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; --<BR>&gt; &gt; &gt; Jeff Squyres<BR>&gt; &gt; &gt; jsquyres@cisco.com<BR>&gt; &gt; &gt; For corporate legal information go to:<BR>&gt; &gt; &gt; http://www.cisco.com/web/about/doing_business/legal/cri/<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 7<BR>&gt; &gt; &gt; Date: Thu, 19 May 2011 22:04:46 -0400<BR>&gt; &gt; &gt; From: Jeff Squyres &lt;jsquyres@cisco.com&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] MPI_COMM_DUP freeze with OpenMPI 1.4.1<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;0DCF20B8-CA5C-4746-8187-A2DFF39B15DD@cisco.com&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset=us-ascii<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On May 13, 2011, at 8:31 AM, francoise.roch@obs.ujf-grenoble.fr wrote:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Here is the MUMPS portion of code (in zmumps_part1.F file) where <BR>&gt; &gt; the slaves call MPI_COMM_DUP , id%PAR and MASTER are initialized to 0 <BR>&gt; &gt; before :<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; CALL MPI_COMM_SIZE(id%COMM, id%NPROCS, IERR )<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; I re-indented so that I could read it better:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; CALL MPI_COMM_SIZE(id%COMM, id%NPROCS, IERR )<BR>&gt; &gt; &gt; IF ( id%PAR .eq. 0 ) THEN<BR>&gt; &gt; &gt; IF ( id%MYID .eq. MASTER ) THEN<BR>&gt; &gt; &gt; color = MPI_UNDEFINED<BR>&gt; &gt; &gt; ELSE<BR>&gt; &gt; &gt; color = 0<BR>&gt; &gt; &gt; END IF<BR>&gt; &gt; &gt; CALL MPI_COMM_SPLIT( id%COMM, color, 0,<BR>&gt; &gt; &gt; &amp; id%COMM_NODES, IERR )<BR>&gt; &gt; &gt; id%NSLAVES = id%NPROCS - 1<BR>&gt; &gt; &gt; ELSE<BR>&gt; &gt; &gt; CALL MPI_COMM_DUP( id%COMM, id%COMM_NODES, IERR )<BR>&gt; &gt; &gt; id%NSLAVES = id%NPROCS<BR>&gt; &gt; &gt; END IF<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; IF (id%PAR .ne. 0 .or. id%MYID .NE. MASTER) THEN<BR>&gt; &gt; &gt; CALL MPI_COMM_DUP( id%COMM_NODES, id%COMM_LOAD, IERR<BR>&gt; &gt; &gt; ENDIF<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; That doesn't look right -- both MPI_COMM_SPLIT and MPI_COMM_DUP are <BR>&gt; &gt; collective, meaning that all processes in the communicator must call <BR>&gt; &gt; them. In the first case, only some processes are calling <BR>&gt; &gt; MPI_COMM_SPLIT. Is there some other logic that forces the rest of the <BR>&gt; &gt; processes to call MPI_COMM_SPLIT, too?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; --<BR>&gt; &gt; &gt; Jeff Squyres<BR>&gt; &gt; &gt; jsquyres@cisco.com<BR>&gt; &gt; &gt; For corporate legal information go to:<BR>&gt; &gt; &gt; http://www.cisco.com/web/about/doing_business/legal/cri/<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 8<BR>&gt; &gt; &gt; Date: Thu, 19 May 2011 22:30:03 -0400<BR>&gt; &gt; &gt; From: Jeff Squyres &lt;jsquyres@cisco.com&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] Trouble with MPI-IO<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;EEFB638F-72F1-4208-8EA2-4F25F610C47B@cisco.com&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset=us-ascii<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Props for that testio script. I think you win the award for "most <BR>&gt; &gt; easy to reproduce test case." :-)<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; I notice that some of the lines went over 72 columns, so I renamed <BR>&gt; &gt; the file x.f90 and changed all the comments from "c" to "!" and joined <BR>&gt; &gt; the two &amp;-split lines. The error about implicit type for lenr went <BR>&gt; &gt; away, but then when I enabled better type checking by using "use mpi" <BR>&gt; &gt; instead of "include 'mpif.h'", I got the following:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; x.f90:99.77:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; call mpi_type_indexed(lenij,ijlena,ijdisp,mpi_real,ij_vector_type,ierr)<BR>&gt; &gt; &gt; 1<BR>&gt; &gt; &gt; Error: There is no specific subroutine for the generic <BR>&gt; &gt; 'mpi_type_indexed' at (1)<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; I looked at our mpi F90 module and see the following:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; interface MPI_Type_indexed<BR>&gt; &gt; &gt; subroutine MPI_Type_indexed(count, array_of_blocklengths, <BR>&gt; &gt; array_of_displacements, oldtype, newtype, ierr)<BR>&gt; &gt; &gt; integer, intent(in) :: count<BR>&gt; &gt; &gt; integer, dimension(*), intent(in) :: array_of_blocklengths<BR>&gt; &gt; &gt; integer, dimension(*), intent(in) :: array_of_displacements<BR>&gt; &gt; &gt; integer, intent(in) :: oldtype<BR>&gt; &gt; &gt; integer, intent(out) :: newtype<BR>&gt; &gt; &gt; integer, intent(out) :: ierr<BR>&gt; &gt; &gt; end subroutine MPI_Type_indexed<BR>&gt; &gt; &gt; end interface<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; I don't quite grok the syntax of the "allocatable" type ijdisp, so <BR>&gt; &gt; that might be the problem here...?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Regardless, I'm not entirely sure if the problem is the &gt;72 <BR>&gt; &gt; character lines, but then when that is gone, I'm not sure how the <BR>&gt; &gt; allocatable stuff fits in... (I'm not enough of a Fortran programmer <BR>&gt; &gt; to know)<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On May 10, 2011, at 7:14 PM, Tom Rosmond wrote:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I would appreciate someone with experience with MPI-IO look at the<BR>&gt; &gt; &gt; &gt; simple fortran program gzipped and attached to this note. It is<BR>&gt; &gt; &gt; &gt; imbedded in a script so that all that is necessary to run it is do:<BR>&gt; &gt; &gt; &gt; 'testio' from the command line. The program generates a small 2-D <BR>&gt; &gt; input<BR>&gt; &gt; &gt; &gt; array, sets up an MPI-IO environment, and write a 2-D output array<BR>&gt; &gt; &gt; &gt; twice, with the only difference being the displacement arrays used to<BR>&gt; &gt; &gt; &gt; construct the indexed datatype. For the first write, simple<BR>&gt; &gt; &gt; &gt; monotonically increasing displacements are used, for the second the<BR>&gt; &gt; &gt; &gt; displacements are 'shuffled' in one dimension. They are printed during<BR>&gt; &gt; &gt; &gt; the run.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; For the first case the file is written properly, but for the <BR>&gt; &gt; second the<BR>&gt; &gt; &gt; &gt; program hangs on MPI_FILE_WRITE_AT_ALL and must be aborted manually.<BR>&gt; &gt; &gt; &gt; Although the program is compiled as an mpi program, I am running on a<BR>&gt; &gt; &gt; &gt; single processor, which makes the problem more puzzling.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; The program should be relatively self-explanatory, but if more<BR>&gt; &gt; &gt; &gt; information is needed, please ask. I am on an 8 core Xeon based Dell<BR>&gt; &gt; &gt; &gt; workstation running Scientific Linux 5.5, Intel fortran 12.0.3, and<BR>&gt; &gt; &gt; &gt; OpenMPI 1.5.3. I have also attached output from 'ompi_info'.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; T. Rosmond<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; <BR>&gt; &gt; &lt;testio.gz&gt;&lt;info_ompi.gz&gt;_______________________________________________<BR>&gt; &gt; &gt; &gt; users mailing list<BR>&gt; &gt; &gt; &gt; users@open-mpi.org<BR>&gt; &gt; &gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; --<BR>&gt; &gt; &gt; Jeff Squyres<BR>&gt; &gt; &gt; jsquyres@cisco.com<BR>&gt; &gt; &gt; For corporate legal information go to:<BR>&gt; &gt; &gt; http://www.cisco.com/web/about/doing_business/legal/cri/<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 9<BR>&gt; &gt; &gt; Date: Thu, 19 May 2011 20:24:25 -0700<BR>&gt; &gt; &gt; From: Tom Rosmond &lt;rosmond@reachone.com&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] Trouble with MPI-IO<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;1305861865.4284.104.camel@cedar.reachone.com&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Thanks for looking at my problem. Sounds like you did reproduce my<BR>&gt; &gt; &gt; problem. I have added some comments below<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On Thu, 2011-05-19 at 22:30 -0400, Jeff Squyres wrote:<BR>&gt; &gt; &gt; &gt; Props for that testio script. I think you win the award for "most <BR>&gt; &gt; easy to reproduce test case." :-)<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I notice that some of the lines went over 72 columns, so I renamed <BR>&gt; &gt; the file x.f90 and changed all the comments from "c" to "!" and joined <BR>&gt; &gt; the two &amp;-split lines. The error about implicit type for lenr went <BR>&gt; &gt; away, but then when I enabled better type checking by using "use mpi" <BR>&gt; &gt; instead of "include 'mpif.h'", I got the following:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; What fortran compiler did you use?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; In the original script my Intel compile used the -132 option,<BR>&gt; &gt; &gt; allowing up to that many columns per line. I still think in<BR>&gt; &gt; &gt; F77 fortran much of the time, and use 'c' for comments out<BR>&gt; &gt; &gt; of habit. The change to '!' doesn't make any difference.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; x.f90:99.77:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; call <BR>&gt; &gt; mpi_type_indexed(lenij,ijlena,ijdisp,mpi_real,ij_vector_type,ierr)<BR>&gt; &gt; &gt; &gt; 1<BR>&gt; &gt; &gt; &gt; Error: There is no specific subroutine for the generic <BR>&gt; &gt; 'mpi_type_indexed' at (1)<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Hmmm, very strange, since I am looking right at the MPI standard<BR>&gt; &gt; &gt; documents with that routine documented. I too get this compile failure<BR>&gt; &gt; &gt; when I switch to 'use mpi'. Could that be a problem with the Open MPI<BR>&gt; &gt; &gt; fortran libraries???<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I looked at our mpi F90 module and see the following:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; interface MPI_Type_indexed<BR>&gt; &gt; &gt; &gt; subroutine MPI_Type_indexed(count, array_of_blocklengths, <BR>&gt; &gt; array_of_displacements, oldtype, newtype, ierr)<BR>&gt; &gt; &gt; &gt; integer, intent(in) :: count<BR>&gt; &gt; &gt; &gt; integer, dimension(*), intent(in) :: array_of_blocklengths<BR>&gt; &gt; &gt; &gt; integer, dimension(*), intent(in) :: array_of_displacements<BR>&gt; &gt; &gt; &gt; integer, intent(in) :: oldtype<BR>&gt; &gt; &gt; &gt; integer, intent(out) :: newtype<BR>&gt; &gt; &gt; &gt; integer, intent(out) :: ierr<BR>&gt; &gt; &gt; &gt; end subroutine MPI_Type_indexed<BR>&gt; &gt; &gt; &gt; end interface<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I don't quite grok the syntax of the "allocatable" type ijdisp, so <BR>&gt; &gt; that might be the problem here...?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Just a standard F90 'allocatable' statement. I've written thousands<BR>&gt; &gt; &gt; just like it.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Regardless, I'm not entirely sure if the problem is the &gt;72 <BR>&gt; &gt; character lines, but then when that is gone, I'm not sure how the <BR>&gt; &gt; allocatable stuff fits in... (I'm not enough of a Fortran programmer <BR>&gt; &gt; to know)<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; Anyone else out that who can comment????<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; T. Rosmond<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; On May 10, 2011, at 7:14 PM, Tom Rosmond wrote:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; &gt; I would appreciate someone with experience with MPI-IO look at the<BR>&gt; &gt; &gt; &gt; &gt; simple fortran program gzipped and attached to this note. It is<BR>&gt; &gt; &gt; &gt; &gt; imbedded in a script so that all that is necessary to run it is do:<BR>&gt; &gt; &gt; &gt; &gt; 'testio' from the command line. The program generates a small <BR>&gt; &gt; 2-D input<BR>&gt; &gt; &gt; &gt; &gt; array, sets up an MPI-IO environment, and write a 2-D output array<BR>&gt; &gt; &gt; &gt; &gt; twice, with the only difference being the displacement arrays <BR>&gt; &gt; used to<BR>&gt; &gt; &gt; &gt; &gt; construct the indexed datatype. For the first write, simple<BR>&gt; &gt; &gt; &gt; &gt; monotonically increasing displacements are used, for the second the<BR>&gt; &gt; &gt; &gt; &gt; displacements are 'shuffled' in one dimension. They are printed <BR>&gt; &gt; during<BR>&gt; &gt; &gt; &gt; &gt; the run.<BR>&gt; &gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; &gt; For the first case the file is written properly, but for the <BR>&gt; &gt; second the<BR>&gt; &gt; &gt; &gt; &gt; program hangs on MPI_FILE_WRITE_AT_ALL and must be aborted manually.<BR>&gt; &gt; &gt; &gt; &gt; Although the program is compiled as an mpi program, I am running <BR>&gt; &gt; on a<BR>&gt; &gt; &gt; &gt; &gt; single processor, which makes the problem more puzzling.<BR>&gt; &gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; &gt; The program should be relatively self-explanatory, but if more<BR>&gt; &gt; &gt; &gt; &gt; information is needed, please ask. I am on an 8 core Xeon based Dell<BR>&gt; &gt; &gt; &gt; &gt; workstation running Scientific Linux 5.5, Intel fortran 12.0.3, and<BR>&gt; &gt; &gt; &gt; &gt; OpenMPI 1.5.3. I have also attached output from 'ompi_info'.<BR>&gt; &gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; &gt; T. Rosmond<BR>&gt; &gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; &gt; <BR>&gt; &gt; &lt;testio.gz&gt;&lt;info_ompi.gz&gt;_______________________________________________<BR>&gt; &gt; &gt; &gt; &gt; users mailing list<BR>&gt; &gt; &gt; &gt; &gt; users@open-mpi.org<BR>&gt; &gt; &gt; &gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 10<BR>&gt; &gt; &gt; Date: Fri, 20 May 2011 09:25:14 +0200<BR>&gt; &gt; &gt; From: David B?ttner &lt;david.buettner@in.tum.de&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] Problem with MPI_Request, MPI_Isend/recv and<BR>&gt; &gt; &gt; MPI_Wait/Test<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;4DD6175A.1080403@in.tum.de&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset=ISO-8859-1; format=flowed<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Hello,<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; thanks for the quick answer. I am sorry that I forgot to mention <BR>&gt; &gt; this: I<BR>&gt; &gt; &gt; did compile OpenMPI with MPI_THREAD_MULTIPLE support and test if<BR>&gt; &gt; &gt; required == provided after the MPI_Thread_init call.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I do not see any mechanism for protecting the accesses to the <BR>&gt; &gt; requests to a single thread? What is the thread model you're using?<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; Again I am sorry that this was not clear: In the pseudo code below I<BR>&gt; &gt; &gt; wanted to indicate the access-protection I do by thread-id dependent<BR>&gt; &gt; &gt; calls if(0 == thread-id) and by using the trylock(...) (using<BR>&gt; &gt; &gt; pthread-mutexes). In the code all accesses concerning one MPI_Request<BR>&gt; &gt; &gt; (which are pthread-global-pointers in my case) are protected and called<BR>&gt; &gt; &gt; in sequential order, i.e. MPI_Isend/recv is returns before any <BR>&gt; &gt; thread is<BR>&gt; &gt; &gt; allowed to call the corresponding MPI_Test and no-one can call MPI_Test<BR>&gt; &gt; &gt; any more when a thread is allowed to call MPI_Wait.<BR>&gt; &gt; &gt; I did this in the same manner before with other MPI implementations, <BR>&gt; &gt; but<BR>&gt; &gt; &gt; also on the same machine with the same (untouched) OpenMPI<BR>&gt; &gt; &gt; implementation, also using pthreads and MPI in combination, but I used<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; MPI_Request req;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; instead of<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; MPI_Request* req;<BR>&gt; &gt; &gt; (and later)<BR>&gt; &gt; &gt; req = (MPI_Request*)malloc(sizeof(MPI_Request));<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; In my recent (problem) code, I also tried not using pointers, but got<BR>&gt; &gt; &gt; the same problem. Also, as I described in the first mail, I tried<BR>&gt; &gt; &gt; everything concerning the memory allocation of the MPI_Request objects.<BR>&gt; &gt; &gt; I tried not calling malloc. This I guessed wouldn't work, but the<BR>&gt; &gt; &gt; OpenMPI documentation says this:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; " Nonblocking calls allocate a communication request object and<BR>&gt; &gt; &gt; associate it with the request handle the argument request). "<BR>&gt; &gt; &gt; [http://www.open-mpi.org/doc/v1.4/man3/MPI_Isend.3.php] and<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; " [...] if the communication object was created by a nonblocking <BR>&gt; &gt; send or<BR>&gt; &gt; &gt; receive, then it is deallocated and the request handle is set to<BR>&gt; &gt; &gt; MPI_REQUEST_NULL."<BR>&gt; &gt; &gt; [http://www.open-mpi.org/doc/v1.4/man3/MPI_Test.3.php] and (in slightly<BR>&gt; &gt; &gt; different words) [http://www.open-mpi.org/doc/v1.4/man3/MPI_Wait.3.php]<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; So I thought that it might do some kind of optimized memory stuff<BR>&gt; &gt; &gt; internally.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; I also tried allocating req (for each used MPI_Request) once before the<BR>&gt; &gt; &gt; first use and deallocation after the last use (which I thought was the<BR>&gt; &gt; &gt; way it was supposed to work), but that crashes also.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; I tried replacing the pointers through global variables<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; MPI_Request req;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; which didn't do the job...<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; The only thing that seems to work is what I mentioned below: Allocate<BR>&gt; &gt; &gt; every time I am going to need it in the MPI_Isend/recv, use it in<BR>&gt; &gt; &gt; MPI_Test/Wait and after that deallocate it by hand each time.<BR>&gt; &gt; &gt; I don't think that this is supposed to be like this since I have to <BR>&gt; &gt; do a<BR>&gt; &gt; &gt; call to malloc and free so often (for multiple MPI_Request objects in<BR>&gt; &gt; &gt; each iteration) that it will most likely limit performance...<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Anyway I still have the same problem and am still unclear on what kind<BR>&gt; &gt; &gt; of memory allocation I should be doing for the MPI_Requests. Is there<BR>&gt; &gt; &gt; anything else (besides MPI_THREAD_MULTIPLE support, thread access<BR>&gt; &gt; &gt; control, sequential order of MPI_Isend/recv, MPI_Test and MPI_Wait for<BR>&gt; &gt; &gt; one MPI_Request object) I need to take care of? If not, what could I do<BR>&gt; &gt; &gt; to find the source of my problem?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Thanks again for any kind of help!<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Kind regards,<BR>&gt; &gt; &gt; David<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; &gt; From an implementation perspective, your code is correct only if <BR>&gt; &gt; you initialize the MPI library with MPI_THREAD_MULTIPLE and if the <BR>&gt; &gt; library accepts. Otherwise, there is an assumption that the <BR>&gt; &gt; application is single threaded, or that the MPI behavior is <BR>&gt; &gt; implementation dependent. Please read the MPI standard regarding to <BR>&gt; &gt; MPI_Init_thread for more details.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Regards,<BR>&gt; &gt; &gt; &gt; george.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; On May 19, 2011, at 02:34 , David B?ttner wrote:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;&gt; Hello,<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; I am working on a hybrid MPI (OpenMPI 1.4.3) and Pthread code. I <BR>&gt; &gt; am using MPI_Isend and MPI_Irecv for communication and <BR>&gt; &gt; MPI_Test/MPI_Wait to check if it is done. I do this repeatedly in the <BR>&gt; &gt; outer loop of my code. The MPI_Test is used in the inner loop to check <BR>&gt; &gt; if some function can be called which depends on the received data.<BR>&gt; &gt; &gt; &gt;&gt; The program regularly crashed (only when not using printf...) and <BR>&gt; &gt; after debugging it I figured out the following problem:<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; In MPI_Isend I have an invalid read of memory. I fixed the <BR>&gt; &gt; problem with not re-using a<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; MPI_Request req_s, req_r;<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; but by using<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; MPI_Request* req_s;<BR>&gt; &gt; &gt; &gt;&gt; MPI_Request* req_r<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; and re-allocating them before the MPI_Isend/recv.<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; The documentation says, that in MPI_Wait and MPI_Test (if <BR>&gt; &gt; successful) the request-objects are deallocated and set to <BR>&gt; &gt; MPI_REQUEST_NULL.<BR>&gt; &gt; &gt; &gt;&gt; It also says, that in MPI_Isend and MPI_Irecv, it allocates the <BR>&gt; &gt; Objects and associates it with the request object.<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; As I understand this, this either means I can use a pointer to <BR>&gt; &gt; MPI_Request which I don't have to initialize for this (it doesn't work <BR>&gt; &gt; but crashes), or that I can use a MPI_Request pointer which I have <BR>&gt; &gt; initialized with malloc(sizeof(MPI_REQUEST)) (or passing the address <BR>&gt; &gt; of a MPI_Request req), which is set and unset in the functions. But <BR>&gt; &gt; this version crashes, too.<BR>&gt; &gt; &gt; &gt;&gt; What works is using a pointer, which I allocate before the <BR>&gt; &gt; MPI_Isend/recv and which I free after MPI_Wait in every iteration. In <BR>&gt; &gt; other words: It only uses if I don't reuse any kind of MPI_Request. <BR>&gt; &gt; Only if I recreate one every time.<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; Is this, what is should be like? I believe that a reuse of the <BR>&gt; &gt; memory would be a lot more efficient (less calls to malloc...). Am I <BR>&gt; &gt; missing something here? Or am I doing something wrong?<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; Let me provide some more detailed information about my problem:<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; I am running the program on a 30 node infiniband cluster. Each <BR>&gt; &gt; node has 4 single core Opteron CPUs. I am running 1 MPI Rank per node <BR>&gt; &gt; and 4 threads per rank (-&gt; one thread per core).<BR>&gt; &gt; &gt; &gt;&gt; I am compiling with mpicc of OpenMPI using gcc below.<BR>&gt; &gt; &gt; &gt;&gt; Some pseudo-code of the program can be found at the end of this <BR>&gt; &gt; e-mail.<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; I was able to reproduce the problem using different amount of <BR>&gt; &gt; nodes and even using one node only. The problem does not arise when I <BR>&gt; &gt; put printf-debugging information into the code. This pointed me into <BR>&gt; &gt; the direction that I have some memory problem, where some write <BR>&gt; &gt; accesses some memory it is not supposed to.<BR>&gt; &gt; &gt; &gt;&gt; I ran the tests using valgrind with --leak-check=full and <BR>&gt; &gt; --show-reachable=yes, which pointed me either to MPI_Isend or MPI_Wait <BR>&gt; &gt; depending on whether I had the threads spin in a loop for MPI_Test to <BR>&gt; &gt; return success or used MPI_Wait respectively.<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; I would appreciate your help with this. Am I missing something <BR>&gt; &gt; important here? Is there a way to re-use the request in the different <BR>&gt; &gt; iterations other than I thought it should work?<BR>&gt; &gt; &gt; &gt;&gt; Or is there a way to re-initialize the allocated memory before <BR>&gt; &gt; the MPI_Isend/recv so that I at least don't have to call free and <BR>&gt; &gt; malloc each time?<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; Thank you very much for your help!<BR>&gt; &gt; &gt; &gt;&gt; Kind regards,<BR>&gt; &gt; &gt; &gt;&gt; David B?ttner<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; _____________________<BR>&gt; &gt; &gt; &gt;&gt; Pseudo-Code of program:<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; MPI_Request* req_s;<BR>&gt; &gt; &gt; &gt;&gt; MPI_Request* req_w;<BR>&gt; &gt; &gt; &gt;&gt; OUTER-LOOP<BR>&gt; &gt; &gt; &gt;&gt; if(0 == threadid)<BR>&gt; &gt; &gt; &gt;&gt; {<BR>&gt; &gt; &gt; &gt;&gt; req_s = malloc(sizeof(MPI_Request));<BR>&gt; &gt; &gt; &gt;&gt; req_r = malloc(sizeof(MPI_Request));<BR>&gt; &gt; &gt; &gt;&gt; MPI_Isend(..., req_s)<BR>&gt; &gt; &gt; &gt;&gt; MPI_Irecv(..., req_r)<BR>&gt; &gt; &gt; &gt;&gt; }<BR>&gt; &gt; &gt; &gt;&gt; pthread_barrier<BR>&gt; &gt; &gt; &gt;&gt; INNER-LOOP (while NOT_DONE or RET)<BR>&gt; &gt; &gt; &gt;&gt; if(TRYLOCK&amp;&amp; NOT_DONE)<BR>&gt; &gt; &gt; &gt;&gt; {<BR>&gt; &gt; &gt; &gt;&gt; if(MPI_TEST(req_r))<BR>&gt; &gt; &gt; &gt;&gt; {<BR>&gt; &gt; &gt; &gt;&gt; Call_Function_A;<BR>&gt; &gt; &gt; &gt;&gt; NOT_DONE = 0;<BR>&gt; &gt; &gt; &gt;&gt; }<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; }<BR>&gt; &gt; &gt; &gt;&gt; RET = Call_Function_B;<BR>&gt; &gt; &gt; &gt;&gt; }<BR>&gt; &gt; &gt; &gt;&gt; pthread_barrier_wait<BR>&gt; &gt; &gt; &gt;&gt; if(0 == threadid)<BR>&gt; &gt; &gt; &gt;&gt; {<BR>&gt; &gt; &gt; &gt;&gt; MPI_WAIT(req_s)<BR>&gt; &gt; &gt; &gt;&gt; MPI_WAIT(req_r)<BR>&gt; &gt; &gt; &gt;&gt; free(req_s);<BR>&gt; &gt; &gt; &gt;&gt; free(req_r);<BR>&gt; &gt; &gt; &gt;&gt; }<BR>&gt; &gt; &gt; &gt;&gt; _____________<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; --<BR>&gt; &gt; &gt; &gt;&gt; David B?ttner, Informatik, Technische Universit?t M?nchen<BR>&gt; &gt; &gt; &gt;&gt; TUM I-10 - FMI 01.06.059 - Tel. 089 / 289-17676<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; _______________________________________________<BR>&gt; &gt; &gt; &gt;&gt; users mailing list<BR>&gt; &gt; &gt; &gt;&gt; users@open-mpi.org<BR>&gt; &gt; &gt; &gt;&gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt; &gt; "To preserve the freedom of the human mind then and freedom of the <BR>&gt; &gt; press, every spirit should be ready to devote itself to martyrdom; for <BR>&gt; &gt; as long as we may think as we will, and speak as we think, the <BR>&gt; &gt; condition of man will proceed in improvement."<BR>&gt; &gt; &gt; &gt; -- Thomas Jefferson, 1799<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; _______________________________________________<BR>&gt; &gt; &gt; &gt; users mailing list<BR>&gt; &gt; &gt; &gt; users@open-mpi.org<BR>&gt; &gt; &gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; --<BR>&gt; &gt; &gt; David B?ttner, Informatik, Technische Universit?t M?nchen<BR>&gt; &gt; &gt; TUM I-10 - FMI 01.06.059 - Tel. 089 / 289-17676<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 11<BR>&gt; &gt; &gt; Date: Fri, 20 May 2011 06:23:21 -0400<BR>&gt; &gt; &gt; From: Jeff Squyres &lt;jsquyres@cisco.com&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] Trouble with MPI-IO<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;A5B121E9-E664-49D0-AE54-2CFE527129D2@cisco.com&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset=us-ascii<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On May 19, 2011, at 11:24 PM, Tom Rosmond wrote:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; What fortran compiler did you use?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; gfortran.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; In the original script my Intel compile used the -132 option,<BR>&gt; &gt; &gt; &gt; allowing up to that many columns per line.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Gotcha.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;&gt; x.f90:99.77:<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; call <BR>&gt; &gt; mpi_type_indexed(lenij,ijlena,ijdisp,mpi_real,ij_vector_type,ierr)<BR>&gt; &gt; &gt; &gt;&gt; 1<BR>&gt; &gt; &gt; &gt;&gt; Error: There is no specific subroutine for the generic <BR>&gt; &gt; 'mpi_type_indexed' at (1)<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Hmmm, very strange, since I am looking right at the MPI standard<BR>&gt; &gt; &gt; &gt; documents with that routine documented. I too get this compile failure<BR>&gt; &gt; &gt; &gt; when I switch to 'use mpi'. Could that be a problem with the Open MPI<BR>&gt; &gt; &gt; &gt; fortran libraries???<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; I think that that error is telling us that there's a compile-time <BR>&gt; &gt; mismatch -- that the signature of what you've passed doesn't match the <BR>&gt; &gt; signature of OMPI's MPI_Type_indexed subroutine.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;&gt; I looked at our mpi F90 module and see the following:<BR>&gt; &gt; &gt; &gt;&gt;<BR>&gt; &gt; &gt; &gt;&gt; interface MPI_Type_indexed<BR>&gt; &gt; &gt; &gt;&gt; subroutine MPI_Type_indexed(count, array_of_blocklengths, <BR>&gt; &gt; array_of_displacements, oldtype, newtype, ierr)<BR>&gt; &gt; &gt; &gt;&gt; integer, intent(in) :: count<BR>&gt; &gt; &gt; &gt;&gt; integer, dimension(*), intent(in) :: array_of_blocklengths<BR>&gt; &gt; &gt; &gt;&gt; integer, dimension(*), intent(in) :: array_of_displacements<BR>&gt; &gt; &gt; &gt;&gt; integer, intent(in) :: oldtype<BR>&gt; &gt; &gt; &gt;&gt; integer, intent(out) :: newtype<BR>&gt; &gt; &gt; &gt;&gt; integer, intent(out) :: ierr<BR>&gt; &gt; &gt; &gt;&gt; end subroutine MPI_Type_indexed<BR>&gt; &gt; &gt; &gt;&gt; end interface<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Shouldn't ijlena and ijdisp be 1D arrays, not 2D arrays?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; --<BR>&gt; &gt; &gt; Jeff Squyres<BR>&gt; &gt; &gt; jsquyres@cisco.com<BR>&gt; &gt; &gt; For corporate legal information go to:<BR>&gt; &gt; &gt; http://www.cisco.com/web/about/doing_business/legal/cri/<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 12<BR>&gt; &gt; &gt; Date: Fri, 20 May 2011 07:26:19 -0400<BR>&gt; &gt; &gt; From: Jeff Squyres &lt;jsquyres@cisco.com&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] MPI_Alltoallv function crashes when np &gt; 100<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;F9F71854-B9DD-459F-999D-8A8AEF8D6006@cisco.com&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset=GB2312<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; I missed this email in my INBOX, sorry.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Can you be more specific about what exact error is occurring? You <BR>&gt; &gt; just say that the application crashes...? Please send all the <BR>&gt; &gt; information listed here:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; http://www.open-mpi.org/community/help/<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On Apr 26, 2011, at 10:51 PM, ?????? wrote:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; It seems that the const variable SOMAXCONN who used by listen() <BR>&gt; &gt; system call causes this problem. Can anybody help me resolve this <BR>&gt; &gt; question?<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; 2011/4/25 ?????? &lt;xjun.meng@gmail.com&gt;<BR>&gt; &gt; &gt; &gt; Dear all,<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; As I mentioned, when I mpiruned an application with the parameter <BR>&gt; &gt; "np = 150(or bigger)", the application who used the MPI_Alltoallv <BR>&gt; &gt; function would carsh. The problem would recur no matter how many nodes <BR>&gt; &gt; we used.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; The edition of OpenMPI: 1.4.1 or 1.4.3<BR>&gt; &gt; &gt; &gt; The OS: linux redhat 2.6.32<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; BTW, my nodes had enough memory to run the application, and the <BR>&gt; &gt; MPI_Alltoall function worked well at my environment.<BR>&gt; &gt; &gt; &gt; Did anybody meet the same problem? Thanks.<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Best Regards<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; _______________________________________________<BR>&gt; &gt; &gt; &gt; users mailing list<BR>&gt; &gt; &gt; &gt; users@open-mpi.org<BR>&gt; &gt; &gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; --<BR>&gt; &gt; &gt; Jeff Squyres<BR>&gt; &gt; &gt; jsquyres@cisco.com<BR>&gt; &gt; &gt; For corporate legal information go to:<BR>&gt; &gt; &gt; http://www.cisco.com/web/about/doing_business/legal/cri/<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 13<BR>&gt; &gt; &gt; Date: Fri, 20 May 2011 07:28:28 -0400<BR>&gt; &gt; &gt; From: Jeff Squyres &lt;jsquyres@cisco.com&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] MPI_ERR_TRUNCATE with MPI_Allreduce() error,<BR>&gt; &gt; &gt; but only sometimes...<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;CAEF632E-757B-49EE-B545-5CCCBC712247@cisco.com&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset=us-ascii<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Sorry for the super-late reply. :-\<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Yes, ERR_TRUNCATE means that the receiver didn't have a large enough <BR>&gt; &gt; buffer.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Have you tried upgrading to a newer version of Open MPI? 1.4.3 is <BR>&gt; &gt; the current stable release (I have a very dim and not guaranteed to be <BR>&gt; &gt; correct recollection that we fixed something in the internals of <BR>&gt; &gt; collectives somewhere with regards to ERR_TRUNCATE...?).<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On Apr 25, 2011, at 4:44 PM, Wei Hao wrote:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Hi:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; I'm running openmpi 1.2.8. I'm working on a project where one part <BR>&gt; &gt; involves communicating an integer, representing the number of data <BR>&gt; &gt; points I'm keeping track of, to all the processors. The line is simple:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; MPI_Allreduce(&amp;np,&amp;geo_N,1,MPI_INT,MPI_MAX,MPI_COMM_WORLD);<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; where np and geo_N are integers, np is the result of a local <BR>&gt; &gt; calculation, and geo_N has been declared on all the processors. geo_N <BR>&gt; &gt; is nondecreasing. This line works the first time I call it (geo_N goes <BR>&gt; &gt; from 0 to some other integer), but if I call it later in the program, <BR>&gt; &gt; I get the following error:<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; [woodhen-039:26189] *** An error occurred in MPI_Allreduce<BR>&gt; &gt; &gt; &gt; [woodhen-039:26189] *** on communicator MPI_COMM_WORLD<BR>&gt; &gt; &gt; &gt; [woodhen-039:26189] *** MPI_ERR_TRUNCATE: message truncated<BR>&gt; &gt; &gt; &gt; [woodhen-039:26189] *** MPI_ERRORS_ARE_FATAL (goodbye)<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; As I understand it, MPI_ERR_TRUNCATE means that the output buffer <BR>&gt; &gt; is too small, but I'm not sure where I've made a mistake. It's <BR>&gt; &gt; particularly frustrating because it seems to work fine the first time. <BR>&gt; &gt; Does anyone have any thoughts?<BR>&gt; &gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Thanks<BR>&gt; &gt; &gt; &gt; Wei<BR>&gt; &gt; &gt; &gt; _______________________________________________<BR>&gt; &gt; &gt; &gt; users mailing list<BR>&gt; &gt; &gt; &gt; users@open-mpi.org<BR>&gt; &gt; &gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; --<BR>&gt; &gt; &gt; Jeff Squyres<BR>&gt; &gt; &gt; jsquyres@cisco.com<BR>&gt; &gt; &gt; For corporate legal information go to:<BR>&gt; &gt; &gt; http://www.cisco.com/web/about/doing_business/legal/cri/<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Message: 14<BR>&gt; &gt; &gt; Date: Fri, 20 May 2011 08:14:07 -0400<BR>&gt; &gt; &gt; From: Jeff Squyres &lt;jsquyres@cisco.com&gt;<BR>&gt; &gt; &gt; Subject: Re: [OMPI users] Trouble with MPI-IO<BR>&gt; &gt; &gt; To: Open MPI Users &lt;users@open-mpi.org&gt;<BR>&gt; &gt; &gt; Message-ID: &lt;42DB03B3-9CF4-4ACB-AA20-B857E5F76087@cisco.com&gt;<BR>&gt; &gt; &gt; Content-Type: text/plain; charset="us-ascii"<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; On May 20, 2011, at 6:23 AM, Jeff Squyres wrote:<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; &gt; Shouldn't ijlena and ijdisp be 1D arrays, not 2D arrays?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Ok, if I convert ijlena and ijdisp to 1D arrays, I don't get the <BR>&gt; &gt; compile error (even though they're allocatable -- so allocate was a <BR>&gt; &gt; red herring, sorry). That's all that "use mpi" is complaining about -- <BR>&gt; &gt; that the function signatures didn't match.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; use mpi is your friend -- even if you don't use F90 constructs much. <BR>&gt; &gt; Compile-time checking is Very Good Thing (you were effectively <BR>&gt; &gt; "getting lucky" by passing in the 2D arrays, I think).<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Attached is my final version. And with this version, I see the hang <BR>&gt; &gt; when running it with the "T" parameter.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; That being said, I'm not an expert on the MPI IO stuff -- your code <BR>&gt; &gt; *looks* right to me, but I could be missing something subtle in the <BR>&gt; &gt; interpretation of MPI_FILE_SET_VIEW. I tried running your code with <BR>&gt; &gt; MPICH 1.3.2p1 and it also hung.<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; Rob (ROMIO guy) -- can you comment this code? Is it correct?<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; --<BR>&gt; &gt; &gt; Jeff Squyres<BR>&gt; &gt; &gt; jsquyres@cisco.com<BR>&gt; &gt; &gt; For corporate legal information go to:<BR>&gt; &gt; &gt; http://www.cisco.com/web/about/doing_business/legal/cri/<BR>&gt; &gt; &gt; -------------- next part --------------<BR>&gt; &gt; &gt; A non-text attachment was scrubbed...<BR>&gt; &gt; &gt; Name: x.f90<BR>&gt; &gt; &gt; Type: application/octet-stream<BR>&gt; &gt; &gt; Size: 3820 bytes<BR>&gt; &gt; &gt; Desc: not available<BR>&gt; &gt; &gt; URL: <BR>&gt; &gt; &lt;http://www.open-mpi.org/MailArchives/users/attachments/20110520/53a5461b/attachment.obj&gt;<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; ------------------------------<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; _______________________________________________<BR>&gt; &gt; &gt; users mailing list<BR>&gt; &gt; &gt; users@open-mpi.org<BR>&gt; &gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; &gt; &gt;<BR>&gt; &gt; &gt; End of users Digest, Vol 1911, Issue 1<BR>&gt; &gt; &gt; **************************************<BR>&gt; &gt;<BR>&gt; &gt;<BR>&gt; &gt; _______________________________________________<BR>&gt; &gt; users mailing list<BR>&gt; &gt; users@open-mpi.org<BR>&gt; &gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; -------------- next part --------------<BR>&gt; HTML attachment scrubbed and removed<BR>&gt; <BR>&gt; ------------------------------<BR>&gt; <BR>&gt; _______________________________________________<BR>&gt; users mailing list<BR>&gt; users@open-mpi.org<BR>&gt; http://www.open-mpi.org/mailman/listinfo.cgi/users<BR>&gt; <BR>&gt; End of users Digest, Vol 1911, Issue 4<BR>&gt; **************************************<BR> 		 	   		  </body>
</html>
