<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type">
</head>
<body bgcolor="#ffffff" text="#000000">
Hi Josh,<br>
<br>
The OpenMPI version is 1.3.3.<br>
<br>
The command ompi-ps doesn't work.<br>
<br>
[root@compute-3-18 ~]# ompi-ps -j 2726959 -p 16241<br>
[root@compute-3-18 ~]# ompi-ps -v -j 2726959 -p 16241<br>
[compute-3-18.local:16254] orte_ps: Acquiring list of HNPs and setting
contact info into RML...<br>
[root@compute-3-18 ~]# ompi-ps -v -j 2726959<br>
[compute-3-18.local:16255] orte_ps: Acquiring list of HNPs and setting
contact info into RML...<br>
<br>
[root@compute-3-18 ~]# ps uaxf | grep sdiaz<br>
root&nbsp;&nbsp;&nbsp;&nbsp; 16260&nbsp; 0.0&nbsp; 0.0 51084&nbsp; 680 pts/0&nbsp;&nbsp;&nbsp; S+&nbsp;&nbsp; 13:38&nbsp;&nbsp; 0:00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
\_ grep sdiaz<br>
sdiaz&nbsp;&nbsp;&nbsp; 16203&nbsp; 0.0&nbsp; 0.0 53164 1220 ?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ss&nbsp;&nbsp; 13:37&nbsp;&nbsp; 0:00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \_
-bash /opt/cesga/sge62/default/spool/compute-3-18/job_scripts/2726959<br>
sdiaz&nbsp;&nbsp;&nbsp; 16241&nbsp; 0.0&nbsp; 0.0 41028 2480 ?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; S&nbsp;&nbsp;&nbsp; 13:37&nbsp;&nbsp; 0:00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
\_ mpirun -np 2 -am ft-enable-cr ./pi3<br>
sdiaz&nbsp;&nbsp;&nbsp; 16242&nbsp; 0.0&nbsp; 0.0 36484 1840 ?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Sl&nbsp;&nbsp; 13:37&nbsp;&nbsp;
0:00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \_ /opt/cesga/sge62/bin/lx24-x86/qrsh -inherit
-nostdin -V compute-3-17.local&nbsp; orted -mca ess env -mca orte_ess_jobid
2769879040 -mca orte_ess_vpid 1 -mca orte_ess_num_procs 2 --hnp-uri
"2769879040.0;tcp://192.168.4.143:57010" -mca
mca_base_param_file_prefix ft-enable-cr -mca mca_base_param_file_path
/opt/cesga/openmpi-1.3.3/share/openmpi/amca-param-sets:/home_no_usc/cesga/sdiaz/mpi_test
-mca mca_base_param_file_path_force /home_no_usc/cesga/sdiaz/mpi_test<br>
sdiaz&nbsp;&nbsp;&nbsp; 16245&nbsp; 0.1&nbsp; 0.0 99464 4616 ?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Sl&nbsp;&nbsp; 13:37&nbsp;&nbsp;
0:00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \_ ./pi3<br>
<br>
[root@compute-3-18 ~]# ompi-ps -n c3-18<br>
[root@compute-3-18 ~]# ompi-ps -n compute-3-18<br>
[root@compute-3-18 ~]# ompi-ps -n<br>
<br>
There is not directory on the /tmp of the node. However, if the
application is run without SGE, the directory is created but if I do
ompi-ps -j MPIRUN_PID, it seems hanged and I interrupt it. Does it take
long time?<br>
what means the option -j of ompi-ps command? isn't it related to a
batch system(like sge, condor...), is it?<br>
<br>
Thanks for the ticket. I will follow it.<br>
<br>
Talking with Alan, I realized that there are few transport protocols
that are supported. And maybe it is the problem. Currently, SGE is
using qrsh to expand mpi process. I can change this protocol and use
ssh. So, I'm going to test it this afternoon and I will comment to you
the results.<br>
<br>
Regards,<br>
Sergio<br>
<br>
<br>
Josh Hursey escribi&oacute;:
<blockquote cite="mid:C86CDED3-2DA4-407F-ADD4-273EBC788AF3@open-mpi.org"
 type="cite"><br>
On Oct 28, 2009, at 7:41 AM, Sergio D&iacute;az wrote:
  <br>
  <br>
  <blockquote type="cite">Hello,
    <br>
    <br>
I have achieved the checkpoint of an easy program without SGE. Now, I'm
trying to do the integration openmpi+sge but I have some problems...
When I try to do checkpoint of the mpirun PID, I got an error similar
to the error gotten when the PID doesn't exit. The example below.
    <br>
  </blockquote>
  <br>
I do not have any experience with the SGE environment, so I suspect
that there may something 'special' about the environment that is
tripping up the ompi-checkpoint tool.
  <br>
  <br>
First of all, what version of Open MPI are you using?
  <br>
  <br>
Somethings to check:
  <br>
&nbsp;- Does 'ompi-ps' work when your application is running?
  <br>
&nbsp;- Is there an /tmp/openmpi-sessions-* directory on the node where
mpirun is currently running? This directory contains information on how
to connect to the mpirun process from an external tool, if it's missing
then this could be the cause of the problem.
  <br>
  <br>
  <blockquote type="cite"><br>
Any ideas?
    <br>
Somebody have a script to do it automatic with SGE?. For example I have
one to do checkpoint each X seconds with BLCR and non-mpi jobs. It is
launched by SGE if you have configured the queue and the ckpt
environment.
    <br>
  </blockquote>
  <br>
I do not know of any integration of the Open MPI checkpointing work
with SGE at the moment.
  <br>
  <br>
As far as time triggered checkpointing, I have a feature ticket open
about this:
  <br>
&nbsp; <a class="moz-txt-link-freetext" href="https://svn.open-mpi.org/trac/ompi/ticket/1961">https://svn.open-mpi.org/trac/ompi/ticket/1961</a>
  <br>
  <br>
It is not available yet, but in the works.
  <br>
  <br>
  <br>
  <blockquote type="cite"><br>
Is it possible choose the name of the ckpt folder when you do the
ompi-checkpoint? I can't find the option to do it.
    <br>
  </blockquote>
  <br>
Not at this time. Though I could see it as a useful feature, and
shouldn't be too hard to implement. I filed a ticket if you want to
follow the progress:
  <br>
&nbsp; <a class="moz-txt-link-freetext" href="https://svn.open-mpi.org/trac/ompi/ticket/2098">https://svn.open-mpi.org/trac/ompi/ticket/2098</a>
  <br>
  <br>
-- Josh
  <br>
  <br>
  <blockquote type="cite"><br>
    <br>
Regards,
    <br>
Sergio
    <br>
    <br>
    <br>
--------------------------------
    <br>
    <br>
[sdiaz@compute-3-17 ~]$ ps auxf
    <br>
....
    <br>
root&nbsp;&nbsp;&nbsp;&nbsp; 20044&nbsp; 0.0&nbsp; 0.0&nbsp; 4468 1224 ?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; S&nbsp;&nbsp;&nbsp; 13:28&nbsp;&nbsp; 0:00&nbsp; \_
sge_shepherd-2645150 -bg
    <br>
sdiaz&nbsp;&nbsp;&nbsp; 20072&nbsp; 0.0&nbsp; 0.0 53172 1212 ?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ss&nbsp;&nbsp; 13:28&nbsp;&nbsp; 0:00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \_
-bash /opt/cesga/sge62/default/spool/compute-3-17/job_scripts/2645150
    <br>
sdiaz&nbsp;&nbsp;&nbsp; 20112&nbsp; 0.2&nbsp; 0.0 41028 2480 ?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; S&nbsp;&nbsp;&nbsp; 13:28&nbsp;&nbsp; 0:00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
\_ mpirun -np 2 -am ft-enable-cr pi3
    <br>
sdiaz&nbsp;&nbsp;&nbsp; 20113&nbsp; 0.0&nbsp; 0.0 36484 1824 ?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Sl&nbsp;&nbsp; 13:28&nbsp;&nbsp;
0:00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \_ /opt/cesga/sge62/bin/lx24-x86/qrsh -inherit
-nostdin -V compute-3-18..........
    <br>
sdiaz&nbsp;&nbsp;&nbsp; 20116&nbsp; 1.2&nbsp; 0.0 99464 4616 ?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Sl&nbsp;&nbsp; 13:28&nbsp;&nbsp;
0:00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \_ pi3
    <br>
    <br>
    <br>
[sdiaz@compute-3-17 ~]$ ompi-checkpoint 20112
    <br>
[compute-3-17.local:20124] HNP with PID 20112 Not found!
    <br>
    <br>
[sdiaz@compute-3-17 ~]$ ompi-checkpoint -s 20112
    <br>
[compute-3-17.local:20135] HNP with PID 20112 Not found!
    <br>
    <br>
[sdiaz@compute-3-17 ~]$ ompi-checkpoint -s --term 20112
    <br>
[compute-3-17.local:20136] HNP with PID 20112 Not found!
    <br>
    <br>
[sdiaz@compute-3-17 ~]$ ompi-checkpoint --hnp-pid 20112
    <br>
--------------------------------------------------------------------------
    <br>
ompi-checkpoint PID_OF_MPIRUN
    <br>
&nbsp; Open MPI Checkpoint Tool
    <br>
    <br>
&nbsp;&nbsp; -am &lt;arg0&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Aggregate MCA parameter set file list
    <br>
&nbsp;&nbsp; -gmca|--gmca &lt;arg0&gt; &lt;arg1&gt;
    <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Pass global MCA parameters that are applicable
to
    <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; all contexts (arg0 is the parameter name; arg1
is
    <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; the parameter value)
    <br>
-h|--help&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; This help message
    <br>
&nbsp;&nbsp; --hnp-jobid &lt;arg0&gt;&nbsp;&nbsp;&nbsp; This should be the jobid of the HNP
whose
    <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; applications you wish to checkpoint.
    <br>
&nbsp;&nbsp; --hnp-pid &lt;arg0&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; This should be the pid of the mpirun
whose
    <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; applications you wish to checkpoint.
    <br>
&nbsp;&nbsp; -mca|--mca &lt;arg0&gt; &lt;arg1&gt;
    <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Pass context-specific MCA parameters; they are
    <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; considered global if --gmca is not used and
only
    <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; one context is specified (arg0 is the
parameter
    <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; name; arg1 is the parameter value)
    <br>
-s|--status&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Display status messages describing the
progression
    <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; of the checkpoint
    <br>
&nbsp;&nbsp; --term&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Terminate the application after checkpoint
    <br>
-v|--verbose&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Be Verbose
    <br>
-w|--nowait&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Do not wait for the application to finish
    <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; checkpointing before returning
    <br>
    <br>
--------------------------------------------------------------------------
    <br>
[sdiaz@compute-3-17 ~]$ exit
    <br>
logout
    <br>
Connection to c3-17 closed.
    <br>
[sdiaz@svgd mpi_test]$ ssh c3-18
    <br>
Last login: Wed Oct 28 13:24:12 2009 from svgd.local
    <br>
-bash-3.00$ ps auxf |grep sdiaz
    <br>
    <br>
sdiaz&nbsp;&nbsp;&nbsp; 14412&nbsp; 0.0&nbsp; 0.0&nbsp; 1888&nbsp; 560 ?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ss&nbsp;&nbsp; 13:28&nbsp;&nbsp; 0:00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \_
/opt/cesga/sge62/utilbin/lx24-x86/qrsh_starter
/opt/cesga/sge62/default/spool/compute-3-18/active_jobs/2645150.1/1.compute-3-18
    <br>
sdiaz&nbsp;&nbsp;&nbsp; 14419&nbsp; 0.0&nbsp; 0.0 35728 2260 ?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; S&nbsp;&nbsp;&nbsp; 13:28&nbsp;&nbsp; 0:00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
\_ orted -mca ess env -mca orte_ess_jobid 2295267328 -mca orte_ess_vpid
1 -mca orte_ess_num_procs 2 --hnp-uri
2295267328.0;tcp://192.168.4.144:36596 -mca mca_base_param_file_prefix
ft-enable-cr -mca mca_base_param_file_path
/opt/cesga/openmpi-1.3.3/share/openmpi/amca-param-sets:/home_no_usc/cesga/sdiaz/mpi_test
-mca mca_base_param_file_path_force /home_no_usc/cesga/sdiaz/mpi_test
    <br>
sdiaz&nbsp;&nbsp;&nbsp; 14420&nbsp; 0.0&nbsp; 0.0 99452 4596 ?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Sl&nbsp;&nbsp; 13:28&nbsp;&nbsp;
0:00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \_ pi3
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
--&nbsp;<br>
Sergio D&iacute;az Montes
    <br>
Centro de Supercomputacion de Galicia
    <br>
Avda. de Vigo. s/n (Campus Sur) 15706 Santiago de Compostela (Spain)
    <br>
Tel: +34 981 56 98 10 ; Fax: +34 981 59 46 16
    <br>
email: <a class="moz-txt-link-abbreviated" href="mailto:sdiaz@cesga.es">sdiaz@cesga.es</a> ; <a class="moz-txt-link-freetext" href="http://www.cesga.es/">http://www.cesga.es/</a>
    <br>
&lt;image002.jpg&gt;
    <br>
------------------------------------------------
    <br>
_______________________________________________
    <br>
users mailing list
    <br>
<a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
    <br>
<a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
    <br>
  </blockquote>
  <br>
  <br>
_______________________________________________
  <br>
users mailing list
  <br>
<a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
  <br>
<a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
  <br>
  <br>
</blockquote>
<br>
<br>
<div class="moz-signature">-- <br>
Sergio D&iacute;az Montes<br>
Centro de Supercomputacion de Galicia<br>
Avda. de Vigo. s/n (Campus Sur) 15706 Santiago de Compostela (Spain)<br>
Tel: +34 981 56 98 10 ; Fax: +34 981 59 46 16 <br>
email: <a class="moz-txt-link-abbreviated" href="mailto:sdiaz@cesga.es">sdiaz@cesga.es</a> ; <a href="http://www.cesga.es/">http://www.cesga.es/</a><br>
<img src="cid:part1.01090000.04060209@cesga.es"><br>
------------------------------------------------ <br>
</div>
</body>
</html>

