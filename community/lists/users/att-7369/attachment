<p>Hi,&nbsp;</p><p>Sorry for not answering sooner,<br></p><p>In Open MPI 1.3 we added a paffinity mapping module.</p><p>The syntax is quite simple and flexible: </p><p>rank N=hostA slot=socket:core_range&nbsp; &nbsp;</p><p>rank M=hostB slot=cpu</p>
<p>see the fallowing example:</p><p>ex:</p><p>#mpirun -rf rankfile_name ./app</p><p></p><p>#cat rankfile_name</p><p>rank 0=host1 slot=0</p><p>rank 1=host2 slot=0:*</p><p>rank 2=host3 slot=1:0,1</p><p>rank 3=host3 slot=1:2-3</p>
<p>rank 4=host1 slot=1:0,0:2</p><p></p><p>explanation:</p><p>Let&#39;s assume we have Quad core Dual CPU machines named host1,host2,host3</p><p>Using the rankfile above we get rank 0 running on CPU#0 &nbsp;( cat /proc/cpu_info you see what is CPU #0 )</p>
<p>rank 1 will run on all cores of socket #0</p><p>rank 2 will run on host3 socket #1, cores 0,1</p><p>rank 3 will run on host3 socket #1, cores from #2 to #3</p><p>rank 4 will run on host1 socket1:core0 and socket0:core2</p>
<p></p><p>So, using threads you probably should use slot=0:*, this way all threads will run on all cores of socket #0 ( or any other specified ).</p><p>or coma separated list of exact pairs like rank4 in the example above.</p>
<p>you can also use -mca paffinity_base_verbose 10 to see the mapping that took place in the job.</p><p></p><p></p><p>Best Regards.</p><p>Lenny.&nbsp;</p><p><br></p><div><span class="gmail_quote">On 11/20/08, <b class="gmail_sendername">Ralph Castain</b> &lt;<a href="mailto:rhc@lanl.gov">rhc@lanl.gov</a>&gt; wrote:</span><blockquote class="gmail_quote" style="margin:0;margin-left:0.8ex;border-left:1px #ccc solid;padding-left:1ex">
At the very least, you would have to call these functions -after- MPI_Init so they could override what OMPI did.<div><span class="e" id="q_11dba83fc77603e9_1"><br>
<br>
<br>
On Nov 20, 2008, at 8:03 AM, Gabriele Fatigati wrote:<br>
<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
And in the hybrid program MPi+OpenMP?<br>
Are these considerations still good?<br>
<br>
2008/11/20 Edgar Gabriel &lt;<a href="mailto:gabriel@cs.uh.edu" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">gabriel@cs.uh.edu</a>&gt;:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
I don&#39;t think that they conflict with our paffinity module and setting. My<br>
understanding is that if you set a new affinity mask, it simply overwrites<br>
the previous setting. So in the worst case it voids the setting made by Open<br>
MPI, but I don&#39;t think that it should cause &#39;problems&#39;. Admittedly, I<br>
haven&#39;t tried the library and the function calls yet, I just learned<br>
relatively recently about them...<br>
<br>
Thanks<br>
Edga<br>
<br>
Ralph Castain wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
<br>
Interesting - learn something new every day! :-)<br>
<br>
How does this interact with OMPI&#39;s paffinity/maffinity assignments? With<br>
the rank/slot mapping and binding system?<br>
<br>
Should users -not- set paffinity if they include these numa calls in their<br>
code?<br>
<br>
Can we detect any potential conflict in OMPI and avoid setting<br>
paffinity_alone? Reason I ask: many systems set paffinity_alone in the<br>
default mca param file because they always assign dedicated nodes to users.<br>
While users can be told to be sure to turn it &quot;off&quot; when using these calls,<br>
it seems inevitable that they will forget - and complaints will appear.<br>
<br>
Thanks<br>
Ralph<br>
<br>
<br>
<br>
On Nov 20, 2008, at 7:34 AM, Edgar Gabriel wrote:<br>
<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
if you look at recent versions of libnuma, there are two functions called<br>
numa_run_on_node() and numa_run_on_node_mask(), which allow thread-based<br>
assignments to CPUs....<br>
<br>
Thanks<br>
Edgar<br>
<br>
Gabriele Fatigati wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
<br>
Is there a way to assign one thread to one core? Also from code, not<br>
necessary with OpenMPI option.<br>
Thanks.<br>
2008/11/19 Stephen Wornom &lt;<a href="mailto:stephen.wornom@sophia.inria.fr" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">stephen.wornom@sophia.inria.fr</a>&gt;:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
<br>
Gabriele Fatigati wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
<br>
Ok,<br>
but in Ompi 1.3 how can i enable it?<br>
<br>
</blockquote>
This may not be relevant, but I could not get a hybrid mpi+OpenMP code<br>
to<br>
work correctly.<br>
Would my problem be related to Gabriele&#39;s and perhaps fixed in openmpi<br>
1.3?<br>
Stephen<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
<br>
2008/11/18 Ralph Castain &lt;<a href="mailto:rhc@lanl.gov" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">rhc@lanl.gov</a>&gt;:<br>
<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
I am afraid it is only available in 1.3 - we didn&#39;t backport it to<br>
the<br>
1.2<br>
series<br>
<br>
<br>
On Nov 18, 2008, at 10:06 AM, Gabriele Fatigati wrote:<br>
<br>
<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
Hi,<br>
how can i set &quot;slot mapping&quot; as you told me? With TASK GEOMETRY? Or<br>
is<br>
a new 1.3 OpenMPI feature?<br>
<br>
Thanks.<br>
<br>
2008/11/18 Ralph Castain &lt;<a href="mailto:rhc@lanl.gov" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">rhc@lanl.gov</a>&gt;:<br>
<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
Unfortunately, paffinity doesn&#39;t know anything about assigning<br>
threads<br>
to<br>
cores. This is actually a behavior of Linux, which only allows<br>
paffinity<br>
to<br>
be set at the process level. So, when you set paffinity on a<br>
process,<br>
you<br>
bind all threads of that process to the specified core(s). You<br>
cannot<br>
specify that a thread be given a specific core.<br>
<br>
In this case, your two threads/process are sharing the same core<br>
and<br>
thus<br>
contending for it. As you&#39;d expect in that situation, one thread<br>
gets<br>
the<br>
vast majority of the attention, while the other thread is mostly<br>
idle.<br>
<br>
If you can upgrade to the beta 1.3 release, try using the slot<br>
mapping<br>
to<br>
assign multiple cores to each process. This will ensure that the<br>
threads<br>
for<br>
that process have exclusive access to those cores, but will not<br>
bind a<br>
particular thread to one core - the threads can &quot;move around&quot;<br>
across<br>
the<br>
specified set of cores. Your threads will then be able to run<br>
without<br>
interfering with each other.<br>
<br>
Ralph<br>
<br>
<br>
On Nov 18, 2008, at 9:18 AM, Gabriele Fatigati wrote:<br>
<br>
<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
Dear OpenMPI developers,<br>
i have a strange problem with mixed program MPI+OPENMP over<br>
OpenMPI<br>
<a href="http://1.2.6." target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">1.2.6.</a> I&#39;m using PJL TASK &nbsp;GEOMETRY in LSF Scheduler, setting 2<br>
MPI<br>
process every compute node, and 2 OMP threads per process. Using<br>
paffinity and maffinity, i&#39;ve noted that over every node, i have 2<br>
thread that works 100%, and 2 threads doesn&#39;t works, or works very<br>
few.<br>
<br>
If i disable paffinity and maffinity, 4 threads works well,<br>
without<br>
load imbalance.<br>
I don&#39;t understand this issue: paffinity and maffinity should map<br>
every thread over a specific core, optimizing the cache flow, but<br>
i<br>
have this without settings there!<br>
<br>
Can i use paffinity and maffinity in mixed MPI+OpenMP program? Or<br>
it<br>
works only over MPI thread?<br>
<br>
Thanks in advance.<br>
<br>
<br>
--<br>
Ing. Gabriele Fatigati<br>
<br>
CINECA Systems &amp; Tecnologies Department<br>
<br>
Supercomputing &nbsp;Group<br>
<br>
Via Magnanelli 6/3, Casalecchio di Reno (BO) Italy<br>
<br>
<a href="http://www.cineca.it" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">www.cineca.it</a> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Tel: &nbsp; +39 051 6171722<br>
<br>
<a href="mailto:g.fatigati@cineca.it" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">g.fatigati@cineca.it</a><br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
</blockquote>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
<br>
<br>
</blockquote>
--<br>
Ing. Gabriele Fatigati<br>
<br>
CINECA Systems &amp; Tecnologies Department<br>
<br>
Supercomputing &nbsp;Group<br>
<br>
Via Magnanelli 6/3, Casalecchio di Reno (BO) Italy<br>
<br>
<a href="http://www.cineca.it" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">www.cineca.it</a> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Tel: &nbsp; +39 051 6171722<br>
<br>
<a href="mailto:g.fatigati@cineca.it" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">g.fatigati@cineca.it</a><br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
</blockquote>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
<br>
<br>
</blockquote>
<br>
<br>
<br>
</blockquote>
<br>
--<br>
<a href="mailto:stephen.wornom@sophia.inria.fr" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">stephen.wornom@sophia.inria.fr</a><br>
2004 route des lucioles - BP93<br>
Sophia Antipolis<br>
06902 CEDEX<br>
<br>
Tel: 04 92 38 50 54<br>
Fax: 04 97 15 53 51<br>
<br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
</blockquote></blockquote>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</blockquote>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</blockquote>
<br>
--<br>
Edgar Gabriel<br>
Assistant Professor<br>
Parallel Software Technologies Lab &nbsp; &nbsp; &nbsp;<a href="http://pstl.cs.uh.edu" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">http://pstl.cs.uh.edu</a><br>
Department of Computer Science &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;University of Houston<br>
Philip G. Hoffman Hall, Room 524 &nbsp; &nbsp; &nbsp; &nbsp;Houston, TX-77204, USA<br>
Tel: +1 (713) 743-3857 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Fax: +1 (713) 743-3335<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
<br>
</blockquote>
<br>
<br>
<br>
-- <br>
Ing. Gabriele Fatigati<br>
<br>
CINECA Systems &amp; Tecnologies Department<br>
<br>
Supercomputing &nbsp;Group<br>
<br>
Via Magnanelli 6/3, Casalecchio di Reno (BO) Italy<br>
<br>
<a href="http://www.cineca.it" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">www.cineca.it</a> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Tel: &nbsp; +39 051 6171722<br>
<br>
<a href="mailto:g.fatigati@cineca.it" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">g.fatigati@cineca.it</a><br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</blockquote>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</span></div></blockquote></div><br>

