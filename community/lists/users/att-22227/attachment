<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" xmlns="http://www.w3.org/TR/REC-html40">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="Generator" content="Microsoft Word 14 (filtered medium)">
<!--[if !mso]><style>v\:* {behavior:url(#default#VML);}
o\:* {behavior:url(#default#VML);}
w\:* {behavior:url(#default#VML);}
.shape {behavior:url(#default#VML);}
</style><![endif]--><style><!--
/* Font Definitions */
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0in;
	margin-bottom:.0001pt;
	font-size:12.0pt;
	font-family:"Times New Roman","serif";}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-priority:99;
	color:purple;
	text-decoration:underline;}
p
	{mso-style-priority:99;
	mso-margin-top-alt:auto;
	margin-right:0in;
	mso-margin-bottom-alt:auto;
	margin-left:0in;
	font-size:12.0pt;
	font-family:"Times New Roman","serif";}
p.MsoAcetate, li.MsoAcetate, div.MsoAcetate
	{mso-style-priority:99;
	mso-style-link:"Balloon Text Char";
	margin:0in;
	margin-bottom:.0001pt;
	font-size:8.0pt;
	font-family:"Tahoma","sans-serif";}
span.BalloonTextChar
	{mso-style-name:"Balloon Text Char";
	mso-style-priority:99;
	mso-style-link:"Balloon Text";
	font-family:"Tahoma","sans-serif";}
span.EmailStyle20
	{mso-style-type:personal;
	font-family:"Calibri","sans-serif";
	color:#1F497D;}
span.EmailStyle21
	{mso-style-type:personal;
	font-family:"Calibri","sans-serif";
	color:#1F497D;}
span.EmailStyle22
	{mso-style-type:personal-reply;
	font-family:"Calibri","sans-serif";
	color:#1F497D;}
.MsoChpDefault
	{mso-style-type:export-only;
	font-size:10.0pt;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
--></style><!--[if gte mso 9]><xml>
<o:shapedefaults v:ext="edit" spidmax="1026" />
</xml><![endif]--><!--[if gte mso 9]><xml>
<o:shapelayout v:ext="edit">
<o:idmap v:ext="edit" data="1" />
</o:shapelayout></xml><![endif]-->
</head>
<body lang="EN-US" link="blue" vlink="purple">
<div class="WordSection1">
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">Also, just to be clear, that attached listing is ordered by data in the first column and doesn’t reflect the call sequence.&nbsp; In actual implementation, all the
 messages labeled “mpi-recv” are mpi_irecv and are all posted before any of the mpi_isends are posted.<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D"><o:p>&nbsp;</o:p></span></p>
<div>
<div style="border:none;border-top:solid #B5C4DF 1.0pt;padding:3.0pt 0in 0in 0in">
<p class="MsoNormal"><b><span style="font-size:10.0pt;font-family:&quot;Tahoma&quot;,&quot;sans-serif&quot;">From:</span></b><span style="font-size:10.0pt;font-family:&quot;Tahoma&quot;,&quot;sans-serif&quot;"> users-bounces@open-mpi.org [mailto:users-bounces@open-mpi.org]
<b>On Behalf Of </b>Blosch, Edwin L<br>
<b>Sent:</b> Thursday, June 27, 2013 12:48 PM<br>
<b>To:</b> Open MPI Users<br>
<b>Subject:</b> EXTERNAL: Re: [OMPI users] Application hangs on mpi_waitall<o:p></o:p></span></p>
</div>
</div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">Attached is the message list for rank 0 for the communication step that is failing.&nbsp; There are about 160 isends and irecvs.&nbsp; The ‘message size’ is actually
 a number of cells.&nbsp; On some steps only one 8-byte word per cell is communicated, at another step we exchange 7 words, and another step we exchange 21 words.&nbsp; You can see the smallest is 10 cells, the largest around 1000 cells.<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D"><o:p>&nbsp;</o:p></span></p>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">Thus for the 7-word communication step, the smallest messages are 560 bytes, the largest are 56000 bytes, and there is a distribution of sizes.&nbsp; For the single-word
 communication step, the size distribution would be from 80 bytes to 8000 and for the 21-word step it would be from 1680 to 168000 bytes.<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D"><o:p>&nbsp;</o:p></span></p>
<div>
<div style="border:none;border-top:solid #B5C4DF 1.0pt;padding:3.0pt 0in 0in 0in">
<p class="MsoNormal"><b><span style="font-size:10.0pt;font-family:&quot;Tahoma&quot;,&quot;sans-serif&quot;">From:</span></b><span style="font-size:10.0pt;font-family:&quot;Tahoma&quot;,&quot;sans-serif&quot;">
<a href="mailto:users-bounces@open-mpi.org">users-bounces@open-mpi.org</a> [<a href="mailto:users-bounces@open-mpi.org">mailto:users-bounces@open-mpi.org</a>]
<b>On Behalf Of </b>Rolf vandeVaart<br>
<b>Sent:</b> Thursday, June 27, 2013 9:02 AM<br>
<b>To:</b> Open MPI Users<br>
<b>Subject:</b> EXTERNAL: Re: [OMPI users] Application hangs on mpi_waitall<o:p></o:p></span></p>
</div>
</div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">Ed, how large are the messages that you are sending and receiving?
<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">Rolf<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D"><o:p>&nbsp;</o:p></span></p>
<div style="border:none;border-left:solid blue 1.5pt;padding:0in 0in 0in 4.0pt">
<div>
<div style="border:none;border-top:solid #B5C4DF 1.0pt;padding:3.0pt 0in 0in 0in">
<p class="MsoNormal"><b><span style="font-size:10.0pt;font-family:&quot;Tahoma&quot;,&quot;sans-serif&quot;">From:</span></b><span style="font-size:10.0pt;font-family:&quot;Tahoma&quot;,&quot;sans-serif&quot;">
<a href="mailto:users-bounces@open-mpi.org">users-bounces@open-mpi.org</a> [<a href="mailto:users-bounces@open-mpi.org">mailto:users-bounces@open-mpi.org</a>]
<b>On Behalf Of </b>Ed Blosch<br>
<b>Sent:</b> Thursday, June 27, 2013 9:01 AM<br>
<b>To:</b> <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<b>Subject:</b> Re: [OMPI users] Application hangs on mpi_waitall<o:p></o:p></span></p>
</div>
</div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<div>
<p class="MsoNormal">It ran a bit longer but still deadlocked. &nbsp;All matching sends are posted 1:1with posted recvs so it is a delivery issue of some kind. &nbsp;I'm running a debug compiled version tonight to see what that might turn up. &nbsp;I may try to rewrite with
 blocking sends and see if that works. &nbsp;I can also try adding a barrier (irecvs, barrier, isends, waitall) to make sure sends are not buffering waiting for recvs to be posted.<o:p></o:p></p>
</div>
<div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
<div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
<div>
<div>
<p class="MsoNormal"><span style="font-size:9.0pt;color:#575757">Sent via the Samsung Galaxy S™ III, an AT&amp;T 4G LTE smartphone<o:p></o:p></span></p>
</div>
</div>
<p class="MsoNormal"><br>
<br>
<br>
-------- Original message --------<br>
From: George Bosilca &lt;<a href="mailto:bosilca@icl.utk.edu">bosilca@icl.utk.edu</a>&gt;
<br>
Date: <br>
To: Open MPI Users &lt;<a href="mailto:users@open-mpi.org">users@open-mpi.org</a>&gt; <br>
Subject: Re: [OMPI users] Application hangs on mpi_waitall <br>
<br>
<br>
Ed,<br>
<br>
Im not sure but there might be a case where the BTL is getting overwhelmed by the nob-blocking operations while trying to setup the connection. There is a simple test for this. Add an MPI_Alltoall with a reasonable size (100k) before you start posting the non-blocking
 receives, and let's see if this solves your issue.<br>
<br>
&nbsp; George.<br>
<br>
<br>
On Jun 26, 2013, at 04:02 , <a href="mailto:eblosch@1scom.net">eblosch@1scom.net</a> wrote:<br>
<br>
&gt; An update: I recoded the mpi_waitall as a loop over the requests with<br>
&gt; mpi_test and a 30 second timeout.&nbsp; The timeout happens unpredictably,<br>
&gt; sometimes after 10 minutes of run time, other times after 15 minutes, for<br>
&gt; the exact same case.<br>
&gt; <br>
&gt; After 30 seconds, I print out the status of all outstanding receive<br>
&gt; requests.&nbsp; The message tags that are outstanding have definitely been<br>
&gt; sent, so I am wondering why they are not getting received?<br>
&gt; <br>
&gt; As I said before, everybody posts non-blocking standard receives, then<br>
&gt; non-blocking standard sends, then calls mpi_waitall. Each process is<br>
&gt; typically waiting on 200 to 300 requests. Is deadlock possible via this<br>
&gt; implementation approach under some kind of unusual conditions?<br>
&gt; <br>
&gt; Thanks again,<br>
&gt; <br>
&gt; Ed<br>
&gt; <br>
&gt;&gt; I'm running OpenMPI 1.6.4 and seeing a problem where mpi_waitall never<br>
&gt;&gt; returns.&nbsp; The case runs fine with MVAPICH.&nbsp; The logic associated with the<br>
&gt;&gt; communications has been extensively debugged in the past; we don't think<br>
&gt;&gt; it has errors.&nbsp;&nbsp; Each process posts non-blocking receives, non-blocking<br>
&gt;&gt; sends, and then does waitall on all the outstanding requests.<br>
&gt;&gt; <br>
&gt;&gt; The work is broken down into 960 chunks. If I run with 960 processes (60<br>
&gt;&gt; nodes of 16 cores each), things seem to work.&nbsp; If I use 160 processes<br>
&gt;&gt; (each process handling 6 chunks of work), then each process is handling 6<br>
&gt;&gt; times as much communication, and that is the case that hangs with OpenMPI<br>
&gt;&gt; 1.6.4; again, seems to work with MVAPICH.&nbsp; Is there an obvious place to<br>
&gt;&gt; start, diagnostically?&nbsp; We're using the openib btl.<br>
&gt;&gt; <br>
&gt;&gt; Thanks,<br>
&gt;&gt; <br>
&gt;&gt; Ed<br>
&gt;&gt; _______________________________________________<br>
&gt;&gt; users mailing list<br>
&gt;&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt;&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; <br>
&gt; <br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><o:p></o:p></p>
</div>
<div>
<div class="MsoNormal" align="center" style="text-align:center">
<hr size="2" width="100%" align="center">
</div>
</div>
<div>
<p class="MsoNormal">This email message is for the sole use of the intended recipient(s) and may contain confidential information.&nbsp; Any unauthorized review, use, disclosure or distribution is prohibited.&nbsp; If you are not the intended recipient, please contact
 the sender by reply email and destroy all copies of the original message. <o:p></o:p></p>
</div>
<div>
<div class="MsoNormal" align="center" style="text-align:center">
<hr size="2" width="100%" align="center">
</div>
</div>
</div>
</body>
</html>
