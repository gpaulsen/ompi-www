<html><head></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; ">That isn't the situation, Terry. We had problems with early OMPI releases, particularly the 1.2 series. In response, the labs wrote an epilogue to ensure that the session directories were removed. Executing the epilogue is now standard operating procedure, even though our more recent releases do a much better job of cleanup.<div><br></div><div>Frankly, it's a good idea anyway. It hurts nothing, takes milliseconds to do, and guarantees nothing got left behind (e.g., if someone was using a debug version of OMPI and directed opal_output to a file).</div><div><br><div><div>On Nov 4, 2011, at 4:43 AM, TERRY DONTJE wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite">

  
    <meta content="text/html; charset=ISO-8859-1" http-equiv="Content-Type">
  
  <div bgcolor="#ffffff" text="#000000">
    David, are you saying your jobs consistently leave behind session
    files after the job exits?&nbsp; It really shouldn't even in the case
    when a job aborts, I thought, mpirun took great pains to cleanup
    after itself.&nbsp;&nbsp;&nbsp; Can you tell us what version of OMPI you are
    running with?&nbsp; I think I could see kill -9 of mpirun and processes
    below would cause turds to be left behind.<br>
    <br>
    --td<br>
    <br>
    On 11/4/2011 2:37 AM, David Turner wrote:
    <blockquote cite="mid:4EB3883E.5050706@lbl.gov" type="cite">% df
      /tmp
      <br>
      Filesystem&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1K-blocks&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Used Available Use% Mounted on
      <br>
      -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 12330084&nbsp;&nbsp;&nbsp; 822848&nbsp; 11507236&nbsp;&nbsp; 7% /
      <br>
      % df /
      <br>
      Filesystem&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1K-blocks&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Used Available Use% Mounted on
      <br>
      -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 12330084&nbsp;&nbsp;&nbsp; 822848&nbsp; 11507236&nbsp;&nbsp; 7% /
      <br>
      <br>
      That works out to 11GB.&nbsp; But...
      <br>
      <br>
      The compute nodes have 24GB.&nbsp; Freshly booted, about 3.2GB is
      <br>
      consumed by the kernel, various services, and the root file
      system.
      <br>
      At this time, usage of /tmp is essentially nil.
      <br>
      <br>
      We set user memory limits to 20GB.
      <br>
      <br>
      I would imagine that the size of the session directories depends
      on a
      <br>
      number of factors; perhaps the developers can comment on that.&nbsp; I
      have
      <br>
      only seen total sizes in the 10s of MBs on our 8-node, 24GB nodes.
      <br>
      <br>
      As long as they're removed after each job, they don't really
      compete
      <br>
      with the application for available memory.
      <br>
      <br>
      On 11/3/11 8:40 PM, Ed Blosch wrote:
      <br>
      <blockquote type="cite">Thanks very much, exactly what I wanted to
        hear. How big is /tmp?
        <br>
        <br>
        -----Original Message-----
        <br>
        From: <a class="moz-txt-link-abbreviated" href="mailto:users-bounces@open-mpi.org">users-bounces@open-mpi.org</a>
        [<a class="moz-txt-link-freetext" href="mailto:users-bounces@open-mpi.org">mailto:users-bounces@open-mpi.org</a>] On
        <br>
        Behalf Of David Turner
        <br>
        Sent: Thursday, November 03, 2011 6:36 PM
        <br>
        To: <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
        <br>
        Subject: Re: [OMPI users] EXTERNAL: Re: How to set up state-less
        node /tmp
        <br>
        for OpenMPI usage
        <br>
        <br>
        I'm not a systems guy, but I'll pitch in anyway.&nbsp; On our
        cluster,
        <br>
        all the compute nodes are completely diskless.&nbsp; The root file
        system,
        <br>
        including /tmp, resides in memory (ramdisk).&nbsp; OpenMPI puts these
        <br>
        session directories therein.&nbsp; All our jobs run through a batch
        <br>
        system (torque).&nbsp; At the conclusion of each batch job, an
        epilogue
        <br>
        process runs that removes all files belonging to the owner of
        the
        <br>
        current batch job from /tmp (and also looks for and kills orphan
        <br>
        processes belonging to the user).&nbsp; This epilogue had to written
        <br>
        by our systems staff.
        <br>
        <br>
        I believe this is a fairly common configuration for diskless
        <br>
        clusters.
        <br>
        <br>
        On 11/3/11 4:09 PM, Blosch, Edwin L wrote:
        <br>
        <blockquote type="cite">Thanks for the help.&nbsp; A couple
          follow-up-questions, maybe this starts to
          <br>
        </blockquote>
        go outside OpenMPI:
        <br>
        <blockquote type="cite">
          <br>
          What's wrong with using /dev/shm?&nbsp; I think you said earlier in
          this thread
          <br>
        </blockquote>
        that this was not a safe place.
        <br>
        <blockquote type="cite">
          <br>
          If the NFS-mount point is moved from /tmp to /work, would a
          /tmp magically
          <br>
        </blockquote>
        appear in the filesystem for a stateless node?&nbsp; How big would it
        be, given
        <br>
        that there is no local disk, right?&nbsp; That may be something I
        have to ask the
        <br>
        vendor, which I've tried, but they don't quite seem to get the
        question.
        <br>
        <blockquote type="cite">
          <br>
          Thanks
          <br>
          <br>
          <br>
          <br>
          <br>
          -----Original Message-----
          <br>
          From: <a class="moz-txt-link-abbreviated" href="mailto:users-bounces@open-mpi.org">users-bounces@open-mpi.org</a>
          [<a class="moz-txt-link-freetext" href="mailto:users-bounces@open-mpi.org">mailto:users-bounces@open-mpi.org</a>] On
          <br>
        </blockquote>
        Behalf Of Ralph Castain
        <br>
        <blockquote type="cite">Sent: Thursday, November 03, 2011 5:22
          PM
          <br>
          To: Open MPI Users
          <br>
          Subject: Re: [OMPI users] EXTERNAL: Re: How to set up
          state-less node /tmp
          <br>
        </blockquote>
        for OpenMPI usage
        <br>
        <blockquote type="cite">
          <br>
          <br>
          On Nov 3, 2011, at 2:55 PM, Blosch, Edwin L wrote:
          <br>
          <br>
          <blockquote type="cite">I might be missing something here. Is
            there a side-effect or performance
            <br>
          </blockquote>
        </blockquote>
        loss if you don't use the sm btl?&nbsp; Why would it exist if there
        is a wholly
        <br>
        equivalent alternative?&nbsp; What happens to traffic that is
        intended for
        <br>
        another process on the same node?
        <br>
        <blockquote type="cite">
          <br>
          There is a definite performance impact, and we wouldn't
          recommend doing
          <br>
        </blockquote>
        what Eugene suggested if you care about performance.
        <br>
        <blockquote type="cite">
          <br>
          The correct solution here is get your sys admin to make /tmp
          local. Making
          <br>
        </blockquote>
        /tmp NFS mounted across multiple nodes is a major "faux pas" in
        the Linux
        <br>
        world - it should never be done, for the reasons stated by Jeff.
        <br>
        <blockquote type="cite">
          <br>
          <br>
          <blockquote type="cite">
            <br>
            Thanks
            <br>
            <br>
            <br>
            -----Original Message-----
            <br>
            From: <a class="moz-txt-link-abbreviated" href="mailto:users-bounces@open-mpi.org">users-bounces@open-mpi.org</a>
            [<a class="moz-txt-link-freetext" href="mailto:users-bounces@open-mpi.org">mailto:users-bounces@open-mpi.org</a>] On
            <br>
          </blockquote>
        </blockquote>
        Behalf Of Eugene Loh
        <br>
        <blockquote type="cite">
          <blockquote type="cite">Sent: Thursday, November 03, 2011 1:23
            PM
            <br>
            To: <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
            <br>
            Subject: Re: [OMPI users] EXTERNAL: Re: How to set up
            state-less node
            <br>
          </blockquote>
        </blockquote>
        /tmp for OpenMPI usage
        <br>
        <blockquote type="cite">
          <blockquote type="cite">
            <br>
            Right.&nbsp; Actually "--mca btl ^sm".&nbsp; (Was missing "btl".)
            <br>
            <br>
            On 11/3/2011 11:19 AM, Blosch, Edwin L wrote:
            <br>
            <blockquote type="cite">I don't tell OpenMPI what BTLs to
              use. The default uses sm and puts a
              <br>
            </blockquote>
          </blockquote>
        </blockquote>
        session file on /tmp, which is NFS-mounted and thus not a good
        choice.
        <br>
        <blockquote type="cite">
          <blockquote type="cite">
            <blockquote type="cite">
              <br>
              Are you suggesting something like --mca ^sm?
              <br>
              <br>
              <br>
              -----Original Message-----
              <br>
              From: <a class="moz-txt-link-abbreviated" href="mailto:users-bounces@open-mpi.org">users-bounces@open-mpi.org</a>
              [<a class="moz-txt-link-freetext" href="mailto:users-bounces@open-mpi.org">mailto:users-bounces@open-mpi.org</a>] On
              <br>
            </blockquote>
          </blockquote>
        </blockquote>
        Behalf Of Eugene Loh
        <br>
        <blockquote type="cite">
          <blockquote type="cite">
            <blockquote type="cite">Sent: Thursday, November 03, 2011
              12:54 PM
              <br>
              To: <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
              <br>
              Subject: Re: [OMPI users] EXTERNAL: Re: How to set up
              state-less node
              <br>
            </blockquote>
          </blockquote>
        </blockquote>
        /tmp for OpenMPI usage
        <br>
        <blockquote type="cite">
          <blockquote type="cite">
            <blockquote type="cite">
              <br>
              I've not been following closely.&nbsp; Why must one use
              shared-memory
              <br>
              communications?&nbsp; How about using other BTLs in a
              "loopback" fashion?
              <br>
              _______________________________________________
              <br>
              users mailing list
              <br>
              <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
              <br>
              <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
              <br>
              _______________________________________________
              <br>
              users mailing list
              <br>
              <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
              <br>
              <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
              <br>
            </blockquote>
            _______________________________________________
            <br>
            users mailing list
            <br>
            <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
            <br>
            <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
            <br>
            _______________________________________________
            <br>
            users mailing list
            <br>
            <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
            <br>
            <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
            <br>
          </blockquote>
          <br>
          <br>
          _______________________________________________
          <br>
          users mailing list
          <br>
          <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
          <br>
          <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
          <br>
          _______________________________________________
          <br>
          users mailing list
          <br>
          <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
          <br>
          <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
          <br>
        </blockquote>
        <br>
        <br>
      </blockquote>
      <br>
      <br>
    </blockquote>
    <br>
    <div class="moz-signature">-- <br>
      <meta content="text/html; charset=ISO-8859-1" http-equiv="Content-Type">
      <div class="moz-signature">
        <meta http-equiv="content-type" content="text/html;
          charset=ISO-8859-1">
        <title></title>
        <span>&lt;Mail Attachment.gif&gt;</span><br>
        <div class="moz-signature">
          <div class="moz-signature">
            <div class="moz-signature">
              <div class="moz-signature">Terry D. Dontje | Principal
                Software Engineer<br>
                <div class="moz-signature"><font size="2" color="#666666" face="Verdana">Developer
                    Tools
                    Engineering | +1.781.442.2631<br>
                  </font>
                  <font size="2" color="#ff0000" face="Verdana">Oracle
                  </font><font size="2" color="#666666" face="Verdana"><b>
                      - Performance
                      Technologies</b></font><br>
                  <font size="2" color="#666666" face="Verdana">
                    95 Network Drive, Burlington, MA 01803<br>
                    Email <a moz-do-not-send="true" href="mailto:terry.dontje@oracle.com">terry.dontje@oracle.com</a><br>
                  </font><br>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
      <br>
      <br>
    </div>
  </div>

_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>http://www.open-mpi.org/mailman/listinfo.cgi/users</blockquote></div><br></div></body></html>
