<html><body>
<p> &quot;dmesg |grep Node&quot;  on Cell will show :<br>
Node 0: CPUS 0-1<br>
Node 1:  CPUS 2-3<br>
.<br>
Linux on Cell/BE  puts the  CPU-node mapping in /sys/devices/system/node instead of /sys/devices/system/cpu.<br>
<br>
Regards,<br>
Mi  <br>
<img width="16" height="16" src="cid:1__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt="Inactive hide details for &quot;Lenny Verkhovsky&quot; &lt;lenny.verkhovsky@gmail.com&gt;">&quot;Lenny Verkhovsky&quot; &lt;lenny.verkhovsky@gmail.com&gt;<br>
<br>
<br>

<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr valign="top"><td style="background-image:url(cid:2__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com); background-repeat: no-repeat; " width="40%">
<ul>
<ul>
<ul>
<ul><b><font size="2">&quot;Lenny Verkhovsky&quot; &lt;lenny.verkhovsky@gmail.com&gt;</font></b><font size="2"> </font><br>
<font size="2">Sent by: users-bounces@open-mpi.org</font>
<p><font size="2">10/27/2008 04:58 PM</font>
<table border="1">
<tr valign="top"><td width="168" bgcolor="#FFFFFF"><div align="center"><font size="2">Please respond to<br>
Open MPI Users &lt;users@open-mpi.org&gt;</font></div></td></tr>
</table>
</ul>
</ul>
</ul>
</ul>
</td><td width="60%">
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr valign="top"><td width="1%"><img width="58" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""><br>
<div align="right"><font size="2">To</font></div></td><td width="100%"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""><br>
<font size="2">&quot;Open MPI Users&quot; &lt;users@open-mpi.org&gt;</font></td></tr>

<tr valign="top"><td width="1%"><img width="58" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""><br>
<div align="right"><font size="2">cc</font></div></td><td width="100%"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""><br>
</td></tr>

<tr valign="top"><td width="1%"><img width="58" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""><br>
<div align="right"><font size="2">Subject</font></div></td><td width="100%"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""><br>
<font size="2">Re: [OMPI users] Working with a CellBlade cluster</font></td></tr>
</table>

<table border="0" cellspacing="0" cellpadding="0">
<tr valign="top"><td width="58"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""></td><td width="336"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""></td></tr>
</table>
</td></tr>
</table>
<br>
<font size="4">can you update me with the mapping or the way to get it from the OS on the Cell.</font>
<p><font size="4">thanks</font>
<p><br>
<font size="4">On Thu, Oct 23, 2008 at 8:08 PM, Mi Yan &lt;</font><a href="mailto:miyan@us.ibm.com"><u><font size="4" color="#0000FF">miyan@us.ibm.com</font></u></a><font size="4">&gt; wrote:</font>
<ul><font size="4">Lenny,<br>
<br>
Thanks. <br>
I asked the Cell/BE Linux Kernel developer to get the CPU mapping :) The mapping is fixed in current kernel. </font><br>
<font size="4"><br>
Mi <br>
</font><font size="4">&quot;Lenny Verkhovsky&quot; &lt;</font><a href="mailto:lenny.verkhovsky@gmail.com" target="_blank"><u><font size="4" color="#0000FF">lenny.verkhovsky@gmail.com</font></u></a><font size="4">&gt;<br>
<br>
</font></ul>
<br>

<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr valign="top"><td width="56%">
<ul>
<ul>
<ul>
<ul>
<ul>
<ul>
<ul>
<ul><b>&quot;Lenny Verkhovsky&quot; &lt;</b><a href="mailto:lenny.verkhovsky@gmail.com" target="_blank"><b><u><font color="#0000FF">lenny.verkhovsky@gmail.com</font></u></b></a><b>&gt;</b> <br>
Sent by: <a href="mailto:users-bounces@open-mpi.org" target="_blank"><u><font color="#0000FF">users-bounces@open-mpi.org</font></u></a><font size="4"> </font>
<p>10/23/2008 01:52 PM</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>

<table width="100%" border="1">
<tr valign="top"><td width="100%" bgcolor="#FFFFFF"><div align="center">Please respond to<br>
Open MPI Users &lt;<a href="mailto:users@open-mpi.org" target="_blank"><u><font color="#0000FF">users@open-mpi.org</font></u></a>&gt;</div></td></tr>
</table>
</td><td width="44%">
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr valign="top"><td width="18%"><div align="right">To</div></td><td width="82%"><br>
&quot;Open MPI Users&quot; &lt;<a href="mailto:users@open-mpi.org" target="_blank"><u><font color="#0000FF">users@open-mpi.org</font></u></a>&gt;</td></tr>

<tr valign="top"><td width="18%"><div align="right">cc</div></td><td width="82%"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""></td></tr>

<tr valign="top"><td width="18%"><div align="right">Subject</div></td><td width="82%"><br>
Re: [OMPI users] Working with a CellBlade cluster</td></tr>
</table>

<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr valign="top"><td width="15%"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""></td><td width="85%"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""></td></tr>
</table>
</td></tr>
</table>

<ul><font size="5"><br>
According to </font><a href="https://svn.open-mpi.org/trac/ompi/milestone/Open%20MPI%201.3" target="_blank"><u><font size="5" color="#0000FF">https://svn.open-mpi.org/trac/ompi/milestone/Open%20MPI%201.3</font></u></a><font size="5"> very soon, <br>
but you can download trunk version </font><a href="http://www.open-mpi.org/svn/" target="_blank"><u><font size="5" color="#0000FF">http://www.open-mpi.org/svn/</font></u></a><font size="5"> and check if it works for you.</font><font size="4"><br>
</font><font size="5"><br>
how can you check mapping CPUs by OS , my cat /proc/cpuinfo shows very little info<br>
# cat /proc/cpuinfo<br>
processor : 0<br>
cpu : Cell Broadband Engine, altivec supported<br>
clock : 3200.000000MHz<br>
revision : 48.0 (pvr 0070 3000)<br>
processor : 1<br>
cpu : Cell Broadband Engine, altivec supported<br>
clock : 3200.000000MHz<br>
revision : 48.0 (pvr 0070 3000)<br>
processor : 2<br>
cpu : Cell Broadband Engine, altivec supported<br>
clock : 3200.000000MHz<br>
revision : 48.0 (pvr 0070 3000)<br>
processor : 3<br>
cpu : Cell Broadband Engine, altivec supported<br>
clock : 3200.000000MHz<br>
revision : 48.0 (pvr 0070 3000)<br>
timebase : 26666666<br>
platform : Cell<br>
machine : CHRP IBM,0793-1RZ<br>
<br>
</font><font size="4"><br>
</font><font size="5"><br>
On Thu, Oct 23, 2008 at 3:00 PM, Mi Yan &lt;</font><a href="mailto:miyan@us.ibm.com" target="_blank"><u><font size="5" color="#0000FF">miyan@us.ibm.com</font></u></a><font size="5">&gt; wrote:</font><font size="4"> </font>
<ul>
<ul><font size="5">Hi, Lenny,<br>
<br>
So rank file map will be supported in OpenMPI 1.3? I'm using OpenMPI1.2.6 and did not find parameter &quot;rmaps_rank_file_&quot;. <br>
Do you have idea when OpenMPI 1.3 will be available? OpenMPI 1.3 has quite a few features I'm looking for.<br>
<br>
Thanks, <br>
<br>
Mi </font><font size="4"><br>
</font><font size="5">&quot;Lenny Verkhovsky&quot; &lt;</font><a href="mailto:lenny.verkhovsky@gmail.com" target="_blank"><u><font size="5" color="#0000FF">lenny.verkhovsky@gmail.com</font></u></a><font size="5">&gt;<br>
</font></ul>
</ul>

<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr valign="top"><td width="0%"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""></td><td width="67%">
<ul>
<ul>
<ul>
<ul>
<ul>
<ul>
<ul>
<ul>
<ul>
<ul>
<ul>
<ul>
<ul>
<ul>
<ul>
<ul><b><font size="4">&quot;Lenny Verkhovsky&quot; &lt;</font></b><a href="mailto:lenny.verkhovsky@gmail.com" target="_blank"><b><u><font size="4" color="#0000FF">lenny.verkhovsky@gmail.com</font></u></b></a><b><font size="4">&gt;</font></b><font size="4"> <br>
Sent by: </font><a href="mailto:users-bounces@open-mpi.org" target="_blank"><u><font size="4" color="#0000FF">users-bounces@open-mpi.org</font></u></a><font size="5"> </font>
<p><font size="4">10/23/2008 05:48 AM</font><font size="5"> </font></ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
<br>

<table width="100%" border="1">
<tr valign="top"><td width="100%" bgcolor="#FFFFFF"><div align="center"><font size="4">Please respond to<br>
Open MPI Users &lt;</font><a href="mailto:users@open-mpi.org" target="_blank"><u><font size="4" color="#0000FF">users@open-mpi.org</font></u></a><font size="4">&gt;</font></div></td></tr>
</table>
</td><td width="0%"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""></td><td width="33%">
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr valign="top"><td width="16%" valign="middle"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""></td><td width="84%"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""></td></tr>

<tr valign="top"><td width="16%"><div align="right"><font size="4">To</font></div></td><td width="84%"><font size="4"><br>
&quot;Open MPI Users&quot; &lt;</font><a href="mailto:users@open-mpi.org" target="_blank"><u><font size="4" color="#0000FF">users@open-mpi.org</font></u></a><font size="4">&gt;</font></td></tr>

<tr valign="top"><td width="16%"><div align="right"><font size="4">cc</font></div></td><td width="84%"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""></td></tr>

<tr valign="top"><td width="16%" valign="middle"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""></td><td width="84%" valign="middle"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""></td></tr>

<tr valign="top"><td width="16%"><div align="right"><font size="4">Subject</font></div></td><td width="84%"><font size="4"><br>
Re: [OMPI users] Working with a CellBlade cluster</font></td></tr>
</table>

<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr valign="top"><td width="50%"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""></td><td width="50%"><img width="1" height="1" src="cid:3__=0ABBFE62DFD847EF8f9e8a93df938@us.ibm.com" border="0" alt=""></td></tr>
</table>
</td></tr>
</table>

<ul>
<ul><font size="6"><br>
Hi,</font><font size="5"><br>
</font><font size="6"><br>
<br>
If I understand you correctly the most suitable way to do it is by paffinity that we have in Open MPI 1.3 and the trank.<br>
how ever usually OS is distributing processes evenly between sockets by it self.<br>
<br>
There still no formal FAQ due to a multiple reasons but you can read how to use it in the attached scratch ( there were few name changings of the params, so check with ompi_info )<br>
<br>
shared memory is used between processes that share same machine, and openib is used between different machines ( hostnames ), no special mca params are needed.<br>
<br>
Best Regards<br>
Lenny,</font><font size="5"> </font>
<p>
<p><font size="6">On Sun, Oct 19, 2008 at 10:32 AM, Gilbert Grosdidier &lt;</font><a href="mailto:grodid@mail.cern.ch" target="_blank"><u><font size="6" color="#0000FF">grodid@mail.cern.ch</font></u></a><font size="6">&gt; wrote:</font><font size="5"> </font>
<ul>
<ul>
<ul>
<ul><font size="6">Working with a CellBlade cluster (QS22), the requirement is to have one<br>
instance of the executable running on each socket of the blade (there are 2<br>
sockets). The application is of the 'domain decomposition' type, and each<br>
instance is required to often send/receive data with both the remote blades and<br>
the neighbor socket.<br>
<br>
Question is : which specification must be used for the mca btl component<br>
to force 1) shmem type messages when communicating with this neighbor socket,<br>
while 2) using openib to communicate with the remote blades ?<br>
Is '-mca btl sm,openib,self' suitable for this ?<br>
<br>
Also, which debug flags could be used to crosscheck that the messages are<br>
_actually_ going thru the right channel for a given channel, please ?<br>
<br>
We are currently using OpenMPI 1.2.5 shipped with RHEL5.2 (ppc64).<br>
Which version do you think is currently the most optimised for these<br>
processors and problem type ? Should we go towards OpenMPI 1.2.8 instead ?<br>
Or even try some OpenMPI 1.3 nightly build ?<br>
<br>
Thanks in advance for your help, Gilbert.<br>
<br>
_______________________________________________<br>
users mailing list</font><u><font size="4" color="#0000FF"><br>
</font></u><a href="mailto:users@open-mpi.org" target="_blank"><u><font size="6" color="#0000FF">users@open-mpi.org</font></u></a><u><font size="4" color="#0000FF"><br>
</font></u><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank"><u><font size="6" color="#0000FF">http://www.open-mpi.org/mailman/listinfo.cgi/users</font></u></a></ul>
</ul>
</ul>
</ul>
<i><font size="5">(See attached file: RANKS_FAQ.doc)</font></i><tt><font size="5"><br>
_______________________________________________ <br>
<br>
users mailing list</font></tt><u><font size="4" color="#0000FF"><br>
</font></u><a href="mailto:users@open-mpi.org" target="_blank"><tt><u><font size="5" color="#0000FF">users@open-mpi.org</font></u></tt></a><u><font size="4" color="#0000FF"><br>
</font></u><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank"><tt><u><font size="5" color="#0000FF">http://www.open-mpi.org/mailman/listinfo.cgi/users</font></u></tt></a><font size="5"><br>
<br>
_______________________________________________<br>
users mailing list</font><u><font size="4" color="#0000FF"><br>
</font></u><a href="mailto:users@open-mpi.org" target="_blank"><u><font size="5" color="#0000FF">users@open-mpi.org</font></u></a><u><font size="4" color="#0000FF"><br>
</font></u><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank"><u><font size="5" color="#0000FF">http://www.open-mpi.org/mailman/listinfo.cgi/users</font></u></a></ul>
</ul>
<tt><font size="4">_______________________________________________<br>
users mailing list</font></tt><tt><u><font size="4" color="#0000FF"><br>
</font></u></tt><a href="mailto:users@open-mpi.org" target="_blank"><tt><u><font size="4" color="#0000FF">users@open-mpi.org</font></u></tt></a><tt><u><font size="4" color="#0000FF"><br>
</font></u></tt><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank"><tt><u><font size="4" color="#0000FF">http://www.open-mpi.org/mailman/listinfo.cgi/users</font></u></tt></a><br>
<font size="4"><br>
_______________________________________________<br>
users mailing list</font><u><font size="4" color="#0000FF"><br>
</font></u><a href="mailto:users@open-mpi.org"><u><font size="4" color="#0000FF">users@open-mpi.org</font></u></a><u><font size="4" color="#0000FF"><br>
</font></u><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank"><u><font size="4" color="#0000FF">http://www.open-mpi.org/mailman/listinfo.cgi/users</font></u></a></ul>
<tt>_______________________________________________<br>
users mailing list<br>
users@open-mpi.org<br>
</tt><tt><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></tt><br>
</body></html>

