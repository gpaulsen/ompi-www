<html dir="ltr">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<style id="owaParaStyle" type="text/css">P {margin-top:0;margin-bottom:0;}</style>
</head>
<body ocsi="0" fpstyle="1" style="word-wrap: break-word;">
<div style="direction: ltr;font-family: Tahoma;color: #000000;font-size: 10pt;">I have tried the 1.7 series (specifically 1.7.3) and I get the same behavior.<br>
<br>
When I run &quot;mpirun -oversubscribe -np 24 hostname&quot;, three instances of &quot;hostname&quot; are run on each node.<br>
<br>
The contents of the $PBS_NODEFILE are:<br>
n0007<br>
n0006<br>
n0005<br>
n0004<br>
n0003<br>
n0002<br>
n0001<br>
n0000<br>
<br>
but, since I have compiled OpenMPI using the &quot;--with-tm&quot;,&nbsp; it appears that OpenMPI is not using the $PBS_NODEFILE (which I tested by modifying the torque pbs_mom to write a $PBS_NODEFILE that contained &quot;slot=xx&quot; information for each node. mpirun complained
 when I did this).<br>
<br>
Regards,<br>
<br>
Jason<br>
<br>
<div style="font-family: Times New Roman; color: rgb(0, 0, 0); font-size: 16px;">
<hr tabindex="-1">
<div style="direction: ltr;" id="divRpF717112"><font color="#000000" face="Tahoma" size="2"><b>From:</b> users [users-bounces@open-mpi.org] on behalf of Ralph Castain [rhc@open-mpi.org]<br>
<b>Sent:</b> Friday, November 22, 2013 11:04 AM<br>
<b>To:</b> Open MPI Users<br>
<b>Subject:</b> Re: [OMPI users] Oversubscription of nodes with Torque and OpenMPI<br>
</font><br>
</div>
<div></div>
<div>Really shouldn't matter - this is clearly a bug in OMPI if it is doing mapping as you describe. Out of curiosity, have you tried the 1.7 series? Does it behave the same?
<div><br>
</div>
<div>I can take a look at the code later today and try to figure out what happened.</div>
<div><br>
<div>
<div>On Nov 22, 2013, at 9:56 AM, Jason Gans &lt;<a href="mailto:jgans@lanl.gov" target="_blank">jgans@lanl.gov</a>&gt; wrote:</div>
<br class="Apple-interchange-newline">
<blockquote type="cite">
<div style="font-size: 12px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px;">
On 11/22/13 10:47 AM, Reuti wrote:<br>
<blockquote type="cite">Hi,<br>
<br>
Am 22.11.2013 um 17:32 schrieb Gans, Jason D:<br>
<br>
<blockquote type="cite">I would like to run an instance of my application on every *core* of a small cluster. I am using Torque 2.5.12 to run jobs on the cluster. The cluster in question is a heterogeneous collection of machines that are all past their prime.
 Specifically, the number of cores ranges from 2-8. Here is the Torque &quot;nodes&quot; file:<br>
<br>
n0000 np=2<br>
n0001 np=2<br>
n0002 np=8<br>
n0003 np=8<br>
n0004 np=2<br>
n0005 np=2<br>
n0006 np=2<br>
n0007 np=4<br>
<br>
When I use openmpi-1.6.3, I can oversubscribe nodes but the tasks are allocated to nodes without regard to the number of cores on each node (specified by the &quot;np=xx&quot; in the nodes file). For example, when I run &quot;mpirun -np 24 hostname&quot;, mpirun places three instances
 of &quot;hostname&quot; on each node, despite the fact that some nodes only have two processors and some have more.<br>
</blockquote>
You submitted the job itself by requesting 24 cores for it too?<br>
<br>
-- Reuti<br>
</blockquote>
Since there are only 8 Torque nodes in the cluster, I submitted the job by requesting 8 nodes, i.e. &quot;qsub -I -l nodes=8&quot;.<br>
<blockquote type="cite"><br>
<br>
<blockquote type="cite">Is there a way to have OpenMPI &quot;gracefully&quot; oversubscribe nodes by allocating instances based on the &quot;np=xx&quot; information in the Torque nodes file? It this a Torque problem?<br>
<br>
p.s. I do get the desired behavior when I run *without* Torque and specify the following machine file to mpirun:<br>
<br>
n0000 slots=2<br>
n0001 slots=2<br>
n0002 slots=8<br>
n0003 slots=8<br>
n0004 slots=2<br>
n0005 slots=2<br>
n0006 slots=2<br>
n0007 slots=4<br>
<br>
Regards,<br>
<br>
Jason<br>
<br>
<br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
http://www.open-mpi.org/mailman/listinfo.cgi/users<br>
</blockquote>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
http://www.open-mpi.org/mailman/listinfo.cgi/users<br>
</blockquote>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></div>
</blockquote>
</div>
<br>
</div>
</div>
</div>
</div>
</body>
</html>

