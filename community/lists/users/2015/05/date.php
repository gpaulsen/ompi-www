<? 
if (preg_match("/\/[12][0-9][0-9][0-9]\/[01][0-9]\//", $_SERVER["REQUEST_URI"])) {
    include("../../include/index-header.inc");
} else {
    include("include/index-header.inc");
}
?>
<div class="center">
<table border="2" width="100%" class="links">
<tr>
<th><a href="index.php">Thread view</a></th>
<th><a href="subject.php">Subject view</a></th>
<th><a href="author.php">Author view</a></th>
</tr><tr><th><a href="http://www.open-mpi.org/community/lists/users/2015/04/date.php">Previous Folder, Date view</a></th><th><a href="http://www.open-mpi.org/community/lists/users/2015/06/date.php">Next Folder, Date view</a></th><th><a href="http://www.open-mpi.org/community/lists/users/index.php">List of Folders</a></th></tr>
</table>
</div>
<div class="center">
<table>
<tr>
<th colspan="4">177 Messages</th>
</tr>
<tr>
  <th>Starting:</th><td><em>2005-01-11 11:35:37</em></td>
  <th>Ending:</th><td><em>2016-07-27 12:01:45</em></td>
</tr>
</table>
</div>
<hr>
<ul>
<li><a href="27005.php"><strong>Re: [OMPI users] [EXTERNAL]  MPI-Checker - Static Analyzer</strong></a>&nbsp;<a name="27005"><em>Alexander Droste</em></a>&nbsp;<em>(2015-05-31 13:51:21)</em></li>
<li><a href="27004.php"><strong>Re: [OMPI users] [EXTERNAL]  MPI-Checker - Static Analyzer</strong></a>&nbsp;<a name="27004"><em>Hammond, Simon David (-EXP)</em></a>&nbsp;<em>(2015-05-31 12:51:48)</em></li>
<li><a href="27003.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="27003"><em>Timothy Brown</em></a>&nbsp;<em>(2015-05-30 11:29:57)</em></li>
<li><a href="27002.php"><strong>Re: [OMPI users] Building OpenMPI on Raspberry Pi 2</strong></a>&nbsp;<a name="27002"><em>Jeff Layton</em></a>&nbsp;<em>(2015-05-30 09:42:59)</em></li>
<li><a href="27001.php"><strong>Re: [OMPI users] mpirun</strong></a>&nbsp;<a name="27001"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-30 09:24:04)</em></li>
<li><a href="27000.php"><strong>[OMPI users] MPI-Checker - Static Analyzer</strong></a>&nbsp;<a name="27000"><em>Alexander Droste</em></a>&nbsp;<em>(2015-05-30 07:47:36)</em></li>
<li><a href="26999.php"><strong>Re: [OMPI users] Building OpenMPI on Raspberry Pi 2</strong></a>&nbsp;<a name="26999"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-30 06:46:33)</em></li>
<li><a href="26998.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26998"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-30 06:34:24)</em></li>
<li><a href="26997.php"><strong>Re: [OMPI users] How can I discover valid values for MCA parameters?</strong></a>&nbsp;<a name="26997"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-30 06:29:56)</em></li>
<li><a href="26996.php"><strong>Re: [OMPI users] mpirun</strong></a>&nbsp;<a name="26996"><em>Marco Atzeri</em></a>&nbsp;<em>(2015-05-30 02:07:18)</em></li>
<li><a href="26995.php"><strong>Re: [OMPI users] mpirun</strong></a>&nbsp;<a name="26995"><em>Tim Prince</em></a>&nbsp;<em>(2015-05-29 22:42:37)</em></li>
<li><a href="26994.php"><strong>Re: [OMPI users] mpirun</strong></a>&nbsp;<a name="26994"><em>Gilles Gouaillardet</em></a>&nbsp;<em>(2015-05-29 19:26:07)</em></li>
<li><a href="26993.php"><strong>Re: [OMPI users] mpirun</strong></a>&nbsp;<a name="26993"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-29 17:21:57)</em></li>
<li><a href="26992.php"><strong>Re: [OMPI users] mpirun</strong></a>&nbsp;<a name="26992"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-29 16:13:56)</em></li>
<li><a href="26991.php"><strong>Re: [OMPI users] mpirun</strong></a>&nbsp;<a name="26991"><em>Walt Brainerd</em></a>&nbsp;<em>(2015-05-29 15:58:24)</em></li>
<li><a href="26990.php"><strong>Re: [OMPI users] mpirun</strong></a>&nbsp;<a name="26990"><em>Walt Brainerd</em></a>&nbsp;<em>(2015-05-29 15:53:49)</em></li>
<li><a href="26989.php"><strong>Re: [OMPI users] mpirun</strong></a>&nbsp;<a name="26989"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-29 15:35:15)</em></li>
<li><a href="26988.php"><strong>[OMPI users] mpirun</strong></a>&nbsp;<a name="26988"><em>Walt Brainerd</em></a>&nbsp;<em>(2015-05-29 15:34:00)</em></li>
<li><a href="26987.php"><strong>Re: [OMPI users] Building OpenMPI on Raspberry Pi 2</strong></a>&nbsp;<a name="26987"><em>Jeff Layton</em></a>&nbsp;<em>(2015-05-29 14:17:39)</em></li>
<li><a href="26986.php"><strong>Re: [OMPI users] Building OpenMPI on Raspberry Pi 2</strong></a>&nbsp;<a name="26986"><em>George Bosilca</em></a>&nbsp;<em>(2015-05-29 13:51:07)</em></li>
<li><a href="26985.php"><strong>Re: [OMPI users] How can I discover valid values for MCA parameters?</strong></a>&nbsp;<a name="26985"><em>Blosch, Edwin L</em></a>&nbsp;<em>(2015-05-29 12:14:45)</em></li>
<li><a href="26984.php"><strong>Re: [OMPI users] How can I discover valid values for MCA parameters?</strong></a>&nbsp;<a name="26984"><em>Nathan Hjelm</em></a>&nbsp;<em>(2015-05-29 12:13:16)</em></li>
<li><a href="26983.php"><strong>[OMPI users] How can I discover valid values for MCA parameters?</strong></a>&nbsp;<a name="26983"><em>Blosch, Edwin L</em></a>&nbsp;<em>(2015-05-29 12:05:57)</em></li>
<li><a href="26982.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26982"><em>Timothy Brown</em></a>&nbsp;<em>(2015-05-29 11:19:01)</em></li>
<li><a href="26981.php"><strong>Re: [OMPI users] Building OpenMPI on Raspberry Pi 2</strong></a>&nbsp;<a name="26981"><em>Jeff Layton</em></a>&nbsp;<em>(2015-05-29 10:09:30)</em></li>
<li><a href="26980.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26980"><em>Bruno Queiros</em></a>&nbsp;<em>(2015-05-29 09:43:50)</em></li>
<li><a href="26979.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26979"><em>Bruno Queiros</em></a>&nbsp;<em>(2015-05-29 09:43:17)</em></li>
<li><a href="26978.php"><strong>Re: [OMPI users] Building OpenMPI on Raspberry Pi 2</strong></a>&nbsp;<a name="26978"><em>Jeff Layton</em></a>&nbsp;<em>(2015-05-29 09:35:02)</em></li>
<li><a href="26977.php"><strong>Re: [OMPI users] Building OpenMPI on Raspberry Pi 2</strong></a>&nbsp;<a name="26977"><em>Gilles Gouaillardet</em></a>&nbsp;<em>(2015-05-29 09:21:29)</em></li>
<li><a href="26976.php"><strong>[OMPI users] Building OpenMPI on Raspberry Pi 2</strong></a>&nbsp;<a name="26976"><em>Jeff Layton</em></a>&nbsp;<em>(2015-05-29 08:11:12)</em></li>
<li><a href="26975.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26975"><em>Luis Kornblueh</em></a>&nbsp;<em>(2015-05-29 08:03:41)</em></li>
<li><a href="26974.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26974"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-29 07:07:50)</em></li>
<li><a href="26973.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26973"><em>Bruno Queiros</em></a>&nbsp;<em>(2015-05-29 06:54:46)</em></li>
<li><a href="26972.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26972"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-29 06:36:24)</em></li>
<li><a href="26971.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26971"><em>Bruno Queiros</em></a>&nbsp;<em>(2015-05-29 06:14:02)</em></li>
<li><a href="26970.php"><strong>Re: [OMPI users] MXM problem</strong></a>&nbsp;<a name="26970"><em>&#208;&#162;&#208;&#184;&#208;&#188;&#209;&#131;&#209;&#128; &#208;&#152;&#209;&#129;&#208;&#188;&#208;&#176;&#208;&#179;&#208;&#184;&#208;&#187;&#208;&#190;&#208;&#178;</em></a>&nbsp;<em>(2015-05-28 14:13:20)</em></li>
<li><a href="26969.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26969"><em>Luis Kornblueh</em></a>&nbsp;<em>(2015-05-28 13:36:09)</em></li>
<li><a href="26968.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26968"><em>Luis Kornblueh</em></a>&nbsp;<em>(2015-05-28 13:34:31)</em></li>
<li><a href="26967.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26967"><em>Bruno Queiros</em></a>&nbsp;<em>(2015-05-28 13:08:19)</em></li>
<li><a href="26966.php"><strong>Re: [OMPI users] MXM problem</strong></a>&nbsp;<a name="26966"><em>Mike Dubman</em></a>&nbsp;<em>(2015-05-28 13:07:10)</em></li>
<li><a href="26965.php"><strong>Re: [OMPI users] MXM problem</strong></a>&nbsp;<a name="26965"><em>Timur Ismagilov</em></a>&nbsp;<em>(2015-05-28 12:33:20)</em></li>
<li><a href="26964.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26964"><em>Bruno Queiros</em></a>&nbsp;<em>(2015-05-28 09:10:24)</em></li>
<li><a href="26963.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26963"><em>Thomas Jahns</em></a>&nbsp;<em>(2015-05-28 07:25:40)</em></li>
<li><a href="26962.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26962"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-28 06:20:36)</em></li>
<li><a href="26961.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26961"><em>Bruno Queiros</em></a>&nbsp;<em>(2015-05-28 05:29:02)</em></li>
<li><a href="26960.php"><strong>Re: [OMPI users] MXM problem</strong></a>&nbsp;<a name="26960"><em>Timur Ismagilov</em></a>&nbsp;<em>(2015-05-28 03:21:57)</em></li>
<li><a href="26959.php"><strong>Re: [OMPI users] Running HPL on RPi cluster, seems like MPI is somehow not configured properly since it work with 1 node but not more</strong></a>&nbsp;<a name="26959"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-27 13:36:26)</em></li>
<li><a href="26958.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26958"><em>David Shrader</em></a>&nbsp;<em>(2015-05-27 13:28:21)</em></li>
<li><a href="26957.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26957"><em>Bruno Queiros</em></a>&nbsp;<em>(2015-05-27 13:01:29)</em></li>
<li><a href="26956.php"><strong>Re: [OMPI users] Running HPL on RPi cluster, seems like MPI is somehow not configured properly since it work with 1 node but not more</strong></a>&nbsp;<a name="26956"><em>Heerdt, Lanze M.</em></a>&nbsp;<em>(2015-05-27 12:47:25)</em></li>
<li><a href="26955.php"><strong>Re: [OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26955"><em>David Shrader</em></a>&nbsp;<em>(2015-05-27 12:40:36)</em></li>
<li><a href="26954.php"><strong>[OMPI users] Openmpi compilation errors</strong></a>&nbsp;<a name="26954"><em>Bruno Queiros</em></a>&nbsp;<em>(2015-05-27 12:25:54)</em></li>
<li><a href="26953.php"><strong>Re: [OMPI users] 1.8.5, mxm, and a spurious '-L' flag</strong></a>&nbsp;<a name="26953"><em>Mike Dubman</em></a>&nbsp;<em>(2015-05-27 03:22:52)</em></li>
<li><a href="26952.php"><strong>Re: [OMPI users] Running HPL on RPi cluster, seems like MPI is somehow not configured properly since it work with 1 node but not more</strong></a>&nbsp;<a name="26952"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-26 22:10:08)</em></li>
<li><a href="26951.php"><strong>Re: [OMPI users] Running HPL on RPi cluster, seems like MPI is somehow not configured properly since it work with 1 node but not more</strong></a>&nbsp;<a name="26951"><em>Gilles Gouaillardet</em></a>&nbsp;<em>(2015-05-26 22:07:35)</em></li>
<li><a href="26950.php"><strong>Re: [OMPI users] Running HPL on RPi cluster, seems like MPI is somehow not configured properly since it work with 1 node but not more</strong></a>&nbsp;<a name="26950"><em>Heerdt, Lanze M.</em></a>&nbsp;<em>(2015-05-26 21:38:29)</em></li>
<li><a href="26949.php"><strong>Re: [OMPI users] Running HPL on RPi cluster, seems like MPI is somehow not configured properly since it work with 1 node but not more</strong></a>&nbsp;<a name="26949"><em>Gilles Gouaillardet</em></a>&nbsp;<em>(2015-05-26 20:13:45)</em></li>
<li><a href="26948.php"><strong>Re: [OMPI users] Running HPL on RPi cluster, seems like MPI is somehow not configured properly since it work with 1 node but not more</strong></a>&nbsp;<a name="26948"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-26 19:42:28)</em></li>
<li><a href="26947.php"><strong>Re: [OMPI users] 1.8.5, mxm, and a spurious '-L' flag</strong></a>&nbsp;<a name="26947"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-26 15:38:05)</em></li>
<li><a href="26946.php"><strong>Re: [OMPI users] 1.8.5, mxm, and a spurious '-L' flag</strong></a>&nbsp;<a name="26946"><em>Mike Dubman</em></a>&nbsp;<em>(2015-05-26 15:27:06)</em></li>
<li><a href="26945.php"><strong>[OMPI users] Running HPL on RPi cluster, seems like MPI is somehow not configured properly since it work with 1 node but not more</strong></a>&nbsp;<a name="26945"><em>Heerdt, Lanze M.</em></a>&nbsp;<em>(2015-05-26 15:26:53)</em></li>
<li><a href="26944.php"><strong>Re: [OMPI users] 1.8.5, mxm, and a spurious '-L' flag</strong></a>&nbsp;<a name="26944"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-26 15:11:45)</em></li>
<li><a href="26943.php"><strong>Re: [OMPI users] 1.8.5, mxm, and a spurious '-L' flag</strong></a>&nbsp;<a name="26943"><em>Mike Dubman</em></a>&nbsp;<em>(2015-05-26 13:54:11)</em></li>
<li><a href="26942.php"><strong>Re: [OMPI users] 1.8.5, mxm, and a spurious '-L' flag</strong></a>&nbsp;<a name="26942"><em>David Shrader</em></a>&nbsp;<em>(2015-05-26 13:40:00)</em></li>
<li><a href="26941.php"><strong>Re: [OMPI users] 1.8.5, mxm, and a spurious '-L' flag</strong></a>&nbsp;<a name="26941"><em>Mike Dubman</em></a>&nbsp;<em>(2015-05-26 13:28:10)</em></li>
<li><a href="26940.php"><strong>Re: [OMPI users] 1.8.5, mxm, and a spurious '-L' flag</strong></a>&nbsp;<a name="26940"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-26 11:59:05)</em></li>
<li><a href="26939.php"><strong>Re: [OMPI users] 1.8.5, mxm, and a spurious '-L' flag</strong></a>&nbsp;<a name="26939"><em>David Shrader</em></a>&nbsp;<em>(2015-05-26 11:54:33)</em></li>
<li><a href="26938.php"><strong>Re: [OMPI users] 1.8.5, mxm, and a spurious '-L' flag</strong></a>&nbsp;<a name="26938"><em>Mike Dubman</em></a>&nbsp;<em>(2015-05-26 11:50:39)</em></li>
<li><a href="26937.php"><strong>Re: [OMPI users] 1.8.5, mxm, and a spurious '-L' flag</strong></a>&nbsp;<a name="26937"><em>Mike Dubman</em></a>&nbsp;<em>(2015-05-26 11:41:52)</em></li>
<li><a href="26936.php"><strong>Re: [OMPI users] 1.8.5, mxm, and a spurious '-L' flag</strong></a>&nbsp;<a name="26936"><em>David Shrader</em></a>&nbsp;<em>(2015-05-26 10:50:15)</em></li>
<li><a href="26935.php"><strong>Re: [OMPI users] Problems running linpack benchmark on old Sunfire	opteron nodes</strong></a>&nbsp;<a name="26935"><em>Rolf vandeVaart</em></a>&nbsp;<em>(2015-05-26 10:33:02)</em></li>
<li><a href="26934.php"><strong>Re: [OMPI users] Problems running linpack benchmark on old Sunfire opteron nodes</strong></a>&nbsp;<a name="26934"><em>Aur&#195;&#169;lien Bouteiller</em></a>&nbsp;<em>(2015-05-26 10:10:01)</em></li>
<li><a href="26933.php"><strong>Re: [OMPI users] MXM problem</strong></a>&nbsp;<a name="26933"><em>Timur Ismagilov</em></a>&nbsp;<em>(2015-05-26 05:40:25)</em></li>
<li><a href="26932.php"><strong>Re: [OMPI users] MXM problem</strong></a>&nbsp;<a name="26932"><em>Timur Ismagilov</em></a>&nbsp;<em>(2015-05-26 04:38:14)</em></li>
<li><a href="26931.php"><strong>Re: [OMPI users] Error: &quot;all nodes which are allocated for this job are already filled&quot;</strong></a>&nbsp;<a name="26931"><em>Mike Dubman</em></a>&nbsp;<em>(2015-05-26 02:55:43)</em></li>
<li><a href="26930.php"><strong>Re: [OMPI users] Error: &quot;all nodes which are allocated for this job are already filled&quot;</strong></a>&nbsp;<a name="26930"><em>Rahul Yadav</em></a>&nbsp;<em>(2015-05-26 00:08:15)</em></li>
<li><a href="26929.php"><strong>Re: [OMPI users] Error: &quot;all nodes which are allocated for this job are already filled&quot;</strong></a>&nbsp;<a name="26929"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-26 00:03:00)</em></li>
<li><a href="26928.php"><strong>Re: [OMPI users] Error: &quot;all nodes which are allocated for this job are already filled&quot;</strong></a>&nbsp;<a name="26928"><em>Gilles Gouaillardet</em></a>&nbsp;<em>(2015-05-26 00:00:24)</em></li>
<li><a href="26927.php"><strong>Re: [OMPI users] Error: &quot;all nodes which are allocated for this job are already filled&quot;</strong></a>&nbsp;<a name="26927"><em>Rahul Yadav</em></a>&nbsp;<em>(2015-05-25 23:51:02)</em></li>
<li><a href="26926.php"><strong>[OMPI users] Fwd: Re[4]:  MXM problem</strong></a>&nbsp;<a name="26926"><em>Timur Ismagilov</em></a>&nbsp;<em>(2015-05-25 14:09:42)</em></li>
<li><a href="26925.php"><strong>Re: [OMPI users] MXM problem</strong></a>&nbsp;<a name="26925"><em>Mike Dubman</em></a>&nbsp;<em>(2015-05-25 13:31:59)</em></li>
<li><a href="26924.php"><strong>Re: [OMPI users] MXM problem</strong></a>&nbsp;<a name="26924"><em>Timur Ismagilov</em></a>&nbsp;<em>(2015-05-25 13:26:11)</em></li>
<li><a href="26923.php"><strong>Re: [OMPI users] MXM problem</strong></a>&nbsp;<a name="26923"><em>Mike Dubman</em></a>&nbsp;<em>(2015-05-25 12:39:03)</em></li>
<li><a href="26922.php"><strong>Re: [OMPI users] MXM problem</strong></a>&nbsp;<a name="26922"><em>Timur Ismagilov</em></a>&nbsp;<em>(2015-05-25 12:11:32)</em></li>
<li><a href="26921.php"><strong>Re: [OMPI users] MXM problem</strong></a>&nbsp;<a name="26921"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-25 12:04:24)</em></li>
<li><a href="26920.php"><strong>Re: [OMPI users] Default value of btl_openib_memalign_threshold</strong></a>&nbsp;<a name="26920"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-25 11:56:48)</em></li>
<li><a href="26919.php"><strong>[OMPI users] MXM problem</strong></a>&nbsp;<a name="26919"><em>Timur Ismagilov</em></a>&nbsp;<em>(2015-05-25 11:55:45)</em></li>
<li><a href="26918.php"><strong>Re: [OMPI users] Default value of btl_openib_memalign_threshold</strong></a>&nbsp;<a name="26918"><em>Xavier Besseron</em></a>&nbsp;<em>(2015-05-25 11:46:36)</em></li>
<li><a href="26917.php"><strong>[OMPI users] NAS Parallel Benchmark implementation for (open) MPI/C</strong></a>&nbsp;<a name="26917"><em>etcamargo</em></a>&nbsp;<em>(2015-05-25 10:41:33)</em></li>
<li><a href="26916.php"><strong>Re: [OMPI users] Default value of btl_openib_memalign_threshold</strong></a>&nbsp;<a name="26916"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-25 10:12:36)</em></li>
<li><a href="26915.php"><strong>Re: [OMPI users] Default value of btl_openib_memalign_threshold</strong></a>&nbsp;<a name="26915"><em>Xavier Besseron</em></a>&nbsp;<em>(2015-05-25 06:04:13)</em></li>
<li><a href="26914.php"><strong>Re: [OMPI users] Default value of btl_openib_memalign_threshold</strong></a>&nbsp;<a name="26914"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-24 20:27:05)</em></li>
<li><a href="26913.php"><strong>[OMPI users] Fwd: Default value of btl_openib_memalign_threshold</strong></a>&nbsp;<a name="26913"><em>Xavier Besseron</em></a>&nbsp;<em>(2015-05-24 12:07:52)</em></li>
<li><a href="26912.php"><strong>Re: [OMPI users] OPENMPI only recognize 4 cores of AWS EC2 machine</strong></a>&nbsp;<a name="26912"><em>XingFENG</em></a>&nbsp;<em>(2015-05-24 05:43:10)</em></li>
<li><a href="26911.php"><strong>Re: [OMPI users] OPENMPI only recognize 4 cores of AWS EC2 machine</strong></a>&nbsp;<a name="26911"><em>Gilles Gouaillardet</em></a>&nbsp;<em>(2015-05-24 05:41:16)</em></li>
<li><a href="26910.php"><strong>Re: [OMPI users] OPENMPI only recognize 4 cores of AWS EC2 machine</strong></a>&nbsp;<a name="26910"><em>XingFENG</em></a>&nbsp;<em>(2015-05-24 05:26:27)</em></li>
<li><a href="26909.php"><strong>Re: [OMPI users] OPENMPI only recognize 4 cores of AWS EC2 machine</strong></a>&nbsp;<a name="26909"><em>Gilles Gouaillardet</em></a>&nbsp;<em>(2015-05-24 05:24:14)</em></li>
<li><a href="26908.php"><strong>[OMPI users] OPENMPI only recognize 4 cores of AWS EC2 machine</strong></a>&nbsp;<a name="26908"><em>XingFENG</em></a>&nbsp;<em>(2015-05-24 04:24:19)</em></li>
<li><a href="26907.php"><strong>Re: [OMPI users] Problems running linpack benchmark on old Sunfire opteron nodes</strong></a>&nbsp;<a name="26907"><em>Gilles Gouaillardet</em></a>&nbsp;<em>(2015-05-23 03:55:03)</em></li>
<li><a href="26906.php"><strong>[OMPI users] Problems running linpack benchmark on old Sunfire opteron nodes</strong></a>&nbsp;<a name="26906"><em>Lane, William</em></a>&nbsp;<em>(2015-05-23 03:17:09)</em></li>
<li><a href="26905.php"><strong>Re: [OMPI users] 1.8.5, mxm, and a spurious '-L' flag</strong></a>&nbsp;<a name="26905"><em>Mike Dubman</em></a>&nbsp;<em>(2015-05-23 02:05:22)</em></li>
<li><a href="26904.php"><strong>[OMPI users] 1.8.5, mxm, and a spurious '-L' flag</strong></a>&nbsp;<a name="26904"><em>David Shrader</em></a>&nbsp;<em>(2015-05-22 18:07:20)</em></li>
<li><a href="26903.php"><strong>[OMPI users] Fwd: job post</strong></a>&nbsp;<a name="26903"><em>Joshua Ladd</em></a>&nbsp;<em>(2015-05-22 11:46:58)</em></li>
<li><a href="26902.php"><strong>Re: [OMPI users] cuIpcOpenMemHandle failure when using OpenMPI 1.8.5 with CUDA 7.0 and Multi-Process Service</strong></a>&nbsp;<a name="26902"><em>Rolf vandeVaart</em></a>&nbsp;<em>(2015-05-21 15:04:28)</em></li>
<li><a href="26901.php"><strong>Re: [OMPI users] cuIpcOpenMemHandle failure when using OpenMPI 1.8.5 with CUDA 7.0 and Multi-Process Service</strong></a>&nbsp;<a name="26901"><em>Lev Givon</em></a>&nbsp;<em>(2015-05-21 14:18:33)</em></li>
<li><a href="26900.php"><strong>Re: [OMPI users] cuIpcOpenMemHandle failure when using OpenMPI 1.8.5 with CUDA 7.0 and Multi-Process Service</strong></a>&nbsp;<a name="26900"><em>Lev Givon</em></a>&nbsp;<em>(2015-05-21 11:32:33)</em></li>
<li><a href="26899.php"><strong>Re: [OMPI users] Open MPI collectives algorithm selection</strong></a>&nbsp;<a name="26899"><em>Khalid Hasanov</em></a>&nbsp;<em>(2015-05-21 04:09:51)</em></li>
<li><a href="26898.php"><strong>Re: [OMPI users] Open MPI collectives algorithm selection</strong></a>&nbsp;<a name="26898"><em>George Bosilca</em></a>&nbsp;<em>(2015-05-20 23:14:35)</em></li>
<li><a href="26897.php"><strong>Re: [OMPI users] Open MPI collectives algorithm selection</strong></a>&nbsp;<a name="26897"><em>Khalid Hasanov</em></a>&nbsp;<em>(2015-05-20 19:52:53)</em></li>
<li><a href="26896.php"><strong>Re: [OMPI users] Open MPI collectives algorithm selection</strong></a>&nbsp;<a name="26896"><em>George Bosilca</em></a>&nbsp;<em>(2015-05-20 19:05:04)</em></li>
<li><a href="26895.php"><strong>Re: [OMPI users] Performance differences using mpirun and SLURM</strong></a>&nbsp;<a name="26895"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-20 18:01:17)</em></li>
<li><a href="26894.php"><strong>[OMPI users] Performance differences using mpirun and SLURM</strong></a>&nbsp;<a name="26894"><em>Patrick LeGresley</em></a>&nbsp;<em>(2015-05-20 17:15:15)</em></li>
<li><a href="26893.php"><strong>Re: [OMPI users] 'The MPI_Comm_rank() function was called before MPI_INIT was invoked'</strong></a>&nbsp;<a name="26893"><em>Gilles Gouaillardet</em></a>&nbsp;<em>(2015-05-20 08:07:17)</em></li>
<li><a href="26892.php"><strong>Re: [OMPI users] cuIpcOpenMemHandle failure when using OpenMPI 1.8.5 with CUDA 7.0 and Multi-Process Service</strong></a>&nbsp;<a name="26892"><em>Rolf vandeVaart</em></a>&nbsp;<em>(2015-05-20 07:48:15)</em></li>
<li><a href="26891.php"><strong>[OMPI users] 'The MPI_Comm_rank() function was called before MPI_INIT was invoked'</strong></a>&nbsp;<a name="26891"><em>#MOHAMMAD ASIF KHAN#</em></a>&nbsp;<em>(2015-05-20 06:07:08)</em></li>
<li><a href="26890.php"><strong>Re: [OMPI users] Openmpi 1.8.5 on Linux with threading support</strong></a>&nbsp;<a name="26890"><em>Nilo Menezes</em></a>&nbsp;<em>(2015-05-20 03:53:04)</em></li>
<li><a href="26889.php"><strong>Re: [OMPI users] cuIpcOpenMemHandle failure when using OpenMPI 1.8.5 with CUDA 7.0 and Multi-Process Service</strong></a>&nbsp;<a name="26889"><em>Lev Givon</em></a>&nbsp;<em>(2015-05-19 22:25:20)</em></li>
<li><a href="26888.php"><strong>Re: [OMPI users] Open MPI collectives algorithm selection</strong></a>&nbsp;<a name="26888"><em>Khalid Hasanov</em></a>&nbsp;<em>(2015-05-19 21:53:04)</em></li>
<li><a href="26887.php"><strong>Re: [OMPI users] Open MPI collectives algorithm selection</strong></a>&nbsp;<a name="26887"><em>Gilles Gouaillardet</em></a>&nbsp;<em>(2015-05-19 21:47:04)</em></li>
<li><a href="26886.php"><strong>Re: [OMPI users] Open MPI collectives algorithm selection</strong></a>&nbsp;<a name="26886"><em>Khalid Hasanov</em></a>&nbsp;<em>(2015-05-19 21:30:58)</em></li>
<li><a href="26885.php"><strong>Re: [OMPI users] Open MPI collectives algorithm selection</strong></a>&nbsp;<a name="26885"><em>Gilles Gouaillardet</em></a>&nbsp;<em>(2015-05-19 21:12:06)</em></li>
<li><a href="26884.php"><strong>Re: [OMPI users] cuIpcOpenMemHandle failure when using OpenMPI 1.8.5 with CUDA 7.0 and Multi-Process Service</strong></a>&nbsp;<a name="26884"><em>Lev Givon</em></a>&nbsp;<em>(2015-05-19 20:32:53)</em></li>
<li><a href="26883.php"><strong>Re: [OMPI users] cuIpcOpenMemHandle failure when using OpenMPI 1.8.5 with CUDA 7.0 and Multi-Process Service</strong></a>&nbsp;<a name="26883"><em>Rolf vandeVaart</em></a>&nbsp;<em>(2015-05-19 20:28:46)</em></li>
<li><a href="26882.php"><strong>[OMPI users] Open MPI collectives algorithm selection</strong></a>&nbsp;<a name="26882"><em>Khalid Hasanov</em></a>&nbsp;<em>(2015-05-19 19:39:08)</em></li>
<li><a href="26881.php"><strong>[OMPI users] cuIpcOpenMemHandle failure when using OpenMPI 1.8.5 with CUDA 7.0 and Multi-Process Service</strong></a>&nbsp;<a name="26881"><em>Lev Givon</em></a>&nbsp;<em>(2015-05-19 18:29:38)</em></li>
<li><a href="26880.php"><strong>Re: [OMPI users] Openmpi 1.8.5 on Linux with threading support</strong></a>&nbsp;<a name="26880"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-19 09:34:18)</em></li>
<li><a href="26879.php"><strong>[OMPI users] Openmpi 1.8.5 on Linux with threading support</strong></a>&nbsp;<a name="26879"><em>Nilo Menezes</em></a>&nbsp;<em>(2015-05-19 07:04:47)</em></li>
<li><a href="26878.php"><strong>Re: [OMPI users] openmpi-1.8.5: ORTE was unable to start daemons</strong></a>&nbsp;<a name="26878"><em>Siegmar Gross</em></a>&nbsp;<em>(2015-05-18 06:51:04)</em></li>
<li><a href="26877.php"><strong>Re: [OMPI users] openmpi-1.8.5: ORTE was unable to start daemons</strong></a>&nbsp;<a name="26877"><em>Siegmar Gross</em></a>&nbsp;<em>(2015-05-17 05:52:11)</em></li>
<li><a href="26876.php"><strong>Re: [OMPI users] openmpi-1.8.5: ORTE was unable to start daemons</strong></a>&nbsp;<a name="26876"><em>Siegmar Gross</em></a>&nbsp;<em>(2015-05-15 11:32:10)</em></li>
<li><a href="26875.php"><strong>Re: [OMPI users] openmpi-1.8.5: Java UnsupportedClassVersionError for Solaris</strong></a>&nbsp;<a name="26875"><em>Siegmar Gross</em></a>&nbsp;<em>(2015-05-15 10:18:18)</em></li>
<li><a href="26874.php"><strong>Re: [OMPI users] About POSIX APIs used on openMPI</strong></a>&nbsp;<a name="26874"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-15 08:37:12)</em></li>
<li><a href="26873.php"><strong>Re: [OMPI users] openmpi-1.8.5: ORTE was unable to start daemons</strong></a>&nbsp;<a name="26873"><em>Gilles Gouaillardet</em></a>&nbsp;<em>(2015-05-15 08:34:34)</em></li>
<li><a href="26872.php"><strong>Re: [OMPI users] openmpi-1.8.5: Java UnsupportedClassVersionError for Solaris</strong></a>&nbsp;<a name="26872"><em>Gilles Gouaillardet</em></a>&nbsp;<em>(2015-05-15 08:21:17)</em></li>
<li><a href="26871.php"><strong>[OMPI users] openmpi-1.8.5: ORTE was unable to start daemons</strong></a>&nbsp;<a name="26871"><em>Siegmar Gross</em></a>&nbsp;<em>(2015-05-15 07:57:13)</em></li>
<li><a href="26870.php"><strong>[OMPI users] openmpi-1.8.5: Java UnsupportedClassVersionError for Solaris</strong></a>&nbsp;<a name="26870"><em>Siegmar Gross</em></a>&nbsp;<em>(2015-05-15 07:32:33)</em></li>
<li><a href="26869.php"><strong>[OMPI users] About POSIX APIs used on openMPI</strong></a>&nbsp;<a name="26869"><em>Chaitra Kumar</em></a>&nbsp;<em>(2015-05-15 02:29:40)</em></li>
<li><a href="26868.php"><strong>Re: [OMPI users] OpenMPI on Windows without Cygwin</strong></a>&nbsp;<a name="26868"><em>J Martin Rushton</em></a>&nbsp;<em>(2015-05-14 06:54:19)</em></li>
<li><a href="26867.php"><strong>Re: [OMPI users] MPI_Comm_spawn and shared memory</strong></a>&nbsp;<a name="26867"><em>Radoslaw Martyniszyn</em></a>&nbsp;<em>(2015-05-14 03:26:30)</em></li>
<li><a href="26866.php"><strong>Re: [OMPI users] MPI_Comm_spawn and shared memory</strong></a>&nbsp;<a name="26866"><em>Gilles Gouaillardet</em></a>&nbsp;<em>(2015-05-14 03:12:02)</em></li>
<li><a href="26865.php"><strong>[OMPI users] MPI_Comm_spawn and shared memory</strong></a>&nbsp;<a name="26865"><em>Radoslaw Martyniszyn</em></a>&nbsp;<em>(2015-05-14 02:52:53)</em></li>
<li><a href="26864.php"><strong>Re: [OMPI users] OpenMPI on Windows without Cygwin</strong></a>&nbsp;<a name="26864"><em>Damien</em></a>&nbsp;<em>(2015-05-13 16:28:22)</em></li>
<li><a href="26863.php"><strong>Re: [OMPI users] OpenMPI on Windows without Cygwin</strong></a>&nbsp;<a name="26863"><em>Walt Brainerd</em></a>&nbsp;<em>(2015-05-13 16:19:06)</em></li>
<li><a href="26862.php"><strong>Re: [OMPI users] OpenMPI on Windows without Cygwin</strong></a>&nbsp;<a name="26862"><em>Damien</em></a>&nbsp;<em>(2015-05-13 11:55:23)</em></li>
<li><a href="26861.php"><strong>Re: [OMPI users] Error: &quot;all nodes which are allocated for this job are already filled&quot;</strong></a>&nbsp;<a name="26861"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-13 11:02:56)</em></li>
<li><a href="26860.php"><strong>Re: [OMPI users] Error: &quot;all nodes which are allocated for this job are already filled&quot;</strong></a>&nbsp;<a name="26860"><em>Rahul Yadav</em></a>&nbsp;<em>(2015-05-13 03:21:08)</em></li>
<li><a href="26859.php"><strong>Re: [OMPI users] libnuma with openmpi</strong></a>&nbsp;<a name="26859"><em>Chaitra Kumar</em></a>&nbsp;<em>(2015-05-12 05:27:39)</em></li>
<li><a href="26858.php"><strong>Re: [OMPI users] libnuma with openmpi</strong></a>&nbsp;<a name="26858"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-12 00:33:49)</em></li>
<li><a href="26857.php"><strong>Re: [OMPI users] libnuma with openmpi</strong></a>&nbsp;<a name="26857"><em>Chaitra Kumar</em></a>&nbsp;<em>(2015-05-12 00:26:40)</em></li>
<li><a href="26856.php"><strong>Re: [OMPI users] failure of 1.8.5 on FreeBSD</strong></a>&nbsp;<a name="26856"><em>Steve Kargl</em></a>&nbsp;<em>(2015-05-11 17:29:18)</em></li>
<li><a href="26855.php"><strong>[OMPI users] OpenMPI on Windows without Cygwin</strong></a>&nbsp;<a name="26855"><em>Walt Brainerd</em></a>&nbsp;<em>(2015-05-11 17:07:41)</em></li>
<li><a href="26854.php"><strong>[OMPI users] failure of 1.8.5 on FreeBSD</strong></a>&nbsp;<a name="26854"><em>Steve Kargl</em></a>&nbsp;<em>(2015-05-11 15:55:01)</em></li>
<li><a href="26853.php"><strong>Re: [OMPI users] libnuma with openmpi</strong></a>&nbsp;<a name="26853"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-11 12:30:41)</em></li>
<li><a href="26852.php"><strong>[OMPI users] libnuma with openmpi</strong></a>&nbsp;<a name="26852"><em>Chaitra Kumar</em></a>&nbsp;<em>(2015-05-11 02:17:47)</em></li>
<li><a href="26851.php"><strong>Re: [OMPI users] How does mpirun handle Ctrl+C?</strong></a>&nbsp;<a name="26851"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-08 12:36:32)</em></li>
<li><a href="26850.php"><strong>Re: [OMPI users] How does mpirun handle Ctrl+C?</strong></a>&nbsp;<a name="26850"><em>Seth Axen</em></a>&nbsp;<em>(2015-05-08 01:42:40)</em></li>
<li><a href="26849.php"><strong>Re: [OMPI users] How does mpirun handle Ctrl+C?</strong></a>&nbsp;<a name="26849"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-07 19:00:20)</em></li>
<li><a href="26848.php"><strong>[OMPI users] How does mpirun handle Ctrl+C?</strong></a>&nbsp;<a name="26848"><em>Seth Axen</em></a>&nbsp;<em>(2015-05-07 17:31:26)</em></li>
<li><a href="26847.php"><strong>Re: [OMPI users] Error: &quot;all nodes which are allocated for this job are already filled&quot;</strong></a>&nbsp;<a name="26847"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-07 11:06:14)</em></li>
<li><a href="26846.php"><strong>Re: [OMPI users] performance issue mpi_init</strong></a>&nbsp;<a name="26846"><em>Steven Vancoillie</em></a>&nbsp;<em>(2015-05-07 02:37:51)</em></li>
<li><a href="26845.php"><strong>[OMPI users] Error: &quot;all nodes which are allocated for this job are already filled&quot;</strong></a>&nbsp;<a name="26845"><em>Rahul Yadav</em></a>&nbsp;<em>(2015-05-07 02:24:53)</em></li>
<li><a href="26844.php"><strong>Re: [OMPI users] Support for progress threads in 1.8.4</strong></a>&nbsp;<a name="26844"><em>Kaushal Kumar</em></a>&nbsp;<em>(2015-05-05 20:56:38)</em></li>
<li><a href="26843.php"><strong>Re: [OMPI users] Support for progress threads in 1.8.4</strong></a>&nbsp;<a name="26843"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-05 20:34:55)</em></li>
<li><a href="26842.php"><strong>[OMPI users]  Support for progress threads in 1.8.4</strong></a>&nbsp;<a name="26842"><em>Kaushal Kumar</em></a>&nbsp;<em>(2015-05-05 18:46:19)</em></li>
<li><a href="26841.php"><strong>Re: [OMPI users] what was ompi configured with?</strong></a>&nbsp;<a name="26841"><em>David Shrader</em></a>&nbsp;<em>(2015-05-05 17:55:28)</em></li>
<li><a href="26840.php"><strong>Re: [OMPI users] what was ompi configured with?</strong></a>&nbsp;<a name="26840"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-05 14:58:03)</em></li>
<li><a href="26839.php"><strong>Re: [OMPI users] what was ompi configured with?</strong></a>&nbsp;<a name="26839"><em>Douglas L Reeder</em></a>&nbsp;<em>(2015-05-05 14:58:51)</em></li>
<li><a href="26838.php"><strong>[OMPI users] what was ompi configured with?</strong></a>&nbsp;<a name="26838"><em>David Shrader</em></a>&nbsp;<em>(2015-05-05 14:54:46)</em></li>
<li><a href="26837.php"><strong>Re: [OMPI users] Hang in MPI_Comm_split in 2 RHEL Linux nodes with INTEL MIC cards</strong></a>&nbsp;<a name="26837"><em>Nathan Hjelm</em></a>&nbsp;<em>(2015-05-05 10:48:00)</em></li>
<li><a href="26836.php"><strong>Re: [OMPI users] Hang in MPI_Comm_split in 2 RHEL Linux nodes with INTEL MIC cards</strong></a>&nbsp;<a name="26836"><em>Manumachu Reddy</em></a>&nbsp;<em>(2015-05-05 01:09:47)</em></li>
<li><a href="26835.php"><strong>Re: [OMPI users] Running mpi with different account</strong></a>&nbsp;<a name="26835"><em>XingFENG</em></a>&nbsp;<em>(2015-05-04 09:59:05)</em></li>
<li><a href="26834.php"><strong>Re: [OMPI users] Running mpi with different account</strong></a>&nbsp;<a name="26834"><em>Jeff Squyres (jsquyres)</em></a>&nbsp;<em>(2015-05-04 09:32:57)</em></li>
<li><a href="26833.php"><strong>Re: [OMPI users] Running mpi with different account</strong></a>&nbsp;<a name="26833"><em>XingFENG</em></a>&nbsp;<em>(2015-05-03 20:52:46)</em></li>
<li><a href="26832.php"><strong>Re: [OMPI users] Running mpi with different account</strong></a>&nbsp;<a name="26832"><em>Ralph Castain</em></a>&nbsp;<em>(2015-05-03 10:54:53)</em></li>
<li><a href="26831.php"><strong>Re: [OMPI users] Running mpi with different account</strong></a>&nbsp;<a name="26831"><em>XingFENG</em></a>&nbsp;<em>(2015-05-03 08:54:05)</em></li>
<li><a href="26830.php"><strong>Re: [OMPI users] Running mpi with different account</strong></a>&nbsp;<a name="26830"><em>XingFENG</em></a>&nbsp;<em>(2015-05-03 08:03:30)</em></li>
<li><a href="26829.php"><strong>[OMPI users] Support for progress threads in 1.8.4</strong></a>&nbsp;<a name="26829"><em>Kaushal Kumar</em></a>&nbsp;<em>(2015-05-02 15:13:59)</em></li>
</ul>
<hr>
<div class="center">
<table>
<tr><th><a name="end">Last message date: </a></th><td><em>2016-07-27 12:01:45</em></td>
<th>Archived on: </th><td><em>2016-07-27 12:02:19 EDT</em></td>
</table>
</div>
<div class="center">
<table border="2" width="100%" class="links">
<tr>
<th><a href="index.php">Thread view</a></th>
<th><a href="subject.php">Subject view</a></th>
<th><a href="author.php">Author view</a></th>
</tr><tr><th><a href="http://www.open-mpi.org/community/lists/users/2015/04/date.php">Previous Folder, Date view</a></th><th><a href="http://www.open-mpi.org/community/lists/users/2015/06/date.php">Next Folder, Date view</a></th><th><a href="http://www.open-mpi.org/community/lists/users/index.php">List of Folders</a></th></tr>
</table>
</div>
<!-- trailer="footer" -->
<? 
if (preg_match("/\/[12][0-9][0-9][0-9]\/[01][0-9]\//", $_SERVER{'REQUEST_URI'})) {
    include("../../include/index-footer.inc");
} else {
    include("include/index-footer.inc");
}
?>
