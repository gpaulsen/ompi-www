<div dir="ltr">They are just as you say but while one run until the end (case 3 using --deamons-debug)   the other hangs (Case 1)<div><br></div><div>in the case 1  even if is only in one node with <span class="Apple-style-span" style="border-collapse:collapse;color:rgb(80,0,80);font-family:arial,sans-serif;font-size:11px">plm_rsh_no_tree_spawn 1 flag (that as you say shouldn&#39;t do anything), </span><span class="Apple-style-span" style="border-collapse:collapse;color:rgb(80,0,80);font-family:arial,sans-serif;font-size:11px">the process hangs,</span></div>
<div><span class="Apple-style-span" style="border-collapse:collapse;color:rgb(80,0,80);font-family:arial,sans-serif;font-size:11px"><br></span></div><div><span class="Apple-style-span" style="border-collapse:collapse;color:rgb(80,0,80);font-family:arial,sans-serif;font-size:11px">while in the case 2 without this flags in the same node it runs,</span></div>
<div><span class="Apple-style-span" style="border-collapse:collapse;color:rgb(80,0,80);font-family:arial,sans-serif;font-size:11px"><br></span></div><div><span class="Apple-style-span" style="border-collapse:collapse;color:rgb(80,0,80);font-family:arial,sans-serif;font-size:11px">for the case 3 </span><span class="Apple-style-span" style="border-collapse:collapse;color:rgb(80,0,80);font-family:arial,sans-serif;font-size:11px"> I add to the case 1 the </span>--deamons-debug flag in which case it runs again. </div>
<div><br></div><div>the point where it hangs in the case 1 is in the point in where </div><div><br></div><div> <span class="Apple-style-span" style="border-collapse:collapse;color:rgb(80,0,80);font-family:arial,sans-serif;font-size:11px">Daemon was launched on nexus17.nlroc - beginning to initialize</span></div>
<div><br></div><div>appear in the case 3 </div></div><div class="gmail_extra"><br><br><div class="gmail_quote">On Wed, Jul 16, 2014 at 2:46 AM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div style="word-wrap:break-word">Forgive me, but I am now fully confused - case 1 and case 3 appear identical to me, except for the debug-daemons flag on case 3.<div>
<br><div><br><div><div>On Jul 15, 2014, at 7:56 AM, Ricardo Fernández-Perea &lt;<a href="mailto:rfernandezperea@gmail.com" target="_blank">rfernandezperea@gmail.com</a>&gt; wrote:</div><br><blockquote type="cite"><div dir="ltr">
<div>What I mean with <span style="border-collapse:collapse;font-family:arial,sans-serif;font-size:11px"> &quot;another mpi process&quot;.</span></div>I have 4 nodes where there is  process that use mpi and where initiated using mpirun from the control node already running when I  run the command against any of those  nodes it execute but when I do it against any other node it fails if  <span style="border-collapse:collapse;font-family:arial,sans-serif;font-size:11px">no_tree_spawn flag is used it works OK</span><div>

<span style="border-collapse:collapse;font-family:arial,sans-serif;font-size:11px"><br></span></div><div><span style="border-collapse:collapse;font-family:arial,sans-serif;font-size:11px">case 1 it Fails</span></div>
<div><span style="border-collapse:collapse;font-family:arial,sans-serif;font-size:11px"><br></span></div><div><span style="border-collapse:collapse;font-family:arial,sans-serif;font-size:11px"><div>
/opt/openmpi/bin/mpirun  --mca plm_rsh_no_tree_spawn 1  -mca oob_base_verbose 10 -mca plm_base_verbose 10   -host nexus17 ompi_info</div><div><br></div><div>[nexus10.nlroc:31321] mca: base: components_register: registering plm components</div>

<div>[nexus10.nlroc:31321] mca: base: components_register: found loaded component isolated</div><div>[nexus10.nlroc:31321] mca: base: components_register: component isolated has no register or open function</div><div>[nexus10.nlroc:31321] mca: base: components_register: found loaded component rsh</div>

<div>[nexus10.nlroc:31321] mca: base: components_register: component rsh register function successful</div><div>[nexus10.nlroc:31321] mca: base: components_register: found loaded component slurm</div><div>[nexus10.nlroc:31321] mca: base: components_register: component slurm register function successful</div>

<div>[nexus10.nlroc:31321] mca: base: components_open: opening plm components</div><div>[nexus10.nlroc:31321] mca: base: components_open: found loaded component isolated</div><div>[nexus10.nlroc:31321] mca: base: components_open: component isolated open function successful</div>

<div>[nexus10.nlroc:31321] mca: base: components_open: found loaded component rsh</div><div>[nexus10.nlroc:31321] mca: base: components_open: component rsh open function successful</div><div>[nexus10.nlroc:31321] mca: base: components_open: found loaded component slurm</div>

<div>[nexus10.nlroc:31321] mca: base: components_open: component slurm open function successful</div><div>[nexus10.nlroc:31321] mca:base:select: Auto-selecting plm components</div><div>[nexus10.nlroc:31321] mca:base:select:(  plm) Querying component [isolated]</div>

<div>[nexus10.nlroc:31321] mca:base:select:(  plm) Query of component [isolated] set priority to 0</div><div>[nexus10.nlroc:31321] mca:base:select:(  plm) Querying component [rsh]</div><div>[nexus10.nlroc:31321] mca:base:select:(  plm) Query of component [rsh] set priority to 10</div>

<div>[nexus10.nlroc:31321] mca:base:select:(  plm) Querying component [slurm]</div><div>[nexus10.nlroc:31321] mca:base:select:(  plm) Skipping component [slurm]. Query failed to return a module</div><div>[nexus10.nlroc:31321] mca:base:select:(  plm) Selected component [rsh]</div>

<div>[nexus10.nlroc:31321] mca: base: close: component isolated closed</div><div>[nexus10.nlroc:31321] mca: base: close: unloading component isolated</div><div>[nexus10.nlroc:31321] mca: base: close: component slurm closed</div>

<div>[nexus10.nlroc:31321] mca: base: close: unloading component slurm</div><div>[nexus10.nlroc:31321] mca: base: components_register: registering oob components</div><div>[nexus10.nlroc:31321] mca: base: components_register: found loaded component tcp</div>

<div>[nexus10.nlroc:31321] mca: base: components_register: component tcp register function successful</div><div>[nexus10.nlroc:31321] mca: base: components_open: opening oob components</div><div>[nexus10.nlroc:31321] mca: base: components_open: found loaded component tcp</div>

<div>[nexus10.nlroc:31321] mca: base: components_open: component tcp open function successful</div><div>[nexus10.nlroc:31321] mca:oob:select: checking available component tcp</div><div>[nexus10.nlroc:31321] mca:oob:select: Querying component [tcp]</div>

<div>[nexus10.nlroc:31321] oob:tcp: component_available called</div><div>[nexus10.nlroc:31321] WORKING INTERFACE 1 KERNEL INDEX 1 FAMILY: V4</div><div>[nexus10.nlroc:31321] WORKING INTERFACE 2 KERNEL INDEX 2 FAMILY: V4</div>

<div>[nexus10.nlroc:31321] [[56634,0],0] oob:tcp:init creating module for V4 address on interface en0</div><div>[nexus10.nlroc:31321] [[56634,0],0] oob:tcp:init adding 172.16.1.10 to our list of V4 connections</div><div>
[nexus10.nlroc:31321] [[56634,0],0] TCP STARTUP</div>
<div>[nexus10.nlroc:31321] [[56634,0],0] attempting to bind to IPv4 port 0</div><div>[nexus10.nlroc:31321] [[56634,0],0] assigned IPv4 port 50898</div><div>[nexus10.nlroc:31321] mca:oob:select: Adding component to end</div>

<div>[nexus10.nlroc:31321] mca:oob:select: Found 1 active transports</div><div><br></div><div>I Crtl-C here when it hangs</div><div><br></div><div>^C[nexus10.nlroc:31321] [[56634,0],0] OOB_SEND: rml_oob_send.c:199</div><div>

[nexus10.nlroc:31321] [[56634,0],0] oob:base:send to target [[56634,0],1]</div><div>[nexus10.nlroc:31321] [[56634,0],0] oob:base:send unknown peer [[56634,0],1]</div><div>[nexus10.nlroc:31321] [[56634,0],0] is NOT reachable by TCP</div>

<div>[nexus10.nlroc:31321] mca: base: close: component rsh closed</div><div>[nexus10.nlroc:31321] mca: base: close: unloading component rsh</div><div>[nexus10.nlroc:31321] [[56634,0],0] TCP SHUTDOWN</div><div>[nexus10.nlroc:31321] mca: base: close: component tcp closed</div>

<div>[nexus10.nlroc:31321] mca: base: close: unloading component tcp</div><div><br></div><div><br></div><div>Case 2 to the same node but without the rsh_no_tree flag</div><div><br></div><div><div>/opt/openmpi/bin/mpirun    -mca oob_base_verbose 10 -mca plm_base_verbose 10   -host nexus17 ompi_info</div>

<div>[nexus10.nlroc:31369] mca: base: components_register: registering plm components</div><div>[nexus10.nlroc:31369] mca: base: components_register: found loaded component isolated</div><div>[nexus10.nlroc:31369] mca: base: components_register: component isolated has no register or open function</div>

<div>[nexus10.nlroc:31369] mca: base: components_register: found loaded component rsh</div><div>[nexus10.nlroc:31369] mca: base: components_register: component rsh register function successful</div><div>[nexus10.nlroc:31369] mca: base: components_register: found loaded component slurm</div>

<div>[nexus10.nlroc:31369] mca: base: components_register: component slurm register function successful</div><div>[nexus10.nlroc:31369] mca: base: components_open: opening plm components</div><div>[nexus10.nlroc:31369] mca: base: components_open: found loaded component isolated</div>

<div>[nexus10.nlroc:31369] mca: base: components_open: component isolated open function successful</div><div>[nexus10.nlroc:31369] mca: base: components_open: found loaded component rsh</div><div>[nexus10.nlroc:31369] mca: base: components_open: component rsh open function successful</div>

<div>[nexus10.nlroc:31369] mca: base: components_open: found loaded component slurm</div><div>[nexus10.nlroc:31369] mca: base: components_open: component slurm open function successful</div><div>[nexus10.nlroc:31369] mca:base:select: Auto-selecting plm components</div>

<div>[nexus10.nlroc:31369] mca:base:select:(  plm) Querying component [isolated]</div><div>[nexus10.nlroc:31369] mca:base:select:(  plm) Query of component [isolated] set priority to 0</div><div>[nexus10.nlroc:31369] mca:base:select:(  plm) Querying component [rsh]</div>

<div>[nexus10.nlroc:31369] mca:base:select:(  plm) Query of component [rsh] set priority to 10</div><div>[nexus10.nlroc:31369] mca:base:select:(  plm) Querying component [slurm]</div><div>[nexus10.nlroc:31369] mca:base:select:(  plm) Skipping component [slurm]. Query failed to return a module</div>

<div>[nexus10.nlroc:31369] mca:base:select:(  plm) Selected component [rsh]</div><div>[nexus10.nlroc:31369] mca: base: close: component isolated closed</div><div>[nexus10.nlroc:31369] mca: base: close: unloading component isolated</div>

<div>[nexus10.nlroc:31369] mca: base: close: component slurm closed</div><div>[nexus10.nlroc:31369] mca: base: close: unloading component slurm</div><div>[nexus10.nlroc:31369] mca: base: components_register: registering oob components</div>

<div>[nexus10.nlroc:31369] mca: base: components_register: found loaded component tcp</div><div>[nexus10.nlroc:31369] mca: base: components_register: component tcp register function successful</div><div>[nexus10.nlroc:31369] mca: base: components_open: opening oob components</div>

<div>[nexus10.nlroc:31369] mca: base: components_open: found loaded component tcp</div><div>[nexus10.nlroc:31369] mca: base: components_open: component tcp open function successful</div><div>[nexus10.nlroc:31369] mca:oob:select: checking available component tcp</div>

<div>[nexus10.nlroc:31369] mca:oob:select: Querying component [tcp]</div><div>[nexus10.nlroc:31369] oob:tcp: component_available called</div><div>[nexus10.nlroc:31369] WORKING INTERFACE 1 KERNEL INDEX 1 FAMILY: V4</div><div>

[nexus10.nlroc:31369] WORKING INTERFACE 2 KERNEL INDEX 2 FAMILY: V4</div><div>[nexus10.nlroc:31369] [[56810,0],0] oob:tcp:init creating module for V4 address on interface en0</div><div>[nexus10.nlroc:31369] [[56810,0],0] oob:tcp:init adding 172.16.1.10 to our list of V4 connections</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] TCP STARTUP</div><div>[nexus10.nlroc:31369] [[56810,0],0] attempting to bind to IPv4 port 0</div><div>[nexus10.nlroc:31369] [[56810,0],0] assigned IPv4 port 50908</div><div>[nexus10.nlroc:31369] mca:oob:select: Adding component to end</div>

<div>[nexus10.nlroc:31369] mca:oob:select: Found 1 active transports</div><div>[nexus17.nlroc:60584] mca: base: components_register: registering plm components</div><div>[nexus17.nlroc:60584] mca: base: components_register: found loaded component rsh</div>

<div>[nexus17.nlroc:60584] mca: base: components_register: component rsh register function successful</div><div>[nexus17.nlroc:60584] mca: base: components_open: opening plm components</div><div>[nexus17.nlroc:60584] mca: base: components_open: found loaded component rsh</div>

<div>[nexus17.nlroc:60584] mca: base: components_open: component rsh open function successful</div><div>[nexus17.nlroc:60584] mca:base:select: Auto-selecting plm components</div><div>[nexus17.nlroc:60584] mca:base:select:(  plm) Querying component [rsh]</div>

<div>[nexus17.nlroc:60584] mca:base:select:(  plm) Query of component [rsh] set priority to 10</div><div>[nexus17.nlroc:60584] mca:base:select:(  plm) Selected component [rsh]</div><div>[nexus17.nlroc:60584] mca: base: components_register: registering oob components</div>

<div>[nexus17.nlroc:60584] mca: base: components_register: found loaded component tcp</div><div>[nexus17.nlroc:60584] mca: base: components_register: component tcp register function successful</div><div>[nexus17.nlroc:60584] mca: base: components_open: opening oob components</div>

<div>[nexus17.nlroc:60584] mca: base: components_open: found loaded component tcp</div><div>[nexus17.nlroc:60584] mca: base: components_open: component tcp open function successful</div><div>[nexus17.nlroc:60584] mca:oob:select: checking available component tcp</div>

<div>[nexus17.nlroc:60584] mca:oob:select: Querying component [tcp]</div><div>[nexus17.nlroc:60584] oob:tcp: component_available called</div><div>[nexus17.nlroc:60584] WORKING INTERFACE 1 KERNEL INDEX 1 FAMILY: V4</div><div>

[nexus17.nlroc:60584] WORKING INTERFACE 2 KERNEL INDEX 2 FAMILY: V4</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:init creating module for V4 address on interface en0</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:init adding 172.16.1.17 to our list of V4 connections</div>

<div>[nexus17.nlroc:60584] WORKING INTERFACE 3 KERNEL INDEX 3 FAMILY: V4</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:init creating module for V4 address on interface en2</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:init adding 169.254.210.43 to our list of V4 connections</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] TCP STARTUP</div><div>[nexus17.nlroc:60584] [[56810,0],1] attempting to bind to IPv4 port 0</div><div>[nexus17.nlroc:60584] [[56810,0],1] assigned IPv4 port 54613</div><div>[nexus17.nlroc:60584] mca:oob:select: Adding component to end</div>

<div>[nexus17.nlroc:60584] mca:oob:select: Found 1 active transports</div><div>[nexus17.nlroc:60584] [[56810,0],1]: set_addr to uri 3723100160.0;tcp://<a href="http://172.16.1.10:50908/" target="_blank">172.16.1.10:50908</a></div>
<div>[nexus17.nlroc:60584] [[56810,0],1]:set_addr checking if peer [[56810,0],0] is reachable via component tcp</div>
<div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp: working peer [[56810,0],0] address tcp://<a href="http://172.16.1.10:50908/" target="_blank">172.16.1.10:50908</a></div><div>[nexus17.nlroc:60584] [[56810,0],1] PEER [[56810,0],0] MAY BE REACHABLE USING MODULE AT KINDEX 2 INTERFACE en0</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] PASSING ADDR 172.16.1.10 TO INTERFACE en0 AT KERNEL INDEX 2</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp set addr for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]: peer [[56810,0],0] is reachable via component tcp</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:processing set_peer cmd for interface en0</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:10</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:10</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:476] queue pending to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: initiating connection to [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:490] connect to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] orte_tcp_peer_try_connect: attempting to connect to proc [[56810,0],0] via interface en0</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] orte_tcp_peer_try_connect: attempting to connect to proc [[56810,0],0] via interface en0 on socket 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] orte_tcp_peer_try_connect: attempting to connect to proc [[56810,0],0] on <a href="http://172.16.1.10:50908/" target="_blank">172.16.1.10:50908</a> - 0 retries</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] waiting for connect completion to [[56810,0],0] - activating send event</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div><div>

[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler CONNECTING</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:complete_connect called for peer [[56810,0],0] on socket 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp_peer_complete_connect: sending ack to [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] SEND CONNECT ACK</div><div>[nexus17.nlroc:60584] [[56810,0],1] send blocking of 40 bytes to socket 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] connect-ack sent to socket 9</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp_peer_complete_connect: setting read event on connection to [[56810,0],0]</div><div>[nexus10.nlroc:31369] [[56810,0],0] mca_oob_tcp_listen_thread: new connection: (12, 0) <a href="http://172.16.1.17:54614/" target="_blank">172.16.1.17:54614</a></div>

<div>[nexus10.nlroc:31369] [[56810,0],0] connection_handler: working connection (12, 35) <a href="http://172.16.1.17:54614/" target="_blank">172.16.1.17:54614</a></div><div>[nexus10.nlroc:31369] [[56810,0],0] accept_connection: <a href="http://172.16.1.17:54614/" target="_blank">172.16.1.17:54614</a></div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called</div><div>[nexus10.nlroc:31369] [[56810,0],0] RECV CONNECT ACK FROM UNKNOWN ON SOCKET 12</div><div>[nexus10.nlroc:31369] [[56810,0],0] waiting for connect ack from UNKNOWN</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] connect ack received from UNKNOWN</div><div>[nexus10.nlroc:31369] [[56810,0],0] connect-ack recvd from UNKNOWN</div><div>[nexus10.nlroc:31369] [[56810,0],0] mca_oob_tcp_recv_connect: connection from new peer</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] connect-ack header from [[56810,0],1] is okay</div><div>[nexus10.nlroc:31369] [[56810,0],0] waiting for connect ack from [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0] connect ack received from [[56810,0],1]</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] connect-ack version from [[56810,0],1] matches ours</div><div>[nexus10.nlroc:31369] [[56810,0],0] connect-ack [[56810,0],1] authenticated</div><div>[nexus10.nlroc:31369] [[56810,0],0] tcp:peer_accept called for peer [[56810,0],1] in state UNKNOWN on socket 12</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] SEND CONNECT ACK</div><div>[nexus10.nlroc:31369] [[56810,0],0] send blocking of 40 bytes to socket 12</div><div>[nexus10.nlroc:31369] [[56810,0],0] connect-ack sent to socket 12</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]-[[56810,0],1] tcp_peer_connected on socket 12</div><div>[nexus10.nlroc:31369] [[56810,0],0]-[[56810,0],1] accepted: 172.16.1.10 - 172.16.1.17 nodelay 0 sndbuf 131072 rcvbuf 131072 flags 00000006</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] tcp:set_module called for peer [[56810,0],1]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler called for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] RECV CONNECT ACK FROM [[56810,0],0] ON SOCKET 9</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] waiting for connect ack from [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] connect ack received from [[56810,0],0]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus17.nlroc:60584] [[56810,0],1] connect-ack recvd from [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] connect-ack header from [[56810,0],0] is okay</div><div>[nexus17.nlroc:60584] [[56810,0],1] waiting for connect ack from [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] connect ack received from [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] connect-ack version from [[56810,0],0] matches ours</div><div>[nexus17.nlroc:60584] [[56810,0],1] connect-ack [[56810,0],0] authenticated</div><div>[nexus17.nlroc:60584] [[56810,0],1]-[[56810,0],0] tcp_peer_connected on socket 9</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]-[[56810,0],0] connected: 172.16.1.17 - 172.16.1.10 nodelay 0 sndbuf 131768 rcvbuf 131768 flags 00000006</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler starting send/recv events</div>

<div>[nexus17.nlroc:60[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler read hdr</div><div>584] [[56810,0],1] tcp:set_module called for peer [[56810,0],0]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate data region of size 9699</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div><div>[nexus10.nlroc:31369] [[56810,0],0] RECVD COMPLETE MESSAGE FROM [[56810,0],1] (ORIGIN [[56810,0],1]) OF 9699 BYTES FOR DEST [[56810,0],0] TAG 10</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] DELIVERING TO RML</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 9699 BYTES ON SOCKET 9</div><div>[nexus10.nlroc:31369] [[56810,0],0]: set_addr to uri 3723100160.1;tcp://<a href="http://172.16.1.17/" target="_blank">172.16.1.17</a>,<a href="http://169.254.210.43:54613/" target="_blank">169.254.210.43:54613</a></div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:set_addr checking if peer [[56810,0],1] is reachable via component tcp</div><div>[nexus10.nlroc:31369] [[56810,0],0] oob:tcp: working peer [[56810,0],1] address tcp://<a href="http://172.16.1.17/" target="_blank">172.16.1.17</a>,<a href="http://169.254.210.43:54613/" target="_blank">169.254.210.43:54613</a></div>

<div>[nexus10.nlroc:31369] [[56810,0],0] PEER [[56810,0],1] MAY BE REACHABLE USING MODULE AT KINDEX 2 INTERFACE en0</div><div>[nexus10.nlroc:31369] [[56810,0],0] PASSING ADDR 172.16.1.17 TO INTERFACE en0 AT KERNEL INDEX 2</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp set addr for peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0] UNFOUND KERNEL INDEX -13 FOR ADDRESS 169.254.210.43</div><div>[nexus10.nlroc:31369] [[56810,0],0]: peer [[56810,0],1] is reachable via component tcp</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] OOB_SEND: rml_oob_send.c:199</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:processing set_peer cmd for interface en0</div><div>[nexus10.nlroc:31369] [[56810,0],0] oob:base:send to target [[56810,0],1]</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] oob:base:send known transport for peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0] oob:tcp:send_nb to peer [[56810,0],1]:1</div><div>[nexus10.nlroc:31369] [[56810,0],0] tcp:send_nb to peer [[56810,0],1]</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:[oob_tcp.c:508] post send to [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:[oob_tcp.c:442] processing send to peer [[56810,0],1]:1</div><div>[nexus10.nlroc:31369] [[56810,0],0] tcp:send_nb: already connected to [[56810,0],1] - queueing for send</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:[oob_tcp.c:469] queue send to [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0] tcp:send_handler called to send to peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0] tcp:send_handler SENDING TO [[56810,0],1]</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] MESSAGE SEND COMPLETE TO [[56810,0],1] OF 105 BYTES ON SOCKET 12</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler called for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler CONNECTED</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler allocate new recv msg</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler read hdr</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler allocate data region of size 105</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]: set_addr to uri 3723100160.0;tcp://<a href="http://172.16.1.10:50908/" target="_blank">172.16.1.10:50908</a></div><div>[nexus10.nlroc:31369] [[56810,0],0]:set_addr peer [[56810,0],0] is me</div>
<div>
[nexus10.nlroc:31369] [[56810,0],0]: set_addr to uri 3723100160.1;tcp://<a href="http://172.16.1.17/" target="_blank">172.16.1.17</a>,<a href="http://169.254.210.43:54613/" target="_blank">169.254.210.43:54613</a></div><div>
[nexus10.nlroc:31369] [[56810,0],0]:set_addr checking if peer [[56810,0],1] is reachable via component tcp</div>
<div>[nexus10.nlroc:31369] [[56810,0],0] oob:tcp: working peer [[56810,0],1] address tcp://<a href="http://172.16.1.17/" target="_blank">172.16.1.17</a>,<a href="http://169.254.210.43:54613/" target="_blank">169.254.210.43:54613</a></div>
<div>[nexus10.nlroc:31369] [[56810,0],0] PEER [[56810,0],1] MAY BE REACHABLE USING MODULE AT KINDEX 2 INTERFACE en0</div>
<div>[nexus10.nlroc:31369] [[56810,0],0] PASSING ADDR 172.16.1.17 TO INTERFACE en0 AT KERNEL INDEX 2</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp set addr for peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0] UNFOUND KERNEL INDEX -13 FOR ADDRESS 169.254.210.43</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]: peer [[56810,0],1] is reachable via component tcp</div><div>[nexus10.nlroc:31369] [[56810,0],0] OOB_SEND: rml_oob_send.c:199</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:processing set_peer cmd for interface en0</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] oob:base:send to target [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0] oob:base:send known transport for peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0] oob:tcp:send_nb to peer [[56810,0],1]:15</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] tcp:send_nb to peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:[oob_tcp.c:508] post send to [[56810,0],1]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler called for peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler CONNECTED</div><div>[nexus17.nlroc:60584] [[56810,0],1] RECVD COMPLETE MESSAGE FROM [[56810,0],0] (ORIGIN [[56810,0],0]) OF 105 BYTES FOR DEST [[56810,0],1] TAG 1</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] DELIVERING TO RML</div><div>[nexus10.nlroc:31369] [[56810,0],0]:[oob_tcp.c:442] processing send to peer [[56810,0],1]:15</div><div>[nexus10.nlroc:31369] [[56810,0],0] tcp:send_nb: already connected to [[56810,0],1] - queueing for send</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:[oob_tcp.c:469] queue send to [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0] tcp:send_handler called to send to peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0] tcp:send_handler SENDING TO [[56810,0],1]</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] MESSAGE SEND COMPLETE TO [[56810,0],1] OF 885 BYTES ON SOCKET 12</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler called for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler CONNECTED</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler allocate new recv msg</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler read hdr</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler allocate data region of size 885</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler called for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:recv:handler CONNECTED</div><div>[nexus17.nlroc:60584] [[56810,0],1] RECVD COMPLETE MESSAGE FROM [[56810,0],0] (ORIGIN [[56810,0],0]) OF 885 BYTES FOR DEST [[56810,0],1] TAG 15</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] DELIVERING TO RML</div><div>[nexus17.nlroc:60584] [[56810,0],1]: set_addr to uri 3723100160.0;tcp://<a href="http://172.16.1.10:50908/" target="_blank">172.16.1.10:50908</a></div>
<div>[nexus17.nlroc:60584] [[56810,0],1]:set_addr checking if peer [[56810,0],0] is reachable via component tcp</div>
<div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp: working peer [[56810,0],0] address tcp://<a href="http://172.16.1.10:50908/" target="_blank">172.16.1.10:50908</a></div><div>[nexus17.nlroc:60584] [[56810,0],1] PEER [[56810,0],0] MAY BE REACHABLE USING MODULE AT KINDEX 2 INTERFACE en0</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] PASSING ADDR 172.16.1.10 TO INTERFACE en0 AT KERNEL INDEX 2</div><div>[nexus17.nlroc:60584] [[56810,0],1]:tcp set addr for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]: peer [[56810,0],0] is reachable via component tcp</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]: set_addr to uri 3723100160.1;tcp://<a href="http://172.16.1.17/" target="_blank">172.16.1.17</a>,<a href="http://169.254.210.43:54613/" target="_blank">169.254.210.43:54613</a></div>
<div>[nexus17.nlroc:60584] [[56810,0],1]:set_addr peer [[56810,0],1] is me</div>
<div>[nexus17.nlroc:60584] [[56810,0],1]:tcp:processing set_peer cmd for interface en0</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:5</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:5</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div><div>

[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate data region of size 54</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 54 BYTES ON SOCKET 9</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] RECVD COMPLETE MESSAGE FROM [[56810,0],1] (ORIGIN [[56810,0],1]) OF 54 BYTES FOR DEST [[56810,0],0] TAG 5</div><div>[nexus10.nlroc:31369] [[56810,0],0] DELIVERING TO RML</div><div>

[nexus10.nlroc:31369] [[56810,0],0] plm:base:receive update proc state command from [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0] plm:base:receive got update_proc_state for job [56810,1]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate data region of size 183</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 183 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 118 BYTES ON SOCKET 9</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] RECVD COMPLETE MESSAGE FROM [[56810,0],1] (ORIGIN [[56810,0],1]) OF 183 BYTES FOR DEST [[56810,0],0] TAG 2</div><div>[nexus10.nlroc:31369] [[56810,0],0] DELIVERING TO RML</div><div>

[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate data region of size 118</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] RECVD COMPLETE MESSAGE FROM [[56810,0],1] (ORIGIN [[56810,0],1]) OF 118 BYTES FOR DEST [[56810,0],0] TAG 2</div><div>[nexus10.nlroc:31369] [[56810,0],0] DELIVERING TO RML</div><div>

[nexus17.nlroc:60585] mca: base: components_register: registering oob components</div><div>[nexus17.nlroc:60585] mca: base: components_register: found loaded component tcp</div><div>[nexus17.nlroc:60585] mca: base: components_register: component tcp register function successful</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 294 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 199 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 203 BYTES ON SOCKET 9</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler read hdr</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate data region of size 294</div><div>[nexus10.nlroc:31369] [[56810,0],0] RECVD COMPLETE MESSAGE FROM [[56810,0],1] (ORIGIN [[56810,0],1]) OF 294 BYTES FOR DEST [[56810,0],0] TAG 2</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] DELIVERING TO RML</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate data region of size 199</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] RECVD COMPLETE MESSAGE FROM [[56810,0],1] (ORIGIN [[56810,0],1]) OF 199 BYTES FOR DEST [[56810,0],0] TAG 2</div><div>[nexus10.nlroc:31369] [[56810,0],0] DELIVERING TO RML</div><div>

[nexus17.nlroc:60585] mca: base: components_register: registering plm components</div><div>[nexus17.nlroc:60585] mca: base: components_register: found loaded component isolated</div><div>[nexus17.nlroc:60585] mca: base: components_register: component isolated has no register or open function</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate new recv msg</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate data region of size 203</div><div>[nexus10.nlroc:31369] [[56810,0],0] RECVD COMPLETE MESSAGE FROM [[56810,0],1] (ORIGIN [[56810,0],1]) OF 203 BYTES FOR DEST [[56810,0],0] TAG 2</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] DELIVERING TO RML</div><div>[nexus17.nlroc:60585] mca: base: components_register: found loaded component rsh</div><div>[nexus17.nlroc:60585] mca: base: components_register: component rsh register function successful</div>

<div>[nexus17.nlroc:60585] mca: base: components_register: found loaded component slurm</div><div>[nexus17.nlroc:60585] mca: base: components_register: component slurm register function successful</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler read hdr</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate data region of size 92</div><div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 92 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 395 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div><div>[nexus10.nlroc:31369] [[56810,0],0] RECVD COMPLETE MESSAGE FROM [[56810,0],1] (ORIGIN [[56810,0],1]) OF 92 BYTES FOR DEST [[56810,0],0] TAG 2</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] DELIVERING TO RML</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate data region of size 395</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] RECVD COMPLETE MESSAGE FROM [[56810,0],1] (ORIGIN [[56810,0],1]) OF 395 BYTES FOR DEST [[56810,0],0] TAG 2</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div><div>

[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 572 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 1009 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] [nexus10.nlroc:31369] [[56810,0],0] DELIVERING TO RML</div><div>oob:base:send known transport for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div>

<div>                 Package: Open MPI <a href="mailto:XXX@nexus10.nlroc" target="_blank">XXX@nexus10.nlroc</a> Distribution</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div>
<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div>
<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate data region of size 572</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 773 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus10.nlroc:31369] [[56810,0],0] RECVD COMPLETE MESSAGE FROM [[56810,0],1] (ORIGIN [[56810,0],1]) OF 572 BYTES FOR DEST [[56810,0],0] TAG 2</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] DELIVERING TO RML</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate data region of size 1009</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 558 BYTES ON SOCKET 9</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: a[nexus10.nlroc:31369] [[56810,0],0] RECVD COMPLETE MESSAGE FROM [[56810,0],1] (ORIGIN [[56810,0],1]) OF 1009 BYTES FOR DEST [[56810,0],0] TAG 2</div>

<div>lready connected to [[56810,0],0] - queueing for send</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 484 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div><div>[nexus10.nlroc:31369] [[56810,0],0] DELIVERING TO RML</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div><div>

[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 747 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate new recv msg</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate data region of size 773</div><div>[nexus10.nlroc:31369] [[56810,0],0] RECVD COMPLETE MESSAGE FROM [[56810,0],1] (ORIGIN [[56810,0],1]) OF 773 BYTES FOR DEST [[56810,0],0] TAG 2</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] DELIVERING TO RML</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 591 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div><div>[nexus17.nlroc:[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler called for peer [[56810,0],1]</div><div>60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb: already connected to [[56810,0],0] - queueing for send</div><div>

[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:469] queue send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler called to send to peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_handler SENDING TO [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] MESSAGE SEND COMPLETE TO [[56810,0],0] OF 635 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60584] [[56810,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send to target [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1] oob:base:send known transport for peer [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1] oob:tcp:send_nb to peer [[56810,0],0]:2</div><div>[nexus17.nlroc:60584] [[56810,0],1] tcp:send_nb to peer [[56810,0],0]</div>

<div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:508] post send to [[56810,0],0]</div><div>[nexus17.nlroc:60584] [[56810,0],1]:[oob_tcp.c:442] processing send to peer [[56810,0],0]:2</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler CONNECTED</div>

<div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31369] [[56810,0],0]:tcp:recv:handler allocate data region of size 558</div>

<div>[nexus10.nlroc:31369] [[56810,0],0] RECVD COMPLETE MESSAGE FROM [[56810,0],1] (ORIGIN [[56810,0],1]) OF 558 BYTES FOR DEST [[56810,0],0] TAG 2</div><div>[nexus10.nlroc:31369] [[56810,0],0] DELIVERING TO RML</div><div>

                Open MPI: 1.8.1</div><div>  Open MPI repo revision: r31483</div><div>   Open MPI release date: Apr 22, 2014</div></div><div>…</div></span><span style="border-collapse:collapse;font-family:arial,sans-serif;font-size:11px">it continue and fully finish </span></div>

<div><font face="arial, sans-serif"><span style="border-collapse:collapse;font-size:11px"><br></span></font><span style="border-collapse:collapse;font-family:arial,sans-serif;font-size:11px"><div>
 Case 3 is runs</div><div><br></div><div><div>/opt/openmpi/bin/mpirun  --mca plm_rsh_no_tree_spawn 1  -mca oob_base_verbose 10 -mca plm_base_verbose 10   --debug-daemons -host nexus17 ompi_info</div><div>[nexus10.nlroc:31479] mca: base: components_register: registering plm components</div>

<div>[nexus10.nlroc:31479] mca: base: components_register: found loaded component isolated</div><div>[nexus10.nlroc:31479] mca: base: components_register: component isolated has no register or open function</div><div>[nexus10.nlroc:31479] mca: base: components_register: found loaded component rsh</div>

<div>[nexus10.nlroc:31479] mca: base: components_register: component rsh register function successful</div><div>[nexus10.nlroc:31479] mca: base: components_register: found loaded component slurm</div><div>[nexus10.nlroc:31479] mca: base: components_register: component slurm register function successful</div>

<div>[nexus10.nlroc:31479] mca: base: components_open: opening plm components</div><div>[nexus10.nlroc:31479] mca: base: components_open: found loaded component isolated</div><div>[nexus10.nlroc:31479] mca: base: components_open: component isolated open function successful</div>

<div>[nexus10.nlroc:31479] mca: base: components_open: found loaded component rsh</div><div>[nexus10.nlroc:31479] mca: base: components_open: component rsh open function successful</div><div>[nexus10.nlroc:31479] mca: base: components_open: found loaded component slurm</div>

<div>[nexus10.nlroc:31479] mca: base: components_open: component slurm open function successful</div><div>[nexus10.nlroc:31479] mca:base:select: Auto-selecting plm components</div><div>[nexus10.nlroc:31479] mca:base:select:(  plm) Querying component [isolated]</div>

<div>[nexus10.nlroc:31479] mca:base:select:(  plm) Query of component [isolated] set priority to 0</div><div>[nexus10.nlroc:31479] mca:base:select:(  plm) Querying component [rsh]</div><div>[nexus10.nlroc:31479] mca:base:select:(  plm) Query of component [rsh] set priority to 10</div>

<div>[nexus10.nlroc:31479] mca:base:select:(  plm) Querying component [slurm]</div><div>[nexus10.nlroc:31479] mca:base:select:(  plm) Skipping component [slurm]. Query failed to return a module</div><div>[nexus10.nlroc:31479] mca:base:select:(  plm) Selected component [rsh]</div>

<div>[nexus10.nlroc:31479] mca: base: close: component isolated closed</div><div>[nexus10.nlroc:31479] mca: base: close: unloading component isolated</div><div>[nexus10.nlroc:31479] mca: base: close: component slurm closed</div>

<div>[nexus10.nlroc:31479] mca: base: close: unloading component slurm</div><div>[nexus10.nlroc:31479] mca: base: components_register: registering oob components</div><div>[nexus10.nlroc:31479] mca: base: components_register: found loaded component tcp</div>

<div>[nexus10.nlroc:31479] mca: base: components_register: component tcp register function successful</div><div>[nexus10.nlroc:31479] mca: base: components_open: opening oob components</div><div>[nexus10.nlroc:31479] mca: base: components_open: found loaded component tcp</div>

<div>[nexus10.nlroc:31479] mca: base: components_open: component tcp open function successful</div><div>[nexus10.nlroc:31479] mca:oob:select: checking available component tcp</div><div>[nexus10.nlroc:31479] mca:oob:select: Querying component [tcp]</div>

<div>[nexus10.nlroc:31479] oob:tcp: component_available called</div><div>[nexus10.nlroc:31479] WORKING INTERFACE 1 KERNEL INDEX 1 FAMILY: V4</div><div>[nexus10.nlroc:31479] WORKING INTERFACE 2 KERNEL INDEX 2 FAMILY: V4</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] oob:tcp:init creating module for V4 address on interface en0</div><div>[nexus10.nlroc:31479] [[56724,0],0] oob:tcp:init adding 172.16.1.10 to our list of V4 connections</div><div>
[nexus10.nlroc:31479] [[56724,0],0] TCP STARTUP</div>
<div>[nexus10.nlroc:31479] [[56724,0],0] attempting to bind to IPv4 port 0</div><div>[nexus10.nlroc:31479] [[56724,0],0] assigned IPv4 port 50923</div><div>[nexus10.nlroc:31479] mca:oob:select: Adding component to end</div>

<div>[nexus10.nlroc:31479] mca:oob:select: Found 1 active transports</div><div>Daemon was launched on nexus17.nlroc - beginning to initialize</div><div>[nexus17.nlroc:60663] mca: base: components_register: registering plm components</div>

<div>[nexus17.nlroc:60663] mca: base: components_register: found loaded component rsh</div><div>[nexus17.nlroc:60663] mca: base: components_register: component rsh register function successful</div><div>[nexus17.nlroc:60663] mca: base: components_open: opening plm components</div>

<div>[nexus17.nlroc:60663] mca: base: components_open: found loaded component rsh</div><div>[nexus17.nlroc:60663] mca: base: components_open: component rsh open function successful</div><div>[nexus17.nlroc:60663] mca:base:select: Auto-selecting plm components</div>

<div>[nexus17.nlroc:60663] mca:base:select:(  plm) Querying component [rsh]</div><div>[nexus17.nlroc:60663] mca:base:select:(  plm) Query of component [rsh] set priority to 10</div><div>[nexus17.nlroc:60663] mca:base:select:(  plm) Selected component [rsh]</div>

<div>[nexus17.nlroc:60663] mca: base: components_register: registering oob components</div><div>[nexus17.nlroc:60663] mca: base: components_register: found loaded component tcp</div><div>[nexus17.nlroc:60663] mca: base: components_register: component tcp register function successful</div>

<div>[nexus17.nlroc:60663] mca: base: components_open: opening oob components</div><div>[nexus17.nlroc:60663] mca: base: components_open: found loaded component tcp</div><div>[nexus17.nlroc:60663] mca: base: components_open: component tcp open function successful</div>

<div>[nexus17.nlroc:60663] mca:oob:select: checking available component tcp</div><div>[nexus17.nlroc:60663] mca:oob:select: Querying component [tcp]</div><div>[nexus17.nlroc:60663] oob:tcp: component_available called</div>

<div>[nexus17.nlroc:60663] WORKING INTERFACE 1 KERNEL INDEX 1 FAMILY: V4</div><div>[nexus17.nlroc:60663] WORKING INTERFACE 2 KERNEL INDEX 2 FAMILY: V4</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:tcp:init creating module for V4 address on interface en0</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] oob:tcp:init adding 172.16.1.17 to our list of V4 connections</div><div>[nexus17.nlroc:60663] WORKING INTERFACE 3 KERNEL INDEX 3 FAMILY: V4</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:tcp:init creating module for V4 address on interface en2</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] oob:tcp:init adding 169.254.210.43 to our list of V4 connections</div><div>[nexus17.nlroc:60663] [[56724,0],1] TCP STARTUP</div><div>[nexus17.nlroc:60663] [[56724,0],1] attempting to bind to IPv4 port 0</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] assigned IPv4 port 54631</div><div>[nexus17.nlroc:60663] mca:oob:select: Adding component to end</div><div>[nexus17.nlroc:60663] mca:oob:select: Found 1 active transports</div><div>

Daemon [[56724,0],1] checking in as pid 60663 on host nexus17</div><div>[nexus17.nlroc:60663] [[56724,0],1] orted: up and running - waiting for commands!</div><div>[nexus17.nlroc:60663] [[56724,0],1]: set_addr to uri 3717464064.0;tcp://<a href="http://172.16.1.10:50923/" target="_blank">172.16.1.10:50923</a></div>

<div>[nexus17.nlroc:60663] [[56724,0],1]:set_addr checking if peer [[56724,0],0] is reachable via component tcp</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:tcp: working peer [[56724,0],0] address tcp://<a href="http://172.16.1.10:50923/" target="_blank">172.16.1.10:50923</a></div>

<div>[nexus17.nlroc:60663] [[56724,0],1] PEER [[56724,0],0] MAY BE REACHABLE USING MODULE AT KINDEX 2 INTERFACE en0</div><div>[nexus17.nlroc:60663] [[56724,0],1] PASSING ADDR 172.16.1.10 TO INTERFACE en0 AT KERNEL INDEX 2</div>

<div>[nexus17.nlroc:60663] [[56724,0],1]:tcp set addr for peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1]: peer [[56724,0],0] is reachable via component tcp</div><div>[nexus17.nlroc:60663] [[56724,0],1] OOB_SEND: rml_oob_send.c:199</div>

<div>[nexus17.nlroc:60663] [[56724,0],1]:tcp:processing set_peer cmd for interface en0</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:base:send to target [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:tcp:send_nb to peer [[56724,0],0]:10</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_nb to peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:508] post send to [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:442] processing send to peer [[56724,0],0]:10</div>

<div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:476] queue pending to [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_nb: initiating connection to [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:490] connect to [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] orte_tcp_peer_try_connect: attempting to connect to proc [[56724,0],0] via interface en0</div><div>[nexus17.nlroc:60663] [[56724,0],1] orte_tcp_peer_try_connect: attempting to connect to proc [[56724,0],0] via interface en0 on socket 9</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] orte_tcp_peer_try_connect: attempting to connect to proc [[56724,0],0] on <a href="http://172.16.1.10:50923/" target="_blank">172.16.1.10:50923</a> - 0 retries</div><div>[nexus17.nlroc:60663] [[56724,0],1] waiting for connect completion to [[56724,0],0] - activating send event</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler called to send to peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler CONNECTING</div><div>[nexus17.nlroc:60663] [[56724,0],1]:tcp:complete_connect called for peer [[56724,0],0] on socket 9</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] mca_oob_tcp_listen_thread: new connection: (12, 0) <a href="http://172.16.1.17:54632/" target="_blank">172.16.1.17:54632</a></div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp_peer_complete_connect: sending ack to [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] SEND CONNECT ACK</div><div>[nexus17.nlroc:60663] [[56724,0],1] send blocking of 40 bytes to socket 9</div><div>[nexus17.nlroc:60663] [[56724,0],1] connect-ack sent to socket 9</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] tcp_peer_complete_connect: setting read event on connection to [[56724,0],0]</div><div>[nexus10.nlroc:31479] [[56724,0],0] connection_handler: working connection (12, 35) <a href="http://172.16.1.17:54632/" target="_blank">172.16.1.17:54632</a></div>

<div>[nexus10.nlroc:31479] [[56724,0],0] accept_connection: <a href="http://172.16.1.17:54632/" target="_blank">172.16.1.17:54632</a></div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler called</div><div>[nexus10.nlroc:31479] [[56724,0],0] RECV CONNECT ACK FROM UNKNOWN ON SOCKET 12</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] waiting for connect ack from UNKNOWN</div><div>[nexus10.nlroc:31479] [[56724,0],0] connect ack received from UNKNOWN</div><div>[nexus10.nlroc:31479] [[56724,0],0] connect-ack recvd from UNKNOWN</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] mca_oob_tcp_recv_connect: connection from new peer</div><div>[nexus10.nlroc:31479] [[56724,0],0] connect-ack header from [[56724,0],1] is okay</div><div>[nexus10.nlroc:31479] [[56724,0],0] waiting for connect ack from [[56724,0],1]</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] connect ack received from [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0] connect-ack version from [[56724,0],1] matches ours</div><div>[nexus10.nlroc:31479] [[56724,0],0] connect-ack [[56724,0],1] authenticated</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] tcp:peer_accept called for peer [[56724,0],1] in state UNKNOWN on socket 12</div><div>[nexus10.nlroc:31479] [[56724,0],0] SEND CONNECT ACK</div><div>[nexus10.nlroc:31479] [[56724,0],0] send blocking of 40 bytes to socket 12</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] connect-ack sent to socket 12</div><div>[nexus10.nlroc:31479] [[56724,0],0]-[[56724,0],1] tcp_peer_connected on socket 12</div><div>[nexus10.nlroc:31479] [[56724,0],0]-[[56724,0],1] accepted: 172.16.1.10 - 172.16.1.17 nodelay 0 sndbuf 131072 rcvbuf 131072 flags 00000006</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] tcp:set_module called for peer [[56724,0],1]</div><div>[nexus17.nlroc:60663] [[56724,0],1]:tcp:recv:handler called for peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] RECV CONNECT ACK FROM [[56724,0],0] ON SOCKET 9</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] waiting for connect ack from [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] connect ack received from [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] connect-ack recvd from [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] connect-ack header from [[56724,0],0] is okay</div><div>[nexus17.nlroc:60663] [[56724,0],1] waiting for connect ack from [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] connect ack received from [[56724,0],0]</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler called for peer [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler CONNECTED</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate new recv msg</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate data region of size 9699</div><div>[nexus17.nlroc:60663] [[56724,0],1] connect-ack version from [[56724,0],0] matches ours</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] connect-ack [[56724,0],0] authenticated</div><div>[nexus17.nlroc:60663] [[56724,0],1]-[[56724,0],0] tcp_peer_connected on socket 9</div><div>[nexus17.nlroc:60663] [[56724,0],1]-[[56724,0],0] connected: 172.16.1.17 - 172.16.1.10 nodelay 0 sndbuf 131768 rcvbuf 131768 flags 00000006</div>

<div>[nexus17.nlroc:60663] [[56724,0],1]:tcp:recv:handler starting send/recv events</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:set_module called for peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler called to send to peer [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler SENDING TO [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] MESSAGE SEND COMPLETE TO [[56724,0],0] OF 9699 BYTES ON SOCKET 9</div><div>[nexus10.nlroc:31479] [[56724,0],0] RECVD COMPLETE MESSAGE FROM [[56724,0],1] (ORIGIN [[56724,0],1]) OF 9699 BYTES FOR DEST [[56724,0],0] TAG 10</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] DELIVERING TO RML</div><div>[nexus10.nlroc:31479] [[56724,0],0]: set_addr to uri 3717464064.1;tcp://<a href="http://172.16.1.17/" target="_blank">172.16.1.17</a>,<a href="http://169.254.210.43:54631/" target="_blank">169.254.210.43:54631</a></div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:set_addr checking if peer [[56724,0],1] is reachable via component tcp</div><div>[nexus10.nlroc:31479] [[56724,0],0] oob:tcp: working peer [[56724,0],1] address tcp://<a href="http://172.16.1.17/" target="_blank">172.16.1.17</a>,<a href="http://169.254.210.43:54631/" target="_blank">169.254.210.43:54631</a></div>

<div>[nexus10.nlroc:31479] [[56724,0],0] PEER [[56724,0],1] MAY BE REACHABLE USING MODULE AT KINDEX 2 INTERFACE en0</div><div>[nexus10.nlroc:31479] [[56724,0],0] PASSING ADDR 172.16.1.17 TO INTERFACE en0 AT KERNEL INDEX 2</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp set addr for peer [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0] UNFOUND KERNEL INDEX -13 FOR ADDRESS 169.254.210.43</div><div>[nexus10.nlroc:31479] [[56724,0],0]: peer [[56724,0],1] is reachable via component tcp</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:processing set_peer cmd for interface en0</div><div>[nexus10.nlroc:31479] [[56724,0],0]: set_addr to uri 3717464064.0;tcp://<a href="http://172.16.1.10:50923/" target="_blank">172.16.1.10:50923</a></div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:set_addr peer [[56724,0],0] is me</div><div>[nexus10.nlroc:31479] [[56724,0],0]: set_addr to uri 3717464064.1;tcp://<a href="http://172.16.1.17/" target="_blank">172.16.1.17</a>,<a href="http://169.254.210.43:54631/" target="_blank">169.254.210.43:54631</a></div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:set_addr checking if peer [[56724,0],1] is reachable via component tcp</div><div>[nexus10.nlroc:31479] [[56724,0],0] oob:tcp: working peer [[56724,0],1] address tcp://<a href="http://172.16.1.17/" target="_blank">172.16.1.17</a>,<a href="http://169.254.210.43:54631/" target="_blank">169.254.210.43:54631</a></div>

<div>[nexus10.nlroc:31479] [[56724,0],0] PEER [[56724,0],1] MAY BE REACHABLE USING MODULE AT KINDEX 2 INTERFACE en0</div><div>[nexus10.nlroc:31479] [[56724,0],0] PASSING ADDR 172.16.1.17 TO INTERFACE en0 AT KERNEL INDEX 2</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp set addr for peer [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0] UNFOUND KERNEL INDEX -13 FOR ADDRESS 169.254.210.43</div><div>[nexus10.nlroc:31479] [[56724,0],0]: peer [[56724,0],1] is reachable via component tcp</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] OOB_SEND: rml_oob_send.c:199</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:processing set_peer cmd for interface en0</div><div>[nexus10.nlroc:31479] [[56724,0],0] oob:base:send to target [[56724,0],1]</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] oob:base:send known transport for peer [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0] oob:tcp:send_nb to peer [[56724,0],1]:15</div><div>[nexus10.nlroc:31479] [[56724,0],0] tcp:send_nb to peer [[56724,0],1]</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:[oob_tcp.c:508] post send to [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0] orted_cmd: received add_local_procs</div><div>[nexus10.nlroc:31479] [[56724,0],0]:[oob_tcp.c:442] processing send to peer [[56724,0],1]:15</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] tcp:send_nb: already connected to [[56724,0],1] - queueing for send</div><div>[nexus10.nlroc:31479] [[56724,0],0]:[oob_tcp.c:469] queue send to [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0] tcp:send_handler called to send to peer [[56724,0],1]</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] tcp:send_handler SENDING TO [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0] MESSAGE SEND COMPLETE TO [[56724,0],1] OF 956 BYTES ON SOCKET 12</div><div>[nexus17.nlroc:60663] [[56724,0],1]:tcp:recv:handler called for peer [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1]:tcp:recv:handler CONNECTED</div><div>[nexus17.nlroc:60663] [[56724,0],1]:tcp:recv:handler allocate new recv msg</div><div>[nexus17.nlroc:60663] [[56724,0],1]:tcp:recv:handler read hdr</div>

<div>[nexus17.nlroc:60663] [[56724,0],1]:tcp:recv:handler allocate data region of size 956</div><div>[nexus17.nlroc:60663] [[56724,0],1]:tcp:recv:handler called for peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1]:tcp:recv:handler CONNECTED</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] RECVD COMPLETE MESSAGE FROM [[56724,0],0] (ORIGIN [[56724,0],0]) OF 956 BYTES FOR DEST [[56724,0],1] TAG 15</div><div>[nexus17.nlroc:60663] [[56724,0],1] DELIVERING TO RML</div><div>

[nexus17.nlroc:60663] [[56724,0],1]: set_addr to uri 3717464064.0;tcp://<a href="http://172.16.1.10:50923/" target="_blank">172.16.1.10:50923</a></div><div>[nexus17.nlroc:60663] [[56724,0],1]:set_addr checking if peer [[56724,0],0] is reachable via component tcp</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] oob:tcp: working peer [[56724,0],0] address tcp://<a href="http://172.16.1.10:50923/" target="_blank">172.16.1.10:50923</a></div><div>[nexus17.nlroc:60663] [[56724,0],1] PEER [[56724,0],0] MAY BE REACHABLE USING MODULE AT KINDEX 2 INTERFACE en0</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] PASSING ADDR 172.16.1.10 TO INTERFACE en0 AT KERNEL INDEX 2</div><div>[nexus17.nlroc:60663] [[56724,0],1]:tcp set addr for peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1]: peer [[56724,0],0] is reachable via component tcp</div>

<div>[nexus17.nlroc:60663] [[56724,0],1]: set_addr to uri 3717464064.1;tcp://<a href="http://172.16.1.17/" target="_blank">172.16.1.17</a>,<a href="http://169.254.210.43:54631/" target="_blank">169.254.210.43:54631</a></div>
<div>[nexus17.nlroc:60663] [[56724,0],1]:set_addr peer [[56724,0],1] is me</div>
<div>[nexus17.nlroc:60663] [[56724,0],1]:tcp:processing set_peer cmd for interface en0</div><div>[nexus17.nlroc:60663] [[56724,0],1] orted_cmd: received add_local_procs</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler called for peer [[56724,0],1]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:base:send to target [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:base:send known transport for peer [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] oob:tcp:send_nb to peer [[56724,0],0]:5</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_nb to peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:508] post send to [[56724,0],0]</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler CONNECTED</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler read hdr</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate data region of size 54</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler called for peer [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler CONNECTED</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] RECVD COMPLETE MESSAGE FROM [[56724,0],1] (ORIGIN [[56724,0],1]) OF 54 BYTES FOR DEST [[56724,0],0] TAG 5</div><div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:442] processing send to peer [[56724,0],0]:5</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_nb: already connected to [[56724,0],0] - queueing for send</div><div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:469] queue send to [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler called to send to peer [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler SENDING TO [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] MESSAGE SEND COMPLETE TO [[56724,0],0] OF 54 BYTES ON SOCKET 9</div><div>[nexus10.nlroc:31479] [[56724,0],0] DELIVERING TO RML</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] plm:base:receive update proc state command from [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0] plm:base:receive got update_proc_state for job [56724,1]</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler called for peer [[56724,0],1]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:base:send to target [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:base:send known transport for peer [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] oob:tcp:send_nb to peer [[56724,0],0]:2</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler CONNECTED</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate new recv msg</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate data region of size 183</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler called for peer [[56724,0],1]</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler CONNECTED</div><div>[nexus10.nlroc:31479] [[56724,0],0] RECVD COMPLETE MESSAGE FROM [[56724,0],1] (ORIGIN [[56724,0],1]) OF 183 BYTES FOR DEST [[56724,0],0] TAG 2</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] DELIVERING TO RML</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_nb to peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:508] post send to [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:442] processing send to peer [[56724,0],0]:2</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_nb: already connected to [[56724,0],0] - queueing for send</div><div>

[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:469] queue send to [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler called to send to peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler SENDING TO [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] MESSAGE SEND COMPLETE TO [[56724,0],0] OF 183 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60663] [[56724,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:base:send to target [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] oob:base:send known transport for peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:tcp:send_nb to peer [[56724,0],0]:2</div><div>[nexus17.nlroc:[nexus17.nlroc:60664] mca: base: components_register: registering oob components</div>

<div>[nexus17.nlroc:60664] mca: base: components_register: found loaded component tcp</div><div>60663] [[56724,0],1] tcp:send_nb to peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:508] post send to [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:442] processing send to peer [[56724,0],0]:2</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_nb: already connected to [[56724,0],0] - queueing for send</div><div>

[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:469] queue send to [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler called to send to peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler SENDING TO [[56724,0],0]</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler called for peer [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler CONNECTED</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate new recv msg</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler read hdr</div><div>[nexus17.nlroc:60663] [[56724,0],1] MESSAGE SEND COMPLETE TO [[56724,0],0] OF 118 BYTES ON SOCKET 9</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate data region of size 118</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] RECVD COMPLETE MESSAGE FROM [[56724,0],1] (ORIGIN [[56724,0],1]) OF 118 BYTES FOR DEST [[56724,0],0] TAG 2</div><div>[nexus10.nlroc:31479] [[56724,0],0] DELIVERING TO RML</div><div>

[nexus17.nlroc:60664] mca: base: components_register: component tcp register function successful</div><div>[nexus17.nlroc:60663] [[56724,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:base:send to target [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] oob:base:send known transport for peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:tcp:send_nb to peer [[56724,0],0]:2</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_nb to peer [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:508] post send to [[56724,0],0]</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler called for peer [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler CONNECTED</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate data region of size 294</div>

<div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:442] processing send to peer [[56724,0],0]:2</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_nb: already connected to [[56724,0],0] - queueing for send</div><div>

[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:469] queue send to [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler called to send to peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler SENDING TO [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] MESSAGE SEND COMPLETE TO [[56724,0],0] OF 294 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60663] [[56724,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:base:send to target [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] oob:base:send known transport for peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:tcp:send_nb to peer [[56724,0],0]:2</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_nb to peer [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:508] post send to [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:442] processing send to peer [[56724,0],0]:2</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_nb: already connected to [[56724,0],0] - queueing for send</div>

<div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:469] queue send to [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler called to send to peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler SENDING TO [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] MESSAGE SEND COMPLETE TO [[56724,0],0] OF 282 BYTES ON SOCKET 9</div><div>[nexus17.nlroc:60663] [[56724,0],1] OOB_SEND: rml_oob_send.c:199</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:base:send to target [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] oob:base:send known transport for peer [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] oob:tcp:send_nb to peer [[56724,0],0]:2</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_nb to peer [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:508] post send to [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler called for peer [[56724,0],1]</div><div>0],1]:[oob_tcp.c:442] processing send to peer [[56724,0],0]:2</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_nb: already connected to [[56724,0],0] - queueing for send</div><div>[nexus17.nlroc:60663] [[56724,0],1]:[oob_tcp.c:469] queue send to [[56724,0],0]</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler CONNECTED</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] RECVD COMPLETE MESSAGE FROM [[56724,0],1] (ORIGIN [[56724,0],1]) OF 294 BYTES FOR DEST [[56724,0],0] TAG 2</div><div>[nexus10.nlroc:31479] [[56724,0],0] DELIVERING TO RML</div><div>

[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler called for peer [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler CONNECTED</div><div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler called to send to peer [[56724,0],0]</div>

<div>[nexus17.nlroc:60663] [[56724,0],1] tcp:send_handler SENDING TO [[56724,0],0]</div><div>[nexus17.nlroc:60663] [[56724,0],1] MESSAGE SEND COMPLETE TO [[56724,0],0] OF 120 BYTES ON SOCKET 9</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate new recv msg</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate data region of size 282</div><div>[nexus10.nlroc:31479] [[56724,0],0] RECVD COMPLETE MESSAGE FROM [[56724,0],1] (ORIGIN [[56724,0],1]) OF 282 BYTES FOR DEST [[56724,0],0] TAG 2</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] DELIVERING TO RML</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler called for peer [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler CONNECTED</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate data region of size 120</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] RECVD COMPLETE MESSAGE FROM [[56724,0],1] (ORIGIN [[56724,0],1]) OF 120 BYTES FOR DEST [[56724,0],0] TAG 2</div><div>[nexus10.nlroc:31479] [[56724,0],0] DELIVERING TO RML</div><div>

[nexus17.nlroc:60664] mca: base: components_register: registering plm components</div><div>[nexus17.nlroc:60664] mca: base: components_register: found loaded component isolated</div><div>[nexus17.nlroc:60664] mca: base: components_register: component isolated has no register or open function</div>

<div>[nexus17.nlroc:60664] mca: base: components_register: found loaded component rsh</div><div>[nexus17.nlroc:60664] mca: base: components_register: component rsh register function successful</div><div>[nexus17.nlroc:60664] mca: base: components_register: found loaded component slurm</div>

<div>[nexus17.nlroc:60664] mca: base: components_register: component slurm register function successful</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler called for peer [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler CONNECTED</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate new recv msg</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate data region of size 92</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] RECVD COMPLETE MESSAGE FROM [[56724,0],1] (ORIGIN [[56724,0],1]) OF 92 BYTES FOR DEST [[56724,0],0] TAG 2</div><div>[nexus10.nlroc:31479] [[56724,0],0] DELIVERING TO RML</div><div>

[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler called for peer [[56724,0],1]</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler CONNECTED</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate new recv msg</div>

<div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler read hdr</div><div>[nexus10.nlroc:31479] [[56724,0],0]:tcp:recv:handler allocate data region of size 560</div><div>[nexus10.nlroc:31479] [[56724,0],0] RECVD COMPLETE MESSAGE FROM [[56724,0],1] (ORIGIN [[56724,0],1]) OF 560 BYTES FOR DEST [[56724,0],0] TAG 2</div>

<div>[nexus10.nlroc:31479] [[56724,0],0] DELIVERING TO RML</div><div>                 Package: Open MPI <a href="mailto:XXXX@nexus10.nlroc" target="_blank">XXXX@nexus10.nlroc</a> Distribution</div></div><div><br></div><div>
…</div><div><br></div><div>and continue until the end</div>
<div><br></div><div><br></div></span></div></div><div class="gmail_extra"><br><br><div class="gmail_quote">On Tue, Jul 15, 2014 at 2:58 PM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br>

<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div style="word-wrap:break-word">I&#39;m afraid I don&#39;t understand your comment about &quot;another mpi process&quot;. Looking at your output, it would appear that there is something going on with host nexus17. In both cases, mpirun is launching a single daemon onto only one other node - the only difference was in the node being used. The &quot;no_tree_spawn&quot; flag did nothing as that only applies when there are multiple nodes being used.<div>

<br></div><div>I would check to see if there is a firewall between nexus10 and nexus17. You can also add -mca oob_base_verbose 10 to your cmd line and see if the daemon on nexus17 is able to connect back to mpirun., and add --debug-daemons to see any error messages that daemon may be trying to report.</div>

<div><br></div><div><br><div><div><div><div><div>On Jul 15, 2014, at 3:08 AM, Ricardo Fernández-Perea &lt;<a href="mailto:rfernandezperea@gmail.com" target="_blank">rfernandezperea@gmail.com</a>&gt; wrote:</div>
<br></div></div><blockquote type="cite"><div><div><div dir="ltr">I have try if another mpi process is running in the node already the process run <div><br><div>$ricardo$ /opt/openmpi/bin/mpirun  --mca plm_rsh_no_tree_spawn 1 -mca plm_base_verbose 10 -host nexus16 ompi_info</div>


<div><div>[nexus10.nlroc:27397] mca: base: components_register: registering plm components</div><div>[nexus10.nlroc:27397] mca: base: components_register: found loaded component isolated</div><div>[nexus10.nlroc:27397] mca: base: components_register: component isolated has no register or open function</div>


<div>[nexus10.nlroc:27397] mca: base: components_register: found loaded component rsh</div><div>[nexus10.nlroc:27397] mca: base: components_register: component rsh register function successful</div><div>[nexus10.nlroc:27397] mca: base: components_register: found loaded component slurm</div>


<div>[nexus10.nlroc:27397] mca: base: components_register: component slurm register function successful</div><div>[nexus10.nlroc:27397] mca: base: components_open: opening plm components</div><div>[nexus10.nlroc:27397] mca: base: components_open: found loaded component isolated</div>


<div>[nexus10.nlroc:27397] mca: base: components_open: component isolated open function successful</div><div>[nexus10.nlroc:27397] mca: base: components_open: found loaded component rsh</div><div>[nexus10.nlroc:27397] mca: base: components_open: component rsh open function successful</div>


<div>[nexus10.nlroc:27397] mca: base: components_open: found loaded component slurm</div><div>[nexus10.nlroc:27397] mca: base: components_open: component slurm open function successful</div><div>[nexus10.nlroc:27397] mca:base:select: Auto-selecting plm components</div>


<div>[nexus10.nlroc:27397] mca:base:select:(  plm) Querying component [isolated]</div><div>[nexus10.nlroc:27397] mca:base:select:(  plm) Query of component [isolated] set priority to 0</div><div>[nexus10.nlroc:27397] mca:base:select:(  plm) Querying component [rsh]</div>


<div>[nexus10.nlroc:27397] mca:base:select:(  plm) Query of component [rsh] set priority to 10</div><div>[nexus10.nlroc:27397] mca:base:select:(  plm) Querying component [slurm]</div><div>[nexus10.nlroc:27397] mca:base:select:(  plm) Skipping component [slurm]. Query failed to return a module</div>


<div>[nexus10.nlroc:27397] mca:base:select:(  plm) Selected component [rsh]</div><div>[nexus10.nlroc:27397] mca: base: close: component isolated closed</div><div>[nexus10.nlroc:27397] mca: base: close: unloading component isolated</div>


<div>[nexus10.nlroc:27397] mca: base: close: component slurm closed</div><div>[nexus10.nlroc:27397] mca: base: close: unloading component slurm</div><div>[nexus10.nlroc:27397] [[52326,0],0] plm:base:receive update proc state command from [[52326,0],1]</div>


<div>[nexus10.nlroc:27397] [[52326,0],0] plm:base:receive got update_proc_state for job [52326,1]</div><div>[nexus16.nlroc:59687] mca: base: components_register: registering plm components</div><div>[nexus16.nlroc:59687] mca: base: components_register: found loaded component isolated</div>


<div>[nexus16.nlroc:59687] mca: base: components_register: component isolated has no register or open function</div><div>[nexus16.nlroc:59687] mca: base: components_register: found loaded component rsh</div><div>[nexus16.nlroc:59687] mca: base: components_register: component rsh register function successful</div>


<div>[nexus16.nlroc:59687] mca: base: components_register: found loaded component slurm</div><div>[nexus16.nlroc:59687] mca: base: components_register: component slurm register function successful</div></div><div><div>                 Package: Open MPI <a href="mailto:XXXX@nexus10.nlroc" target="_blank">XXXX@nexus10.nlroc</a> Distribution</div>


<div>                Open MPI: 1.8.1</div><div>  Open MPI repo revision: r31483</div><div>   Open MPI release date: Apr 22, 2014</div><div>                Open RTE: 1.8.1</div></div><div>…</div><div><br></div><div>but if the compute node has not a mpi process running in it it already hangs as</div>


<div><br></div><div><div>/opt/openmpi/bin/mpirun  --mca plm_rsh_no_tree_spawn 1 -mca plm_base_verbose 10 -host nexus17 ompi_info</div><div>[nexus10.nlroc:27438] mca: base: components_register: registering plm components</div>


<div>[nexus10.nlroc:27438] mca: base: components_register: found loaded component isolated</div><div>[nexus10.nlroc:27438] mca: base: components_register: component isolated has no register or open function</div><div>[nexus10.nlroc:27438] mca: base: components_register: found loaded component rsh</div>


<div>[nexus10.nlroc:27438] mca: base: components_register: component rsh register function successful</div><div>[nexus10.nlroc:27438] mca: base: components_register: found loaded component slurm</div><div>[nexus10.nlroc:27438] mca: base: components_register: component slurm register function successful</div>


<div>[nexus10.nlroc:27438] mca: base: components_open: opening plm components</div><div>[nexus10.nlroc:27438] mca: base: components_open: found loaded component isolated</div><div>[nexus10.nlroc:27438] mca: base: components_open: component isolated open function successful</div>


<div>[nexus10.nlroc:27438] mca: base: components_open: found loaded component rsh</div><div>[nexus10.nlroc:27438] mca: base: components_open: component rsh open function successful</div><div>[nexus10.nlroc:27438] mca: base: components_open: found loaded component slurm</div>


<div>[nexus10.nlroc:27438] mca: base: components_open: component slurm open function successful</div><div>[nexus10.nlroc:27438] mca:base:select: Auto-selecting plm components</div><div>[nexus10.nlroc:27438] mca:base:select:(  plm) Querying component [isolated]</div>


<div>[nexus10.nlroc:27438] mca:base:select:(  plm) Query of component [isolated] set priority to 0</div><div>[nexus10.nlroc:27438] mca:base:select:(  plm) Querying component [rsh]</div><div>[nexus10.nlroc:27438] mca:base:select:(  plm) Query of component [rsh] set priority to 10</div>


<div>[nexus10.nlroc:27438] mca:base:select:(  plm) Querying component [slurm]</div><div>[nexus10.nlroc:27438] mca:base:select:(  plm) Skipping component [slurm]. Query failed to return a module</div><div>[nexus10.nlroc:27438] mca:base:select:(  plm) Selected component [rsh]</div>


<div>[nexus10.nlroc:27438] mca: base: close: component isolated closed</div><div>[nexus10.nlroc:27438] mca: base: close: unloading component isolated</div><div>[nexus10.nlroc:27438] mca: base: close: component slurm closed</div>


<div>[nexus10.nlroc:27438] mca: base: close: unloading component slurm</div></div><div><br></div><div>and  it stop there</div></div><div><br></div><div><br></div></div><div class="gmail_extra"><br><br><div class="gmail_quote">


On Mon, Jul 14, 2014 at 8:56 PM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">


<div style="word-wrap:break-word">Hmmm...no, it worked just fine for me. It sounds like something else is going on.<div><br></div><div>Try configuring OMPI with --enable-debug, and then add -mca plm_base_verbose 10 to get a better sense of what is going on.</div>


<div><div><br></div><div><br><div><div>On Jul 14, 2014, at 10:27 AM, Ralph Castain &lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt; wrote:</div><br><blockquote type="cite"><div style="word-wrap:break-word">


I confess I haven&#39;t tested no_tree_spawn in ages, so it is quite possible it has suffered bit rot. I can try to take a look at it in a bit<div><br><div><br><div><div>On Jul 14, 2014, at 10:13 AM, Ricardo Fernández-Perea &lt;<a href="mailto:rfernandezperea@gmail.com" target="_blank">rfernandezperea@gmail.com</a>&gt; wrote:</div>


<br><blockquote type="cite"><div dir="ltr"><div>Thank you for the fast answer </div><div><br></div>While that resolve my problem with cross ssh authentication   a command as<div><br><div>/opt/openmpi/bin/mpirun  --mca mtl mx --mca pml cm --mca plm_rsh_no_tree_spawn 1 -hostfile hostfile ompi_info<br>



</div></div><div><br></div><div>just hung with no output and although there is a ssh connexion no orte program is initiated in the destination nodes</div><div><br></div><div>and while </div><div><br></div><div>/opt/openmpi/bin/mpirun  -host host18 ompi_info<br>



</div><div><br></div><div>works</div><div><br></div><div>/opt/openmpi/bin/mpirun  --mca plm_rsh_no_tree_spawn 1 -host host18 ompi_info<br></div><div><br></div><div>hangs, is there some condition in the use of this parameter.</div>



<div><br></div><div>Yours truly</div><div><br></div><div>Ricardo </div><div><br></div></div><div class="gmail_extra"><br><br><div class="gmail_quote">On Mon, Jul 14, 2014 at 6:35 PM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br>



<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">During the 1.7 series and for all follow-on series, OMPI changed to a mode where it launches a daemon on all allocated nodes at the startup of mpirun. This allows us to determine the hardware topology of the nodes and take that into account when mapping. You can override that behavior by either adding --novm to your cmd line (which will impact your mapping/binding options), or by specifying the hosts to use by editing your hostfile, or adding --host host1,host2 to your cmd line<br>




<br>
The rsh launcher defaults to a tree-based pattern, thus requiring that we be able to ssh from one compute node to another. You can change that to a less scalable direct mode by adding<br>
<br>
--mca plm_rsh_no_tree_spawn 1<br>
<br>
to the cmd line<br>
<div><br>
<br>
On Jul 14, 2014, at 9:21 AM, Ricardo Fernández-Perea &lt;<a href="mailto:rfernandezperea@gmail.com" target="_blank">rfernandezperea@gmail.com</a>&gt; wrote:<br>
<br>
&gt; I&#39;m trying to update to openMPI 1.8.1 thru ssh  and Myrinet<br>
&gt;<br>
&gt; running a command as<br>
&gt;<br>
&gt; /opt/openmpi/bin/mpirun --verbose --mca mtl mx --mca pml cm  -hostfile hostfile -np 16<br>
&gt;<br>
&gt; when the hostfile contain only two nodes as<br>
&gt;<br>
&gt; host1 slots=8 max-slots=8<br>
&gt; host2 slots=8 max-slots=8<br>
&gt;<br>
&gt; it runs perfectly but when the hostfile has a third node as<br>
&gt;<br>
&gt;<br>
&gt; host1 slots=8 max-slots=8<br>
&gt; host2 slots=8 max-slots=8<br>
&gt; host3 slots=8 max-slots=8<br>
&gt;<br>
&gt; it try to establish an ssh connection between  the running hosts1 and host3 that should not run any process  that fails hanging the process without signaling.<br>
&gt;<br>
&gt;<br>
&gt; my ompi_info is as follow<br>
&gt;<br>
&gt;                 Package: Open MPI XXX Distribution<br>
&gt;                 Open MPI: 1.8.1<br>
&gt;   Open MPI repo revision: r31483<br>
&gt;    Open MPI release date: Apr 22, 2014<br>
&gt;                 Open RTE: 1.8.1<br>
&gt;   Open RTE repo revision: r31483<br>
&gt;    Open RTE release date: Apr 22, 2014<br>
&gt;                     OPAL: 1.8.1<br>
&gt;       OPAL repo revision: r31483<br>
&gt;        OPAL release date: Apr 22, 2014<br>
&gt;                  MPI API: 3.0<br>
&gt;             Ident string: 1.8.1<br>
&gt;                   Prefix: /opt/openmpi<br>
&gt;  Configured architecture: x86_64-apple-darwin9.8.0<br>
&gt;           Configure host: XXXX<br>
&gt;            Configured by: XXXX<br>
&gt;            Configured on: Thu Jun 12 10:37:33 CEST 2014<br>
&gt;           Configure host: XXXX<br>
&gt;                 Built by: XXXX<br>
&gt;                 Built on: Thu Jun 12 11:13:16 CEST 2014<br>
&gt;               Built host: XXXX<br>
&gt;               C bindings: yes<br>
&gt;             C++ bindings: yes<br>
&gt;              Fort mpif.h: yes (single underscore)<br>
&gt;             Fort use mpi: yes (full: ignore TKR)<br>
&gt;        Fort use mpi size: deprecated-ompi-info-value<br>
&gt;         Fort use mpi_f08: yes<br>
&gt;  Fort mpi_f08 compliance: The mpi_f08 module is available, but due to<br>
&gt;                           limitations in the ifort compiler, does not support<br>
&gt;                           the following: array subsections, direct passthru<br>
&gt;                           (where possible) to underlying Open MPI&#39;s C<br>
&gt;                           functionality<br>
&gt;   Fort mpi_f08 subarrays: no<br>
&gt;            Java bindings: no<br>
&gt;   Wrapper compiler rpath: unnecessary<br>
&gt;               C compiler: icc<br>
&gt;      C compiler absolute: /opt/intel/Compiler/11.1/080/bin/intel64/icc<br>
&gt;   C compiler family name: INTEL<br>
&gt;       C compiler version: 1110.20091130<br>
&gt;             C++ compiler: icpc<br>
&gt;    C++ compiler absolute: /opt/intel/Compiler/11.1/080/bin/intel64/icpc<br>
&gt;            Fort compiler: ifort<br>
&gt;        Fort compiler abs: /opt/intel/Compiler/11.1/080/bin/intel64/ifort<br>
&gt;          Fort ignore TKR: yes (!DEC$ ATTRIBUTES NO_ARG_CHECK ::)<br>
&gt;    Fort 08 assumed shape: no<br>
&gt;       Fort optional args: yes<br>
&gt;       Fort BIND(C) (all): yes<br>
&gt;       Fort ISO_C_BINDING: yes<br>
&gt;  Fort SUBROUTINE BIND(C): yes<br>
&gt;        Fort TYPE,BIND(C): yes<br>
&gt;  Fort T,BIND(C,name=&quot;a&quot;): yes<br>
&gt;             Fort PRIVATE: yes<br>
&gt;           Fort PROTECTED: yes<br>
&gt;            Fort ABSTRACT: yes<br>
&gt;        Fort ASYNCHRONOUS: yes<br>
&gt;           Fort PROCEDURE: yes<br>
&gt;  Fort f08 using wrappers: yes<br>
&gt;              C profiling: yes<br>
&gt;            C++ profiling: yes<br>
&gt;    Fort mpif.h profiling: yes<br>
&gt;   Fort use mpi profiling: yes<br>
&gt;    Fort use mpi_f08 prof: yes<br>
&gt;           C++ exceptions: no<br>
&gt;           Thread support: posix (MPI_THREAD_MULTIPLE: no, OPAL support: yes,<br>
&gt;                           OMPI progress: no, ORTE progress: yes, Event lib:<br>
&gt;                           yes)<br>
&gt;            Sparse Groups: no<br>
&gt;   Internal debug support: no<br>
&gt;   MPI interface warnings: yes<br>
&gt;      MPI parameter check: runtime<br>
&gt; Memory profiling support: no<br>
&gt; Memory debugging support: no<br>
&gt;          libltdl support: yes<br>
&gt;    Heterogeneous support: no<br>
&gt;  mpirun default --prefix: no<br>
&gt;          MPI I/O support: yes<br>
&gt;        MPI_WTIME support: gettimeofday<br>
&gt;      Symbol vis. support: yes<br>
&gt;    Host topology support: yes<br>
&gt;           MPI extensions:<br>
&gt;    FT Checkpoint support: no (checkpoint thread: no)<br>
&gt;    C/R Enabled Debugging: no<br>
&gt;      VampirTrace support: yes<br>
&gt;   MPI_MAX_PROCESSOR_NAME: 256<br>
&gt;     MPI_MAX_ERROR_STRING: 256<br>
&gt;      MPI_MAX_OBJECT_NAME: 64<br>
&gt;         MPI_MAX_INFO_KEY: 36<br>
&gt;         MPI_MAX_INFO_VAL: 256<br>
&gt;        MPI_MAX_PORT_NAME: 1024<br>
&gt;   MPI_MAX_DATAREP_STRING: 128<br>
&gt;<br>
&gt;<br>
</div>&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
&gt; Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/07/24764.php" target="_blank">http://www.open-mpi.org/community/lists/users/2014/07/24764.php</a><br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/07/24765.php" target="_blank">http://www.open-mpi.org/community/lists/users/2014/07/24765.php</a><br>
</blockquote></div><br></div>
_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>


Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/07/24766.php" target="_blank">http://www.open-mpi.org/community/lists/users/2014/07/24766.php</a></blockquote></div><br></div></div></div></blockquote>


</div><br></div></div></div><br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/07/24768.php" target="_blank">http://www.open-mpi.org/community/lists/users/2014/07/24768.php</a><br></blockquote></div><br></div>
_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>

</div></div>Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/07/24769.php" target="_blank">http://www.open-mpi.org/community/lists/users/2014/07/24769.php</a></blockquote></div><br></div></div>

</div><br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/07/24770.php" target="_blank">http://www.open-mpi.org/community/lists/users/2014/07/24770.php</a><br></blockquote></div><br></div>
_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/07/24771.php" target="_blank">http://www.open-mpi.org/community/lists/users/2014/07/24771.php</a></blockquote></div><br></div></div></div><br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2014/07/24776.php" target="_blank">http://www.open-mpi.org/community/lists/users/2014/07/24776.php</a><br></blockquote></div><br></div>

