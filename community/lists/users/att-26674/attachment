<div dir="ltr"><div class="gmail_default" style="font-family:verdana,sans-serif;color:#0b5394">Ahh, I appreciate this explanation. This is a good thing to keep in mind. I read up on how functions like `top` measure the processor load. Since the OS cannot distinguish between physical and virtual cores, `top` does not provide an accurate measurement, hence, I should not be using it as an absolute judge of the load on my system. </div><div class="gmail_default" style="font-family:verdana,sans-serif;color:#0b5394"><br></div><div class="gmail_default" style="font-family:verdana,sans-serif;color:#0b5394">Thank you,</div><div class="gmail_default" style="font-family:verdana,sans-serif;color:#0b5394">Namu</div><div class="gmail_extra"><br><div class="gmail_quote">On Fri, Apr 10, 2015 at 3:40 PM, Damien <span dir="ltr">&lt;<a href="mailto:damien@khubla.com" target="_blank">damien@khubla.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
  
    
  
  <div bgcolor="#FFFFFF" text="#000000">
    Namu,<br>
    <br>
    Hyperthreads aren&#39;t real cores, they&#39;re really just another hardware
    thread (two per physical core).  You have two CPUs with 6 physical
    cores each.  If you start 2 simulations, each with 6 MPI processes
    running, your 12 physical cores will each be running at 100%. 
    Adding another simulation with another 6 MPI processes will
    oversubscribe your physical cores (you&#39;re asking for 150%), which is
    why you&#39;re still seeing 12 processors at 100%, and everything else
    very low.  Your physical cores are switching hardware threads, but
    each core can&#39;t go any faster.  Hyperthreads only help when your
    software doesn&#39;t load a core to 100%.  Then the other hyperthread on
    that core can switch in and use leftover capacity.  Hardware thread
    switching is much faster than software thread switching, which is
    why it&#39;s there.<br>
    <br>
    Most simulation software will load cores to 100% (even if it doesn&#39;t
    use that 100% wisely, which is a whole other flame war) and
    hyperthreading doesn&#39;t help you.<br>
    <br>
    Damien  <br><div><div>
    <br>
    <div>On 2015-04-10 2:22 PM, namu patel
      wrote:<br>
    </div>
    </div></div><blockquote type="cite"><div><div>
      <div dir="ltr">
        <div class="gmail_default" style="font-family:verdana,sans-serif;color:#0b5394">Hello
          All,</div>
        <div class="gmail_default" style="font-family:verdana,sans-serif;color:#0b5394"><br>
        </div>
        <div class="gmail_default" style="font-family:verdana,sans-serif;color:#0b5394">I am
          using OpenMPI 1.8.4 on my workstation with 2 CPUs, each with
          12 processors (6 with hyper-threading). When I run simulations
          using mpiexec, I&#39;m noticing a strange performance issue. If I
          run two simulations, each with 6 processors, then everything
          is fine and 12 processors are under 100% load. When I start a
          3rd simulation with 6 processors, I notice throttling in all 3
          simulations and only 12 processors are at 100%, the rest are
          below 10%. My guess is that somehow the processes from the 3rd
          simulations are doubling onto the already busy processors. How
          can I be certain that this is the case?</div>
        <div class="gmail_default" style="font-family:verdana,sans-serif;color:#0b5394"><br>
        </div>
        <div class="gmail_default" style="font-family:verdana,sans-serif;color:#0b5394">Thanks, </div>
        <div class="gmail_default" style="font-family:verdana,sans-serif;color:#0b5394">namu</div>
      </div>
      <br>
      <fieldset></fieldset>
      <br>
      </div></div><pre>_______________________________________________
users mailing list
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2015/04/26671.php" target="_blank">http://www.open-mpi.org/community/lists/users/2015/04/26671.php</a></pre>
    </blockquote>
    <br>
  </div>

<br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2015/04/26673.php" target="_blank">http://www.open-mpi.org/community/lists/users/2015/04/26673.php</a><br></blockquote></div><br></div></div>

