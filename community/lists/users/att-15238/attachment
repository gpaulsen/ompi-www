<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta content="text/html; charset=ISO-8859-1"
      http-equiv="Content-Type">
  </head>
  <body text="#000000" bgcolor="#ffffff">
    Bonjour,<br>
    <br>
    &nbsp;Back to this painful issue, partly because&nbsp; I found a workaround,<br>
    and partly because I would like to help.<br>
    <br>
    &nbsp;The initial post was :
    <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2010/11/14843.php">http://www.open-mpi.org/community/lists/users/2010/11/14843.php</a><br>
    where I reported about OMPI 1.4.1, but it was the same for 1.4.3.<br>
    <br>
    &nbsp;I spotted the culprit to be line <b>#274</b> into btl_openib.c
    where it was required to replace<br>
    <font face="Courier New, Courier, monospace"><b>mca_btl_openib_component.qp_infos[qp].u.pp_qp.rd_rsv)
        * nprocs;</b></font><br>
    with<br>
    <font face="Courier New, Courier, monospace"><b>mca_btl_openib_component.qp_infos[qp].u.pp_qp.rd_rsv)
        * <font color="#ff0000">32</font>;</b></font><br>
    mostly because nprocs = 4096 or 8192 in our case, which was leading
    to a<br>
    very huge memlock resource requirement.<br>
    <br>
    &nbsp;Since I don't believe there is a relevant mca parameter to control
    this value accurately<br>
    (am I wrong ?), I would suggest to invent such switch.<br>
    <br>
    &nbsp;It occurs to work because the number of peers for a given node
    (apart for rank 0) is very low,<br>
    but it is definitely useful when all-to-all communication is not
    required on a big cluster.<br>
    <br>
    &nbsp;Could someone comment on this ?<br>
    <br>
    &nbsp;More info on request.<br>
    <br>
    &nbsp;Thanks,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Happy New Year to you all,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; G.<br>
    <br>
    <br>
    <br>
    Le 29/11/2010 16:58, Gilbert Grosdidier a &eacute;crit&nbsp;:
    <blockquote cite="mid:4CF3CDA8.5060405@cern.ch" type="cite">
      <meta http-equiv="Content-Type" content="text/html;
        charset=ISO-8859-1">
      Bonjour John,
      <div><br>
      </div>
      <div>&nbsp;Thanks for your feedback, but my investigations so far did
        not help:</div>
      <div>the memlock limit on the compute nodes are actually set to
        unlimited.</div>
      <div>This most probably means that even if the btl_openib hits
        some memory allocation</div>
      <div>limit, the message I got is inaccurate because the memlock
        resource is indeed already unlimited.</div>
      <div><br>
      </div>
      <div>&nbsp;Then, the btl allocation mechanism seems to be stopped&nbsp;</div>
      <div>by the memlock resource being exhausted because the former is</div>
      <div>attempting to create too many buffers, for example. I tried
        to explore this</div>
      <div>kind of assumption by decreasing :</div>
      <div>-&nbsp;btl_ofud_rd_num down to 32 or even 16</div>
      <div>-&nbsp;btl_openib_cq_size down to 256 or even 64</div>
      <div>but to no avail.</div>
      <div><br>
      </div>
      <div>&nbsp;So, I am asking for help about which other parameter could
        lead to (locked ?) memory exhaustion,</div>
      <div>knowing that the current memlock wall shows up&nbsp;</div>
      <div>- when I run with 4096 or 8192 cores (for 2048, that's fine)</div>
      <div>- there are 4GB of RAM available for each core</div>
      <div>- each core is communicating with no more than 8 neighbours,
        and they</div>
      <div>stay the same along the whole job life.</div>
      <div><br>
      </div>
      <div>&nbsp;Does this triggers some idea for anyone ?</div>
      <div><br>
      </div>
      <div><br>
      </div>
      <div>&nbsp;Thanks in advance, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Best, &nbsp; &nbsp;Gilbert.</div>
      <div><br>
      </div>
      <div><br>
        <div>
          <div>Le 20 nov. 10 &agrave; 19:27, John Hearns a &eacute;crit :</div>
          <br class="Apple-interchange-newline">
          <blockquote type="cite">
            <div>On 20 November 2010 16:31, Gilbert Grosdidier <br>
              <blockquote type="cite">Bonjour,<br>
              </blockquote>
              <br>
              Bonjour Gilbert.<br>
              <br>
              I manage ICE clusters also.<br>
              <br>
              Please could you have look at /etc/init.d/pbs on the
              compute blades?<br>
              <br>
              <br>
              <br>
              Do you have something like:<br>
              <br>
              &nbsp;&nbsp;&nbsp;if [ "${PBS_START_MOM}" -gt 0 ] ; then<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if check_prog "mom" ; then<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;echo "PBS mom already running."<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;check_maxsys<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;site_mom_startup<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if [ -f /etc/sgi-release -o -f
              /etc/sgi-compute-node-release ] ; then<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MEMLOCKLIM=`ulimit -l`<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NOFILESLIM=`ulimit -n`<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;STACKLIM=`ulimit -s`<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ulimit -l unlimited<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ulimit -n 16384<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ulimit -s unlimited<br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fi<br>
              _______________________________________________<br>
              users mailing list<br>
              <a moz-do-not-send="true" href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
              <a moz-do-not-send="true" class="moz-txt-link-freetext"
                href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
            </div>
          </blockquote>
        </div>
      </div>
      <br>
      <pre wrap="">
<fieldset class="mimeAttachmentHeader"></fieldset>
_______________________________________________
users mailing list
<a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
<a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></pre>
    </blockquote>
    <br>
    <pre class="moz-signature" cols="72">-- 
 Cordialement,   Gilbert.

--
*---------------------------------------------------------------------*
  Gilbert Grosdidier             <a class="moz-txt-link-abbreviated" href="mailto:Gilbert.Grosdidier@in2p3.fr">Gilbert.Grosdidier@in2p3.fr</a>
  LAL / IN2P3 / CNRS                 Phone : +33 1 6446 8909
  Facult&eacute; des Sciences, Bat. 200     Fax   : +33 1 6446 8546
  B.P. 34, F-91898 Orsay Cedex (FRANCE)
*---------------------------------------------------------------------*</pre>
  </body>
</html>

