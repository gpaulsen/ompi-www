<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" xmlns="http://www.w3.org/TR/REC-html40"><head>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<meta name=Generator content="Microsoft Word 14 (filtered medium)"><style><!--
/* Font Definitions */
@font-face
	{font-family:SimSun;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:SimSun;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:"\@SimSun";
	panose-1:2 1 6 0 3 1 1 1 1 1;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0cm;
	margin-bottom:.0001pt;
	font-size:12.0pt;
	font-family:"Times New Roman","serif";}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-priority:99;
	color:purple;
	text-decoration:underline;}
p.MsoAcetate, li.MsoAcetate, div.MsoAcetate
	{mso-style-priority:99;
	mso-style-link:"Sprechblasentext Zchn";
	margin:0cm;
	margin-bottom:.0001pt;
	font-size:8.0pt;
	font-family:"Tahoma","sans-serif";}
span.SprechblasentextZchn
	{mso-style-name:"Sprechblasentext Zchn";
	mso-style-priority:99;
	mso-style-link:Sprechblasentext;
	font-family:"Tahoma","sans-serif";}
span.E-MailFormatvorlage19
	{mso-style-type:personal-reply;
	font-family:"Calibri","sans-serif";
	color:#1F497D;}
.MsoChpDefault
	{mso-style-type:export-only;
	font-size:10.0pt;
	font-family:"Calibri","sans-serif";}
@page WordSection1
	{size:612.0pt 792.0pt;
	margin:70.85pt 70.85pt 2.0cm 70.85pt;}
div.WordSection1
	{page:WordSection1;}
--></style><!--[if gte mso 9]><xml>
<o:shapedefaults v:ext="edit" spidmax="1026" />
</xml><![endif]--><!--[if gte mso 9]><xml>
<o:shapelayout v:ext="edit">
<o:idmap v:ext="edit" data="1" />
</o:shapelayout></xml><![endif]--></head><body lang=DE link=blue vlink=purple><div class=WordSection1><p class=MsoNormal><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>Hello all,<o:p></o:p></span></p><p class=MsoNormal><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>after the correct configuration, mpirun (v 1.10.2) works fine when all tpc ports are open. I can ssh to all hosts without a password.<o:p></o:p></span></p><p class=MsoNormal><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>Then it comes back to my first question: how to specify the ports for MPI communication? <o:p></o:p></span></p><p class=MsoNormal><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>I opened the ports 40000-50000 for outgoing traffic, when I run: <o:p></o:p></span></p><p class=MsoNormal><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D;background:yellow;mso-highlight:yellow'>mpirun --mca btl_tcp_port_min_v4 40040 --mca btl_tcp_port_range_v4 10 --mca oob_tcp_static_ipv4_ports 40020 --host &lt;IP1&gt;,&lt;IP2&gt;  hostname</span><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'><o:p></o:p></span></p><p class=MsoNormal><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>it works, but not every time. Same as when I run <span style='background:yellow;mso-highlight:yellow'>mpirun  --mca oob_tcp_static_ipv4_ports 40020 --host &lt;IP1&gt;,&lt;IP2&gt;  hostname</span><o:p></o:p></span></p><p class=MsoNormal><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>It is strange that sometimes I can get outputs, sometimes it just hangs. Did I miss something? <o:p></o:p></span></p><p class=MsoNormal><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>Best,<o:p></o:p></span></p><p class=MsoNormal><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>Ping<o:p></o:p></span></p><p class=MsoNormal><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><b><span style='font-size:10.0pt;font-family:"Tahoma","sans-serif"'>Von:</span></b><span style='font-size:10.0pt;font-family:"Tahoma","sans-serif"'> users [mailto:users-bounces@open-mpi.org] <b>Im Auftrag von </b>Gilles Gouaillardet<br><b>Gesendet:</b> Freitag, 3. </span><span lang=EN-US style='font-size:10.0pt;font-family:"Tahoma","sans-serif"'>Juni 2016 00:14<br><b>An:</b> Open MPI Users<br><b>Betreff:</b> Re: [OMPI users] Firewall settings for MPI communication<o:p></o:p></span></p><p class=MsoNormal><span lang=EN-US><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span lang=EN-US>The syntax is<o:p></o:p></span></p><div><p class=MsoNormal><span lang=EN-US>configure --enable-mpirun-prefix-by-default --prefix=&lt;path to OpenMPI&gt; ...<o:p></o:p></span></p></div><div><p class=MsoNormal><span lang=EN-US><o:p>&nbsp;</o:p></span></p></div><div><p class=MsoNormal><span lang=EN-US>all hosts must be able to ssh each other passwordless.<o:p></o:p></span></p></div><div><p class=MsoNormal><span lang=EN-US>that means you need to generate a user&nbsp;ssh key pair on all hosts, add your public keys to the list of authorized keys, and ssh to all hosts in order to populate your known hosts<o:p></o:p></span></p></div><div><p class=MsoNormal><span lang=EN-US>(ssh requires you confirm host public keys the very first time you ssh to a new host)<o:p></o:p></span></p></div><div><p class=MsoNormal><span lang=EN-US>iirc, that can&nbsp;be automated with ssh-keyscan.<o:p></o:p></span></p></div><div><p class=MsoNormal><span lang=EN-US><o:p>&nbsp;</o:p></span></p></div><div><p class=MsoNormal><span lang=EN-US>when ssh is fully configured, mpirun should work just fine<o:p></o:p></span></p></div><div><p class=MsoNormal><span lang=EN-US><o:p>&nbsp;</o:p></span></p></div><div><p class=MsoNormal><span lang=EN-US>Cheers,<o:p></o:p></span></p></div><div><p class=MsoNormal><span lang=EN-US><o:p>&nbsp;</o:p></span></p></div><div><p class=MsoNormal><span lang=EN-US>Gilles<o:p></o:p></span></p></div><div><p class=MsoNormal><span lang=EN-US><br>On Friday, June 3, 2016, Ping Wang &lt;</span><a href="mailto:ping.wang@asc-s.de"><span lang=EN-US>ping.wang@asc-s.de</span></a><span lang=EN-US>&gt; wrote:<o:p></o:p></span></p><div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif"'>Hi,</span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif"'>&nbsp;</span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif"'>thank you Gilles for your suggestion.&nbsp; I tried: &nbsp;<span style='color:#558ED5'>mpirun --prefix &lt;path to Open MPI&gt;&nbsp; --host &lt;public IP&gt; hostname</span>, then it works.</span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif"'>I’m sure both IPs are the ones of the VM on which mpirun is running, and they are unique. </span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif"'>&nbsp;</span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif"'>I also </span><span lang=EN-US>configured Open MPI with --enable-mpirun-prefix-by-default, but I still need to <span style='color:#558ED5'>add </span></span><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#558ED5'>--prefix &lt;path to Open MPI&gt; </span><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif"'>to get mpirun work.</span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif"'>I used: <span style='color:#558ED5'>./configure --enable-mpirun-prefix-by-default =&quot;&lt;path to Open MPI&gt; &nbsp;&quot;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;make<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;make install</span></span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif"'>Did I miss something or I misunderstood the way to configure Open MPI? </span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif"'>&nbsp;</span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif"'>When I run: <span style='color:#558ED5'>ssh &lt; internal/public IP &gt; `which orted`</span></span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif"'>The output is: <span style='color:#558ED5;background:#FCFDFE'>Warning: Permanently added </span><span style='color:#558ED5'>&lt; internal/public IP &gt; <span style='background:#FCFDFE'>' (ECDSA) to the list of known hosts.</span><br><span style='background:#FCFDFE'>/usr/local/bin/orted</span></span></span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";background:#FCFDFE'>Is it all right?</span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";background:#FCFDFE'>&nbsp;</span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US style='font-size:11.0pt;font-family:"Calibri","sans-serif";background:#FCFDFE'>Cheers,</span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span style='font-size:11.0pt;font-family:"Calibri","sans-serif";background:#FCFDFE'>Ping</span><o:p></o:p></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>&nbsp;</span><o:p></o:p></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span style='font-size:11.0pt;font-family:"Calibri","sans-serif";color:#1F497D'>&nbsp;</span><o:p></o:p></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><b><span style='font-size:10.0pt;font-family:"Tahoma","sans-serif"'>Von:</span></b><span style='font-size:10.0pt;font-family:"Tahoma","sans-serif"'> users [mailto:</span><a href="javascript:_e(%7B%7D,'cvml','users-bounces@open-mpi.org');" target="_blank"><span style='font-size:10.0pt;font-family:"Tahoma","sans-serif"'>users-bounces@open-mpi.org</span></a><span style='font-size:10.0pt;font-family:"Tahoma","sans-serif"'>] <b>Im Auftrag von </b>Gilles Gouaillardet<br><b>Gesendet:</b> Donnerstag, 2. </span><span lang=EN-US style='font-size:10.0pt;font-family:"Tahoma","sans-serif"'>Juni 2016 17:06<br><b>An:</b> Open MPI Users<br><b>Betreff:</b> Re: [OMPI users] Firewall settings for MPI communication</span><span lang=EN-US><o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>&nbsp;<o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>are you saying both IP are the ones of the VM on which mpirun is running ?<o:p></o:p></span></p><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>orted is only launched on all the machines *except* the one running mpirun.<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>&nbsp;<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>can you double/triple check the IPs are ok and unique ?<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>for example, mpirun --host &lt;internal IP&gt; /sbin/ifconfig -a<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>can you also make sure Open MPI is installed on all your VMs in the same directory ?<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>also make sure Open MPI has all the dependencies on all the VMs<o:p></o:p></span></p></div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>ssh xxx ldd `which orted`<o:p></o:p></span></p><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>should show no missing dependency<o:p></o:p></span></p><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>&nbsp;<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>generally speaking, I recommend you configure Open MPI with<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>--enable-mpirun-prefix-by-default<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>&nbsp;<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>you can also try to replace<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>mpirun<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>with<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>`which mpirun`<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>or<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>mpirun --prefix &lt;path to Open MPI&gt;<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>&nbsp;<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>Cheers,<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>&nbsp;<o:p></o:p></span></p></div><div><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>Gilles<br><br>On Thursday, June 2, 2016, Ping Wang &lt;</span><a href="javascript:_e(%7B%7D,'cvml','ping.wang@asc-s.de');" target="_blank"><span lang=EN-US>ping.wang@asc-s.de</span></a><span lang=EN-US>&gt; wrote:<o:p></o:p></span></p><p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><span lang=EN-US>Hi,<br><br>I've installed Open MPI v1.10.2. Every VM on the cloud has two IPs (internal IP, public IP).<br>When I run: mpirun --host &lt;internal IP&gt; hostname, the output is the hostname of the VM.<br>But when I run: mpirun --host &lt;public IP&gt; hostname, the output is<br><br>bash: orted: command not found<br>--------------------------------------------------------------------------<br>ORTE was unable to reliably start one or more daemons.<br>This usually is caused by:<br><br>* not finding the required libraries and/or binaries on<br>&nbsp; one or more nodes. Please check your PATH and LD_LIBRARY_PATH<br>&nbsp; settings, or configure OMPI with --enable-orterun-prefix-by-default<br><br>* lack of authority to execute on one or more specified nodes.<br>&nbsp; Please verify your allocation and authorities.<br><br>* the inability to write startup files into /tmp (--tmpdir/orte_tmpdir_base).<br>&nbsp; Please check with your sys admin to determine the correct location to use.<br><br>*&nbsp; compilation of the orted with dynamic libraries when static are required<br>&nbsp; (e.g., on Cray). Please check your configure cmd line and consider using<br>&nbsp; one of the contrib/platform definitions for your system type.<br><br>* an inability to create a connection back to mpirun due to a<br>&nbsp; lack of common network interfaces and/or no route found between<br>&nbsp; them. Please check network connectivity (including firewalls<br>&nbsp; and network routing requirements).<br><br>Both IPs are the IP of the VM where MPI is running. Did I do something wrong in the configuration?<br><br>Thanks for any help.<br><br></span>Ping<br><br>-----Ursprüngliche Nachricht-----<br>Von: users [<a href="mailto:users-bounces@open-mpi.org">mailto:users-bounces@open-mpi.org</a>] Im Auftrag von Jeff Squyres (jsquyres)<br>Gesendet: Mittwoch, 1. <span lang=EN-US>Juni 2016 15:02<br>An: Open MPI User's List<br>Betreff: Re: [OMPI users] Firewall settings for MPI communication<br><br>In addition, you might want to consider upgrading to Open MPI v1.10.x (v1.6.x is fairly ancient).<br><br>&gt; On Jun 1, 2016, at 7:46 AM, Gilles Gouaillardet &lt;</span><a href="mailto:gilles.gouaillardet@gmail.com"><span lang=EN-US>gilles.gouaillardet@gmail.com</span></a><span lang=EN-US>&gt; wrote:<br>&gt;<br>&gt; which network are your VMs using for communications ?<br>&gt; if this is tcp, then you also have to specify a restricted set of<br>&gt; allowed ports for the tcp btl<br>&gt;<br>&gt; that would be something like<br>&gt; mpirun --mca btl_tcp_dynamic_ports 49990-50010 ...<br>&gt;<br>&gt; please double check the Open MPI 1.6.5 parameter and syntax with<br>&gt; ompi_info --all (or check the archives, I think I posted the correct<br>&gt; command line a few weeks ago)<br>&gt;<br>&gt; Cheers,<br>&gt;<br>&gt; Gilles<br>&gt;<br>&gt; On Wednesday, June 1, 2016, Ping Wang &lt;</span><a href="mailto:ping.wang@asc-s.de"><span lang=EN-US>ping.wang@asc-s.de</span></a><span lang=EN-US>&gt; wrote:<br>&gt; I'm using Open MPI 1.6.5 to run OpenFOAM in parallel on several VMs on<br>&gt; a cloud. mpirun hangs without any error messages. I think this is a<br>&gt; firewall issue. Because when I open all the TCP ports(1-65535) in the<br>&gt; security group of VMs, mpirun works well. However I was suggested to<br>&gt; open as less ports as possible. So I have to limit MPI to run on a<br>&gt; range of ports. I opened the port range 49990-50010 for MPI<br>&gt; communication. And use command<br>&gt;<br>&gt;<br>&gt;<br>&gt; mpirun --mca oob_tcp_dynamic_ports 49990-50010 -np 4 --hostfile machines simpleFoam –parallel.<br>&gt;<br>&gt;<br>&gt;<br>&gt; But it still hangs. How can I specify a port range that OpenMPI will use? I appreciate any help you can provide.<br>&gt;<br>&gt;<br>&gt;<br>&gt; Best,<br>&gt;<br>&gt; Ping Wang<br>&gt;<br>&gt;<br>&gt;<br>&gt; &lt;image001.png&gt;<br>&gt;<br>&gt; ------------------------------------------------------<br>&gt;<br>&gt; Ping Wang<br>&gt;<br>&gt; Automotive Simulation Center Stuttgart e.V.<br>&gt;<br>&gt; Nobelstraße 15<br>&gt;<br>&gt; D-70569 Stuttgart<br>&gt;<br>&gt; Telefon: +49 711 699659-14<br>&gt;<br>&gt; Fax: +49 711 699659-29<br>&gt;<br>&gt; E-Mail: </span><a href="mailto:ping.wang@asc-s.de"><span lang=EN-US>ping.wang@asc-s.de</span></a><span lang=EN-US><br>&gt;<br>&gt; Web: </span><a href="http://www.asc-s.de" target="_blank"><span lang=EN-US>http://www.asc-s.de</span></a><span lang=EN-US><br>&gt;<br>&gt; Social Media: &lt;image002.gif&gt;/asc.stuttgart<br>&gt;<br>&gt; ------------------------------------------------------<br>&gt;<br>&gt;<br>&gt;<br>&gt;<br>&gt;<br>&gt; _______________________________________________<br>&gt; users mailing list<br>&gt; </span><a href="mailto:users@open-mpi.org"><span lang=EN-US>users@open-mpi.org</span></a><span lang=EN-US><br>&gt; Subscription: </span><a href="https://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank"><span lang=EN-US>https://www.open-mpi.org/mailman/listinfo.cgi/users</span></a><span lang=EN-US><br>&gt; Link to this post:<br>&gt; </span><a href="http://www.open-mpi.org/community/lists/users/2016/06/29340.php" target="_blank"><span lang=EN-US>http://www.open-mpi.org/community/lists/users/2016/06/29340.php</span></a><span lang=EN-US><br><br><br>--<br>Jeff Squyres<br></span><a href="mailto:jsquyres@cisco.com"><span lang=EN-US>jsquyres@cisco.com</span></a><span lang=EN-US><br>For corporate legal information go to: </span><a href="http://www.cisco.com/web/about/doing_business/legal/cri/" target="_blank"><span lang=EN-US>http://www.cisco.com/web/about/doing_business/legal/cri/</span></a><span lang=EN-US><br><br>_______________________________________________<br>users mailing list<br></span><a href="mailto:users@open-mpi.org"><span lang=EN-US>users@open-mpi.org</span></a><span lang=EN-US><br>Subscription: </span><a href="https://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank"><span lang=EN-US>https://www.open-mpi.org/mailman/listinfo.cgi/users</span></a><span lang=EN-US><br>Link to this post: </span><a href="http://www.open-mpi.org/community/lists/users/2016/06/29342.php" target="_blank"><span lang=EN-US>http://www.open-mpi.org/community/lists/users/2016/06/29342.php</span></a><span lang=EN-US><br><br><br><br>_______________________________________________<br>users mailing list<br></span><a href="mailto:users@open-mpi.org"><span lang=EN-US>users@open-mpi.org</span></a><span lang=EN-US><br>Subscription: </span><a href="https://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank"><span lang=EN-US>https://www.open-mpi.org/mailman/listinfo.cgi/users</span></a><span lang=EN-US><br>Link to this post: </span><a href="http://www.open-mpi.org/community/lists/users/2016/06/29349.php" target="_blank"><span lang=EN-US>http://www.open-mpi.org/community/lists/users/2016/06/29349.php</span></a><span lang=EN-US><o:p></o:p></span></p></div></div></div></div></div></div></body></html>

