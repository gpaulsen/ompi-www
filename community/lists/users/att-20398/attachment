<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" xmlns="http://www.w3.org/TR/REC-html40"><head><META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=us-ascii"><meta name=Generator content="Microsoft Word 14 (filtered medium)"><style><!--
/* Font Definitions */
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:Consolas;
	panose-1:2 11 6 9 2 2 4 3 2 4;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0cm;
	margin-bottom:.0001pt;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-priority:99;
	color:purple;
	text-decoration:underline;}
span.EmailStyle17
	{mso-style-type:personal;
	font-family:"Calibri","sans-serif";
	color:windowtext;}
span.EmailStyle18
	{mso-style-type:personal-reply;
	font-family:"Calibri","sans-serif";
	color:#1F497D;}
.MsoChpDefault
	{mso-style-type:export-only;
	font-size:10.0pt;}
@page WordSection1
	{size:612.0pt 792.0pt;
	margin:72.0pt 72.0pt 72.0pt 72.0pt;}
div.WordSection1
	{page:WordSection1;}
--></style><!--[if gte mso 9]><xml>
<o:shapedefaults v:ext="edit" spidmax="1026" />
</xml><![endif]--><!--[if gte mso 9]><xml>
<o:shapelayout v:ext="edit">
<o:idmap v:ext="edit" data="1" />
</o:shapelayout></xml><![endif]--></head><body lang=EN-US link=blue vlink=purple><div class=WordSection1><p class=MsoNormal><span style='color:#1F497D'>Hi,<o:p></o:p></span></p><p class=MsoNormal><span style='color:#1F497D'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='color:#1F497D'>I would suggest that (if you haven&#8217;t done it already) you trace your program&#8217;s execution with Vampir or Scalasca. The latter has some pretty nice analysis capabilities built-in and can detect common patterns that would make your code not to scale, no matter how good the MPI library is. Also Open MPI has many knobs that you can tune via MCA parameters. Start with the general tuning FAQ:<o:p></o:p></span></p><p class=MsoNormal><span style='color:#1F497D'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='color:#1F497D'><a href="http://www.open-mpi.org/faq/?category=tuning">http://www.open-mpi.org/faq/?category=tuning</a><o:p></o:p></span></p><p class=MsoNormal><span style='color:#1F497D'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='color:#1F497D'>then move to the InfiniBand tuning FAQ:<o:p></o:p></span></p><p class=MsoNormal><span style='color:#1F497D'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='color:#1F497D'><a href="http://www.open-mpi.org/faq/?category=openfabrics">http://www.open-mpi.org/faq/?category=openfabrics</a><o:p></o:p></span></p><p class=MsoNormal><span style='color:#1F497D'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='color:#1F497D'>Kind regards,<o:p></o:p></span></p><p class=MsoNormal><span style='color:#1F497D'>Hristo<o:p></o:p></span></p><p class=MsoNormal><span style='color:#1F497D'>--<o:p></o:p></span></p><p class=MsoNormal><span style='color:#1F497D'>Hristo Iliev, Ph.D. -- High Performance Computing<o:p></o:p></span></p><p class=MsoNormal><span style='color:#1F497D'>RWTH Aachen University, Center for Computing and Communication<o:p></o:p></span></p><p class=MsoNormal><span lang=DE style='color:#1F497D'>Rechen- und Kommunikationszentrum der RWTH Aachen<o:p></o:p></span></p><p class=MsoNormal><span lang=DE style='color:#1F497D'>Seffenter Weg 23,&nbsp; D 52074&nbsp; Aachen (Germany)<o:p></o:p></span></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><div style='border:none;border-left:solid blue 1.5pt;padding:0cm 0cm 0cm 4.0pt'><div><div style='border:none;border-top:solid #B5C4DF 1.0pt;padding:3.0pt 0cm 0cm 0cm'><p class=MsoNormal><b><span style='font-size:10.0pt;font-family:"Tahoma","sans-serif"'>From:</span></b><span style='font-size:10.0pt;font-family:"Tahoma","sans-serif"'> users-bounces@open-mpi.org [mailto:users-bounces@open-mpi.org] <b>On Behalf Of </b>Hodge, Gary C<br><b>Sent:</b> Wednesday, October 03, 2012 6:41 PM<br><b>To:</b> users@open-mpi.org<br><b>Subject:</b> [OMPI users] unacceptable latency in gathering process<o:p></o:p></span></p></div></div><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>Hi all,<o:p></o:p></p><p class=MsoNormal>I am running on an IBM BladeCenter, using Open MPI 1.4.1, and opensm subnet manager for Infiniband<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>Our application has real time requirements and it has recently been proven that it does not scale to meet future requirements.<o:p></o:p></p><p class=MsoNormal>Presently, I am re-organizing the application to process work in a more parallel manner then it does now.<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>Jobs arrive at the rate of 200 per second and are sub-divided into groups of objects by a master process (MP) on its own node.<o:p></o:p></p><p class=MsoNormal>The MP then assigns the object groups to 20 slave processes (SP), each running on their own node, to do the expensive computational work in parallel.<o:p></o:p></p><p class=MsoNormal>The SPs then send their results to a gatherer process (GP) on its own node that merges the results for the job and sends it onward for final processing.<o:p></o:p></p><p class=MsoNormal>The highest latency for the last 1024 jobs that were processed is then written to a log file that is displayed by a GUI.<o:p></o:p></p><p class=MsoNormal>Each process uses the same controller method for sending and&nbsp; receiving messages as follows:<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>For (each CPU that sends us input)<o:p></o:p></p><p class=MsoNormal>{<o:p></o:p></p><p class=MsoNormal style='text-indent:36.0pt'>MPI_Irecv(&#8230;.)<o:p></o:p></p><p class=MsoNormal>}<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>While (true)<o:p></o:p></p><p class=MsoNormal>{<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; For (each CPU that sends us input)<o:p></o:p></p><p class=MsoNormal style='text-indent:36.0pt'>{<o:p></o:p></p><p class=MsoNormal style='margin-left:36.0pt;text-indent:36.0pt'>MPI_Test(&#8230;.)<o:p></o:p></p><p class=MsoNormal style='margin-left:36.0pt;text-indent:36.0pt'>If (message was received)<o:p></o:p></p><p class=MsoNormal style='margin-left:36.0pt;text-indent:36.0pt'>{<o:p></o:p></p><p class=MsoNormal style='margin-left:36.0pt;text-indent:36.0pt'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Copy the message<o:p></o:p></p><p class=MsoNormal style='margin-left:72.0pt;text-indent:36.0pt'>Queue the copy to our input queue<o:p></o:p></p><p class=MsoNormal style='margin-left:36.0pt;text-indent:36.0pt'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Irecv(&#8230;) <o:p></o:p></p><p class=MsoNormal style='margin-left:36.0pt;text-indent:36.0pt'>}<o:p></o:p></p><p class=MsoNormal style='text-indent:36.0pt'>}<o:p></o:p></p><p class=MsoNormal style='text-indent:36.0pt'>If (there are messages on our input queue)<o:p></o:p></p><p class=MsoNormal style='text-indent:36.0pt'>{<o:p></o:p></p><p class=MsoNormal style='text-indent:36.0pt'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8230; process the FIRST message on queue (this may queue messages for output) &#8230;.<o:p></o:p></p><p class=MsoNormal style='text-indent:36.0pt'><o:p>&nbsp;</o:p></p><p class=MsoNormal style='text-indent:36.0pt'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; For (each message on our output queue)<o:p></o:p></p><p class=MsoNormal style='text-indent:36.0pt'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {<o:p></o:p></p><p class=MsoNormal style='text-indent:36.0pt'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Send(&#8230;)<o:p></o:p></p><p class=MsoNormal style='text-indent:36.0pt'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<o:p></o:p></p><p class=MsoNormal style='text-indent:36.0pt'>}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <o:p></o:p></p><p class=MsoNormal>}<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>My problem is that I do not meet our applications performance requirements for a job (~ 20 ms) until I reduce the number of SPs from 20 to 4 or less.<o:p></o:p></p><p class=MsoNormal>I added some debug into the GP and found that there are never more than 14 messages received in the for loop that calls MPI_Test.<o:p></o:p></p><p class=MsoNormal>The messages that were sent from the other 6 SPs will eventually arrive at the GP in a long stream after experiencing high latency (over 600 ms).<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>Going forward, we need to handle more objects per job and will need to have more than 4 SPs to keep up.<o:p></o:p></p><p class=MsoNormal>My thought is that I have to obey this 4 SPs to 1 GP ratio and create intermediate GPs to gather results from every 4 slaves.<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>Is this a contention problem at the GP?<o:p></o:p></p><p class=MsoNormal>Is there debugging or logging I can turn on in the MPI to prove that contention is occurring?<o:p></o:p></p><p class=MsoNormal>Can I configure MPI receive processing to improve upon the 4 to 1 ratio?<o:p></o:p></p><p class=MsoNormal>Can I improve the controller method (listed above) to gain a performance improvement?<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>Thanks for any suggestions.<o:p></o:p></p><p class=MsoNormal>Gary Hodge<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p></div></div></body></html>
