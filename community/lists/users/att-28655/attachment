<div dir="ltr"><div>Giles,</div><div>Thanks for the small bug fix.  It helped clear up that test case but I&#39;m again running into another segmentation fault on a more complicated problem.</div><div><br></div><div>I&#39;ve attached another &#39;working&#39; example.  This time I am using the MPI_Ineighbor_alltoallw on a triangular topology;  node 0 communicates bi-directionally with nodes 1 and 2, node 1 with nodes 0 and 2, and node 2 with node 0 and 1.  Each node is sending one double (with value my_rank) to each of its neighbors.  </div><div><br></div><div>The code has two different calls to the MPI API that only differ in the receive buffer arguments.  In both versions, I am sending from and receiving into the same static array.  In the working (non-segfaulting) version, I am receiving into the latter half of the array by pointing to the start of the second half (&amp;send_number[2]) and specifying displacements of 0 and 8 bytes.  In the segfaulting version, I am again receiving into the latter half of the array by pointing to the start of the array (send_number) with displacements of 16 to 24 bytes.</div><div><br></div><div>The program run with the command &#39;mpirun -n 3 ./simpleneighborhood_multiple&#39; compiled with the latest <span>OpenMPI</span>  (1.10.2) + patch encounters a segmentation fault when receiving using the latter commands.  The same program compiled with MPICH (3.2) runs without any problems and with the expected results. </div><div><br></div><div>Let me know if I&#39;m screwing anything up.  Thanks for the help.</div><div><br></div><div>Sincerely,</div><div>Jun</div><div><br></div></div><div class="gmail_extra"><br><div class="gmail_quote">On Mon, Feb 29, 2016 at 9:34 PM, Gilles Gouaillardet <span dir="ltr">&lt;<a href="mailto:gilles@rist.or.jp" target="_blank">gilles@rist.or.jp</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
  
    
  
  <div text="#000000" bgcolor="#FFFFFF">
    Thanks for the report and the test case,<br>
    <br>
    this is a bug and i pushed a commit to master.<br>
    for the time being, you can download a patch for v1.10 at
<a href="https://github.com/ggouaillardet/ompi-release/commit/4afdab0aa86e5127767c4dfbdb763b4cb641e37a.patch" target="_blank">https://github.com/ggouaillardet/ompi-release/commit/4afdab0aa86e5127767c4dfbdb763b4cb641e37a.patch</a><br>
    <br>
    Cheers,<br>
    <br>
    Gilles<div><div class="h5"><br>
    <br>
    <div>On 3/1/2016 12:17 AM, Jun Kudo wrote:<br>
    </div>
    </div></div><blockquote type="cite"><div><div class="h5">
      <div dir="ltr">
        <div>Hello,</div>
        <div>I&#39;m trying to use the neighborhood collective communication
          capabilities (MPI_Ineighbor_x) of MPI coupled with the
          distributed graph constructor (MPI_Dist_graph_create_adjacent)
          but I&#39;m encountering a segmentation fault on a test case.</div>
        <div><br>
        </div>
        <div>I have attached a &#39;working&#39; example where I create a MPI
          communicator with a simple distributed graph topology where
          Rank 0 contains Node 0 that communicates bi-directionally
          (receiving from and sending to) with Node 1 located on Rank
          1.  I then attempt to send integer messages using the
          neighborhood collective MPI_Ineighbor_alltoall.  The program
          run with the command &#39;mpirun -n 2 ./simpleneighborhood&#39;
          compiled with the latest OpenMPI  (1.10.2) encounters a
          segmentation fault during the non-blocking call.  The same
          program compiled with MPICH (3.2) runs without any problems
          and with the expected results.  To muddy the waters a little
          more, the same program compiled with OpenMPI but using the
          blocking neighborhood collective, MPI_Neighbor_alltoall, seems
          to run just fine as well.</div>
        <div><br>
        </div>
        <div>I&#39;m not really sure at this point if I&#39;m making a simple
          mistake in the construction of my test or if something is more
          fundamentally wrong.  I would appreciate any insight into my
          problem!  </div>
        <div><br>
        </div>
        <div>Thanks ahead of the time for help and let me know if I can
          provide anymore information.</div>
        <div><br>
        </div>
        <div>Sincerely,</div>
        <div>Jun</div>
      </div>
      <br>
      <fieldset></fieldset>
      <br>
      </div></div><pre>_______________________________________________
users mailing list
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2016/02/28608.php" target="_blank">http://www.open-mpi.org/community/lists/users/2016/02/28608.php</a></pre>
    </blockquote>
    <br>
  </div>

<br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank" rel="noreferrer">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2016/02/28610.php" target="_blank" rel="noreferrer">http://www.open-mpi.org/community/lists/users/2016/02/28610.php</a><br></blockquote></div><br></div>

