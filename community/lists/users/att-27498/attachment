is name resolution working on *all* the nodes ?<div>orted might be ssh&#39;ed in a tree fashion.</div><div>that means orted can either be ssh&#39;ed by the node running mpirun or any other node.</div><div>from n0009.scs00, can you make sure</div><div>ssh n0189.mako0 ssh n0198.mako0 echo ok</div><div>ssh n0233.mako0 ssh n0198.mako0 echo ok</div><div>both work ?</div><div><br></div><div>per your log, mpirun might remove the domain name from the ssh command under the hood.</div><div>e.g. </div><div>ssh n0189.mako0 ssh n0198 echo ok</div><div>or</div><div>ssh n0198 ssh n0198.mako0 echo ok</div><div>if that is the case, then I have no idea why we are doing this ...</div><div><br></div><div>Cheers,</div><div><br></div><div>Gilles</div><div><div><br>On Thursday, August 27, 2015, Yong Qin &lt;<a href="mailto:yong.qin@gmail.com">yong.qin@gmail.com</a>&gt; wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir="ltr"><div>&gt; regardless of number of nodes<br><br>No, this is not true. I was referring to this specific test, which was the one that preventing me from thinking about FQDN, and the DN is different in this case. As I clearly stated in my original question - &quot;The issue only exposes itself when more than 2 nodes are involved.&quot;<br><br>[yqin@n0009.scs00 ~]$ mpirun -V<br>mpirun (Open MPI) 1.10.0<br><br>[yqin@n0009.scs00 ~]$ mpirun -np 2 -H n0189.mako0,n0233.mako0 hostname<br>n0189.mako0<br>n0233.mako0<br></div><div class="gmail_extra"><br><div class="gmail_quote">On Tue, Aug 25, 2015 at 4:39 PM, Ralph Castain <span dir="ltr">&lt;<a href="javascript:_e(%7B%7D,&#39;cvml&#39;,&#39;rhc@open-mpi.org&#39;);" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div style="word-wrap:break-word">Your earlier message indicates that it works fine so long as the DN was the same, regardless of number of nodes. It only failed when the DN’s of the nodes differed.<div><br></div><div><br><div><blockquote type="cite"><div><div><div>On Aug 25, 2015, at 3:31 PM, Yong Qin &lt;<a href="javascript:_e(%7B%7D,&#39;cvml&#39;,&#39;yong.qin@gmail.com&#39;);" target="_blank">yong.qin@gmail.com</a>&gt; wrote:</div><br></div></div><div><div><div><div dir="ltr"><div><div>Of course! I blame that two-node test distracted me from checking all the FQDN relevant parameters. :)<br><br></div>So why would the two-node test pass in this case without allowing the FQDN then?<br><br></div>Thanks,<br><div><div class="gmail_extra"><br><div class="gmail_quote">On Tue, Aug 25, 2015 at 2:35 PM, Ralph Castain <span dir="ltr">&lt;<a href="javascript:_e(%7B%7D,&#39;cvml&#39;,&#39;rhc@open-mpi.org&#39;);" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">You need to set —mca orte_keep_fqdn_hostnames 1 on your mpirun line, or set the equivalent MCA param<br>
<div><div><br>
<br>
&gt; On Aug 25, 2015, at 2:24 PM, Yong Qin &lt;<a href="javascript:_e(%7B%7D,&#39;cvml&#39;,&#39;yong.qin@gmail.com&#39;);" target="_blank">yong.qin@gmail.com</a>&gt; wrote:<br>
&gt;<br>
&gt; Hi,<br>
&gt;<br>
&gt; This has been bothering me for a while but I never got a chance to identify the root cause. I know this issue could be due to misconfig of network or ssh in many cases. But I&#39;m pretty sure that we don&#39;t fall into that category at all. Proof? This issue doesn&#39;t happen in 1.6.x and earlier releases, but only in 1.8+ including the 1.10.0 which was released today.<br>
&gt;<br>
&gt; [yqin@n0009.scs00 ~]$ mpirun -V<br>
&gt; mpirun (Open MPI) 1.6.5<br>
&gt;<br>
&gt; [yqin@n0009.scs00 ~]$ mpirun -np 3 -H n0189.mako0,n0233.mako0,n0198.mako0 hostname<br>
&gt; n0233.mako0<br>
&gt; n0189.mako0<br>
&gt; n0198.mako0<br>
&gt;<br>
&gt; [yqin@n0009.scs00 ~]$ mpirun -V<br>
&gt; mpirun (Open MPI) 1.8.8<br>
&gt;<br>
&gt; [yqin@n0009.scs00 ~]$ mpirun -np 3 -H n0189.mako0,n0233.mako0,n0198.mako0 hostname<br>
&gt; ssh: Could not resolve hostname n0198: Name or service not known<br>
&gt; --------------------------------------------------------------------------<br>
&gt; ORTE was unable to reliably start one or more daemons.<br>
&gt; This usually is caused by:<br>
&gt;<br>
&gt; * not finding the required libraries and/or binaries on<br>
&gt;   one or more nodes. Please check your PATH and LD_LIBRARY_PATH<br>
&gt;   settings, or configure OMPI with --enable-orterun-prefix-by-default<br>
&gt;<br>
&gt; * lack of authority to execute on one or more specified nodes.<br>
&gt;   Please verify your allocation and authorities.<br>
&gt;<br>
&gt; * the inability to write startup files into /tmp (--tmpdir/orte_tmpdir_base).<br>
&gt;   Please check with your sys admin to determine the correct location to use.<br>
&gt;<br>
&gt; *  compilation of the orted with dynamic libraries when static are required<br>
&gt;   (e.g., on Cray). Please check your configure cmd line and consider using<br>
&gt;   one of the contrib/platform definitions for your system type.<br>
&gt;<br>
&gt; * an inability to create a connection back to mpirun due to a<br>
&gt;   lack of common network interfaces and/or no route found between<br>
&gt;   them. Please check network connectivity (including firewalls<br>
&gt;   and network routing requirements).<br>
&gt; --------------------------------------------------------------------------<br>
&gt;<br>
&gt; [yqin@n0009.scs00 ~]$ mpirun -V<br>
&gt; mpirun (Open MPI) 1.10.0<br>
&gt;<br>
&gt; [yqin@n0009.scs00 ~]$ mpirun -np 3 -H n0189.mako0,n0233.mako0,n0198.mako0 hostname<br>
&gt; ssh: Could not resolve hostname n0198: Name or service not known<br>
&gt; --------------------------------------------------------------------------<br>
&gt; ORTE was unable to reliably start one or more daemons.<br>
&gt; This usually is caused by:<br>
&gt;<br>
&gt; * not finding the required libraries and/or binaries on<br>
&gt;   one or more nodes. Please check your PATH and LD_LIBRARY_PATH<br>
&gt;   settings, or configure OMPI with --enable-orterun-prefix-by-default<br>
&gt;<br>
&gt; * lack of authority to execute on one or more specified nodes.<br>
&gt;   Please verify your allocation and authorities.<br>
&gt;<br>
&gt; * the inability to write startup files into /tmp (--tmpdir/orte_tmpdir_base).<br>
&gt;   Please check with your sys admin to determine the correct location to use.<br>
&gt;<br>
&gt; *  compilation of the orted with dynamic libraries when static are required<br>
&gt;   (e.g., on Cray). Please check your configure cmd line and consider using<br>
&gt;   one of the contrib/platform definitions for your system type.<br>
&gt;<br>
&gt; * an inability to create a connection back to mpirun due to a<br>
&gt;   lack of common network interfaces and/or no route found between<br>
&gt;   them. Please check network connectivity (including firewalls<br>
&gt;   and network routing requirements).<br>
&gt; --------------------------------------------------------------------------<br>
&gt;<br>
&gt;<br>
&gt; Note that I was running the mpirun from &quot;n0009.scs00&quot;. If I ran it from a native &quot;mako0&quot; node, it would pass as well.<br>
&gt;<br>
&gt; [yqin@n0198.mako0 ~]$ mpirun -V<br>
&gt; mpirun (Open MPI) 1.10.0<br>
&gt;<br>
&gt; [yqin@n0198.mako0 ~]$ mpirun -np 3 -H n0189.mako0,n0233.mako0,n0198.mako0 hostname<br>
&gt; n0189.mako0<br>
&gt; n0198.mako0<br>
&gt; n0233.mako0<br>
&gt;<br>
&gt; The network connection between n0009.scs00 and all the &quot;mako0&quot; nodes are clear and no firewall at all, and all on the same subnet. The only thing that I can think of is the hostname itself. From the error message mpirun was trying to resolve n0198, etc., even though the proper hostname that&#39;s passed to it was n0198.mako0. &quot;n0198&quot; by itself would not resolve because we have multiple clusters configured within the same subnet and we do need the cluster name suffix as identifier. But this is also not always true, for example, if I only have two nodes involved than it would pass as well.<br>
&gt;<br>
&gt; [yqin@n0009.scs00 ~]$ mpirun -V<br>
&gt; mpirun (Open MPI) 1.10.0<br>
&gt;<br>
&gt; [yqin@n0009.scs00 ~]$ mpirun -np 2 -H n0189.mako0,n0233.mako0 hostname<br>
&gt; n0189.mako0<br>
&gt; n0233.mako0<br>
&gt;<br>
&gt; The issue only exposes itself when more than 2 nodes are involved. Any thoughts?<br>
&gt;<br>
&gt; Thanks,<br>
&gt;<br>
&gt; Yong Qin<br>
</div></div>&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="javascript:_e(%7B%7D,&#39;cvml&#39;,&#39;users@open-mpi.org&#39;);" target="_blank">users@open-mpi.org</a><br>
&gt; Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" rel="noreferrer" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2015/08/27489.php" rel="noreferrer" target="_blank">http://www.open-mpi.org/community/lists/users/2015/08/27489.php</a><br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="javascript:_e(%7B%7D,&#39;cvml&#39;,&#39;users@open-mpi.org&#39;);" target="_blank">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" rel="noreferrer" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2015/08/27490.php" rel="noreferrer" target="_blank">http://www.open-mpi.org/community/lists/users/2015/08/27490.php</a></blockquote></div><br></div></div></div>
_______________________________________________<br>users mailing list<br><a href="javascript:_e(%7B%7D,&#39;cvml&#39;,&#39;users@open-mpi.org&#39;);" target="_blank">users@open-mpi.org</a><br>Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></div></div>Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2015/08/27491.php" target="_blank">http://www.open-mpi.org/community/lists/users/2015/08/27491.php</a></div></blockquote></div><br></div></div><br>_______________________________________________<br>
users mailing list<br>
<a href="javascript:_e(%7B%7D,&#39;cvml&#39;,&#39;users@open-mpi.org&#39;);" target="_blank">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" rel="noreferrer" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2015/08/27493.php" rel="noreferrer" target="_blank">http://www.open-mpi.org/community/lists/users/2015/08/27493.php</a><br></blockquote></div><br></div></div>
</blockquote></div></div>

