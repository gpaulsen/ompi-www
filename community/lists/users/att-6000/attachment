Hi,<br><br>Does anybody face problems running Openmpi on two hosts with different networks (gateway to reach the other) ?<br>Let say compil02 ip adress is <a href="http://172.3.9.10">172.3.9.10</a> and r009n001 is <a href="http://10.160.4.1">10.160.4.1</a><br>
<br>There is no problem with MPI_init free executables (for example hostname)<br><br>compil02% /tmp/HALMPI/openmpi-1.2.2/bin/mpirun --prefix /tmp/HALMPI/openmpi-1.2.2 -np 1 -host compil02 hostname : -np 1 -host r009n001 hostname<br>
r009n001<br>compil02<br><br>But as soon as I try a simple hello world , it &#39;s crashing with the following error message.<br>Please note that when I try to run hello between r009n001 (<a href="http://10.160.4.1">10.160.4.1</a>) and r009n002 (<a href="http://10.160.4.2">10.160.4.2</a>), it works fine<br>
<br>Thanks in advance for your help.<br>Regards <br><br>Geoffroy<br><br><br>PS: same error with openmpi v1.2.5<br><br><br>compil02% /tmp/HALMPI/openmpi-1.2.2/bin/mpirun --prefix /tmp/HALMPI/openmpi-1.2.2 -np 1 -host compil02 /tmp/hello : -np 1 -host r009n001 /tmp/hello<br>
--------------------------------------------------------------------------<br>Process 0.1.0 is unable to reach 0.1.1 for MPI communication.<br>If you specified the use of a BTL component, you may have<br>forgotten a component (such as &quot;self&quot;) in the list of<br>
usable components.<br>--------------------------------------------------------------------------<br>--------------------------------------------------------------------------<br>It looks like MPI_INIT failed for some reason; your parallel process is<br>
likely to abort.&nbsp; There are many reasons that a parallel process can<br>fail during MPI_INIT; some of which are due to configuration or environment<br>problems.&nbsp; This failure appears to be an internal failure; here&#39;s some<br>
additional information (which may only be relevant to an Open MPI<br>developer):<br><br>&nbsp; PML add procs failed<br>&nbsp; --&gt; Returned &quot;Unreachable&quot; (-12) instead of &quot;Success&quot; (0)<br>--------------------------------------------------------------------------<br>
--------------------------------------------------------------------------<br>Process 0.1.1 is unable to reach 0.1.0 for MPI communication.<br>If you specified the use of a BTL component, you may have<br>forgotten a component (such as &quot;self&quot;) in the list of<br>
usable components.<br>--------------------------------------------------------------------------<br>--------------------------------------------------------------------------<br>It looks like MPI_INIT failed for some reason; your parallel process is<br>
likely to abort.&nbsp; There are many reasons that a parallel process can<br>fail during MPI_INIT; some of which are due to configuration or environment<br>problems.&nbsp; This failure appears to be an internal failure; here&#39;s some<br>
additional information (which may only be relevant to an Open MPI<br>developer):<br><br>&nbsp; PML add procs failed<br>&nbsp; --&gt; Returned &quot;Unreachable&quot; (-12) instead of &quot;Success&quot; (0)<br>--------------------------------------------------------------------------<br>
*** An error occurred in MPI_Init<br>*** before MPI was initialized<br>*** MPI_ERRORS_ARE_FATAL (goodbye)<br>*** An error occurred in MPI_Init<br>*** before MPI was initialized<br>*** MPI_ERRORS_ARE_FATAL (goodbye)<br><br>

