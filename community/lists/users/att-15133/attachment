<html><head></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; "><br><div><div>On Dec 15, 2010, at 10:14 AM, Gilbert Grosdidier wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><div style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; ">Bonjour Ralph,<div><br></div><div>&nbsp;Thanks for taking time to help me.</div><div><br><div><div>Le 15 déc. 10 à 16:27, Ralph Castain a écrit :</div><br class="Apple-interchange-newline"><blockquote type="cite"><div>It would appear that there is something trying to talk to a socket opened by one of your daemons. At a guess, I would bet the problem is that a prior job left a daemon alive that is talking on the same socket.<br></div></blockquote><div><br></div><div>gg= At first glance, this could be possible, although I got no evidence</div><div>about it when looking for ghost processes of mine on the relevant nodes.</div><br><blockquote type="cite"><div><br>Are you by chance using static ports for the job? </div></blockquote><div><br></div><div>gg= How could I know that ?</div><div>Is there an easy way to workaround these static ports ?&nbsp;</div><div>Would it prevent the jobs to collide ghost jobs/processes as suggested below, please ?</div><div>I did not spot any info about static ports inside of ompi_info output ... ;-)</div></div></div></div></blockquote><div><br></div>It wouldn't happen by default - you would have had to tell us to use static ports by specifying an OOB port range. If you didn't do that (and remember, it could be in a default mca param file!), then the ports are dynamically assigned.</div><div><br><blockquote type="cite"><div style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; "><div><div><br><blockquote type="cite"><div>Did you run another job just before this one that might have left a daemon somewhere?<br></div></blockquote><div><br></div><div>gg= Again, it could be possible that with my many jobs crashing over the cluster,</div><div>PBS was unable to clean up the nodes in time before restarting a new one.</div><div>But I have no evidence.</div><div><br></div><div>&nbsp;The exact full error message was like this:</div><div>[r36i3n15:18992] [[1468,0],254]-[[1468,0],14] mca_oob_tcp_peer_recv_connect_ack: received unexpected process identifier [[1468,1],1643]</div><div><br></div><div>&nbsp;From some debug info I got, process 1468 seems to relate to node rank 0 (r33i0n0),</div><div>while process 1643 seems to originates from node r36i0n14.</div></div></div></div></blockquote><div><br></div>The "1468,1" is an arbitrary identifier for the overall job. The "1643" indicates that it is an MPI process (rank=1643) within that job that provided the bad identifier.</div><div><br></div><div>The "1468,0" identifiers in the early part of the message indicate that the error occurred on a port being used by two ORTE daemons for communication. Somehow, an MPI process (rank=1643) injected a message into that link.</div><div><br></div><div>It looks like all the messages are flowing within a single job (all three processes mentioned in the error have the same identifier). Only possibility I can think of is that somehow you are reusing ports - is it possible your system doesn't have enough ports to support all the procs?</div><div><br></div><div>I confess I'm a little at a loss &nbsp;- never seen this problem before, and we run on very large clusters.</div><div><br></div><div><br><blockquote type="cite"><div style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; "><div><div><div><br></div><div>&nbsp;But, indeed, none of r33i0n0, r36i0n14 or r36i3n15 exhibits any process like 1468 or 1643,</div><div>while process 18992 is indeed the master one on r36i3n15.</div><div><br></div><div>&nbsp;Thanks, &nbsp; Best, &nbsp; &nbsp;G.</div><div><br></div><div><br></div><blockquote type="cite"><div><br><br>On Dec 15, 2010, at 1:05 AM, Gilbert Grosdidier wrote:<br><br><blockquote type="cite">Bonjour,<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">Running with OpenMPI 1.4.3 on an SGI Altix cluster with 4096 cores, I got<br></blockquote><blockquote type="cite">this error message, right at startup :<br></blockquote><blockquote type="cite">mca_oob_tcp_peer_recv_connect_ack: received unexpected process identifier [[13816,0],209]<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">and the whole job is going to spin for an undefined period, without crashing/aborting.<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">What could be the culprit please ?<br></blockquote><blockquote type="cite">Is there a workaround ?<br></blockquote><blockquote type="cite">Which parameter is to be tuned ?<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">Thanks in advance for any help, &nbsp;&nbsp;&nbsp;Best, &nbsp;&nbsp;&nbsp;G.<br></blockquote><blockquote type="cite"><br></blockquote></div></blockquote></div><div apple-content-edited="true"><div style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; "><span class="Apple-style-span" style="border-collapse: separate; font-family: Helvetica; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-border-horizontal-spacing: 0px; -webkit-border-vertical-spacing: 0px; -webkit-text-decorations-in-effect: none; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; "><div style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; "><span class="Apple-style-span" style="border-collapse: separate; font-family: Helvetica; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-border-horizontal-spacing: 0px; -webkit-border-vertical-spacing: 0px; -webkit-text-decorations-in-effect: none; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; "><div style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; "><div><div><font class="Apple-style-span" color="#2100FF" face="Monaco"><b><font class="Apple-style-span" face="Helvetica"><span class="Apple-style-span" style="font-weight: normal;"><br></span></font></b></font></div></div></div></span><br class="Apple-interchange-newline"></div></span><br class="Apple-interchange-newline"></div><br class="Apple-interchange-newline"> </div><br></div></div>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></blockquote></div><br></body></html>
