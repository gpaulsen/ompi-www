<html><head><meta http-equiv="Content-Type" content="text/html charset=iso-8859-1"></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; "><br><div><div>On Aug 31, 2013, at 14:56 , Huangwei &lt;<a href="mailto:hz283@cam.ac.uk">hz283@cam.ac.uk</a>&gt; wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><div dir="ltr"><div>Hi All, </div><div>&nbsp;</div><div>I would like to send an array A, which has different dimensions in the processors. Then the root receive these As and puts them into another array globA. I know MPI_allgatherv can do this. However, there are still some implementation issues that are not very clear for me. Thank you very much if any of you can give me some suggestions and comments. The piece of code is as follows (I am not sure if it is completely correct):</div>

<div>&nbsp;</div><div>&nbsp;</div><div><font color="#0000ff">!...calculate the total size for the total size of the globA, PROCASize(myidf)&nbsp;is the&nbsp;size of array A in each processor. </font></div><div><font color="#0000ff">&nbsp;<br clear="all">

 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; allocate(PROCASize(numprocs))<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PROCASize(myidf) =&nbsp;Asize<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; call mpi_allreduce(PROCSize,PROCSize,numprocs,mpi_integer,mpi_sum,MPI_COMM_WORLD,ierr)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; globAsize = sum(PROCAsize)</font></div>

<div><font color="#0000ff"></font>&nbsp;</div><div><font color="#0000ff">!...calculate the RECS and DISP for MPI_allgatherv</font></div><div><font color="#0000ff">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; allocate(RECSASize(0:numprocs-1))<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; allocate(DISP(0:numprocs-1))<br>

 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; do i=1,numprocs<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; RECSASize(i-1) = PROCASize(i)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; enddo</font></div><div><font color="#0000ff">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; call mpi_type_extent(mpi_integer, extent, ierr)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; do i=1,numprocs<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; DISP(i-1) = 1 + (i-1)*RECSASIze(i-1)*extent<br>

 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; enddo</font></div><div><font color="#0000ff"></font>&nbsp;</div><div><font color="#0000ff">!...allocate the size of the array globA</font></div><div><font color="#0000ff">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; allocate(globA(globASize*extent))</font></div>

<div><font color="#0000ff">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; call mpi_allgatherv(A,ASize,MPI_INTEGER,globA, RECSASIze, DISP,MPI_INTEGER,MPI_COMM_WORLD,ierr)</font></div><div>&nbsp;</div><div>My Questions:</div><div>&nbsp;</div><div>1, How to allocate the globA, i.e. the receive buff's size? Should I use <font color="#0000ff">globASize*extent <font>or just</font>globalize</font><span style="color: rgb(0, 0, 255); ">?</span></div></div></blockquote><div><br></div>I don't understand what globASize is supposed to be as you do the reduction on PROCSize and then sum PROCAsize.</div><div><br></div><div>Anyway, you should always allocate the memory for collective based on the total number of elements to receive times the extent of each element. In fact to be even more accurate, if we suppose that you correctly computed the DISP array, you should allocate globA as DISP(numprocs-1) + RECSASIze.<br><br><blockquote type="cite"><div dir="ltr"><div><font color="#0000ff"></font>&nbsp;<br class="webkit-block-placeholder"></div><div>2, about the displacements in globA, i.e. DISP(:), it is stand for the order of an array? like 1, 2, 3, ...., this corresponds to <font color="#0000ff">DISP(i-1) = 1 + (i-1)*RECSASIze(i-1)*extent. </font><font>Or this array's elements are the address at which the data from different processors will be stored in globA? </font></div></div></blockquote><div><br></div><div>These are the displacement from the beginning of the array where the data from a peer is stored. The index in this array is the rank of the peer process in the communicator.</div><br><blockquote type="cite"><div dir="ltr">

<div><font color="#0000ff"></font>&nbsp;</div><div><font>3, should the arrays start from 0 to numprocs-1? or start from 1 to numprocs? This may be important when they work as arguments in mpi_allgatherv subroutine. </font></div></div></blockquote><div><br></div><div>It doesn't matter how you allocate it (0:numprocs-1) or simple (numprocs) the compiler will do the right this when creating the call using the array.</div><div><br></div><div>&nbsp; George.</div><br><blockquote type="cite"><div dir="ltr">

<div><font color="#0000ff"></font>&nbsp;</div><div><font color="#0000ff"></font>&nbsp;</div><div>These questions may be too simple for MPI professionals, but I do not have much experience on this. Thus I am sincerely eager to get some comments and suggestions from you. Thank you in advance!</div>

<div><br></div><div><br></div><div>regards,<br>Huangwei</div><div><div dir="ltr"><div><span style="font-family:&quot;Monotype Corsiva&quot;;font-size:12pt"><br></span></div><div>&nbsp;</div><div><br>&nbsp;</div><span></span><span></span><span></span></div>

</div>
</div>
_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>http://www.open-mpi.org/mailman/listinfo.cgi/users</blockquote></div><br></body></html>
