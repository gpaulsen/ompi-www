<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" xmlns="http://www.w3.org/TR/REC-html40">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="Generator" content="Microsoft Word 12 (filtered medium)">
<style><!--
/* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0in;
	margin-bottom:.0001pt;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-priority:99;
	color:purple;
	text-decoration:underline;}
span.EmailStyle17
	{mso-style-type:personal-compose;
	font-family:"Calibri","sans-serif";
	color:windowtext;}
.MsoChpDefault
	{mso-style-type:export-only;
	font-size:10.0pt;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
--></style><!--[if gte mso 9]><xml>
<o:shapedefaults v:ext="edit" spidmax="1026" />
</xml><![endif]--><!--[if gte mso 9]><xml>
<o:shapelayout v:ext="edit">
<o:idmap v:ext="edit" data="1" />
</o:shapelayout></xml><![endif]-->
</head>
<body lang="EN-US" link="blue" vlink="purple">
<div class="WordSection1">
<p class="MsoNormal">Hi all,<o:p></o:p></p>
<p class="MsoNormal">I am running on an IBM BladeCenter, using Open MPI 1.4.1, and opensm subnet manager for Infiniband<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">Our application has real time requirements and it has recently been proven that it does not scale to meet future requirements.<o:p></o:p></p>
<p class="MsoNormal">Presently, I am re-organizing the application to process work in a more parallel manner then it does now.<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">Jobs arrive at the rate of 200 per second and are sub-divided into groups of objects by a master process (MP) on its own node.<o:p></o:p></p>
<p class="MsoNormal">The MP then assigns the object groups to 20 slave processes (SP), each running on their own node, to do the expensive computational work in parallel.<o:p></o:p></p>
<p class="MsoNormal">The SPs then send their results to a gatherer process (GP) on its own node that merges the results for the job and sends it onward for final processing.<o:p></o:p></p>
<p class="MsoNormal">The highest latency for the last 1024 jobs that were processed is then written to a log file that is displayed by a GUI.<o:p></o:p></p>
<p class="MsoNormal">Each process uses the same controller method for sending and&nbsp; receiving messages as follows:<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">For (each CPU that sends us input)<o:p></o:p></p>
<p class="MsoNormal">{<o:p></o:p></p>
<p class="MsoNormal" style="text-indent:.5in">MPI_Irecv(&#8230;.)<o:p></o:p></p>
<p class="MsoNormal">}<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">While (true)<o:p></o:p></p>
<p class="MsoNormal">{<o:p></o:p></p>
<p class="MsoNormal">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; For (each CPU that sends us input)<o:p></o:p></p>
<p class="MsoNormal" style="text-indent:.5in">{<o:p></o:p></p>
<p class="MsoNormal" style="margin-left:.5in;text-indent:.5in">MPI_Test(&#8230;.)<o:p></o:p></p>
<p class="MsoNormal" style="margin-left:.5in;text-indent:.5in">If (message was received)<o:p></o:p></p>
<p class="MsoNormal" style="margin-left:.5in;text-indent:.5in">{<o:p></o:p></p>
<p class="MsoNormal" style="margin-left:.5in;text-indent:.5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Copy the message<o:p></o:p></p>
<p class="MsoNormal" style="margin-left:1.0in;text-indent:.5in">Queue the copy to our input queue<o:p></o:p></p>
<p class="MsoNormal" style="margin-left:.5in;text-indent:.5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Irecv(&#8230;)
<o:p></o:p></p>
<p class="MsoNormal" style="margin-left:.5in;text-indent:.5in">}<o:p></o:p></p>
<p class="MsoNormal" style="text-indent:.5in">}<o:p></o:p></p>
<p class="MsoNormal" style="text-indent:.5in">If (there are messages on our input queue)<o:p></o:p></p>
<p class="MsoNormal" style="text-indent:.5in">{<o:p></o:p></p>
<p class="MsoNormal" style="text-indent:.5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8230; process the FIRST message on queue (this may queue messages for output) &#8230;.<o:p></o:p></p>
<p class="MsoNormal" style="text-indent:.5in"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal" style="text-indent:.5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; For (each message on our output queue)<o:p></o:p></p>
<p class="MsoNormal" style="text-indent:.5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {<o:p></o:p></p>
<p class="MsoNormal" style="text-indent:.5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Send(&#8230;)<o:p></o:p></p>
<p class="MsoNormal" style="text-indent:.5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<o:p></o:p></p>
<p class="MsoNormal" style="text-indent:.5in">}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <o:p></o:p></p>
<p class="MsoNormal">}<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">My problem is that I do not meet our applications performance requirements for a job (~ 20 ms) until I reduce the number of SPs from 20 to 4 or less.<o:p></o:p></p>
<p class="MsoNormal">I added some debug into the GP and found that there are never more than 14 messages received in the for loop that calls MPI_Test.<o:p></o:p></p>
<p class="MsoNormal">The messages that were sent from the other 6 SPs will eventually arrive at the GP in a long stream after experiencing high latency (over 600 ms).<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">Going forward, we need to handle more objects per job and will need to have more than 4 SPs to keep up.<o:p></o:p></p>
<p class="MsoNormal">My thought is that I have to obey this 4 SPs to 1 GP ratio and create intermediate GPs to gather results from every 4 slaves.<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">Is this a contention problem at the GP?<o:p></o:p></p>
<p class="MsoNormal">Is there debugging or logging I can turn on in the MPI to prove that contention is occurring?<o:p></o:p></p>
<p class="MsoNormal">Can I configure MPI receive processing to improve upon the 4 to 1 ratio?<o:p></o:p></p>
<p class="MsoNormal">Can I improve the controller method (listed above) to gain a performance improvement?<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">Thanks for any suggestions.<o:p></o:p></p>
<p class="MsoNormal">Gary Hodge<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
</body>
</html>

