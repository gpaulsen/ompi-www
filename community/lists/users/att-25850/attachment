<div dir="ltr"><div>Dear support,<br><br>I&#39;m encountering an issue with the MPI_Neighbor_alltoallw request of mpi-1.8.3.<br>I have enclosed a test case with information of my workstation.<br><br>In this test, I define a weighted topology for 5 processes, where the weight represent the number of buffers to send/receive :<br>    rank<br>      0 : | x |<br>      1 : | 2 | x |<br>      2 : | 1 | 1 | x |<br>      3 : | 3 | 2 | 3 | x |<br>      4 : | 5 | 2 | 2 | 2 | x |<br><br>In this topology, the rank 1 will send/receive :<br>   2 buffers to/from the rank 0,<br>   1 buffer to/from the rank 2,<br>   2 buffers to/from the rank 3,<br>   2 buffers to/from the rank 4,<br> <br>The send buffer are defined with the MPI_Type_create_hindexed_block. This allows to use a same buffer for several communications without duplicating it (read only).<br>Here the rank 1 will have 2 send buffers (the max of 2, 1, 2, 2).<br>The receiver buffer is a contiguous buffer defined with MPI_Type_contiguous request.<br>Here, the receiver buffer of the rank 1 is of size : 7 (2+1+2+2)<br><br>This test case succesful for 2 or 3 processes. For 4 processes, the test fails 1 times for 3 successes. For 5 processes, the test fails all the time.<br><br></div>The error code is : *** MPI_ERR_IN_STATUS: error code in status<br><div><br>I don&#39;t understand what I am doing wrong.<br><br>Could you please have a look on it?<br><br>Thank you very much.<br><div><div><div><div><div><div><div><br></div><div>Best regards, <br></div><div>Ghislain Viguier<br></div><div><br><div><div>-- <br><div class="gmail_signature"><font color="#333333">Ghislain Viguier</font><div><font color="#333333">Tél. 06 31 95 03 17</font></div></div>
</div></div></div></div></div></div></div></div></div></div></div>

