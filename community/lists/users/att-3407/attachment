Hi Jeff (and everyone),<br><br>Thanks!&nbsp; Now I have compiled the openmpi-1.2.2 successfully under i386-Linux (Debian Sarge) with the following configurations:<br><br>./configure CFLAGS=-g -pg -O3 --enable-mpi-threads --enable-progress-threads --enable-static --disable-shared
<br><br>However when I compile my client program using mpicc and I inserted -static,<br><br>(compile is done by a makefile)<br>mpicc&nbsp; -static -g -pg -O3 -W -Wall -pedantic -std=c99 -o raytrace&nbsp; bbox.o cr.o env.o fbuf.o geo.o
 huprn.o husetup.o hutv.o isect.o main.o matrix.o memory.o poly.o raystack.o shade.o sph.o trace.o tri.o debug.o<br><br><br>&nbsp;it fails to link and complains that <br><br>nction `_int_malloc&#39;:<br>: multiple definition of `_int_malloc&#39;
<br>/usr/lib/libopen-pal.a(lt1-malloc.o)(.text+0x18a0):openmpi-1.2.2/opal/mca/memory/ptmalloc2/malloc.c:3954: first defined here<br>/usr/bin/ld: Warning: size of symbol `_int_malloc&#39; changed from 1266 in /usr/lib/libopen-
pal.a(lt1-malloc.o) to 1333 in /home/490_research/490/src/mpi.optimized_profiling//lib/libopen-pal.a(lt1-malloc.o)<br><br><br>so what could go wrong here?<br><br>Is it because openmpi has internal implementatios of system-provided functions (such as malloc) that are also used in my program, but the one the client program use is provided by the system whereas the one in the library has a different internal implementation?
<br><br>In such case, how could I do the static linking in my client program?&nbsp; I really need static linking as far as possible to do the profiling.<br><br>Thanks!<br><br><br><div><span class="gmail_quote">On 6/8/07, <b class="gmail_sendername">
Jeff Squyres</b> &lt;<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a>&gt; wrote:</span><blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
On Jun 7, 2007, at 2:07 AM, Code Master wrote:<br><br>&gt; I wish to compile openmpi-1.2.2 so that it:<br>&gt; - support MPI_THREAD_MULTIPLE<br>&gt; - enable profiling (generate gmon.out for each process after my<br>&gt; client app finish running) to tell apart CPU time of my client
<br>&gt; program from the MPI library<br>&gt; - static linking for everything (incl client app and all components<br>&gt; of library openmpi)<br>&gt;<br>&gt; in the documentation, it says that --enable-mcs-static=&lt;CSV list&gt;
<br>&gt; will enable static linking of the modules in the list, however what<br>&gt; can I specify if I want to statically link *all* mcs modules<br>&gt; without knowing the list of modules available?<br><br>You should be able to do:
<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;./configure --enable-static --disable-shared ...<br><br>This will do 2 things:<br><br>- libmpi (and friends) will be compiled as .a&#39;s (instead of .so&#39;s)<br>- all the MCA components will be physically contained in libmpi (and
<br>friends) instead of being built as standalone plugins<br><br>&gt; Also this is the plan for my command used for configuring openmpi:<br>&gt;<br>&gt; ./configure CFLAGS=&quot;-g -pg -O3 -static&quot; --prefix=./ --enable-mpi-
<br>&gt; threads --enable-progress-threads --enable-static&nbsp;&nbsp;--disable-shared<br>&gt; --enable-mcs-static --with-devel-headers<br><br>It&#39;s actually --enable-mca-static, not --enable-mcs-static.<br><br>However, that should not be necessary; the --enable-static and --
<br>disable-shared should take care of pulling all the components into<br>the libraries for you.<br><br>--<br>Jeff Squyres<br>Cisco Systems<br><br>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">
users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></div><br>

