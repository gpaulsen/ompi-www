
<br><font size=2 face="sans-serif">The MPI Standard (in my opinion) should
have avoided the word &quot;buffer&quot;. &nbsp;To me, a &quot;buffer&quot;
is something you set aside as scratch space between the application data
structures and the communication calls. </font>
<br>
<br><font size=2 face="sans-serif">In MPI, the communication is done directly
from/to the application's data structures and there are no &quot;buffers&quot;
needed. &nbsp;The point of MPI_Datatypes is their ability to describe the
layout of the data in the application data structure so an MPI_Scatter(),
for example, can operate directly.</font>
<br>
<br><font size=2 face="sans-serif">This saves any need to allocate contiguous
scratch buffers and do packing to send and unpacking after receive.</font>
<br>
<br>
<br><font size=2 face="sans-serif">Dick Treumann &nbsp;- &nbsp;MPI Team
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br>
IBM Systems &amp; Technology Group<br>
Dept X2ZA / MS P963 -- 2455 South Road -- Poughkeepsie, NY 12601<br>
Tele (845) 433-7846 &nbsp; &nbsp; &nbsp; &nbsp; Fax (845) 433-8363<br>
</font>
<br>
<br>
<br>
<table width=100%>
<tr valign=top>
<td><font size=1 color=#5f5f5f face="sans-serif">From:</font>
<td><font size=1 face="sans-serif">Alexandru Blidaru &lt;alexsb92@gmail.com&gt;</font>
<tr valign=top>
<td><font size=1 color=#5f5f5f face="sans-serif">To:</font>
<td><font size=1 face="sans-serif">Open MPI Users &lt;users@open-mpi.org&gt;</font>
<tr valign=top>
<td><font size=1 color=#5f5f5f face="sans-serif">Date:</font>
<td><font size=1 face="sans-serif">07/21/2010 11:19 AM</font>
<tr valign=top>
<td><font size=1 color=#5f5f5f face="sans-serif">Subject:</font>
<td><font size=1 face="sans-serif">Re: [OMPI users] Partitioning problem
set data</font>
<tr valign=top>
<td><font size=1 color=#5f5f5f face="sans-serif">Sent by:</font>
<td><font size=1 face="sans-serif">users-bounces@open-mpi.org</font></table>
<br>
<hr noshade>
<br>
<br>
<br><font size=3>Hey Bill,</font>
<br>
<br><font size=3>I took a look at the documentation for MPI_Scatter(),
but I noticed that you need buffers to use it. My supervisor wasn't really
happy with using buffers, and for that reason the code that I am writing
is only using blocking routines, which will make my life a tad bit harder
due to the fact that i have to avoid a deadlock, i believe it's called.
I know it might not make sense due to the way MPI works, but is there any
Scatter-like function that does not use buffers?&nbsp;</font>
<br>
<br><font size=3>NB: I haven't looked through that book yet, so i am not
sure whether they provide any non-buffer examples.</font>
<br>
<br><font size=3>Alex<br>
</font>
<br><font size=3>On Wed, Jul 21, 2010 at 10:48 AM, Bill Rankin &lt;</font><a href=mailto:Bill.Rankin@sas.com><font size=3 color=blue><u>Bill.Rankin@sas.com</u></font></a><font size=3>&gt;
wrote:</font>
<br><font size=2 color=#004080>Depending on the datatype and its order
in memory, the “Block,*” and “*,Block” (which we used to call “slabs”
in 3D) may be implemented by a simple scatter/gather call in MPI.&nbsp;
&nbsp;The “Block,Block” distribution is a little more complex, but if
you take advantage of MPI’s derived datatypes, you may be able to reference
an arbitrary 3D sub-space as a single data entity and then use gather/scatter
with that.</font>
<p><font size=2 color=#004080>&nbsp;</font>
<p><font size=2 color=#004080>I recommend that look through some of the
examples in “MPI – The Complete Reference (Vol. 1)” by Snir, </font><a href=http://et.al/ target=_blank><font size=2 color=blue><u>et.al</u></font></a><font size=2 color=#004080>.
for use of &nbsp;MPI_Gather(), MPI_Scatter(), as well as the section on
user-defined datatypes.&nbsp; Section 5.2 of “Using MPI” by Gropp, Lusk
and Skjellum has an example code for an N-Body Problem which you may find
useful.</font>
<p><font size=2 color=#004080>&nbsp;</font>
<p><font size=2 color=#004080>Hope this helps. </font>
<p><font size=2 color=#004080>&nbsp;</font>
<p><font size=2 color=#004080>-bill</font>
<p><font size=2 color=#004080>&nbsp;</font>
<p><font size=2 color=#004080>&nbsp;</font>
<p><font size=2><b>From:</b> </font><a href="mailto:users-bounces@open-mpi.org" target=_blank><font size=2 color=blue><u>users-bounces@open-mpi.org</u></font></a><font size=2>
[mailto:</font><a href="mailto:users-bounces@open-mpi.org" target=_blank><font size=2 color=blue><u>users-bounces@open-mpi.org</u></font></a><font size=2>]
<b>On Behalf Of </b>Alexandru Blidaru<b><br>
Sent:</b> Tuesday, July 20, 2010 10:54 AM<b><br>
To:</b> Open MPI Users<b><br>
Subject:</b> Re: [OMPI users] Partitioning problem set data</font>
<p><font size=3>&nbsp;</font>
<p><font size=3>If there is an already existing implementation of the *Block
or Block* methods that splits the array and sends the individual pieces
to the&nbsp;proper&nbsp;nodes, can you point me to it please?&nbsp;</font>
<p><font size=3>On Tue, Jul 20, 2010 at 9:52 AM, Alexandru Blidaru &lt;</font><a href=mailto:alexsb92@gmail.com target=_blank><font size=3 color=blue><u>alexsb92@gmail.com</u></font></a><font size=3>&gt;
wrote:</font>
<p><font size=3>Hi,</font>
<p><font size=3>&nbsp;</font>
<p><font size=3>I have a 3D array, which I need to split into equal n parts,
so that each part would run on a different node. I found the picture in
the attachment from this website (</font><a href=https://computing.llnl.gov/tutorials/parallel_comp/#DesignPartitioning target=_blank><font size=3 color=blue><u>https://computing.llnl.gov/tutorials/parallel_comp/#DesignPartitioning</u></font></a><font size=3>)&nbsp;on
the different ways to partition data. I am interested in the block methods,
as the cyclic methods wouldn't really work for me at all. Obviously the
*, BLOCK and the BLOCK, * methods would be really easy to implement for
3D arrays, assuming that the 2D picture would be looking at the array from
the top. My question is if there are other better ways to do it from a
performance standpoint?</font>
<p><font size=3>&nbsp;</font>
<p><font size=3>Thanks for your replies,</font>
<p><font size=3>Alex</font>
<p><font size=3>&nbsp;</font>
<br><font size=3><br>
_______________________________________________<br>
users mailing list</font><font size=3 color=blue><u><br>
</u></font><a href="mailto:users@open-mpi.org"><font size=3 color=blue><u>users@open-mpi.org</u></font></a><font size=3 color=blue><u><br>
</u></font><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target=_blank><font size=3 color=blue><u>http://www.open-mpi.org/mailman/listinfo.cgi/users</u></font></a>
<br><tt><font size=2>_______________________________________________<br>
users mailing list<br>
users@open-mpi.org<br>
</font></tt><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users"><tt><font size=2>http://www.open-mpi.org/mailman/listinfo.cgi/users</font></tt></a>
<br>
<br>
