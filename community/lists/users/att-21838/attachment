<html><head><meta http-equiv="Content-Type" content="text/html charset=windows-1252"></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; "><br><div><div>On Apr 30, 2013, at 1:54 PM, Vladimir Yamshchikov &lt;<a href="mailto:yaximik@gmail.com">yaximik@gmail.com</a>&gt; wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><div dir="ltr">This is the question I am trying to answer - how many threads I can use with blastx on a grid? If I could request resources by_node,&nbsp;use -pernode option to have one process per node, and then specify the correct number of threads for each node. But I cannot, resurces (slots)&nbsp;are requested per-core (per_process),</div></blockquote><div><br></div>I don't believe that is true - resources are requested for the entire job, not for each process</div><div><br><blockquote type="cite"><div dir="ltr"> so I was instructed to request total number of slots.&nbsp;However, as allocated&nbsp;cores are spread across the nodes, looks like&nbsp;it messes scheduling up causing overload.</div></blockquote><div><br></div>I suggest you look at the SGE documentation - I don't think you are using it correctly</div><div><br></div><div><br><blockquote type="cite">
<div class="gmail_extra"><br><br><div class="gmail_quote">On Tue, Apr 30, 2013 at 3:46 PM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
<div style="word-wrap:break-word"><br><div><div class="im"><div>On Apr 30, 2013, at 1:34 PM, Vladimir Yamshchikov &lt;<a href="mailto:yaximik@gmail.com" target="_blank">yaximik@gmail.com</a>&gt; wrote:</div><br><blockquote type="cite">
<div dir="ltr"><div><font face="arial,helvetica,sans-serif"><font>I asked grid IT and they said they had to kill it as the job was overloading nodes. They saw loads up to 180 instead of close to 12 on 12-core nodes. They think that blastx is not an openmpi application, <font face="arial,helvetica,sans-serif">so o<span style="font-family:&quot;Times New Roman&quot;,serif">penMPI is spawning between
64-96 blastx processes, each of which is then starting up 96 worker threads. Or if blastx can work with openmpi, my blastx synthax mpirun syntax is wrong. Any advice?</span></font></font></font></div><p><span style="font-family:&quot;Times New Roman&quot;,serif"><span style="color:rgb(31,73,125);font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;"><font face="arial,helvetica,sans-serif">I was advised earlier to use –pe openmpi [ARG} , where &nbsp;ARG = number_of_processes
x number_of_threads , and then pass desired number of threads as ‘ mpirun –np
$NSLOTS cpus-per-proc [ number_of_threads]’. When I did that, I got an error
that more threads were requested than number of physical cores. </font></span></span></p><div><span style="font-family:&quot;Times New Roman&quot;,serif;font-size:12pt"></span></div></div></blockquote><div><br></div></div>
How many threads are you trying to launch?? If it is a 12-core node, then you can't have more than 12 - sounds like you are trying to startup 96!</div><div><div class="h5"><div><br><blockquote type="cite"><div dir="ltr">
<div><span style="font-family:&quot;Times New Roman&quot;,serif;font-size:12pt">&nbsp;</span></div>
<div><br>
<br>
</div></div><div class="gmail_extra"><br><br><div class="gmail_quote">On Tue, Apr 30, 2013 at 2:35 PM, Reuti <span dir="ltr">&lt;<a href="mailto:reuti@staff.uni-marburg.de" target="_blank">reuti@staff.uni-marburg.de</a>&gt;</span> wrote:<br>

<blockquote style="margin:0px 0px 0px 0.8ex;padding-left:1ex;border-left-color:rgb(204,204,204);border-left-width:1px;border-left-style:solid" class="gmail_quote">Hi,<br>
<br>
Am 30.04.2013 um 21:26 schrieb Vladimir Yamshchikov:<br>
<div><br>
&gt; My recent job started normally but after a few hours of running died with the following message:<br>
&gt;<br>
&gt; --------------------------------------------------------------------------<br>
&gt; A daemon (pid 19390) died unexpectedly with status 137 while attempting<br>
&gt; to launch so we are aborting.<br>
<br>
</div>I wonder why it rose the failure only after running for hours. As 137 = 128 + 9 it was killed, maybe by the queuing system due to the set time limit? If you check the accouting, what is the output of:<br>
<br>
$ qacct -j &lt;job_id&gt;<br>
<br>
-- Reuti<br>
<div><br>
<br>
&gt; There may be more information reported by the environment (see above).<br>
&gt;<br>
&gt; This may be because the daemon was unable to find all the needed shared<br>
&gt; libraries on the remote node. You may set your LD_LIBRARY_PATH to have the<br>
&gt; location of the shared libraries on the remote nodes and this will<br>
&gt; automatically be forwarded to the remote nodes.<br>
&gt; --------------------------------------------------------------------------<br>
&gt; --------------------------------------------------------------------------<br>
&gt; mpirun noticed that the job aborted, but has no info as to the process<br>
&gt; that caused that situation.<br>
&gt;<br>
&gt; The scheduling script is below:<br>
&gt;<br>
&gt; #$ -S /bin/bash<br>
&gt; #$ -cwd<br>
&gt; #$ -N SC3blastx_64-96thr<br>
&gt; #$ -pe openmpi* 64-96<br>
&gt; #$ -l h_rt=24:00:00,vf=3G<br>
&gt; #$ -j y<br>
&gt; #$ -M <a href="mailto:yaximik@gmail.com" target="_blank">yaximik@gmail.com</a><br>
&gt; #$ -m eas<br>
&gt; #<br>
&gt; # Load the appropriate module files<br>
&gt; # Should be loaded already<br>
&gt; #$ -V<br>
&gt;<br>
&gt; mpirun -np $NSLOTS blastx -query $UABGRID_SCRATCH/SC/AdQ30/fasta/SC1-IS4-Ind1-153ngFr1sep1run1R1AdQ30.fasta -db nr -out $UABGRID_SCRATCH/SC/blastx/SC/SC1-IS4-Ind1-153ngFr1sep1run1R1AdQ30.out -evalue 0.001 -max_intron_length 100000 -outfmt 5 -num_alignments 20 -lcase_masking -num_threads $NSLOTS<br>


&gt;<br>
&gt; What caused this termination? It does not seem scheduling problem as the program run several hours with 96 threads. My $LD_LIBRARY_PATH does have /share/apps/openmpi/1.6.4-gcc/lib entry, so how else should I modify it?<br>


&gt;<br>
&gt; Vladimir<br>
</div>&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</blockquote></div><br></div>
_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></blockquote>
</div><br></div></div></div><br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></div><br></div>
_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>http://www.open-mpi.org/mailman/listinfo.cgi/users</blockquote></div><br></body></html>
