<html>
  <head>
    <meta content="text/html; charset=windows-1252"
      http-equiv="Content-Type">
  </head>
  <body bgcolor="#FFFFFF" text="#000000">
    <p><font face="Helvetica, Arial, sans-serif">Hi </font>Sreenidhi,</p>
    <p>We use predominantly Mellanox HCAs (Connect x3) all connected to
      a giant Qlogic QDR switch. We have QDR/FDR Mellanox and Qlogic
      switches in the mix, but everything is managed by a single subnet
      manager. We have had problems with Mellanox and RHEL OFED stacks
      both in the past due to the heterogeneous mix of systems. <br>
    </p>
    <p>Good luck with your cluster and let me know if you have any other
      questions!</p>
    <p>-Mehmet<br>
    </p>
    <p> <br>
    </p>
    <br>
    <div class="moz-cite-prefix">On 6/15/16 5:30 AM, Sreenidhi
      Bharathkar Ramesh wrote:<br>
    </div>
    <blockquote
cite="mid:CANi1EtPR5FmJoOO+VwgVommkZOnSs_XWOV7BV1HJWd_3OSpsyA@mail.gmail.com"
      type="cite">
      <meta http-equiv="Content-Type" content="text/html;
        charset=windows-1252">
      <div dir="ltr">
        <div>hi Mehmet / Llolsten / Peter,</div>
        <div><br>
        </div>
        <div>Just curious to know what is the NIC or fabric you are
          using in your respective clusters.</div>
        <div><br>
        </div>
        <div>If it is Mellanox, is it not better to use the MLNX_OFED ?</div>
        <div><br>
        </div>
        <div>This information may help us build our cluster. Hence,
          asking.</div>
        <div><br>
        </div>
        <div>Thanks,</div>
        <div>- Sreenidhi.</div>
      </div>
      <div class="gmail_extra"><br>
        <div class="gmail_quote">On Wed, Jun 15, 2016 at 1:17 PM, Peter
          Kjellström <span dir="ltr">&lt;<a moz-do-not-send="true"
              href="mailto:cap@nsc.liu.se" target="_blank">cap@nsc.liu.se</a>&gt;</span>
          wrote:<br>
          <blockquote class="gmail_quote" style="margin:0 0 0
            .8ex;border-left:1px #ccc solid;padding-left:1ex"><span
              class="">On Tue, 14 Jun 2016 13:18:33 -0400<br>
              "Llolsten Kaonga" &lt;<a moz-do-not-send="true"
                href="mailto:llk@soft-forge.com">llk@soft-forge.com</a>&gt;
              wrote:<br>
              <br>
              &gt; Hello Grigory,<br>
              &gt;<br>
              &gt; I am not sure what Redhat does exactly but when you
              install the OS,<br>
              &gt; there is always an InfiniBand Support module during
              the installation<br>
              &gt; process. We never check/install that module when we
              do OS<br>
              &gt; installations because it is usually several versions
              of OFED behind<br>
              &gt; (almost obsolete).<br>
              <br>
            </span>It's not as bad as you assume. Also as I said before
            it's not an OFED<br>
            version at all.<br>
            <br>
            We (and many other medium+ HPC centers) run the redhat stack
            for<br>
            reason that it is 1) good enough 2) not an extra
            complication for the<br>
            system environment.<br>
            <br>
            /Peter K (with ~3000 hpc nodes on rhel-ib for many years)<br>
            <span class="">_______________________________________________<br>
              users mailing list<br>
              <a moz-do-not-send="true" href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
              Subscription: <a moz-do-not-send="true"
                href="https://www.open-mpi.org/mailman/listinfo.cgi/users"
                rel="noreferrer" target="_blank">https://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
            </span>Link to this post: <a moz-do-not-send="true"
              href="http://www.open-mpi.org/community/lists/users/2016/06/29449.php"
              rel="noreferrer" target="_blank">http://www.open-mpi.org/community/lists/users/2016/06/29449.php</a><br>
          </blockquote>
        </div>
        <br>
      </div>
      <br>
      <fieldset class="mimeAttachmentHeader"></fieldset>
      <br>
      <pre wrap="">_______________________________________________
users mailing list
<a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
Subscription: <a class="moz-txt-link-freetext" href="https://www.open-mpi.org/mailman/listinfo.cgi/users">https://www.open-mpi.org/mailman/listinfo.cgi/users</a>
Link to this post: <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/06/29450.php">http://www.open-mpi.org/community/lists/users/2016/06/29450.php</a></pre>
    </blockquote>
    <br>
    <pre class="moz-signature" cols="72">-- 
=========================================
Mehmet Belgin, Ph.D. (<a class="moz-txt-link-abbreviated" href="mailto:mehmet.belgin@oit.gatech.edu">mehmet.belgin@oit.gatech.edu</a>)
Scientific Computing Consultant | OIT - Academic and Research Technologies
Georgia Institute of Technology
258 4th Str NW, Rich Building, Room 326
Atlanta, GA  30332-0700
Office: (404) 385-0665</pre>
  </body>
</html>

