<div dir="ltr">Thank you all for your help. <span style="font-family:arial,sans-serif;font-size:13px">--bind-to-core increased the cluster performance by approximately 10%, so in addition to the improvements through the implementation of Open-MX, the performance now scales within expectations - not linear, but much better than with the original setup.</span></div>
<div class="gmail_extra"><br><br><div class="gmail_quote">On 30 January 2014 20:43, Tim Prince <span dir="ltr">&lt;<a href="mailto:n8tm@aol.com" target="_blank">n8tm@aol.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">

  
    
  
  <div bgcolor="#FFFFFF" text="#000000"><div class="im">
    <br>
    <div>On 1/29/2014 11:30 PM, Ralph Castain
      wrote:<br>
    </div>
    <blockquote type="cite">
      
      <br>
      <div>
        <div>On Jan 29, 2014, at 7:56 PM, Victor &lt;<a href="mailto:victor.major@gmail.com" target="_blank">victor.major@gmail.com</a>&gt;
          wrote:</div>
        <br>
        <blockquote type="cite">
          <div dir="ltr">Thanks for the insights Tim. I was aware that
            the CPUs will choke beyond a certain point. From memory on
            my machine this happens with 5 concurrent MPI jobs with that
            benchmark that I am using.
            <div><br>
            </div>
            <div>My primary question was about scaling between the
              nodes. I was not getting close to double the performance
              when running MPI jobs acros two 4 core nodes. It may be
              better now since I have Open-MX in place, but I have not
              repeated the benchmarks yet since I need to get one
              simulation job done asap.</div>
          </div>
        </blockquote>
        <div><br>
        </div>
        Some of that may be due to expected loss of performance when you
        switch from shared memory to inter-node transports. While it is
        true about saturation of the memory path, what you reported
        could be more consistent with that transition - i.e., it isn&#39;t
        unusual to see applications perform better when run on a single
        node, depending upon how they are written, up to a certain size
        of problem (which your code may not be hitting).</div>
      <div><br>
        <blockquote type="cite">
          <div dir="ltr">
            <div><br>
            </div>
            <div>Regarding your mention of setting affinities and MPI
              ranks do you have a specific (as in syntactically specific
              since I am a novice and easily confused...) examples how I
              may want to set affinities to get the Westmere node
              performing better?</div>
          </div>
        </blockquote>
        <div><br>
        </div>
        mpirun --bind-to-core -cpus-per-rank 2 ...</div>
      <div><br>
      </div>
      <div>will bind each MPI rank to 2 cores. Note that this will
        definitely *not* be a good idea if you are running more than two
        threads in your process - if you are, then set --cpus-per-rank
        to the number of threads, keeping in mind that you want things
        to break evenly across the sockets. In other words, if you have
        two 6 core/socket Westmere&#39;s on the node, then you either want
        to run 6 process at cpus-per-rank=2 if each process runs 2
        threads, or 4 processes with cpus-per-rank=3 if each process
        runs 3 threads, or 2 processes with no cpus-per-rank but
        --bind-to-socket instead of --bind-to-core for any other thread
        number &gt; 3.</div>
      <div><br>
      </div>
      <div>You would not want to run any other number of processes on
        the node or else the binding pattern will cause a single process
        to split its threads across the sockets - which will definitely
        hurt performance.</div>
      <div><br>
      </div>
      <div><br>
      </div>
    </blockquote></div>
    -cpus-per-rank 2 is an effective choice for this platform.  As Ralph
    said, it should work automatically for 2 threads per rank.<br>
    Ralph&#39;s point about not splitting a process across sockets is an
    important one.  Even splitting a process across internal busses,
    which would happen with 3 threads per process, seems problematical.<span class="HOEnZb"><font color="#888888"><br>
    <pre cols="72">-- 
Tim Prince</pre>
  </font></span></div>

<br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></div><br></div>

