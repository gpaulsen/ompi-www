<font size=2 face="sans-serif">Hello,</font>
<br>
<br><font size=2 face="sans-serif">I've been using openmpi (version 1.3.2)
for some time, but recently have had greater than 1000 cores available.</font>
<br><font size=2 face="sans-serif">My code runs fine with 1000 cores but
fails when attempting to use 1200 cores.</font>
<br>
<br><font size=2 face="sans-serif">The only information at the time of
the crash is: &nbsp;&lt;program exited with code 021&gt;.</font>
<br>
<br><font size=2 face="sans-serif">Within the debugger I know the crash
is occurring on an MPI_Send call.</font>
<br><font size=2 face="sans-serif">After inserting printf diagnostics I
know the following... </font>
<br>
<br><font size=2 face="sans-serif">I have a master/slave application with
a 'synchronization' step occurring during initialization.</font>
<br><font size=2 face="sans-serif">The master is using MPI_Send to send
a single integer to all of the slaves.</font>
<br><font size=2 face="sans-serif">I see most of the slave's printing a
diagnostic and then sitting on the MPI_Recv.</font>
<br>
<br><font size=2 face="sans-serif">Then I see the master (finally getting
to the 'home-grown broadcast') and starting to issue MPI_Send to each slave.</font>
<br><font size=2 face="sans-serif">After (in this case) 1019 sends the
crash occurs.</font>
<br>
<br><font size=2 face="sans-serif">I'm looking for information on the cause,
I'm guessing some kind of a message-passing buffer is being overrun, </font>
<br><font size=2 face="sans-serif">and hints on how to avoid these types
of bottlenecks when running on clusters with multiple of thousand</font>
<br><font size=2 face="sans-serif">of cores.</font>
<br>
<br><font size=2 face="sans-serif">thanks !!</font>
<br><font size=2 face="sans-serif">Tim Thompson</font>
<br>
