it is a good question I asked it myself at the first but then I said it should be correct but anyway I want to confirm that:<div>her is the code snippet of the program:</div><div>...</div><div><div>int ranks[size];</div><div>
    for(i=0; i &lt; size; ++i)</div><div>    {</div><div><span class="Apple-tab-span" style="white-space:pre">	</span>ranks[i] = i;</div><div>    }</div></div><div>...</div><div><br></div><div><div>for(p=8; p &lt;= (size); p+=4)</div>
<div><span class="Apple-tab-span" style="white-space:pre">	</span>    {</div><div><span class="Apple-tab-span" style="white-space:pre">	</span>      MPI_Barrier(MPI_COMM_WORLD);</div><div><span class="Apple-tab-span" style="white-space:pre">	</span>      if(!grid_init(p, 1)) continue;</div>
<div><span class="Apple-tab-span" style="white-space:pre">	</span>      if( (p&gt;=m) || (p&gt;=k) || (p&gt;=n) )</div><div><span class="Apple-tab-span" style="white-space:pre">		</span>break;</div><div><span class="Apple-tab-span" style="white-space:pre">	</span>      </div>
<div><span class="Apple-tab-span" style="white-space:pre">	</span>      MPI_Group_incl(world_group, p, ranks, &amp;working_group);</div><div><span class="Apple-tab-span" style="white-space:pre">	</span>      MPI_Comm_create(MPI_COMM_WORLD, working_group, &amp;working_comm);</div>
<div><br></div><div><span class="Apple-tab-span" style="white-space:pre">	</span>      if(working_comm != MPI_COMM_NULL)</div><div><span class="Apple-tab-span" style="white-space:pre">	</span>      {</div><div>...</div><div>
variant_run(&amp;variant5, C, m, k, n, my_rank, p, working_comm); </div><div>...</div><div><span class="Apple-tab-span" style="white-space:pre">		</span>MPI_Group_free(&amp;working_group);</div><div><span class="Apple-tab-span" style="white-space:pre">		</span>MPI_Comm_free(&amp;working_comm);</div>
<div>}</div><div><br></div><div>Inside variant_run, it calls this function where the error is:</div><div><div>void Compute_SUMMA1(Matrix* A, Matrix* B, Matrix *C, size_t M, size_t K, size_t N, size_t my_rank, size_t size, MPI_Comm comm)</div>
<div>{</div><div>    C-&gt;block_matrix = gsl_matrix_calloc(A-&gt;block_matrix-&gt;size1, B-&gt;block_matrix-&gt;size2);</div><div>    C-&gt;distribution_type = TwoD_Block;</div><div>    </div><div>    MPI_Comm grid_comm;</div>
<div>    int dim[2], period[2], reorder = 0, ndims = 2;</div><div>    int coord[2], id;</div><div>    </div><div>    dim[0] = global.PR; dim[1] = global.PC;</div><div>    period[0] = 0; period[1] = 0;</div><div>    </div>
<div>    int ss, rr;</div><div>    MPI_Group comm_group;</div><div>    MPI_Comm_group(comm, &amp;comm_group );</div><div>    MPI_Group_size( comm_group, &amp;ss);</div><div>    MPI_Group_rank( comm_group, &amp;rr);</div><div>
    if(ss == 6)</div><div>    {</div><div><span class="Apple-tab-span" style="white-space:pre">	</span>//printf(&quot;M %d K %d N %d </div><div><span class="Apple-tab-span" style="white-space:pre">	</span>//printf(&quot;my_rank in comm %d   my_rank in world_comm %d\n&quot;, rr, my_rank);</div>
<div><span class="Apple-tab-span" style="white-space:pre">	</span>//printf(&quot; comm size %d  my_rank in comm %d   my_rank in world_comm %d\n&quot;, ss, rr, my_rank);</div><div><span class="Apple-tab-span" style="white-space:pre">	</span>//printf(&quot;SUMMA ... PR %d  PC %d\n&quot;, global.PR, global.PC);</div>
<div>    }</div><div>    //MPI_Barrier(comm);</div><div>//     if(my_rank == 0)</div><div>//     printf(&quot;my_rank %d  ndims %d  dim[0] %d  dim[1] %d  period[0] %d  period[1] %d  reorder %d\n&quot;, </div><div>// <span class="Apple-tab-span" style="white-space:pre">	</span>   my_rank, ndims, dim[0], dim[1], period[0], period[1], reorder);</div>
<div>//     if(comm == MPI_COMM_NULL)</div><div>//       printf(&quot;my_rank %d  comm is empty\n&quot;, my_rank);</div><div>//     </div><div>    MPI_Cart_create(comm, ndims, dim, period, reorder, &amp;grid_comm);</div><div>
    </div><div>    MPI_Comm Acomm, Bcomm;</div><div>    </div><div>    // create column subgrids </div><div>    int remain[2]; //, mdims, dims[2], row_coords[2];</div><div>    remain[0] = 1;</div><div>    remain[1] = 0;</div>
<div>    MPI_Cart_sub(grid_comm, remain, &amp;Bcomm);</div><div>    </div><div>    remain[0] = 0;</div><div>    remain[1] = 1;</div><div>    MPI_Cart_sub(grid_comm, remain, &amp;Acomm);</div></div><div>...</div><div>}</div>
<div class="gmail_quote"><br></div><div class="gmail_quote"><br></div><div class="gmail_quote">As you can see, all ranks will call grid_init which is a global func that returns the grid dims, if it is executed for ranks 24 will produce 4X6 and for 96 produce 8X12 and will store the result in global structure with PR and PC. As it is executed by all prcesses and I checked for rank 0 and some other processes and the result is correct so I assume it should be correct for all other processes.</div>
<div class="gmail_quote"><br></div><div class="gmail_quote">So the grid_comm is correct which is an input to MPI_Cart_sub. The ranks in the working_comm and in MPI_COMM_WORLD should be the same and this should be correct and it is according to filling the rank array at the beginning of this code snippet.</div>
<div class="gmail_quote"><br></div><div class="gmail_quote"><br></div><div class="gmail_quote"><br></div><div class="gmail_quote">On Tue, Jan 10, 2012 at 5:25 PM, Jeff Squyres <span dir="ltr">&lt;<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">This may be a dumb question, but are you 100% sure that the input values are correct?<br>
<div class="HOEnZb"><div class="h5"><br>
On Jan 10, 2012, at 8:16 AM, Anas Al-Trad wrote:<br>
<br>
&gt;  Hi Ralph, I changed the intel icc module from 12.1.0 to 11.1.069, the previous default one used at a Neolith Cluster. I submitted the job and I still waiting for the result. Here is the message of the segmentation fault:<br>

&gt;<br>
&gt; [n764:29867] *** Process received signal ***<br>
&gt; [n764:29867] Signal: Floating point exception (8)<br>
&gt; [n764:29867] Signal code: Integer divide-by-zero (1)<br>
&gt; [n764:29867] Failing at address: 0x2ba640e74627<br>
&gt; [n764:29867] [ 0] /lib64/libc.so.6 [0x2ba641e162d0]<br>
&gt; [n764:29867] [ 1] /software/mpi/openmpi/1.4.1/i101011/lib/libmpi.so.0(mca_topo_base_cart_coords+0x43) [0x2ba640e74627]<br>
&gt; [n764:29867] [ 2] /software/mpi/openmpi/1.4.1/i101011/lib/libmpi.so.0(mca_topo_base_cart_sub+0x1d5) [0x2ba640e74acd]<br>
&gt; [n764:29867] [ 3] /software/mpi/openmpi/1.4.1/i101011/lib/libmpi.so.0(MPI_Cart_sub+0x35) [0x2ba640e472d9]<br>
&gt; [n764:29867] [ 4] /home/x_anaal/thesis/cimple/tst_chng_p/v5/r2/output.o(Compute_SUMMA1+0x226) [0x4088da]<br>
&gt; [n764:29867] [ 5] /home/x_anaal/thesis/cimple/tst_chng_p/v5/r2/output.o(variant_run+0xb2) [0x409058]<br>
&gt; [n764:29867] [ 6] /home/x_anaal/thesis/cimple/tst_chng_p/v5/r2/output.o(main+0xf90) [0x40eeba]<br>
&gt; [n764:29867] [ 7] /lib64/libc.so.6(__libc_start_main+0xf4) [0x2ba641e03994]<br>
&gt; [n764:29867] [ 8] /home/x_anaal/thesis/cimple/tst_chng_p/v5/r2/output.o [0x403fd9]<br>
&gt; [n764:29867] *** End of error message ***<br>
&gt;<br>
&gt; when I run my application, sometimes I get this error and sometimes it is stuck in the middle.<br>
&gt;<br>
</div></div><div class="im HOEnZb">&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
<br>
</div><span class="HOEnZb"><font color="#888888">--<br>
Jeff Squyres<br>
<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a><br>
For corporate legal information go to:<br>
<a href="http://www.cisco.com/web/about/doing_business/legal/cri/" target="_blank">http://www.cisco.com/web/about/doing_business/legal/cri/</a><br>
</font></span><div class="HOEnZb"><div class="h5"><br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</div></div></blockquote></div><br></div>

