<div><font size=2 color=navy face=Arial>
I don't know much about specmpi, but it seems like it is choosing to abort. Maybe the &quot;no room for lattice&quot; has some meaning...?<br><br>-jms<br>Sent from my PDA.  No type good.</font></div>
<br><div><hr size=2 width="100%" align=center tabindex=-1>
<font face=Tahoma size=2>
<b>From</b>: users-bounces@open-mpi.org &lt;users-bounces@open-mpi.org&gt;<br><b>To</b>: users@open-mpi.org &lt;users@open-mpi.org&gt;<br><b>Sent</b>: Wed Apr 28 01:47:01 2010<br><b>Subject</b>: [OMPI users] MPI_ABORT was invoked on rank 0 in communicatorMPI_COMM_WORLD with errorcode 0.<br></font><br></div>
Hi,<br>I am trying to run SPEC MPI 2007 workload on a quad-core machine. However getting this error message. I also tried to use hostfile option by specifying localhost slots=4, but still getting the following error. Please help me.<br>
<br>$mpirun  --mca btl tcp,sm,self -np 4 su3imp_base.solaris <br>SU3 with improved KS action<br>Microcanonical simulation with refreshing<br>MIMD version 6<br>Machine = <br>R algorithm<br>type 0 for no prompts  or 1 for prompts<br>
nflavors 2<br>nx 30<br>ny 30<br>nz 56<br>nt 84<br>iseed 1234<br>LAYOUT = Hypercubes, options = EVENFIRST,<br>NODE 0: no room for lattice<br>termination: Tue Apr 27 23:41:44 2010<br><br>Termination: node 0, status = 1<br>--------------------------------------------------------------------------<br>
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD <br>with errorcode 0.<br><br>NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.<br>You may or may not see output from other processes, depending on<br>
exactly when Open MPI kills them.<br>--------------------------------------------------------------------------<br>--------------------------------------------------------------------------<br>mpirun has exited due to process rank 0 with PID 17239 on<br>
node cache-aware exiting without calling &quot;finalize&quot;. This may<br>have caused other processes in the application to be<br>terminated by signals sent by mpirun (as reported here).<br><br><br clear="all">Best,<br>Kishore Kumar Pusukuri<br>
<a href="http://www.cs.ucr.edu/~kishore">http://www.cs.ucr.edu/~kishore</a><br><br>
