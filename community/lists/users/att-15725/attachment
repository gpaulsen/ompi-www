I would talk to the slurm folks about it - I don&#39;t know anything about the internals of HP-MPI, but I do know the relevant OMPI internals. OMPI doesn&#39;t do anything with respect to the envars. We just use &quot;srun -hostlist &lt;fff&gt;&quot; to launch the daemons. Each daemon subsequently gets a message telling it what local procs to run, and then fork/exec&#39;s those procs. The environment set for those procs is a copy of that given to the daemon, including any and all slurm values.<div>
<br></div><div>So whatever slurm sets, your procs get.</div><div><br></div><div>My guess is that HP-MPI is doing something with the envars to create the difference.</div><div><br></div><div>As for running OMPI procs directly from srun: the slurm folks put out a faq (or its equivalent) on it, I believe. I don&#39;t recall the details (even though I wrote the integration...). If you google our user and/or devel mailing lists, though, you&#39;ll see threads discussing it. Look for &quot;slurmd&quot; in the text - that&#39;s the ORTE integration module for that feature.</div>
<div><br></div><div><br><br><div class="gmail_quote">On Thu, Feb 24, 2011 at 8:55 AM, Henderson, Brent <span dir="ltr">&lt;<a href="mailto:brent.henderson@hp.com">brent.henderson@hp.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;">
I&#39;m running OpenMPI v1.4.3 and slurm v2.2.1.  I built both with the default configuration except setting the prefix.  The tests were run on the exact same nodes (I only have two).<br>
<br>
When I run the test you outline below, I am still missing a bunch of env variables with OpenMPI.  I ran the extra test of using HP-MPI and they are all present as with the srun invocation.  I don&#39;t know if this is my slurm setup or not, but I find this really weird.  If anyone knows the magic to make the fix that Ralph is referring to, I&#39;d appreciate a pointer.<br>

<br>
My guess was that there is a subtle way that the launch differs between the two products.  But, since it works for Jeff, maybe there really is a slurm option that I need to compile in or set to make this work the way I want.  It is not as simple as HP-MPI moving the environment variables itself as some of the numbers will change per process created on the remote nodes.<br>

<br>
Thanks,<br>
<br>
Brent<br>
<div class="im"><br>
[brent@node2 mpi]$ salloc -N 2<br>
</div>salloc: Granted job allocation 29<br>
[brent@node2 mpi]$ srun env | egrep ^SLURM_ | head<br>
SLURM_NODELIST=node[1-2]<br>
SLURM_NNODES=2<br>
SLURM_JOBID=29<br>
SLURM_TASKS_PER_NODE=1(x2)<br>
SLURM_JOB_ID=29<br>
<div class="im">SLURM_NODELIST=node[1-2]<br>
</div>SLURM_NNODES=2<br>
SLURM_JOBID=29<br>
SLURM_TASKS_PER_NODE=1(x2)<br>
SLURM_JOB_ID=29<br>
[brent@node2 mpi]$ srun env | egrep ^SLURM_ | wc -l<br>
66<br>
[brent@node2 mpi]$ srun env | egrep ^SLURM_ | sort &gt; srun.out<br>
[brent@node2 mpi]$ which mpirun<br>
~/bin/openmpi143/bin/mpirun<br>
[brent@node2 mpi]$ mpirun -np 2 --bynode env | egrep ^SLURM_ | head<br>
SLURM_NODELIST=node[1-2]<br>
SLURM_NNODES=2<br>
SLURM_JOBID=29<br>
SLURM_TASKS_PER_NODE=8(x2)<br>
SLURM_JOB_ID=29<br>
SLURM_SUBMIT_DIR=/mnt/node1/home/brent/src/mpi<br>
<div class="im">SLURM_JOB_NODELIST=node[1-2]<br>
</div>SLURM_JOB_CPUS_PER_NODE=8(x2)<br>
SLURM_JOB_NUM_NODES=2<br>
<div class="im">SLURM_NODELIST=node[1-2]<br>
</div>[brent@node2 mpi]$ which mpirun<br>
~/bin/openmpi143/bin/mpirun<br>
[brent@node2 mpi]$ mpirun -np 2 --bynode env | egrep ^SLURM_ | wc -l<br>
42  &lt;-- note, not 66 as above!<br>
[brent@node2 mpi]$ mpirun -np 2 --bynode env | egrep ^SLURM_ | sort &gt; mpirun.out<br>
[brent@node2 mpi]$ diff srun.out mpirun.out<br>
2d1<br>
&lt; SLURM_CHECKPOINT_IMAGE_DIR=/mnt/node1/home/brent/src/mpi<br>
4,5d2<br>
&lt; SLURM_CPUS_ON_NODE=8<br>
&lt; SLURM_CPUS_PER_TASK=1<br>
8d4<br>
&lt; SLURM_DISTRIBUTION=cyclic<br>
10d5<br>
&lt; SLURM_GTIDS=1<br>
22,23d16<br>
&lt; SLURM_LAUNCH_NODE_IPADDR=10.0.205.134<br>
&lt; SLURM_LOCALID=0<br>
25c18<br>
&lt; SLURM_NNODES=2<br>
---<br>
&gt; SLURM_NNODES=1<br>
28d20<br>
&lt; SLURM_NODEID=1<br>
31,35c23,24<br>
&lt; SLURM_NPROCS=2<br>
&lt; SLURM_NPROCS=2<br>
&lt; SLURM_NTASKS=2<br>
&lt; SLURM_NTASKS=2<br>
&lt; SLURM_PRIO_PROCESS=0<br>
---<br>
&gt; SLURM_NPROCS=1<br>
&gt; SLURM_NTASKS=1<br>
38d26<br>
&lt; SLURM_PROCID=1<br>
40,56c28,35<br>
&lt; SLURM_SRUN_COMM_HOST=10.0.205.134<br>
&lt; SLURM_SRUN_COMM_PORT=43247<br>
&lt; SLURM_SRUN_COMM_PORT=43247<br>
&lt; SLURM_STEP_ID=2<br>
&lt; SLURM_STEP_ID=2<br>
&lt; SLURM_STEPID=2<br>
&lt; SLURM_STEPID=2<br>
&lt; SLURM_STEP_LAUNCHER_PORT=43247<br>
&lt; SLURM_STEP_LAUNCHER_PORT=43247<br>
<div class="im">&lt; SLURM_STEP_NODELIST=node[1-2]<br>
&lt; SLURM_STEP_NODELIST=node[1-2]<br>
</div>&lt; SLURM_STEP_NUM_NODES=2<br>
&lt; SLURM_STEP_NUM_NODES=2<br>
&lt; SLURM_STEP_NUM_TASKS=2<br>
&lt; SLURM_STEP_NUM_TASKS=2<br>
&lt; SLURM_STEP_TASKS_PER_NODE=1(x2)<br>
&lt; SLURM_STEP_TASKS_PER_NODE=1(x2)<br>
---<br>
<div class="im">&gt; SLURM_SRUN_COMM_PORT=45154<br>
</div>&gt; SLURM_STEP_ID=5<br>
&gt; SLURM_STEPID=5<br>
<div class="im">&gt; SLURM_STEP_LAUNCHER_PORT=45154<br>
</div>&gt; SLURM_STEP_NODELIST=node1<br>
&gt; SLURM_STEP_NUM_NODES=1<br>
&gt; SLURM_STEP_NUM_TASKS=1<br>
<div class="im">&gt; SLURM_STEP_TASKS_PER_NODE=1<br>
</div>59,62c38,40<br>
&lt; SLURM_TASK_PID=1381<br>
&lt; SLURM_TASK_PID=2288<br>
&lt; SLURM_TASKS_PER_NODE=1(x2)<br>
&lt; SLURM_TASKS_PER_NODE=1(x2)<br>
---<br>
&gt; SLURM_TASK_PID=1429<br>
<div class="im">&gt; SLURM_TASKS_PER_NODE=1<br>
</div>&gt; SLURM_TASKS_PER_NODE=8(x2)<br>
64,65d41<br>
&lt; SLURM_TOPOLOGY_ADDR=node2<br>
&lt; SLURM_TOPOLOGY_ADDR_PATTERN=node<br>
<div class="im">[brent@node2 mpi]$<br>
[brent@node2 mpi]$<br>
[brent@node2 mpi]$<br>
[brent@node2 mpi]$<br>
</div>[brent@node2 mpi]$ /opt/hpmpi/bin/mpirun -srun -n 2 -N 2 env | egrep ^SLURM_ | sort &gt; hpmpi.out<br>
[brent@node2 mpi]$ diff srun.out hpmpi.out<br>
20a21,22<br>
&gt; SLURM_KILL_BAD_EXIT=1<br>
&gt; SLURM_KILL_BAD_EXIT=1<br>
41,48c43,50<br>
&lt; SLURM_SRUN_COMM_PORT=43247<br>
&lt; SLURM_SRUN_COMM_PORT=43247<br>
&lt; SLURM_STEP_ID=2<br>
&lt; SLURM_STEP_ID=2<br>
&lt; SLURM_STEPID=2<br>
&lt; SLURM_STEPID=2<br>
&lt; SLURM_STEP_LAUNCHER_PORT=43247<br>
&lt; SLURM_STEP_LAUNCHER_PORT=43247<br>
---<br>
&gt; SLURM_SRUN_COMM_PORT=33347<br>
&gt; SLURM_SRUN_COMM_PORT=33347<br>
&gt; SLURM_STEP_ID=8<br>
&gt; SLURM_STEP_ID=8<br>
&gt; SLURM_STEPID=8<br>
&gt; SLURM_STEPID=8<br>
&gt; SLURM_STEP_LAUNCHER_PORT=33347<br>
&gt; SLURM_STEP_LAUNCHER_PORT=33347<br>
59,60c61,62<br>
&lt; SLURM_TASK_PID=1381<br>
&lt; SLURM_TASK_PID=2288<br>
---<br>
&gt; SLURM_TASK_PID=1592<br>
&gt; SLURM_TASK_PID=2590<br>
<div class="im">[brent@node2 mpi]$<br>
[brent@node2 mpi]$<br>
</div>[brent@node2 mpi]$ grep SLURM_PROCID srun.out<br>
<div class="im">SLURM_PROCID=0<br>
SLURM_PROCID=1<br>
</div>[brent@node2 mpi]$ grep SLURM_PROCID mpirun.out<br>
SLURM_PROCID=0<br>
[brent@node2 mpi]$ grep SLURM_PROCID hpmpi.out<br>
<div class="im">SLURM_PROCID=0<br>
SLURM_PROCID=1<br>
</div>[brent@node2 mpi]$<br>
<div class="im"><br>
<br>
&gt; -----Original Message-----<br>
&gt; From: <a href="mailto:users-bounces@open-mpi.org">users-bounces@open-mpi.org</a> [mailto:<a href="mailto:users-bounces@open-mpi.org">users-bounces@open-mpi.org</a>] On<br>
</div><div><div></div><div class="h5">&gt; Behalf Of Jeff Squyres<br>
&gt; Sent: Thursday, February 24, 2011 9:31 AM<br>
&gt; To: Open MPI Users<br>
&gt; Subject: Re: [OMPI users] SLURM environment variables at runtime<br>
&gt;<br>
&gt; The weird thing is that when running his test, he saw different results<br>
&gt; with HP MPI vs. Open MPI.<br>
&gt;<br>
&gt; What his test didn&#39;t say was whether those were the same exact nodes or<br>
&gt; not.  It would be good to repeat my experiment with the same exact<br>
&gt; nodes (e.g., inside one SLURM salloc job, or use the -w param to<br>
&gt; specify the same nodes for salloc for OMPI and srun for HP MPI).<br>
&gt;<br>
&gt;<br>
&gt; On Feb 24, 2011, at 10:02 AM, Ralph Castain wrote:<br>
&gt;<br>
&gt; &gt; Like I said, this isn&#39;t an OMPI problem. You have your slurm<br>
&gt; configured to pass certain envars to the remote nodes, and Brent<br>
&gt; doesn&#39;t. It truly is just that simple.<br>
&gt; &gt;<br>
&gt; &gt; I&#39;ve seen this before with other slurm installations. Which envars<br>
&gt; get set on the backend is configurable, that&#39;s all.<br>
&gt; &gt;<br>
&gt; &gt; Has nothing to do with OMPI.<br>
&gt; &gt;<br>
&gt; &gt;<br>
&gt; &gt; On Thu, Feb 24, 2011 at 7:18 AM, Jeff Squyres &lt;<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a>&gt;<br>
&gt; wrote:<br>
&gt; &gt; I&#39;m afraid I don&#39;t see the problem.  Let&#39;s get 4 nodes from slurm:<br>
&gt; &gt;<br>
&gt; &gt; $ salloc -N 4<br>
&gt; &gt;<br>
&gt; &gt; Now let&#39;s run env and see what SLURM_ env variables we see:<br>
&gt; &gt;<br>
&gt; &gt; $ srun env | egrep ^SLURM_ | head<br>
&gt; &gt; SLURM_JOB_ID=95523<br>
&gt; &gt; SLURM_JOB_NUM_NODES=4<br>
&gt; &gt; SLURM_JOB_NODELIST=svbu-mpi[001-004]<br>
&gt; &gt; SLURM_JOB_CPUS_PER_NODE=4(x4)<br>
&gt; &gt; SLURM_JOBID=95523<br>
&gt; &gt; SLURM_NNODES=4<br>
&gt; &gt; SLURM_NODELIST=svbu-mpi[001-004]<br>
&gt; &gt; SLURM_TASKS_PER_NODE=1(x4)<br>
&gt; &gt; SLURM_PRIO_PROCESS=0<br>
&gt; &gt; SLURM_UMASK=0002<br>
&gt; &gt; $ srun env | egrep ^SLURM_ | wc -l<br>
&gt; &gt; 144<br>
&gt; &gt;<br>
&gt; &gt; Good -- there&#39;s 144 of them.  Let&#39;s save them to a file for<br>
&gt; comparison, later.<br>
&gt; &gt;<br>
&gt; &gt; $ srun env | egrep ^SLURM_ | sort &gt; srun.out<br>
&gt; &gt;<br>
&gt; &gt; Now let&#39;s repeat the process with mpirun.  Note that mpirun defaults<br>
&gt; to running one process per core (vs. srun&#39;s default of running one per<br>
&gt; node).  So let&#39;s tone mpirun down to use one process per node and look<br>
&gt; for the SLURM_ env variables.<br>
&gt; &gt;<br>
&gt; &gt; $ mpirun -np 4 --bynode env | egrep ^SLURM_ | head<br>
&gt; &gt; SLURM_JOB_ID=95523<br>
&gt; &gt; SLURM_JOB_NUM_NODES=4<br>
&gt; &gt; SLURM_JOB_NODELIST=svbu-mpi[001-004]<br>
&gt; &gt; SLURM_JOB_ID=95523<br>
&gt; &gt; SLURM_JOB_NUM_NODES=4<br>
&gt; &gt; SLURM_JOB_CPUS_PER_NODE=4(x4)<br>
&gt; &gt; SLURM_JOBID=95523<br>
&gt; &gt; SLURM_NNODES=4<br>
&gt; &gt; SLURM_NODELIST=svbu-mpi[001-004]<br>
&gt; &gt; SLURM_TASKS_PER_NODE=1(x4)<br>
&gt; &gt; $ mpirun -np 4 --bynode env | egrep ^SLURM_ | wc -l<br>
&gt; &gt; 144<br>
&gt; &gt;<br>
&gt; &gt; Good -- we also got 144.  Save them to a file.<br>
&gt; &gt;<br>
&gt; &gt; $ mpirun -np 4 --bynode env | egrep ^SLURM_ | sort &gt; mpirun.out<br>
&gt; &gt;<br>
&gt; &gt; Now let&#39;s compare what we got from srun and from mpirun:<br>
&gt; &gt;<br>
&gt; &gt; $ diff srun.out mpirun.out<br>
&gt; &gt; 93,108c93,108<br>
&gt; &gt; &lt; SLURM_SRUN_COMM_PORT=33571<br>
&gt; &gt; &lt; SLURM_SRUN_COMM_PORT=33571<br>
&gt; &gt; &lt; SLURM_SRUN_COMM_PORT=33571<br>
&gt; &gt; &lt; SLURM_SRUN_COMM_PORT=33571<br>
&gt; &gt; &lt; SLURM_STEP_ID=15<br>
&gt; &gt; &lt; SLURM_STEP_ID=15<br>
&gt; &gt; &lt; SLURM_STEP_ID=15<br>
&gt; &gt; &lt; SLURM_STEP_ID=15<br>
&gt; &gt; &lt; SLURM_STEPID=15<br>
&gt; &gt; &lt; SLURM_STEPID=15<br>
&gt; &gt; &lt; SLURM_STEPID=15<br>
&gt; &gt; &lt; SLURM_STEPID=15<br>
&gt; &gt; &lt; SLURM_STEP_LAUNCHER_PORT=33571<br>
&gt; &gt; &lt; SLURM_STEP_LAUNCHER_PORT=33571<br>
&gt; &gt; &lt; SLURM_STEP_LAUNCHER_PORT=33571<br>
&gt; &gt; &lt; SLURM_STEP_LAUNCHER_PORT=33571<br>
&gt; &gt; ---<br>
&gt; &gt; &gt; SLURM_SRUN_COMM_PORT=54184<br>
&gt; &gt; &gt; SLURM_SRUN_COMM_PORT=54184<br>
&gt; &gt; &gt; SLURM_SRUN_COMM_PORT=54184<br>
&gt; &gt; &gt; SLURM_SRUN_COMM_PORT=54184<br>
&gt; &gt; &gt; SLURM_STEP_ID=18<br>
&gt; &gt; &gt; SLURM_STEP_ID=18<br>
&gt; &gt; &gt; SLURM_STEP_ID=18<br>
&gt; &gt; &gt; SLURM_STEP_ID=18<br>
&gt; &gt; &gt; SLURM_STEPID=18<br>
&gt; &gt; &gt; SLURM_STEPID=18<br>
&gt; &gt; &gt; SLURM_STEPID=18<br>
&gt; &gt; &gt; SLURM_STEPID=18<br>
&gt; &gt; &gt; SLURM_STEP_LAUNCHER_PORT=54184<br>
&gt; &gt; &gt; SLURM_STEP_LAUNCHER_PORT=54184<br>
&gt; &gt; &gt; SLURM_STEP_LAUNCHER_PORT=54184<br>
&gt; &gt; &gt; SLURM_STEP_LAUNCHER_PORT=54184<br>
&gt; &gt; 125,128c125,128<br>
&gt; &gt; &lt; SLURM_TASK_PID=3899<br>
&gt; &gt; &lt; SLURM_TASK_PID=3907<br>
&gt; &gt; &lt; SLURM_TASK_PID=3908<br>
&gt; &gt; &lt; SLURM_TASK_PID=3997<br>
&gt; &gt; ---<br>
&gt; &gt; &gt; SLURM_TASK_PID=3924<br>
&gt; &gt; &gt; SLURM_TASK_PID=3933<br>
&gt; &gt; &gt; SLURM_TASK_PID=3934<br>
&gt; &gt; &gt; SLURM_TASK_PID=4039<br>
&gt; &gt; $<br>
&gt; &gt;<br>
&gt; &gt; They&#39;re identical except for per-step values (ports, PIDs, etc.) --<br>
&gt; these differences are expected.<br>
&gt; &gt;<br>
&gt; &gt; What version of OMPI are you running?  What happens if you repeat<br>
&gt; this experiment?<br>
&gt; &gt;<br>
&gt; &gt; I would find it very strange if Open MPI&#39;s mpirun is filtering some<br>
&gt; SLURM env variables to some processes and not to all -- your output<br>
&gt; shows disparate output between the different processes.  That&#39;s just<br>
&gt; plain weird.<br>
&gt; &gt;<br>
&gt; &gt;<br>
&gt; &gt;<br>
&gt; &gt; On Feb 23, 2011, at 12:05 PM, Henderson, Brent wrote:<br>
&gt; &gt;<br>
&gt; &gt; &gt; SLURM seems to be doing this in the case of a regular srun:<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; [brent@node1 mpi]$ srun -N 2 -n 4 env | egrep<br>
&gt; SLURM_NODEID\|SLURM_PROCID\|SLURM_LOCALID | sort<br>
&gt; &gt; &gt; SLURM_LOCALID=0<br>
&gt; &gt; &gt; SLURM_LOCALID=0<br>
&gt; &gt; &gt; SLURM_LOCALID=1<br>
&gt; &gt; &gt; SLURM_LOCALID=1<br>
&gt; &gt; &gt; SLURM_NODEID=0<br>
&gt; &gt; &gt; SLURM_NODEID=0<br>
&gt; &gt; &gt; SLURM_NODEID=1<br>
&gt; &gt; &gt; SLURM_NODEID=1<br>
&gt; &gt; &gt; SLURM_PROCID=0<br>
&gt; &gt; &gt; SLURM_PROCID=1<br>
&gt; &gt; &gt; SLURM_PROCID=2<br>
&gt; &gt; &gt; SLURM_PROCID=3<br>
&gt; &gt; &gt; [brent@node1 mpi]$<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; Since srun is not supported currently by OpenMPI, I have to use<br>
&gt; salloc - right?  In this case, it is up to OpenMPI to interpret the<br>
&gt; SLURM environment variables it sees in the one process that is launched<br>
&gt; and &#39;do the right thing&#39; - whatever that means in this case.  How does<br>
&gt; OpenMPI start the processes on the remote nodes under the covers?  (use<br>
&gt; srun, generate a hostfile and launch as you would outside SLURM, ...)<br>
&gt; This may be the difference between HP-MPI and OpenMPI.<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; Thanks,<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; Brent<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; From: <a href="mailto:users-bounces@open-mpi.org">users-bounces@open-mpi.org</a> [mailto:<a href="mailto:users-bounces@open-">users-bounces@open-</a><br>
&gt; <a href="http://mpi.org" target="_blank">mpi.org</a>] On Behalf Of Ralph Castain<br>
&gt; &gt; &gt; Sent: Wednesday, February 23, 2011 10:07 AM<br>
&gt; &gt; &gt; To: Open MPI Users<br>
&gt; &gt; &gt; Subject: Re: [OMPI users] SLURM environment variables at runtime<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; Resource managers generally frown on the idea of any program<br>
&gt; passing RM-managed envars from one node to another, and this is<br>
&gt; certainly true of slurm. The reason is that the RM reserves those<br>
&gt; values for its own use when managing remote nodes. For example, if you<br>
&gt; got an allocation and then used mpirun to launch a job across only a<br>
&gt; portion of that allocation, and then ran another mpirun instance in<br>
&gt; parallel on the remainder of the nodes, the slurm envars for those two<br>
&gt; mpirun instances -need- to be quite different. Having mpirun forward<br>
&gt; the values it sees would cause the system to become very confused.<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; We learned the hard way never to cross that line :-(<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; You have two options:<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; (a) you could get your sys admin to configure slurm correctly to<br>
&gt; provide your desired envars on the remote nodes. This is the<br>
&gt; recommended (by slurm and other RMs) way of getting what you requested.<br>
&gt; It is a simple configuration option - if he needs help, he should<br>
&gt; contact the slurm mailing list<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; (b) you can ask mpirun to do so, at your own risk. Specify each<br>
&gt; parameter with a &quot;-x FOO&quot; argument. See &quot;man mpirun&quot; for details. Keep<br>
&gt; an eye out for aberrant behavior.<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; Ralph<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; On Wed, Feb 23, 2011 at 8:38 AM, Henderson, Brent<br>
&gt; &lt;<a href="mailto:brent.henderson@hp.com">brent.henderson@hp.com</a>&gt; wrote:<br>
&gt; &gt; &gt; Hi Everyone, I have an OpenMPI/SLURM specific question,<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; I&#39;m using MPI as a launcher for another application I&#39;m working on<br>
&gt; and it is dependent on the SLURM environment variables making their way<br>
&gt; into the a.out&#39;s environment.  This works as I need if I use HP-<br>
&gt; MPI/PMPI, but when I use OpenMPI, it appears that not all are set as I<br>
&gt; would like across all of the ranks.<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; I have example output below from a simple a.out that just writes<br>
&gt; out the environment that it sees to a file whose name is based on the<br>
&gt; node name and rank number.  Note that with OpenMPI, that things like<br>
&gt; SLURM_NNODES and SLURM_TASKS_PER_NODE are not set the same for ranks on<br>
&gt; the different nodes and things like SLURM_LOCALID are just missing<br>
&gt; entirely.<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; So the question is, should the environment variables on the remote<br>
&gt; nodes (from the perspective of where the job is launched) have the full<br>
&gt; set of SLURM environment variables as seen on the launching node?<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; Thanks,<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; Brent Henderson<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; [brent@node2 mpi]$ rm node*<br>
&gt; &gt; &gt; [brent@node2 mpi]$ mkdir openmpi hpmpi<br>
&gt; &gt; &gt; [brent@node2 mpi]$ salloc -N 2 -n 4 mpirun ./printenv.openmpi<br>
&gt; &gt; &gt; salloc: Granted job allocation 23<br>
&gt; &gt; &gt; Hello world! I&#39;m 3 of 4 on node1<br>
&gt; &gt; &gt; Hello world! I&#39;m 2 of 4 on node1<br>
&gt; &gt; &gt; Hello world! I&#39;m 1 of 4 on node2<br>
&gt; &gt; &gt; Hello world! I&#39;m 0 of 4 on node2<br>
&gt; &gt; &gt; salloc: Relinquishing job allocation 23<br>
&gt; &gt; &gt; [brent@node2 mpi]$ mv node* openmpi/<br>
&gt; &gt; &gt; [brent@node2 mpi]$ egrep<br>
&gt; &#39;NODEID|NNODES|LOCALID|NODELIST|NPROCS|PROCID|TASKS_PER&#39;<br>
&gt; openmpi/node1.3.of.4<br>
&gt; &gt; &gt; SLURM_JOB_NODELIST=node[1-2]<br>
&gt; &gt; &gt; SLURM_NNODES=1<br>
&gt; &gt; &gt; SLURM_NODELIST=node[1-2]<br>
&gt; &gt; &gt; SLURM_TASKS_PER_NODE=1<br>
&gt; &gt; &gt; SLURM_NPROCS=1<br>
&gt; &gt; &gt; SLURM_STEP_NODELIST=node1<br>
&gt; &gt; &gt; SLURM_STEP_TASKS_PER_NODE=1<br>
&gt; &gt; &gt; SLURM_NODEID=0<br>
&gt; &gt; &gt; SLURM_PROCID=0<br>
&gt; &gt; &gt; SLURM_LOCALID=0<br>
&gt; &gt; &gt; [brent@node2 mpi]$ egrep<br>
&gt; &#39;NODEID|NNODES|LOCALID|NODELIST|NPROCS|PROCID|TASKS_PER&#39;<br>
&gt; openmpi/node2.1.of.4<br>
&gt; &gt; &gt; SLURM_JOB_NODELIST=node[1-2]<br>
&gt; &gt; &gt; SLURM_NNODES=2<br>
&gt; &gt; &gt; SLURM_NODELIST=node[1-2]<br>
&gt; &gt; &gt; SLURM_TASKS_PER_NODE=2(x2)<br>
&gt; &gt; &gt; SLURM_NPROCS=4<br>
&gt; &gt; &gt; [brent@node2 mpi]$<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; [brent@node2 mpi]$ /opt/hpmpi/bin/mpirun -srun -N 2 -n 4<br>
&gt; ./printenv.hpmpi<br>
&gt; &gt; &gt; Hello world! I&#39;m 2 of 4 on node2<br>
&gt; &gt; &gt; Hello world! I&#39;m 3 of 4 on node2<br>
&gt; &gt; &gt; Hello world! I&#39;m 0 of 4 on node1<br>
&gt; &gt; &gt; Hello world! I&#39;m 1 of 4 on node1<br>
&gt; &gt; &gt; [brent@node2 mpi]$ mv node* hpmpi/<br>
&gt; &gt; &gt; [brent@node2 mpi]$ egrep<br>
&gt; &#39;NODEID|NNODES|LOCALID|NODELIST|NPROCS|PROCID|TASKS_PER&#39;<br>
&gt; hpmpi/node1.1.of.4<br>
&gt; &gt; &gt; SLURM_NODELIST=node[1-2]<br>
&gt; &gt; &gt; SLURM_TASKS_PER_NODE=2(x2)<br>
&gt; &gt; &gt; SLURM_STEP_NODELIST=node[1-2]<br>
&gt; &gt; &gt; SLURM_STEP_TASKS_PER_NODE=2(x2)<br>
&gt; &gt; &gt; SLURM_NNODES=2<br>
&gt; &gt; &gt; SLURM_NPROCS=4<br>
&gt; &gt; &gt; SLURM_NODEID=0<br>
&gt; &gt; &gt; SLURM_PROCID=1<br>
&gt; &gt; &gt; SLURM_LOCALID=1<br>
&gt; &gt; &gt; [brent@node2 mpi]$ egrep<br>
&gt; &#39;NODEID|NNODES|LOCALID|NODELIST|NPROCS|PROCID|TASKS_PER&#39;<br>
&gt; hpmpi/node2.3.of.4<br>
&gt; &gt; &gt; SLURM_NODELIST=node[1-2]<br>
&gt; &gt; &gt; SLURM_TASKS_PER_NODE=2(x2)<br>
&gt; &gt; &gt; SLURM_STEP_NODELIST=node[1-2]<br>
&gt; &gt; &gt; SLURM_STEP_TASKS_PER_NODE=2(x2)<br>
&gt; &gt; &gt; SLURM_NNODES=2<br>
&gt; &gt; &gt; SLURM_NPROCS=4<br>
&gt; &gt; &gt; SLURM_NODEID=1<br>
&gt; &gt; &gt; SLURM_PROCID=3<br>
&gt; &gt; &gt; SLURM_LOCALID=1<br>
&gt; &gt; &gt; [brent@node2 mpi]$<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; _______________________________________________<br>
&gt; &gt; &gt; users mailing list<br>
&gt; &gt; &gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; &gt; &gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; _______________________________________________<br>
&gt; &gt; &gt; users mailing list<br>
&gt; &gt; &gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; &gt; &gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; &gt;<br>
&gt; &gt;<br>
&gt; &gt; --<br>
&gt; &gt; Jeff Squyres<br>
&gt; &gt; <a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a><br>
&gt; &gt; For corporate legal information go to:<br>
&gt; &gt; <a href="http://www.cisco.com/web/about/doing_business/legal/cri/" target="_blank">http://www.cisco.com/web/about/doing_business/legal/cri/</a><br>
&gt; &gt;<br>
&gt; &gt;<br>
&gt; &gt; _______________________________________________<br>
&gt; &gt; users mailing list<br>
&gt; &gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; &gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; &gt;<br>
&gt; &gt; _______________________________________________<br>
&gt; &gt; users mailing list<br>
&gt; &gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; &gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt;<br>
&gt;<br>
&gt; --<br>
&gt; Jeff Squyres<br>
&gt; <a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a><br>
&gt; For corporate legal information go to:<br>
&gt; <a href="http://www.cisco.com/web/about/doing_business/legal/cri/" target="_blank">http://www.cisco.com/web/about/doing_business/legal/cri/</a><br>
&gt;<br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</div></div></blockquote></div><br></div>

