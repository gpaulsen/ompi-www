<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" xmlns="http://www.w3.org/TR/REC-html40">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="Generator" content="Microsoft Word 14 (filtered medium)">
<!--[if !mso]><style>v\:* {behavior:url(#default#VML);}
o\:* {behavior:url(#default#VML);}
w\:* {behavior:url(#default#VML);}
.shape {behavior:url(#default#VML);}
</style><![endif]--><style><!--
/* Font Definitions */
@font-face
	{font-family:Helvetica;
	panose-1:2 11 6 4 2 2 2 2 2 4;}
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0in;
	margin-bottom:.0001pt;
	font-size:12.0pt;
	font-family:"Times New Roman","serif";}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-priority:99;
	color:purple;
	text-decoration:underline;}
p.MsoAcetate, li.MsoAcetate, div.MsoAcetate
	{mso-style-priority:99;
	mso-style-link:"Balloon Text Char";
	margin:0in;
	margin-bottom:.0001pt;
	font-size:8.0pt;
	font-family:"Tahoma","sans-serif";}
span.apple-converted-space
	{mso-style-name:apple-converted-space;}
span.EmailStyle18
	{mso-style-type:personal-reply;
	font-family:"Calibri","sans-serif";
	color:#1F497D;}
span.BalloonTextChar
	{mso-style-name:"Balloon Text Char";
	mso-style-priority:99;
	mso-style-link:"Balloon Text";
	font-family:"Tahoma","sans-serif";}
.MsoChpDefault
	{mso-style-type:export-only;
	font-size:10.0pt;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
--></style><!--[if gte mso 9]><xml>
<o:shapedefaults v:ext="edit" spidmax="1026" />
</xml><![endif]--><!--[if gte mso 9]><xml>
<o:shapelayout v:ext="edit">
<o:idmap v:ext="edit" data="1" />
</o:shapelayout></xml><![endif]-->
</head>
<body lang="EN-US" link="blue" vlink="purple">
<div class="WordSection1">
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">There is no short-term plan but we are always looking at ways to improve things so this could be looked at some time in the future.<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D"><o:p>&nbsp;</o:p></span></p>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">Rolf<o:p></o:p></span></p>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D"><o:p>&nbsp;</o:p></span></p>
<div style="border:none;border-left:solid blue 1.5pt;padding:0in 0in 0in 4.0pt">
<div>
<div style="border:none;border-top:solid #B5C4DF 1.0pt;padding:3.0pt 0in 0in 0in">
<p class="MsoNormal"><b><span style="font-size:10.0pt;font-family:&quot;Tahoma&quot;,&quot;sans-serif&quot;">From:</span></b><span style="font-size:10.0pt;font-family:&quot;Tahoma&quot;,&quot;sans-serif&quot;"> users [mailto:users-bounces@open-mpi.org]
<b>On Behalf Of </b>Fei Mao<br>
<b>Sent:</b> Wednesday, June 17, 2015 1:48 PM<br>
<b>To:</b> Open MPI Users<br>
<b>Subject:</b> Re: [OMPI users] CUDA-aware MPI_Reduce problem in Openmpi 1.8.5<o:p></o:p></span></p>
</div>
</div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">Hi Rolf,<o:p></o:p></p>
<div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
<div>
<p class="MsoNormal">Thank you very much for clarifying the problem. Is there any plan to support GPU RDMA for reduction in the future?<o:p></o:p></p>
</div>
<div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<div>
<div>
<p class="MsoNormal">On Jun 17, 2015, at 1:38 PM, Rolf vandeVaart &lt;<a href="mailto:rvandevaart@nvidia.com">rvandevaart@nvidia.com</a>&gt; wrote:<o:p></o:p></p>
</div>
<p class="MsoNormal"><br>
<br>
<o:p></o:p></p>
<div>
<div>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">Hi Fei:</span><o:p></o:p></p>
</div>
<div>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">&nbsp;</span><o:p></o:p></p>
</div>
<div>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">The reduction support for CUDA-aware in Open MPI is rather simple.&nbsp; The GPU buffers are copied into temporary host buffers and then the reduction is done with
 the host buffers.&nbsp; At the completion of the host reduction, the data is copied back into the GPU buffers.&nbsp; So, there is no use of CUDA IPC or GPU Direct RDMA in the reduction.</span><o:p></o:p></p>
</div>
<div>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">&nbsp;</span><o:p></o:p></p>
</div>
<div>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">Rolf</span><o:p></o:p></p>
</div>
<div>
<p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;color:#1F497D">&nbsp;</span><o:p></o:p></p>
</div>
<div style="border:none;border-left:solid blue 1.5pt;padding:0in 0in 0in 4.0pt">
<div>
<div style="border:none;border-top:solid #B5C4DF 1.0pt;padding:3.0pt 0in 0in 0in">
<div>
<p class="MsoNormal"><b><span style="font-size:10.0pt;font-family:&quot;Tahoma&quot;,&quot;sans-serif&quot;">From:</span></b><span class="apple-converted-space"><span style="font-size:10.0pt;font-family:&quot;Tahoma&quot;,&quot;sans-serif&quot;">&nbsp;</span></span><span style="font-size:10.0pt;font-family:&quot;Tahoma&quot;,&quot;sans-serif&quot;">users
 [<a href="mailto:users-bounces@open-mpi.org">mailto:users-bounces@open-mpi.org</a>]<span class="apple-converted-space">&nbsp;</span><b>On Behalf Of<span class="apple-converted-space">&nbsp;</span></b>Fei Mao<br>
<b>Sent:</b><span class="apple-converted-space">&nbsp;</span>Wednesday, June 17, 2015 1:08 PM<br>
<b>To:</b><span class="apple-converted-space">&nbsp;</span><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<b>Subject:</b><span class="apple-converted-space">&nbsp;</span>[OMPI users] CUDA-aware MPI_Reduce problem in Openmpi 1.8.5</span><o:p></o:p></p>
</div>
</div>
</div>
<div>
<p class="MsoNormal">&nbsp;<o:p></o:p></p>
</div>
<div>
<p class="MsoNormal">Hi there,<o:p></o:p></p>
</div>
<div>
<div>
<p class="MsoNormal">&nbsp;<o:p></o:p></p>
</div>
</div>
<div>
<div>
<p class="MsoNormal">I am doing benchmarks on a GPU cluster with two CPU sockets and 4 K80 GPUs each node. Two K80 are connected with CPU socket 0, another two with socket 1. An IB ConnectX-3 (FDR) is also under socket 1. We are using Linux&#8217;s OFED, so I know
 there is no way to do GPU RDMA inter-node communication. I can do intra-node IPC for MPI_Send and MPI_Receive with two K80 (4 GPUs in total) which are connected under same socket (PCI-e switch). So I thought I could do intra-node MPI_Reduce with IPC support
 in openmpi 1.8.5.<o:p></o:p></p>
</div>
</div>
<div>
<div>
<p class="MsoNormal">&nbsp;<o:p></o:p></p>
</div>
</div>
<div>
<div>
<p class="MsoNormal">The benchmark I was using is osu-micro-benchmarks-4.4.1, and I got the same results when I use two GPU under the same socket or different socket. The result was the same even I used two GPUs in different nodes.&nbsp;<o:p></o:p></p>
</div>
</div>
<div>
<div>
<p class="MsoNormal">&nbsp;<o:p></o:p></p>
</div>
</div>
<div>
<div>
<p class="MsoNormal">Does MPI_Reduce use IPC for intra-node? Should I have to install Mellanox OFED stack to support GPU RDMA reduction on GPUs even they are under with the same PCI-e switch?<o:p></o:p></p>
</div>
</div>
<div>
<div>
<p class="MsoNormal">&nbsp;<o:p></o:p></p>
</div>
</div>
<div>
<div>
<p class="MsoNormal">Thanks,<o:p></o:p></p>
</div>
</div>
<div>
<div>
<p class="MsoNormal">&nbsp;<o:p></o:p></p>
</div>
</div>
<div>
<div>
<div>
<p class="MsoNormal">Fei Mao<br>
High Performance Computing Technical Consultant&nbsp;<o:p></o:p></p>
</div>
</div>
<div>
<div>
<p class="MsoNormal">SHARCNET |&nbsp;<a href="http://www.sharcnet.ca/"><span style="color:purple">http://www.sharcnet.ca</span></a><br>
Compute/Calcul Canada |&nbsp;<a href="http://www.computecanada.ca/"><span style="color:purple">http://www.computecanada.ca</span></a><o:p></o:p></p>
</div>
</div>
</div>
</div>
<div>
<div class="MsoNormal" align="center" style="text-align:center"><span style="font-size:9.0pt;font-family:&quot;Helvetica&quot;,&quot;sans-serif&quot;">
<hr size="2" width="100%" align="center">
</span></div>
</div>
<div>
<p class="MsoNormal"><span style="font-size:9.0pt;font-family:&quot;Helvetica&quot;,&quot;sans-serif&quot;">This email message is for the sole use of the intended recipient(s) and may contain confidential information.&nbsp; Any unauthorized review, use, disclosure or distribution is
 prohibited.&nbsp; If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.<o:p></o:p></span></p>
</div>
<div>
<div class="MsoNormal" align="center" style="text-align:center"><span style="font-size:9.0pt;font-family:&quot;Helvetica&quot;,&quot;sans-serif&quot;">
<hr size="2" width="100%" align="center">
</span></div>
</div>
<p class="MsoNormal"><span style="font-size:9.0pt;font-family:&quot;Helvetica&quot;,&quot;sans-serif&quot;">_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org"><span style="color:purple">users@open-mpi.org</span></a><br>
Subscription:<span class="apple-converted-space">&nbsp;</span><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users"><span style="color:purple">http://www.open-mpi.org/mailman/listinfo.cgi/users</span></a><br>
Link to this post:<span class="apple-converted-space">&nbsp;</span><a href="http://www.open-mpi.org/community/lists/users/2015/06/27147.php"><span style="color:purple">http://www.open-mpi.org/community/lists/users/2015/06/27147.php</span></a><o:p></o:p></span></p>
</div>
</div>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
</div>
</div>
</body>
</html>

