diff -r '--exclude=*~' -u openmpi-1.6.3/ompi/mca/coll/tuned/coll_tuned_alltoallv.c openmpi-1.6.3.patched/ompi/mca/coll/tuned/coll_tuned_alltoallv.c
--- openmpi-1.6.3/ompi/mca/coll/tuned/coll_tuned_alltoallv.c	2012-04-03 15:30:17.000000000 +0100
+++ openmpi-1.6.3.patched/ompi/mca/coll/tuned/coll_tuned_alltoallv.c	2013-01-24 15:12:13.299568308 +0000
@@ -70,7 +70,7 @@
     }
 
     /* Perform pairwise exchange starting from 1 since local exhange is done */
-    for (step = 1; step < size + 1; step++) {
+    for (step = 1; step < size; step++) {
 
         /* Determine sender and receiver for this step. */
         sendto  = (rank + step) % size;
diff -r '--exclude=*~' -u openmpi-1.6.3/ompi/mca/coll/tuned/coll_tuned_util.c openmpi-1.6.3.patched/ompi/mca/coll/tuned/coll_tuned_util.c
--- openmpi-1.6.3/ompi/mca/coll/tuned/coll_tuned_util.c	2012-04-03 15:30:17.000000000 +0100
+++ openmpi-1.6.3.patched/ompi/mca/coll/tuned/coll_tuned_util.c	2013-01-24 15:11:56.562118400 +0000
@@ -37,25 +37,31 @@
                                      ompi_status_public_t* status )
 
 { /* post receive first, then send, then waitall... should be fast (I hope) */
-    int err, line = 0;
+    int err, line = 0, nreq = 0;
     ompi_request_t* reqs[2];
     ompi_status_public_t statuses[2];
 
-    /* post new irecv */
-    err = MCA_PML_CALL(irecv( recvbuf, rcount, rdatatype, source, rtag, 
-                              comm, &reqs[0]));
-    if (err != MPI_SUCCESS) { line = __LINE__; goto error_handler; }
-
-    /* send data to children */
-    err = MCA_PML_CALL(isend( sendbuf, scount, sdatatype, dest, stag, 
-                              MCA_PML_BASE_SEND_STANDARD, comm, &reqs[1]));
-    if (err != MPI_SUCCESS) { line = __LINE__; goto error_handler; }
+    if (0 != rcount) {
+        /* post new irecv */
+        err = MCA_PML_CALL(irecv( recvbuf, rcount, rdatatype, source, rtag, 
+                                  comm, &reqs[nreq++]));
+        if (err != MPI_SUCCESS) { line = __LINE__; goto error_handler; }
+    }
 
-    err = ompi_request_wait_all( 2, reqs, statuses );
-    if (err != MPI_SUCCESS) { line = __LINE__; goto error_handler_waitall; }
+    if (0 != scount) {
+        /* send data to children */
+        err = MCA_PML_CALL(isend( sendbuf, scount, sdatatype, dest, stag, 
+                                  MCA_PML_BASE_SEND_STANDARD, comm, &reqs[nreq++]));
+        if (err != MPI_SUCCESS) { line = __LINE__; goto error_handler; }
+    }
 
-    if (MPI_STATUS_IGNORE != status) {
-        *status = statuses[0];
+    if (0 != nreq) {
+        err = ompi_request_wait_all( nreq, reqs, statuses );
+        if (err != MPI_SUCCESS) { line = __LINE__; goto error_handler_waitall; }
+    
+        if (MPI_STATUS_IGNORE != status) {
+            *status = statuses[0];
+        }
     }
     
     return (MPI_SUCCESS);
@@ -68,7 +74,7 @@
     if( MPI_ERR_IN_STATUS == err ) {
         /* At least we know he error was detected during the wait_all */
         int err_index = 0;
-        if( MPI_SUCCESS != statuses[1].MPI_ERROR ) {
+        if( nreq > 1 && MPI_SUCCESS != statuses[1].MPI_ERROR ) {
             err_index = 1;
         }
         if (MPI_STATUS_IGNORE != status) {
@@ -107,25 +113,31 @@
                                                     ompi_status_public_t* status )
 
 { /* post receive first, then [local] sync send, then wait... should be fast (I hope) */
-    int err, line = 0;
+    int err, line = 0, nreq = 0;
     ompi_request_t* req[2];
     ompi_status_public_t statuses[2];
 
-    /* post new irecv */
-    err = MCA_PML_CALL(irecv( recvbuf, rcount, rdatatype, source, rtag, 
-                              comm, &(req[0])));
-    if (err != MPI_SUCCESS) { line = __LINE__; goto error_handler; }
-
-    /* send data to children */
-    err = MCA_PML_CALL(isend( sendbuf, scount, sdatatype, dest, stag,
-                              MCA_PML_BASE_SEND_SYNCHRONOUS, comm, &(req[1])));
-    if (err != MPI_SUCCESS) { line = __LINE__; goto error_handler; }
+    if (0 != rcount) {
+        /* post new irecv */
+        err = MCA_PML_CALL(irecv( recvbuf, rcount, rdatatype, source, rtag, 
+                                  comm, &(req[nreq++])));
+        if (err != MPI_SUCCESS) { line = __LINE__; goto error_handler; }
+    }
+
+    if (0 != scount) {
+        /* send data to children */
+        err = MCA_PML_CALL(isend( sendbuf, scount, sdatatype, dest, stag,
+                                  MCA_PML_BASE_SEND_SYNCHRONOUS, comm, &(req[nreq++])));
+        if (err != MPI_SUCCESS) { line = __LINE__; goto error_handler; }
+    }
 
-    err = ompi_request_wait_all( 2, req, statuses );
-    if (err != MPI_SUCCESS) { line = __LINE__; goto error_handler; }
+    if (0 != nreq) {
+        err = ompi_request_wait_all( nreq, req, statuses );
+        if (err != MPI_SUCCESS) { line = __LINE__; goto error_handler; }
 
-    if (MPI_STATUS_IGNORE != status) {
-        *status = statuses[0];
+        if (MPI_STATUS_IGNORE != status) {
+            *status = statuses[0];
+        }
     }
 
     return (MPI_SUCCESS);
@@ -137,7 +149,7 @@
      */
     if( MPI_ERR_IN_STATUS == err ) { 
         int err_index = 0;
-        if( MPI_SUCCESS != statuses[1].MPI_ERROR ) {
+        if( nreq > 1 && MPI_SUCCESS != statuses[1].MPI_ERROR ) {
             err_index = 1;
         }
         if (MPI_STATUS_IGNORE != status) {


