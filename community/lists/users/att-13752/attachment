Hi Cristobal,<br><br>Note that the pic in <a href="http://dl.dropbox.com/u/6380744/clusterLibs.png" target="_blank">http://dl.dropbox.com/u/6380744/clusterLibs.png</a> <br>shows that Scalapack is based on what; it only shows which packages Scalapack uses; hence no OpenMP is there.<br>
<br>Also be clear about the difference:<br>&quot;OpenMP&quot; is for shared memory parallel programming, while<br>&quot;OpenMPI&quot; is an implantation of MPI standard (this list is about OpenMPI obviously). <br><br>best<br>
AA.<br><br><div class="gmail_quote">On Thu, Jul 22, 2010 at 5:06 PM, Cristobal Navarro <span dir="ltr">&lt;<a href="mailto:axischire@gmail.com">axischire@gmail.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
Thanks<br>
<br>
im looking at the manual, seems good.<br>
i think now the picture is more clear.<br>
<br>
i have a very custom algorithm, local problem of research,<br>
paralelizable, thats where openMPI enters.<br>
then, at some point on the program, all the computation traduces to<br>
numeric (double) matrix operations, eigenvalues and derivatives. thats<br>
where a library like PETSc makes its appearance. or a lower level<br>
solution would be GSL and manually implement paralelism with MPI.<br>
<br>
in case someone chooses, a highlevel library like PETSc and some low<br>
level openMPI for its custom algorithms, is there a race for MPI<br>
problem?<br>
<div><div></div><div class="h5"><br>
On Thu, Jul 22, 2010 at 3:42 PM, Gus Correa &lt;<a href="mailto:gus@ldeo.columbia.edu">gus@ldeo.columbia.edu</a>&gt; wrote:<br>
&gt; Hi Cristobal<br>
&gt;<br>
&gt; You may want to take a look at PETSc,<br>
&gt; which has all the machinery for linear algebra that<br>
&gt; you need, can easily attach a variety of Linear Algebra packages,<br>
&gt; including those in the diagram you sent and more,<br>
&gt; builds on top of MPI, and can even build MPI for you, if you prefer.<br>
&gt; It has C and Fortran interfaces, and if I remember right,<br>
&gt; you can build it alternatively with a C++ interface.<br>
&gt; You can choose from real or complex scalars,<br>
&gt; depending on your target problem (e.g. if you are going to do<br>
&gt; signal/image processing with FFTs, you want complex scalars).<br>
&gt; I don&#39;t know if it has high level commands to deal with<br>
&gt; data structures (like trees that you mentioned), but it may.<br>
&gt;<br>
&gt; <a href="http://www.mcs.anl.gov/petsc/petsc-as/" target="_blank">http://www.mcs.anl.gov/petsc/petsc-as/</a><br>
&gt;<br>
&gt; My $0.02<br>
&gt; Gus Correa<br>
&gt; ---------------------------------------------------------------------<br>
&gt; Gustavo Correa<br>
&gt; Lamont-Doherty Earth Observatory - Columbia University<br>
&gt; Palisades, NY, 10964-8000 - USA<br>
&gt; ---------------------------------------------------------------------<br>
&gt;<br>
&gt; Cristobal Navarro wrote:<br>
&gt;&gt;<br>
&gt;&gt; Hello,<br>
&gt;&gt;<br>
&gt;&gt; i am designing a solution to one of my programs, which mixes some tree<br>
&gt;&gt; generation, matrix operatons, eigenvaluies, among other tasks.<br>
&gt;&gt; i have to paralellize all of this for a cluster of 4 nodes (32 cores),<br>
&gt;&gt; and what i first thought was MPI as a blind choice, but after looking<br>
&gt;&gt; at this picture<br>
&gt;&gt;<br>
&gt;&gt; <a href="http://dl.dropbox.com/u/6380744/clusterLibs.png" target="_blank">http://dl.dropbox.com/u/6380744/clusterLibs.png</a> ( On the picture,<br>
&gt;&gt; openMP is missing.)<br>
&gt;&gt;<br>
&gt;&gt; i decided to take a break and sit down, think what best suits to my needs.<br>
&gt;&gt; Adittionally, i am not familiar with Fortran, so i search for C/C++<br>
&gt;&gt; libraries.<br>
&gt;&gt;<br>
&gt;&gt; what are your experiences, what aspects of your proyect do you<br>
&gt;&gt; consider when choosing, is a good practice to mix these libraries in<br>
&gt;&gt; one same proyect?<br>
&gt;&gt; _______________________________________________<br>
&gt;&gt; users mailing list<br>
&gt;&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt;&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt;<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</div></div></blockquote></div><br>

