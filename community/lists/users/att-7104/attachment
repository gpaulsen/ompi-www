<div dir="ltr"><p>can you update me with the mapping or the way to get it from the OS on the Cell.</p><p>thanks<br></p><br><div class="gmail_quote">On Thu, Oct 23, 2008 at 8:08 PM, Mi Yan <span dir="ltr">&lt;<a href="mailto:miyan@us.ibm.com">miyan@us.ibm.com</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"><div>
<p>Lenny,<br>
<br>
     Thanks.  <br>
     I asked the Cell/BE Linux Kernel developer to get the CPU  mapping :)  The mapping is fixed in current kernel. <br><div class="Ih2E3d">
  <br>
 Mi   <br>
<img width="16" height="16" border="0" alt="Inactive hide details for &quot;Lenny Verkhovsky&quot; &lt;lenny.verkhovsky@gmail.com&gt;">&quot;Lenny Verkhovsky&quot; &lt;<a href="mailto:lenny.verkhovsky@gmail.com" target="_blank">lenny.verkhovsky@gmail.com</a>&gt;<br>

<br>
<br>

</div><table width="100%" border="0" cellspacing="0" cellpadding="0"><tbody><tr valign="top"><td width="40%">
<ul>
<ul>
<ul>
<ul><div class="Ih2E3d"><b><font size="2">&quot;Lenny Verkhovsky&quot; &lt;<a href="mailto:lenny.verkhovsky@gmail.com" target="_blank">lenny.verkhovsky@gmail.com</a>&gt;</font></b><font size="2"> </font><br>
<font size="2">Sent by: <a href="mailto:users-bounces@open-mpi.org" target="_blank">users-bounces@open-mpi.org</a></font>
</div><p><font size="2">10/23/2008 01:52 PM</font><div><div class="Wj3C7c">
<table border="1"><tbody><tr valign="top"><td width="168" bgcolor="#FFFFFF"><div align="center"><font size="2">Please respond to<br>
Open MPI Users &lt;<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a>&gt;</font></div></td></tr></tbody></table>
</div></div></p></ul>
</ul>
</ul>
</ul>
</td><td width="60%">
<table width="100%" border="0" cellspacing="0" cellpadding="0"><tbody><tr valign="top"><td width="1%"><img width="58" height="1" border="0" alt=""><br>
<div align="right"><font size="2">To</font></div></td><td width="100%"><img width="1" height="1" border="0" alt=""><br>
<font size="2">&quot;Open MPI Users&quot; &lt;<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a>&gt;</font></td></tr><tr valign="top"><td width="1%"><img width="58" height="1" border="0" alt=""><br>

<div align="right"><font size="2">cc</font></div></td><td width="100%"><img width="1" height="1" border="0" alt=""><br>
</td></tr><tr valign="top"><td width="1%"><img width="58" height="1" border="0" alt=""><br>
<div align="right"><font size="2">Subject</font></div></td><td width="100%"><img width="1" height="1" border="0" alt=""><br>
<font size="2">Re: [OMPI users] Working with a CellBlade cluster</font></td></tr></tbody></table>

<table border="0" cellspacing="0" cellpadding="0"><tbody><tr valign="top"><td width="58"><img width="1" height="1" border="0" alt=""></td><td width="336"><img width="1" height="1" border="0" alt=""></td></tr></tbody></table>

</td></tr></tbody></table><div><div class="Wj3C7c">
<br>
<font size="4">According to </font><a href="https://svn.open-mpi.org/trac/ompi/milestone/Open%20MPI%201.3" target="_blank"><u><font size="4" color="#0000FF">https://svn.open-mpi.org/trac/ompi/milestone/Open%20MPI%201.3</font></u></a><font size="4"> very soon, </font><br>

<font size="4">but you can download trunk version </font><a href="http://www.open-mpi.org/svn/" target="_blank"><u><font size="4" color="#0000FF">http://www.open-mpi.org/svn/</font></u></a><font size="4">  and check if it works for you.</font><br>

<font size="4"> </font><br>
<font size="4">how can you check mapping CPUs by OS , my cat /proc/cpuinfo shows very little info</font><br>
<font size="4"># cat /proc/cpuinfo<br>
processor       : 0<br>
cpu             : Cell Broadband Engine, altivec supported<br>
clock           : 3200.000000MHz<br>
revision        : 48.0 (pvr 0070 3000)</font><br>
<font size="4">processor       : 1<br>
cpu             : Cell Broadband Engine, altivec supported<br>
clock           : 3200.000000MHz<br>
revision        : 48.0 (pvr 0070 3000)</font><br>
<font size="4">processor       : 2<br>
cpu             : Cell Broadband Engine, altivec supported<br>
clock           : 3200.000000MHz<br>
revision        : 48.0 (pvr 0070 3000)</font><br>
<font size="4">processor       : 3<br>
cpu             : Cell Broadband Engine, altivec supported<br>
clock           : 3200.000000MHz<br>
revision        : 48.0 (pvr 0070 3000)</font><br>
<font size="4">timebase        : 26666666<br>
platform        : Cell<br>
machine         : CHRP IBM,0793-1RZ</font><br>
<font size="4"><br>
<br>
 </font><br>
<font size="4">On Thu, Oct 23, 2008 at 3:00 PM, Mi Yan &lt;</font><a href="mailto:miyan@us.ibm.com" target="_blank"><u><font size="4" color="#0000FF">miyan@us.ibm.com</font></u></a><font size="4">&gt; wrote:</font>
<ul><font size="4">Hi, Lenny,<br>
<br>
So rank file map will be supported in OpenMPI 1.3? I&#39;m using OpenMPI1.2.6 and did not find parameter &quot;rmaps_rank_file_&quot;. <br>
Do you have idea when OpenMPI 1.3 will be available? OpenMPI 1.3 has quite a few features I&#39;m looking for.<br>
<br>
Thanks, </font><br>
<font size="4"><br>
Mi <br>
</font><img width="16" height="16" alt="Inactive hide details for &quot;Lenny Verkhovsky&quot; &lt;lenny.verkhovsky@gmail.com&gt;"><font size="4">&quot;Lenny Verkhovsky&quot; &lt;</font><a href="mailto:lenny.verkhovsky@gmail.com" target="_blank"><u><font size="4" color="#0000FF">lenny.verkhovsky@gmail.com</font></u></a><font size="4">&gt;<br>

<br>
</font></ul>
<br>

<table width="100%" border="0" cellspacing="0" cellpadding="0"><tbody><tr valign="top"><td width="0%"><img width="1" height="1" border="0" alt=""></td><td width="55%">
<ul>
<ul>
<ul>
<ul>
<ul>
<ul>
<ul>
<ul><b>&quot;Lenny Verkhovsky&quot; &lt;</b><a href="mailto:lenny.verkhovsky@gmail.com" target="_blank"><b><u><font color="#0000FF">lenny.verkhovsky@gmail.com</font></u></b></a><b>&gt;</b> <br>
Sent by: <a href="mailto:users-bounces@open-mpi.org" target="_blank"><u><font color="#0000FF">users-bounces@open-mpi.org</font></u></a><font size="4"> </font>
<p>10/23/2008 05:48 AM<font size="4"> </font></p></ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>

<table width="100%" border="1"><tbody><tr valign="top"><td width="100%" bgcolor="#FFFFFF"><div align="center">Please respond to<br>
Open MPI Users &lt;<a href="mailto:users@open-mpi.org" target="_blank"><u><font color="#0000FF">users@open-mpi.org</font></u></a>&gt;</div></td></tr></tbody></table>
</td><td width="0%"><img width="1" height="1" border="0" alt=""></td><td width="44%">
<table width="100%" border="0" cellspacing="0" cellpadding="0"><tbody><tr valign="top"><td width="18%" valign="middle"><img width="1" height="1" border="0" alt=""></td><td width="82%"><img width="1" height="1" border="0" alt=""></td>
</tr><tr valign="top"><td width="18%"><img width="58" height="1"><div align="right">To</div></td><td width="82%"><img width="1" height="1"><br>
&quot;Open MPI Users&quot; &lt;<a href="mailto:users@open-mpi.org" target="_blank"><u><font color="#0000FF">users@open-mpi.org</font></u></a>&gt;</td></tr><tr valign="top"><td width="18%"><img width="58" height="1"><div align="right">
cc</div></td><td width="82%"><img width="1" height="1"></td></tr><tr valign="top"><td width="18%" valign="middle"><img width="1" height="1" border="0" alt=""></td><td width="82%" valign="middle"><img width="1" height="1" border="0" alt=""></td>
</tr><tr valign="top"><td width="18%"><img width="58" height="1"><div align="right">Subject</div></td><td width="82%"><img width="1" height="1"><br>
Re: [OMPI users] Working with a CellBlade cluster</td></tr></tbody></table>

<table width="100%" border="0" cellspacing="0" cellpadding="0"><tbody><tr valign="top"><td width="15%"><img width="1" height="1"></td><td width="85%"><img width="1" height="1"></td></tr></tbody></table>
</td></tr></tbody></table>

<ul><font size="5"><br>
Hi,</font><font size="4"><br>
<br>
</font><font size="5"><br>
If I understand you correctly the most suitable way to do it is by paffinity that we have in Open MPI 1.3 and the trank.<br>
how ever usually OS is distributing processes evenly between sockets by it self.</font><font size="4"><br>
</font><font size="5"><br>
There still no formal FAQ due to a multiple reasons but you can read how to use it in the attached scratch ( there were few name changings of the params, so check with ompi_info )</font><font size="4"><br>
</font><font size="5"><br>
shared memory is used between processes that share same machine, and openib is used between different machines ( hostnames ), no special mca params are needed.</font><font size="4"><br>
</font><font size="5"><br>
Best Regards<br>
Lenny,</font><font size="4"> </font>
<p><font size="5"><br>
</font>
<p><font size="5">On Sun, Oct 19, 2008 at 10:32 AM, Gilbert Grosdidier &lt;</font><a href="mailto:grodid@mail.cern.ch" target="_blank"><u><font size="5" color="#0000FF">grodid@mail.cern.ch</font></u></a><font size="5">&gt; wrote:</font><font size="4"> </font>
<ul>
<ul><font size="5">Working with a CellBlade cluster (QS22), the requirement is to have one<br>
instance of the executable running on each socket of the blade (there are 2<br>
sockets). The application is of the &#39;domain decomposition&#39; type, and each<br>
instance is required to often send/receive data with both the remote blades and<br>
the neighbor socket.<br>
<br>
Question is : which specification must be used for the mca btl component<br>
to force 1) shmem type messages when communicating with this neighbor socket,<br>
while 2) using openib to communicate with the remote blades ?<br>
Is &#39;-mca btl sm,openib,self&#39; suitable for this ?<br>
<br>
Also, which debug flags could be used to crosscheck that the messages are<br>
_actually_ going thru the right channel for a given channel, please ?<br>
<br>
We are currently using OpenMPI 1.2.5 shipped with RHEL5.2 (ppc64).<br>
Which version do you think is currently the most optimised for these<br>
processors and problem type ? Should we go towards OpenMPI 1.2.8 instead ?<br>
Or even try some OpenMPI 1.3 nightly build ?<br>
<br>
Thanks in advance for your help, Gilbert.<br>
<br>
_______________________________________________<br>
users mailing list</font><u><font size="4" color="#0000FF"><br>
</font></u><a href="mailto:users@open-mpi.org" target="_blank"><u><font size="5" color="#0000FF">users@open-mpi.org</font></u></a><u><font size="4" color="#0000FF"><br>
</font></u><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank"><u><font size="5" color="#0000FF">http://www.open-mpi.org/mailman/listinfo.cgi/users</font></u></a></ul>
</ul>
<i><font size="4">(See attached file: RANKS_FAQ.doc)</font></i><br>
<tt><font size="4">_______________________________________________ </font></tt><br>
<tt><font size="4"><br>
users mailing list</font></tt><tt><u><font size="4" color="#0000FF"><br>
</font></u></tt><a href="mailto:users@open-mpi.org" target="_blank"><tt><u><font size="4" color="#0000FF">users@open-mpi.org</font></u></tt></a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank"><tt><u><font size="4" color="#0000FF">http://www.open-mpi.org/mailman/listinfo.cgi/users</font></u></tt></a><br>
<font size="4"><br>
_______________________________________________<br>
users mailing list</font><u><font size="4" color="#0000FF"><br>
</font></u><a href="mailto:users@open-mpi.org" target="_blank"><u><font size="4" color="#0000FF">users@open-mpi.org</font></u></a><u><font size="4" color="#0000FF"><br>
</font></u><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank"><u><font size="4" color="#0000FF">http://www.open-mpi.org/mailman/listinfo.cgi/users</font></u></a></p></p></ul>
<tt>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
</tt><tt><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></tt><br>
</div></div></p></div>
<br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></div><br></div>

