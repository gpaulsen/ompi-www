Ha, yeah, I should have been more clear there.&nbsp; I'm simply writing an MPI application.<br><br>Thanks,<br>&nbsp; Brian<br><br><div><span class="gmail_quote">On 11/2/06, <b class="gmail_sendername">Jeff Squyres</b> &lt;<a href="mailto:jsquyres@cisco.com">
jsquyres@cisco.com</a>&gt; wrote:</span><blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">It depends on what you're trying to do.&nbsp;&nbsp;Are you writing new
<br>components internal to Open MPI, or are you just trying to leverage<br>OMPI's PML for some other project?&nbsp;&nbsp;Or are you writing MPI<br>applications?&nbsp;&nbsp;Or ...?<br><br><br>On Nov 2, 2006, at 2:22 PM, Brian Budge wrote:<br>
<br>&gt; Thanks for the pointer, it was a very interesting read.<br>&gt;<br>&gt;&nbsp;&nbsp;It seems that by default OpenMPI uses the nifty pipelining trick<br>&gt; with pinning pages while transfer is happening.&nbsp;&nbsp;Also the pinning<br>
&gt; can be (somewhat) perminant and the state is cached so that next<br>&gt; usage requires no registration.&nbsp;&nbsp;I guess it is possible to use pre-<br>&gt; pinned memory, but do I need to do anything special to do so?&nbsp;&nbsp;I<br>
&gt; will already have some buffers pinned to allow DMAs to devices<br>&gt; across PCI-Express, so it makes sense to use one pinned buffer so<br>&gt; that I can avoid memcpys.<br>&gt;<br>&gt; Are there any HOWTO tutorials or anything?&nbsp;&nbsp;I've searched around,
<br>&gt; but it's possible I just used the wrong search terms.<br>&gt;<br>&gt; Thanks,<br>&gt;&nbsp;&nbsp; Brian<br>&gt;<br>&gt;<br>&gt;<br>&gt; On 11/2/06, Jeff Squyres &lt;<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a>
&gt; wrote: This paper<br>&gt; explains it pretty well:<br>&gt;<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://www.open-mpi.org/papers/euro-pvmmpi-2006-hpc-protocols/">http://www.open-mpi.org/papers/euro-pvmmpi-2006-hpc-protocols/</a><br>&gt;
<br>&gt;<br>&gt;<br>&gt; On Nov 2, 2006, at 1:37 PM, Brian Budge wrote:<br>&gt;<br>&gt; &gt; Hi all -<br>&gt; &gt;<br>&gt; &gt; I'm wondering how DMA is handled in OpenMPI when using the<br>&gt; &gt; infiniband protocol.&nbsp;&nbsp;In particular, will I get a speed gain if my
<br>&gt; &gt; read/write buffers are already pinned via mlock?<br>&gt; &gt;<br>&gt; &gt; Thanks,<br>&gt; &gt;&nbsp;&nbsp; Brian<br>&gt; &gt; _______________________________________________<br>&gt; &gt; users mailing list<br>&gt; &gt; 
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>&gt; &gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>&gt;<br>&gt;<br>&gt; --<br>&gt; Jeff Squyres
<br>&gt; Server Virtualization Business Unit<br>&gt; Cisco Systems<br>&gt;<br>&gt; _______________________________________________<br>&gt; users mailing list<br>&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a>
<br>&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>&gt;<br>&gt; _______________________________________________<br>&gt; users mailing list<br>&gt; 
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br><br><br>--<br>Jeff Squyres<br>Server Virtualization Business Unit
<br>Cisco Systems<br><br>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">
http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></div><br>

