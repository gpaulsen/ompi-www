Hi Ralph,<br><pre><font size="4">fs.file-max = 100000</font></pre>is this ok or less?<br><br>Best Regards,<br>Ashwani<br><br><br><div class="gmail_quote">On Fri, Oct 14, 2011 at 11:45 PM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org">rhc@open-mpi.org</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"><div style="word-wrap:break-word">Can&#39;t offer much about the qsub job. On the first one, what is your limit on the number of file descriptors? Could be your sys admin has it too low.<div>
<br></div><div><br><div><div><div></div><div class="h5"><div>On Oct 14, 2011, at 12:07 PM, Ashwani Kumar Mishra wrote:</div><br></div></div><blockquote type="cite"><div><div></div><div class="h5">Hello,<br>When i try to run the following command i receive the following error when i try to submit this job on the cluster having 40 nodes with each node having 8 processor &amp; 8 GB RAM:<br>
<br>Both the command work well, as long as i use only upto 88 processors in the cluster, but the moment i allocate more than 88 processors it gives me the below 2 errors:<br>
<br>I tried to set the ulimit to unlimited &amp; setting mca parameter opal_set_max_sys_limits to 1 but still the problem wont go.<br><br><br>$ mpirun=<span>/<i>opt</i>/psc/ompi/bin/mpirun</span> abyss-pe np=100 name=cattle k=50 n=10  in=s_1_1_sequence.txt<br>

<br>/opt/mpi/openmpi/1.3.3/intel/<div>bin/mpirun -np 100 ABYSS-P -k50 -q3  --coverage-hist=coverage.hist -s cattle-bubbles.fa  -o cattle-1.fa s_1_1_sequence.txt<br>[<a href="http://coe.iitd.ac.in:19807/" target="_blank">coe:19807</a>]
 [[62863,0],0] ORTE_ERROR_LOG: The system limit on number of pipes a 
process can open was reached in file base/iof_base_setup.c at line 107<br>
[<a href="http://coe.iitd.ac.in:19807/" target="_blank">coe.:19807</a>]
 [[62863,0],0] ORTE_ERROR_LOG: The system limit on number of pipes a 
process can open was reached in file odls_default_module.c at line 203<br>[<a href="http://coe.iitd.ac.in:19807/" target="_blank">coe.:19807</a>]
 [[62863,0],0] ORTE_ERROR_LOG: The system limit on number of network 
connections a process can open was reached in file oob_tcp.c at line 447<br>
--------------------------------------------------------------------------<br>Error: system limit exceeded on number of network connections that can be open<br><br>This can be resolved by setting the mca parameter opal_set_max_sys_limits to 1,<br>


increasing your limit descriptor setting (using limit or ulimit commands),<br>or asking the system administrator to increase the system limit.<br>--------------------------------------------------------------------------<br>


make: *** [cattle-1.fa] Error 1</div><br><br><br><font size="4"><u><b><br>When i submit the same job through qsub, i receive the following error:</b></u></font><br>$ qsub  -cwd -pe  orte 100 -o qsub.out -e qsub.err -b y -N  abyss `which 
mpirun` /home/genome/abyss/bin/ABYSS-P -k 50 s_1_1_sequence.txt -o av<br><br><br>[compute-0-19.local][[28273,1]<div>,125][btl_tcp_endpoint.c:636:mca_btl_tcp_endpoint_complete_connect] connect() to 173.16.255.231 failed: Connection refused (111)<br>


[compute-0-19.local][[28273,1],127][btl_tcp_endpoint.c:636:mca_btl_tcp_endpoint_complete_connect] connect() to 173.16.255.231 failed: Connection refused (111)<br>[compute-0-23.local][[28273,1],135][btl_tcp_endpoint.c:636:mca_btl_tcp_endpoint_complete_connect] connect() to 173.16.255.228 failed: Connection refused (111)<br>


[compute-0-23.local][[28273,1],133][btl_tcp_endpoint.c:636:mca_btl_tcp_endpoint_complete_connect] connect() to 173.16.255.228 failed: Connection refused (111)<br>[compute-0-4.local][[28273,1],113][btl_tcp_endpoint.c:636:mca_btl_tcp_endpoint_complete_connect] connect() to 173.16.255.231 failed: Connection refused (111)</div>

<br><br><br>Best Regards,<br>Ashwani<br><br><br><br></div></div>
_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></blockquote>
</div><br></div></div><br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></div><br>

