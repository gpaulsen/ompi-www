<font size=2 face="sans-serif">Hi Ashika,</font>
<br>
<br><font size=2 face="sans-serif">&nbsp; &nbsp; Yes you can serialize
the call using pthead mutex if you have created threads using pthreads.
Basically whatever thread libray you are using for thread creation provides
synchronization API's which you have to use here.</font>
<br>
<br><font size=2 face="sans-serif">OPAL_THREAD_LOCK and UNLOCK code is
also implemented using supported thread library on your platform(selected
by default during configure or use --with-threads).</font>
<br>
<br><font size=2 face="sans-serif">You can't use OPAL library as it is
not exported to outside MPI programming world.</font>
<br>
<br><font size=2 face="sans-serif">Regards<br>
<br>
Neeraj Chourasia (MTS)<br>
Computational Research Laboratories Ltd.<br>
(A wholly Owned Subsidiary of TATA SONS Ltd)<br>
B-101, ICC Trade Towers, Senapati Bapat Road<br>
Pune 411016 (Mah) INDIA<br>
(O) +91-20-6620 9863 &nbsp;(Fax) +91-20-6620 9862<br>
M: +91.9225520634<br>
</font>
<br>
<br>
<br>
<table width=100%>
<tr valign=top>
<td width=40%><font size=1 face="sans-serif"><b>Ashika Umanga Umagiliya
&lt;aumanga@biggjapan.com&gt;</b> </font>
<br><font size=1 face="sans-serif">Sent by: users-bounces@open-mpi.org</font>
<p><font size=1 face="sans-serif">09/18/2009 09:25 AM</font>
<table border>
<tr valign=top>
<td bgcolor=white>
<div align=center><font size=1 face="sans-serif">Please respond to<br>
Open MPI Users &lt;users@open-mpi.org&gt;</font></div></table>
<br>
<td width=59%>
<table width=100%>
<tr valign=top>
<td>
<div align=right><font size=1 face="sans-serif">To</font></div>
<td><font size=1 face="sans-serif">Open MPI Users &lt;users@open-mpi.org&gt;</font>
<tr valign=top>
<td>
<div align=right><font size=1 face="sans-serif">cc</font></div>
<td>
<tr valign=top>
<td>
<div align=right><font size=1 face="sans-serif">Subject</font></div>
<td><font size=1 face="sans-serif">Re: [OMPI users] Multi-threading &nbsp;with
OpenMPI ?</font></table>
<br>
<table>
<tr valign=top>
<td>
<td></table>
<br></table>
<br>
<br>
<br><tt><font size=2>Thanks Ralph,<br>
<br>
I have not much experience in this area.shall i use <br>
pthread_mutex_lock(*),*pthread_mutex_unlock() ..etc or following which
i <br>
saw in OpenMPI source :<br>
<br>
static opal_mutex_t ompi_lock;<br>
<br>
OPAL_THREAD_LOCK(&amp;ompi_lock);<br>
 &nbsp; //<br>
OPAL_THREAD_UNLOCK(&amp;ompi_lock);<br>
<br>
Thanks in advance,<br>
umanga<br>
<br>
Ralph Castain wrote:<br>
&gt; Only thing I can suggest is to place a thread lock around the call
to <br>
&gt; comm_spawn so that only one thread at a time can execute that <br>
&gt; function. The call to mpi_init_thread is fine - you just need to <br>
&gt; explicitly protect the call to comm_spawn.<br>
&gt;<br>
&gt;<br>
&gt; On Sep 17, 2009, at 7:44 PM, Ashika Umanga Umagiliya wrote:<br>
&gt;<br>
&gt;&gt; HI Jeff, Ralph,<br>
&gt;&gt;<br>
&gt;&gt; Yes, I call MPI_COMM_SPAWN in multiple threads simultaneously.<br>
&gt;&gt; Because I need to expose my parallel algorithm as a web service,
I <br>
&gt;&gt; need multiple clients connect and execute my logic as same time(ie
<br>
&gt;&gt; mutiple threads).<br>
&gt;&gt; For each client , a new thread is created (by Web service framework)
<br>
&gt;&gt; and inside the thread,MPI_Init_Thread() is called if the MPI hasnt
<br>
&gt;&gt; been initialized.<br>
&gt;&gt; The the thread calls MPI_COMM__SPAWN and create new processes.<br>
&gt;&gt;<br>
&gt;&gt; So ,if this is the case isn't there any workarounds ?<br>
&gt;&gt;<br>
&gt;&gt; Thanks in advance,<br>
&gt;&gt; umanga<br>
&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt; Jeff Squyres wrote:<br>
&gt;&gt;&gt; On Sep 16, 2009, at 9:53 PM, Ralph Castain wrote:<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Only the obvious, and not very helpful one: comm_spawn
isn't thread<br>
&gt;&gt;&gt;&gt; safe at this time. You'll need to serialize your requests
to that<br>
&gt;&gt;&gt;&gt; function.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; This is likely the cause of your issues if you are calling
<br>
&gt;&gt;&gt; MPI_COMM_SPAWN in multiple threads simultaneously. &nbsp;Can
you verify?<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; If not, we'll need to dig a little deeper to figure out what's
going <br>
&gt;&gt;&gt; on. &nbsp;But Ralph is right -- read up on the THREAD_MULTIPLE
<br>
&gt;&gt;&gt; constraints (check the OMPI README file) to see if that's
what's <br>
&gt;&gt;&gt; biting you.<br>
&gt;&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt; _______________________________________________<br>
&gt;&gt; users mailing list<br>
&gt;&gt; users@open-mpi.org<br>
&gt;&gt; </font></tt><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users"><tt><font size=2>http://www.open-mpi.org/mailman/listinfo.cgi/users</font></tt></a><tt><font size=2><br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; users@open-mpi.org<br>
&gt; </font></tt><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users"><tt><font size=2>http://www.open-mpi.org/mailman/listinfo.cgi/users</font></tt></a><tt><font size=2><br>
<br>
_______________________________________________<br>
users mailing list<br>
users@open-mpi.org<br>
</font></tt><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users"><tt><font size=2>http://www.open-mpi.org/mailman/listinfo.cgi/users</font></tt></a><tt><font size=2><br>
</font></tt>
<br><p>=====-----=====-----=====



Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. 

Internet communications cannot be guaranteed to be timely,
secure, error or virus-free. The sender does not accept liability
for any errors or omissions.Thank you

=====-----=====-----=====</p>

