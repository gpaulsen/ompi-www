<html><body><div style="color:#000; background-color:#fff; font-family:times new roman, new york, times, serif;font-size:12pt"><div>Hi ,Thank you For your reply.</div><div>I have some problem:</div><div>Q1:&nbsp; I setting 2 kinds&nbsp; mac.para.conf<br></div><div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (1) crs_base_snapshot_dir=/root/kidd_openMPI/Tmp<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; snapc_base_global_snapshot_dir=/root/kidd_openMPI/checkpoints</div><div><br></div><div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; My Master : /root/kidd_openMPI &nbsp; is My opempi-Installed Dir&nbsp; ,it is&nbsp; Shared by NFS .</div><div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <span id="result_box" class="short_text" lang="en"><span class="">Do I have</span> <span class="hps">to</span> <span class="hps">mount</span><span class="hps">&nbsp; a&nbsp;&nbsp;
 User_</span></span><span id="result_box" class="short_text" lang="en"><span class="">Account , </span></span><span id="result_box" class="short_text" lang="en"><span class="">Rather than a&nbsp; dir&nbsp; ?</span></span></div><div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br></div><div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br><span id="result_box" class="short_text" lang="en"><span class=""></span></span></div><div><span id="result_box" class="short_text" lang="en"><span class="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (2) snapc_base_store_in_place=0<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; crs_base_snapshot_dir= /tmp/OmpiStore/local<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; snapc_base_global_snapshot_dir= /tmp/OmpiStore/global</span></span></div><div><br><span id="result_box" class="short_text" lang="en"><span
 class=""></span></span></div><div><span id="result_box" class="short_text" lang="en"><span class="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this&nbsp; case&nbsp; ,I not use&nbsp; NFS&nbsp; in </span></span><span id="result_box" class="short_text" lang="en"><span class="">OmpiStore/local&nbsp; ＆</span></span><span id="result_box" class="short_text" lang="en"><span class=""> OmpiStore/local;</span></span></div><div><span id="result_box" class="short_text" lang="en"><span class="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; is it right ?</span></span></div><div><span id="result_box" class="short_text" lang="en"><span class="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (3)</span></span></div><div><span id="result_box" class="short_text" lang="en"><span class="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Do I setting .openmpi in all-Node ,or just
 seting on Master .</span></span></div><div><span id="result_box" class="short_text" lang="en"><span class="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br></span></span></div><div><span id="result_box" class="short_text" lang="en"><span class="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (4)&nbsp; I install openmpi&nbsp; in root ,should I move&nbsp;&nbsp; to&nbsp; </span></span><span id="result_box" class="short_text" lang="en"><span class="">General-user-account ? <br></span></span></div><div><span id="result_box" class="short_text" lang="en"><span class="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br></span></span></div>  <div style="font-family: times new roman, new york, times, serif; font-size: 12pt;"> <div style="font-family: times new roman, new york, times, serif; font-size: 12pt;"> <div dir="ltr"> <font face="Arial" size="2"> <hr size="1">  <b><span
 style="font-weight:bold;">寄件者：</span></b> Josh Hursey &lt;jjhursey@open-mpi.org&gt;<br> <b><span style="font-weight: bold;">收件者：</span></b> Open MPI Users &lt;users@open-mpi.org&gt; <br> <b><span style="font-weight: bold;">寄件日期：</span></b> 2012/4/24 (週二) 10:58 PM<br> <b><span style="font-weight: bold;">主旨：</span></b> Re: [OMPI users] Ompi-restart failed and process migration<br> </font> </div> <br>On Tue, Apr 24, 2012 at 10:10 AM, kidd &lt;<a ymailto="mailto:q19860103@yahoo.com.tw" href="mailto:q19860103@yahoo.com.tw">q19860103@yahoo.com.tw</a>&gt; wrote:<br>&gt; Hi ,Thank you For your reply.<br>&gt; &nbsp;but I still failed. I must add -x&nbsp; LD_LIBRARY_PATH<br>&gt; this is my&nbsp; All Setting ;<br>&gt; 1) Master-Node(cuda07)&nbsp; &amp;&nbsp; Slaves Node(cuda08) :<br>&gt; &nbsp;&nbsp; Configure:<br>&gt; &nbsp;&nbsp; ./configure --prefix=/root/kidd_openMPI&nbsp; --with-ft=cr<br>&gt; --enable-ft-thread&nbsp;
 --with-blcr=/usr/local/BLCR<br>&gt; &nbsp;&nbsp; --with-blcr-libdir=/usr/local/BLCR/lib&nbsp; --enable-mpirun-prefix-by-default<br>&gt; &nbsp;&nbsp; --enable-static --enable-shared&nbsp; --enable-opal-progress-threads; make ;<br>&gt; make install;<br>&gt;<br>&gt; &nbsp; (2) Path &amp;&amp; LD_PATH:<br>&gt; &nbsp;&nbsp;&nbsp; #In /etc/profile<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp; ==&gt;export PATH=$PATH:/usr/local/BLCR/bin ;<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp; ==&gt;export&nbsp; LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/BLCR/lib<br>&gt; &nbsp;&nbsp; #In ~/.bashrc<br>&gt; &nbsp;&nbsp;&nbsp; ==&gt;export PATH=$PATH:/root/kidd_openMPI/bin<br>&gt; &nbsp;&nbsp;&nbsp; ==&gt;export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/kidd_openMPI/lib<br>&gt;<br>&gt; &nbsp;&nbsp; (3) Compiler &amp;&amp; Running:<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ==&gt; ~/kidd_openMPI/NBody_TEST#&nbsp; mpicc -o&nbsp; TEST -DDEFSIZE=5000&nbsp; \<br>&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
 &nbsp; -DDEF_PROC=2 MPINbodyOMP.c<br>&gt;<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ==&gt; &nbsp; root@cuda07:~/kidd_openMPI/NBody_TEST# mpirun -hostfile Hosts<br>&gt; -np 2 TEST<br>&gt;<br>&gt; &nbsp; TEST: error while loading shared libraries: libcr.so.0: cannot open shared<br>&gt; object file: No such file or directory<br><br><br>I still think the core problem is with the search path given this<br>message. Open MPI is trying to load BLCR's libcr.so.0, and it is not<br>finding the library in the LD_LIBRARY_PATH search path. Something is<br>still off in the backend nodes. Try adding the BLCR<br>PATH/LD_LIBRARY_PATH to your .bashrc instead of the profile.<br><br><br>&gt;<br>&gt; &nbsp;&nbsp; ==&gt; I make sure&nbsp; Master and Slave&nbsp; have&nbsp; same Install and&nbsp; same Path .<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; I&nbsp; let slave-node&nbsp; using cr_restart&nbsp;&nbsp; restart a contextfile ,the<br>&gt; contextfile
 checked by Master ,so<br>&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; Blcr&nbsp; can work;<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; but it still&nbsp; cannot open shared object file-&gt;libcr.so.0:<br><br><br>So BLCR is giving this error?<br><br>&gt;<br>&gt; &nbsp; (4)&nbsp; if&nbsp; &nbsp; I pass&nbsp; -x LD_LIBRARY_PATH<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ( local mount )<br>&gt; &nbsp; &nbsp; &nbsp; &nbsp; (4-1)My mca-params.conf(In Master )<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ==&gt; snapc_base_store_in_place=0<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; crs_base_snapshot_dir=/tmp/OmpiStore/local<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; snapc_base_global_snapshot_dir=/tmp/OmpiStore/global<br>&gt;<br>&gt; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; step
 1: mpirun -hostfile Hosts -np 2 -x LD_LIBRARY_PATH -am<br>&gt; ft-enable-cr ./TEST<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; step 2: ompi-checkpoint -term Pid ( I use another command)<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; step 3:<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cd&nbsp; /tmp/OmpiStore/global<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ==&gt; ompi-restart&nbsp;&nbsp;&nbsp; Ompi_xxxxPid.ckpt .&nbsp;&nbsp; (all process<br>&gt; Only Restart on Master)<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ==&gt; ompi-restart&nbsp;&nbsp;&nbsp; --hostfile Host&nbsp; Ompi_xxxxPid.ckpt .<br>&gt; &nbsp;Error-Message:<br>&gt; root@cuda07:/tmp/OmpiStore/global#<br>&gt; &nbsp; ompi-restart --preload -hostfile Hosts
 ompi_global_snapshot_8873.ckpt/<br>&gt; Warning: Permanently added the RSA host key for IP address '192.168.1.10' to<br>&gt; the list of known hosts.<br>&gt; --------------------------------------------------------------------------<br>&gt; WARNING: Remote peer ([[37567,0],1]) failed to preload a file.<br>&gt; Exit Status: 256<br>&gt; Local&nbsp; File: /tmp/OmpiStore/global/./opal_snapshot_1.ckpt<br>&gt; Remote File:<br>&gt; /tmp/OmpiStore/global/ompi_global_snapshot_8873.ckpt/0/opal_snapshot_1.ckpt<br>&gt; Command:<br>&gt; &nbsp; scp&nbsp; -r<br>&gt; cuda07:/tmp/OmpiStore/global/ompi_global_snapshot_8873.ckpt/0/opal_snapshot_1.ckpt<br>&gt; \<br>&gt; &nbsp;&nbsp; /tmp/OmpiStore/global/./opal_snapshot_1.ckpt<br>&gt;<br>&gt; Will continue attempting to launch the process(es).<br>&gt; --------------------------------------------------------------------------<br>&gt; [cuda08:08899] Error: Unable to access the path [./opal_snapshot_1.ckpt]!<br>&gt;
 --------------------------------------------------------------------------<br>&gt; Error: The filename (opal_snapshot_1.ckpt) is invalid because either you<br>&gt; have not provided a filename<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; or provided an invalid filename.<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Please see --help for usage.<br>&gt; --------------------------------------------------------------------------<br>&gt; I am 0 loop=40&nbsp; in #pragma&nbsp; time1=446.558860<br>&gt; ^Cmpirun: killing job...<br>&gt; /*---------------------------------------------------------------------------------------------------------------------------------------*/<br><br>It looks like the MCA parameters are not being set correctly. Check to<br>make sure that the mca-params.conf file on each nodes matches. Is your<br>$HOME directory mounted on a shared file system? If so, then try to<br>just store the checkpoints to the $HOME for now, until the rest of
 the<br>functionality is working properly.<br><br><br>&gt; &nbsp;(5) A couple solutions:<br>&gt;<br>&gt;&gt; - have the PATH and LD_LIBRARY_PATH set the same on all nodes<br>&gt;&gt; - have ompi-restart pass the -x parameter to the underlying mpirun by<br>&gt;&gt; using the -mpirun_opts command line switch:<br>&gt;&gt; &nbsp; ompi-restart --mpirun_opts "-x LD_LIBRARY_PATH" ..<br>&gt;<br>&gt; &nbsp; &nbsp;&nbsp; How to Using&nbsp;&nbsp; --mpirun_opts ?<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp; this is my command ==&gt;<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp; ompi-restart --mpirun_opts&nbsp; -x&nbsp; LD_LIBRARY_PATH&nbsp; -hostfile Hosts \<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp; ompi_global_snapshot_8873.ckpt/<br>&gt; &nbsp;&nbsp;&nbsp;&nbsp; but it is Error.<br><br><br>Use quotes around the mpirun specific options:<br> ompi-restart --mpirun_opts&nbsp; "-x&nbsp; LD_LIBRARY_PATH"&nbsp; -hostfile Hosts<br>ompi_global_snapshot_8873.ckpt<br>or<br> ompi-restart --mpirun_opts&nbsp;
 "-x&nbsp; LD_LIBRARY_PATH -hostfile Hosts"<br>ompi_global_snapshot_8873.ckpt<br><br>-- Josh<br><br>&gt;<br>&gt; &nbsp;thanks.<br>&gt; ________________________________<br>&gt; 寄件者： Josh Hursey &lt;<a ymailto="mailto:jjhursey@open-mpi.org" href="mailto:jjhursey@open-mpi.org">jjhursey@open-mpi.org</a>&gt;<br>&gt; 收件者： Open MPI Users &lt;<a ymailto="mailto:users@open-mpi.org" href="mailto:users@open-mpi.org">users@open-mpi.org</a>&gt;<br>&gt; 寄件日期： 2012/4/24 (週二) 3:23 AM<br>&gt;<br>&gt; 主旨： Re: [OMPI users] Ompi-restart failed and process migration<br>&gt;<br>&gt; On Mon, Apr 23, 2012 at 2:45 PM, kidd &lt;<a ymailto="mailto:q19860103@yahoo.com.tw" href="mailto:q19860103@yahoo.com.tw">q19860103@yahoo.com.tw</a>&gt; wrote:<br>&gt;&gt; Hi ,Thank you For your reply.<br>&gt;&gt;<br>&gt;&gt; I have some problems：<br>&gt;&gt; (1)<br>&gt;&gt; Now ,In the my platform , all nodes have the same path and<br>&gt;&gt;
 LD_LIBRARY_PATH.<br>&gt;&gt; &nbsp;I set in .bashrc<br>&gt;&gt;<br>&gt;&gt; /--------------------------------------------------------------------------------/<br>&gt;&gt; #BLCR<br>&gt;&gt; export PATH=$PATH:/usr/local/BLCR/bin<br>&gt;&gt; export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/BLCR/lib<br>&gt;&gt; #openMPI<br>&gt;&gt; export PATH=$PATH:/root/kidd_openMPI/bin<br>&gt;&gt; export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/kidd_openMPI/lib<br>&gt;&gt;<br>&gt;&gt; /-------------------------------------------------------------------------------------------/<br>&gt;&gt; but ,when I&nbsp; running&nbsp; mpirun&nbsp; , I have to add&nbsp; " -x&nbsp; LD_LIBRARY_PATH" ,or<br>&gt;&gt; it can't&nbsp; run<br>&gt;&gt; &nbsp;example:&nbsp; mpirun -hostfile hosts&nbsp; -np&nbsp; 2&nbsp; ./TEST .<br>&gt;&gt; &nbsp;Error Message==&gt;<br>&gt;&gt; ./TEST: error while loading shared libraries: libcr.so.0: cannot open<br>&gt;&gt; shared<br>&gt;&gt; object file: No
 such file or directory<br>&gt;<br>&gt; It sounds like something is still not quite right with your<br>&gt; environment and system setup. If you have set the PATH and<br>&gt; LD_LIBRARY_PATH appropriately on all nodes then you should not have to<br>&gt; pass the "-x LD_LIBRARY_PATH" option to mpirun. Additionally, the<br>&gt; error you are seeing is from BLCR. That error seems to indicate that<br>&gt; BLCR is not installed correctly on all nodes.<br>&gt;<br>&gt; Some things to look into (in this order):<br>&gt; 1) Make sure that you have BLCR and Open MPI installed in the same<br>&gt; location on all machines.<br>&gt; 2) Make sure that BLCR works on all machines by checkpointing and<br>&gt; restarting a single process program<br>&gt; 3) Make sure that Open MPI works on all machines -without-<br>&gt; checkpointing, and without passing the -x option.<br>&gt; 4) Checkpoint/restart an MPI job<br>&gt;<br>&gt;<br>&gt;&gt; &nbsp;(2)&nbsp; BLCR need to unify
 linux-kernel&nbsp; of all the Node ?<br>&gt;&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Now ,I reset all&nbsp; Node.(using Ubuntu 10.04)<br>&gt;<br>&gt; I do not understand what you are trying to ask here. Please rephrase.<br>&gt;<br>&gt;<br>&gt;&gt; &nbsp;(3)<br>&gt;&gt; &nbsp; &nbsp; &nbsp; Now , My porgram using&nbsp; DLL . I implements some DLL&nbsp; ,MPI-Program<br>&gt;&gt; calls DLLs .<br>&gt;&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ompi can check/Restart&nbsp; Program contains&nbsp; DLL ?<br>&gt;<br>&gt; I do not understand what you are trying to ask here. Please rephrase.<br>&gt;<br>&gt; -- Josh<br>&gt;<br>&gt;<br>&gt;&gt; ________________________________<br>&gt;&gt;<br>&gt;&gt; ________________________________<br>&gt;&gt; 寄件者： Josh Hursey &lt;<a ymailto="mailto:jjhursey@open-mpi.org" href="mailto:jjhursey@open-mpi.org">jjhursey@open-mpi.org</a>&gt;<br>&gt;&gt; 收件者： Open MPI Users &lt;<a ymailto="mailto:users@open-mpi.org"
 href="mailto:users@open-mpi.org">users@open-mpi.org</a>&gt;<br>&gt;&gt; 寄件日期： 2012/4/23 (週一) 10:51 PM<br>&gt;&gt; 主旨： Re: [OMPI users] Ompi-restart failed and process migration<br>&gt;&gt;<br>&gt;&gt; I wonder if the LD_LIBRARY_PATH is not being set properly upon<br>&gt;&gt; restart. In your mpirun you pass the '-x LD_LIBRARY_PATH'.<br>&gt;&gt; ompi-restart will not pass that variable along for you, so if you are<br>&gt;&gt; using that to set the BLCR path this might be your problem.<br>&gt;&gt;<br>&gt;&gt; A couple solutions:<br>&gt;&gt; - have the PATH and LD_LIBRARY_PATH set the same on all nodes<br>&gt;&gt; - have ompi-restart pass the -x parameter to the underlying mpirun by<br>&gt;&gt; using the -mpirun_opts command line switch:<br>&gt;&gt; &nbsp; ompi-restart --mpirun_opts "-x LD_LIBRARY_PATH" ...<br>&gt;&gt;<br>&gt;&gt; Yes. ompi-restart will let you checkpoint a process on one node and<br>&gt;&gt; restart it on another. You
 will have to restart the whole application<br>&gt;&gt; since the ompi-migration operation is not available in the 1.5 series.<br>&gt;&gt;<br>&gt;&gt; -- Josh<br>&gt;&gt;<br>&gt;&gt; On Sat, Apr 21, 2012 at 4:11 AM, kidd &lt;<a ymailto="mailto:q19860103@yahoo.com.tw" href="mailto:q19860103@yahoo.com.tw">q19860103@yahoo.com.tw</a>&gt; wrote:<br>&gt;&gt;&gt; Hi all,<br>&gt;&gt;&gt; I have Some problems,I wana check/Restart Multiple process on 2 node.<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;&nbsp; My environment:<br>&gt;&gt;&gt;&nbsp; BLCR= 0.8.4&nbsp;&nbsp; , openMPI= 1.5.5&nbsp; , OS = ubuntu 11.04<br>&gt;&gt;&gt; I have 2 Node :<br>&gt;&gt;&gt; &nbsp;N05(Master ,it have NFS shared file system),N07(slave<br>&gt;&gt;&gt;&nbsp; ,mount Master-Node).<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;&nbsp; My configure format=./configure --prefix=/root/kidd_openMPI<br>&gt;&gt;&gt;&nbsp; --with-ft=cr --enable-ft-thread&nbsp; --with-blcr=/usr/local/BLCR<br>&gt;&gt;&gt;&nbsp;
 --with-blcr-libdir=/usr/local/BLCR/lib --enable-mpirun-prefix-by-default<br>&gt;&gt;&gt;&nbsp; --enable-static --enable-shared --enable-opal-multi-threads;<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;&nbsp; I had also set&nbsp; ~/.openmpi/mca-params.conf-&gt;<br>&gt;&gt;&gt; &nbsp;&nbsp;&nbsp; crs_base_snapshot_dir=/root/kidd_openMPI/Tmp<br>&gt;&gt;&gt; &nbsp;&nbsp;&nbsp; snapc_base_global_snapshot_dir=/root/kidd_openMPI/checkpoints.<br>&gt;&gt;&gt;<br>&gt;&gt;&gt; the dir-&gt;kidd_openMPI is my nfs shared dir.<br>&gt;&gt;&gt;<br>&gt;&gt;&gt; &nbsp;My Command :<br>&gt;&gt;&gt;&nbsp; 1. mpicc -o TEST -DDEFSIZE=3000 -DDEF_PROC=2 -fopenmp MPIMatrix.c<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;&nbsp; &nbsp;2. mpirun -hostfile Hosts -am ft-enable-cr -x LD_LIBRARY_PATH<br>&gt;&gt;&gt;&nbsp; &nbsp; &nbsp; -np 2 ./TEST .<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;&nbsp; I can restart process-0 on Master,but process-1 on N07 was failed.<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;&nbsp; I checked my Node,it
 does not install the prelink,<br>&gt;&gt;&gt;&nbsp; so the error(restart-failed) is caused by other reasons.<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;&nbsp; Error Message--&gt;<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;<br>&gt;&gt;&gt; --------------------------------------------------------------------------<br>&gt;&gt;&gt;&nbsp; &nbsp;root@cuda05:~/kidd_openMPI/checkpoints#<br>&gt;&gt;&gt;&nbsp; ompi-restart -hostfile Hosts ompi_global_snapshot_2892.ckpt/<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;<br>&gt;&gt;&gt; --------------------------------------------------------------------------<br>&gt;&gt;&gt;&nbsp; &nbsp;&nbsp; Error: BLCR was not able to restart the process because exec failed.<br>&gt;&gt;&gt;&nbsp; &nbsp;&nbsp;&nbsp; Check the installation of BLCR on all of the machines in your<br>&gt;&gt;&gt;&nbsp; &nbsp;&nbsp;&nbsp; system. The following information may be of help:<br>&gt;&gt;&gt;&nbsp; &nbsp;Return Code : -1<br>&gt;&gt;&gt;&nbsp; &nbsp;BLCR Restart Command :
 cr_restart<br>&gt;&gt;&gt;&nbsp; &nbsp;Restart Command Line : cr_restart<br>&gt;&gt;&gt;&nbsp; /root/kidd_openMPI/checkpoints/ompi_global_snapshot_2892.ckpt/0/<br>&gt;&gt;&gt;&nbsp; opal_snapshot_1.ckpt/ompi_blcr_context.2704<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;<br>&gt;&gt;&gt; --------------------------------------------------------------------------<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;<br>&gt;&gt;&gt; --------------------------------------------------------------------------<br>&gt;&gt;&gt;&nbsp; Error: Unable to obtain the proper restart command to restart from the<br>&gt;&gt;&gt;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; checkpoint file (opal_snapshot_1.ckpt). Returned -1.<br>&gt;&gt;&gt;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Check the installation of the blcr checkpoint/restart service<br>&gt;&gt;&gt;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; on all of the machines in your system.<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;
 ###########################################################################<br>&gt;&gt;&gt;&nbsp; problem 2: I wana let MPI-process can migration to another Node.<br>&gt;&gt;&gt;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if Ompi-Restart&nbsp; Multiple-Node can be successful.<br>&gt;&gt;&gt;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Can restart in another new node, rather than the original node?<br>&gt;&gt;&gt;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; example:<br>&gt;&gt;&gt;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; checkpoint (node1,node2,node3),then restart(node1,node3,node4).<br>&gt;&gt;&gt;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; or just restart(node1,node3(2-process) ).<br>&gt;&gt;&gt;<br>&gt;&gt;&gt; &nbsp;&nbsp; Please help me , thanks .<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;<br>&gt;&gt;&gt; _______________________________________________<br>&gt;&gt;&gt; users mailing list<br>&gt;&gt;&gt; <a ymailto="mailto:users@open-mpi.org"
 href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>&gt;&gt;&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>&gt;&gt;<br>&gt;&gt;<br>&gt;&gt; --<br>&gt;&gt; Joshua Hursey<br>&gt;&gt; Postdoctoral Research Associate<br>&gt;&gt; Oak Ridge National Laboratory<br>&gt;&gt; <a href="http://users.nccs.gov/%7Ejjhursey" target="_blank">http://users.nccs.gov/~jjhursey</a><br>&gt;&gt;<br>&gt;&gt; _______________________________________________<br>&gt;&gt; users mailing list<br>&gt;&gt; <a ymailto="mailto:users@open-mpi.org" href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>&gt;&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>&gt;&gt;<br>&gt;&gt;<br>&gt;&gt;<br>&gt;&gt; _______________________________________________<br>&gt;&gt; users mailing list<br>&gt;&gt; <a
 ymailto="mailto:users@open-mpi.org" href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>&gt;&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>&gt;<br>&gt;<br>&gt;<br>&gt; --<br>&gt; Joshua Hursey<br>&gt; Postdoctoral Research Associate<br>&gt; Oak Ridge National Laboratory<br>&gt; <a href="http://users.nccs.gov/%7Ejjhursey" target="_blank">http://users.nccs.gov/~jjhursey</a><br>&gt;<br>&gt; _______________________________________________<br>&gt; users mailing list<br>&gt; <a ymailto="mailto:users@open-mpi.org" href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>&gt;<br>&gt;<br>&gt; _______________________________________________<br>&gt; users mailing list<br>&gt; <a ymailto="mailto:users@open-mpi.org"
 href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br><br><br>-- <br>Joshua Hursey<br>Postdoctoral Research Associate<br>Oak Ridge National Laboratory<br><a href="http://users.nccs.gov/%7Ejjhursey" target="_blank">http://users.nccs.gov/~jjhursey</a><br><br>_______________________________________________<br>users mailing list<br><a ymailto="mailto:users@open-mpi.org" href="mailto:users@open-mpi.org">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br><br> </div> </div>  </div></body></html>
