<html>
  <head>
    <meta content="text/html; charset=windows-1252"
      http-equiv="Content-Type">
  </head>
  <body bgcolor="#FFFFFF" text="#000000">
    <div class="moz-cite-prefix">It's likely a BIOS bug.<br>
      But I can't say more until you send the relevant data as explained
      earlier.<br>
      Brice<br>
      <br>
      <br>
      <br>
      Le 20/12/2014 18:10, Sergio Manzetti a écrit :<br>
    </div>
    <blockquote cite="mid:DUB126-W4291B4F248562E7137ED85E3680@phx.gbl"
      type="cite">
      <style><!--
.hmmessage P
{
margin:0px;
padding:0px
}
body.hmmessage
{
font-size: 12pt;
font-family:Calibri
}
--></style>
      <div dir="ltr">Dear Brice, the BIOS is the most latest. However, i
        wonder if this could be  a hardware error, as openmpi sources
        claim.  Is there any way to find out if this is a hardware
        error?<br>
        <br>
        Thanks<br>
        <br>
        <br>
        <div>&gt; From: <a class="moz-txt-link-abbreviated" href="mailto:users-request@open-mpi.org">users-request@open-mpi.org</a><br>
          &gt; Subject: users Digest, Vol 3074, Issue 1<br>
          &gt; To: <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
          &gt; Date: Sat, 20 Dec 2014 12:00:02 -0500<br>
          &gt; <br>
          &gt; Send users mailing list submissions to<br>
          &gt; <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
          &gt; <br>
          &gt; To subscribe or unsubscribe via the World Wide Web, visit<br>
          &gt; <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
          &gt; or, via email, send a message with subject or body 'help'
          to<br>
          &gt; <a class="moz-txt-link-abbreviated" href="mailto:users-request@open-mpi.org">users-request@open-mpi.org</a><br>
          &gt; <br>
          &gt; You can reach the person managing the list at<br>
          &gt; <a class="moz-txt-link-abbreviated" href="mailto:users-owner@open-mpi.org">users-owner@open-mpi.org</a><br>
          &gt; <br>
          &gt; When replying, please edit your Subject line so it is
          more specific<br>
          &gt; than "Re: Contents of users digest..."<br>
          &gt; <br>
          &gt; <br>
          &gt; Today's Topics:<br>
          &gt; <br>
          &gt; 1. Re: Deadlock in OpenMPI 1.8.3 and PETSc 3.4.5<br>
          &gt; (Jeff Squyres (jsquyres))<br>
          &gt; 2. Hwloc error with Openmpi 1.8.3 on AMD 64 (Sergio
          Manzetti)<br>
          &gt; 3. Re: Hwloc error with Openmpi 1.8.3 on AMD 64 (Brice
          Goglin)<br>
          &gt; 4. best function to send data (Diego Avesani)<br>
          &gt; <br>
          &gt; <br>
          &gt;
          ----------------------------------------------------------------------<br>
          &gt; <br>
          &gt; Message: 1<br>
          &gt; Date: Fri, 19 Dec 2014 19:26:58 +0000<br>
          &gt; From: "Jeff Squyres (jsquyres)"
          <a class="moz-txt-link-rfc2396E" href="mailto:jsquyres@cisco.com">&lt;jsquyres@cisco.com&gt;</a><br>
          &gt; To: "Open MPI User's List" <a class="moz-txt-link-rfc2396E" href="mailto:users@open-mpi.org">&lt;users@open-mpi.org&gt;</a><br>
          &gt; Cc: <a class="moz-txt-link-rfc2396E" href="mailto:petsc-maint@mcs.anl.gov">"petsc-maint@mcs.anl.gov"</a>
          <a class="moz-txt-link-rfc2396E" href="mailto:petsc-maint@mcs.anl.gov">&lt;petsc-maint@mcs.anl.gov&gt;</a><br>
          &gt; Subject: Re: [OMPI users] Deadlock in OpenMPI 1.8.3 and
          PETSc 3.4.5<br>
          &gt; Message-ID:
          <a class="moz-txt-link-rfc2396E" href="mailto:027AB453-DE85-4F08-BDD7-A676CA90E239@cisco.com">&lt;027AB453-DE85-4F08-BDD7-A676CA90E239@cisco.com&gt;</a><br>
          &gt; Content-Type: text/plain; charset="us-ascii"<br>
          &gt; <br>
          &gt; On Dec 19, 2014, at 10:44 AM, George Bosilca
          <a class="moz-txt-link-rfc2396E" href="mailto:bosilca@icl.utk.edu">&lt;bosilca@icl.utk.edu&gt;</a> wrote:<br>
          &gt; <br>
          &gt; &gt; Regarding your second point, while I do tend to
          agree that such issue is better addressed in the MPI Forum,
          the last attempt to fix this was certainly not a resounding
          success.<br>
          &gt; <br>
          &gt; Yeah, fair enough -- but it wasn't a failure, either. It
          could definitely be moved forward, but it will take
          time/effort, which I unfortunately don't have. I would be
          willing, however, to spin up someone who *does* have
          time/effort available to move the proposal forward.<br>
          &gt; <br>
          &gt; &gt; Indeed, there is a slight window of opportunity for
          inconsistencies in the recursive behavior.<br>
          &gt; <br>
          &gt; You're right; it's a small window in the threading case,
          but a) that's the worst kind :-), and b) the non-threaded case
          is actually worse (because the global state can change from
          underneath the loop).<br>
          &gt; <br>
          &gt; &gt; But the inconsistencies were already in the code,
          especially in the single threaded case. As we never received
          any complaints related to this topic I did not deemed
          interesting to address them with my last commit. Moreover, the
          specific behavior needed by PETSc is available in Open MPI
          when compiled without thread support, as the only thing that
          "protects" the attributes is that global mutex.<br>
          &gt; <br>
          &gt; Mmmm. Ok, I see your point. But this is a (very) slippery
          slope.<br>
          &gt; <br>
          &gt; &gt; For example, in ompi_attr_delete_all(), it gets the
          count of all attributes and then loops &lt;count&gt; times to
          delete each attribute. But each attribute callback can now
          insert or delete attributes on that entity. This can mean that
          the loop can either fail to delete an attribute (because some
          attribute callback already deleted it) or fail to delete *all*
          attributes (because some attribute callback added more).<br>
          &gt; &gt; <br>
          &gt; &gt; To be extremely precise the deletion part is always
          correct<br>
          &gt; <br>
          &gt; ...as long as the hash map is not altered from the
          application (e.g., by adding or deleting another attribute
          during a callback).<br>
          &gt; <br>
          &gt; I understand that you mention above that you're not
          worried about this case. I'm just picking here because there
          is quite definitely a case where the loop is *not* correct.
          PETSc apparently doesn't trigger this badness, but... like I
          said above, it's a (very) slippery slope.<br>
          &gt; <br>
          &gt; &gt; as it copies the values to be deleted into a
          temporary array before calling any callbacks (and before
          releasing the mutex), so we only remove what was in the object
          attribute hash when the function was called. Don't
          misunderstand we have an extremely good reason to do it this
          way, we need to call the callbacks in the order in which they
          were created (mandated by the MPI standard).<br>
          &gt; &gt; <br>
          &gt; &gt; ompi_attr_copy_all() has similar problems -- in
          general, the hash that it is looping over can change
          underneath it.<br>
          &gt; &gt; <br>
          &gt; &gt; For the copy it is a little bit more tricky, as the
          calling order is not imposed. Our peculiar implementation of
          the hash table (with array) makes the code work, with a single
          (possible minor) exception when the hash table itself is grown
          between 2 calls. However, as stated before this issue was
          already present in the code in single threaded cases for
          years. Addressing it is another 2 line patch, but I leave this
          exercise to an interested reader.<br>
          &gt; <br>
          &gt; Yeah, thanks for that. :-)<br>
          &gt; <br>
          &gt; To be clear: both the copy and the delete code could be
          made thread safe. I just don't think we should be encouraging
          users to be exercising undefined / probably not-portable MPI
          code.<br>
          &gt; <br>
          &gt; -- <br>
          &gt; Jeff Squyres<br>
          &gt; <a class="moz-txt-link-abbreviated" href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a><br>
          &gt; For corporate legal information go to:
          <a class="moz-txt-link-freetext" href="http://www.cisco.com/web/about/doing_business/legal/cri/">http://www.cisco.com/web/about/doing_business/legal/cri/</a><br>
          &gt; <br>
          &gt; <br>
          &gt; <br>
          &gt; ------------------------------<br>
          &gt; <br>
          &gt; Message: 2<br>
          &gt; Date: Fri, 19 Dec 2014 20:58:46 +0100<br>
          &gt; From: Sergio Manzetti <a class="moz-txt-link-rfc2396E" href="mailto:sergio.manzetti@outlook.com">&lt;sergio.manzetti@outlook.com&gt;</a><br>
          &gt; To: <a class="moz-txt-link-rfc2396E" href="mailto:users@open-mpi.org">"users@open-mpi.org"</a> <a class="moz-txt-link-rfc2396E" href="mailto:users@open-mpi.org">&lt;users@open-mpi.org&gt;</a><br>
          &gt; Subject: [OMPI users] Hwloc error with Openmpi 1.8.3 on
          AMD 64<br>
          &gt; Message-ID:
          <a class="moz-txt-link-rfc2396E" href="mailto:DUB126-W2190E22E21596A1B834CF4E36B0@phx.gbl">&lt;DUB126-W2190E22E21596A1B834CF4E36B0@phx.gbl&gt;</a><br>
          &gt; Content-Type: text/plain; charset="iso-8859-1"<br>
          &gt; <br>
          &gt; <br>
          &gt; <br>
          &gt; <br>
          &gt; <br>
          &gt; <br>
          &gt; Dear all, when trying to run NWchem with openmpi, I get
          this error.<br>
          &gt; <br>
          &gt; <br>
          &gt; <br>
          &gt;
****************************************************************************<br>
          &gt; * Hwloc has encountered what looks like an error from the
          operating system.<br>
          &gt; *<br>
          &gt; * object intersection without inclusion!<br>
          &gt; * Error occurred in topology.c line 594<br>
          &gt; *<br>
          &gt; * Please report this error message to the hwloc user's
          mailing list,<br>
          &gt; * along with the output from the hwloc-gather-topology.sh
          script.<br>
          &gt; <br>
          &gt; Is there any rationale for solving this?<br>
          &gt; <br>
          &gt; Thanks<br>
          &gt; <br>
          &gt; -------------- next part --------------<br>
          &gt; HTML attachment scrubbed and removed<br>
          &gt; <br>
          &gt; ------------------------------<br>
          &gt; <br>
          &gt; Message: 3<br>
          &gt; Date: Fri, 19 Dec 2014 21:13:19 +0100<br>
          &gt; From: Brice Goglin <a class="moz-txt-link-rfc2396E" href="mailto:Brice.Goglin@inria.fr">&lt;Brice.Goglin@inria.fr&gt;</a><br>
          &gt; To: Open MPI Users <a class="moz-txt-link-rfc2396E" href="mailto:users@open-mpi.org">&lt;users@open-mpi.org&gt;</a><br>
          &gt; Subject: Re: [OMPI users] Hwloc error with Openmpi 1.8.3
          on AMD 64<br>
          &gt; Message-ID: <a class="moz-txt-link-rfc2396E" href="mailto:549486DF.50405@inria.fr">&lt;549486DF.50405@inria.fr&gt;</a><br>
          &gt; Content-Type: text/plain; charset="windows-1252"<br>
          &gt; <br>
          &gt; Hello,<br>
          &gt; <br>
          &gt; The rationale is to read the message and do what it says
          :)<br>
          &gt; <br>
          &gt; Have a look at<br>
          &gt;
          <a class="moz-txt-link-abbreviated" href="http://www.open-mpi.org/projects/hwloc/doc/v1.10.0/a00028.php#faq_os_error">www.open-mpi.org/projects/hwloc/doc/v1.10.0/a00028.php#faq_os_error</a><br>
          &gt; Try upgrading your BIOS and kernel.<br>
          &gt; <br>
          &gt; Otherwise install hwloc and send the output (tarball) of<br>
          &gt; hwloc-gather-topology to hwloc-users (not to OMPI users).<br>
          &gt; <br>
          &gt; thanks<br>
          &gt; Brice<br>
          &gt; <br>
          &gt; <br>
          &gt; <br>
          &gt; Le 19/12/2014 20:58, Sergio Manzetti a ?crit :<br>
          &gt; &gt;<br>
          &gt; &gt;<br>
          &gt; &gt; Dear all, when trying to run NWchem with openmpi, I
          get this error.<br>
          &gt; &gt; <br>
          &gt; &gt; <br>
          &gt; &gt; <br>
          &gt; &gt;
****************************************************************************<br>
          &gt; &gt; * Hwloc has encountered what looks like an error
          from the operating<br>
          &gt; &gt; system.<br>
          &gt; &gt; *<br>
          &gt; &gt; * object intersection without inclusion!<br>
          &gt; &gt; * Error occurred in topology.c line 594<br>
          &gt; &gt; *<br>
          &gt; &gt; * Please report this error message to the hwloc
          user's mailing list,<br>
          &gt; &gt; * along with the output from the
          hwloc-gather-topology.sh script.<br>
          &gt; &gt; <br>
          &gt; &gt; Is there any rationale for solving this?<br>
          &gt; &gt; <br>
          &gt; &gt; Thanks<br>
          &gt; &gt;<br>
          &gt; &gt;<br>
          &gt; &gt; _______________________________________________<br>
          &gt; &gt; users mailing list<br>
          &gt; &gt; <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
          &gt; &gt; Subscription:
          <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
          &gt; &gt; Link to this post:
          <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2014/12/26045.php">http://www.open-mpi.org/community/lists/users/2014/12/26045.php</a><br>
          &gt; <br>
          &gt; -------------- next part --------------<br>
          &gt; HTML attachment scrubbed and removed<br>
          &gt; <br>
          &gt; ------------------------------<br>
          &gt; <br>
          &gt; Message: 4<br>
          &gt; Date: Fri, 19 Dec 2014 23:56:36 +0100<br>
          &gt; From: Diego Avesani <a class="moz-txt-link-rfc2396E" href="mailto:diego.avesani@gmail.com">&lt;diego.avesani@gmail.com&gt;</a><br>
          &gt; To: Open MPI Users <a class="moz-txt-link-rfc2396E" href="mailto:users@open-mpi.org">&lt;users@open-mpi.org&gt;</a><br>
          &gt; Subject: [OMPI users] best function to send data<br>
          &gt; Message-ID:<br>
          &gt;
<a class="moz-txt-link-rfc2396E" href="mailto:CAG8o1y4B0uwYdTrB+SwdBra4Tbk6ih5tOeYpga8b6vs-OtYY9g@mail.gmail.com">&lt;CAG8o1y4B0uwYdTrB+SwdBra4Tbk6ih5tOeYpga8b6vs-OtYY9g@mail.gmail.com&gt;</a><br>
          &gt; Content-Type: text/plain; charset="utf-8"<br>
          &gt; <br>
          &gt; dear all users,<br>
          &gt; I am new in MPI world.<br>
          &gt; I would like to know what is the best choice and meaning
          between different<br>
          &gt; function.<br>
          &gt; <br>
          &gt; In my program I would like that each process send a
          vector of data to all<br>
          &gt; the other process. What do you suggest?<br>
          &gt; Is it correct MPI_Bcast or I am missing something?<br>
          &gt; <br>
          &gt; Thanks a lot<br>
          &gt; <br>
          &gt; Diego<br>
          &gt; -------------- next part --------------<br>
          &gt; HTML attachment scrubbed and removed<br>
          &gt; <br>
          &gt; ------------------------------<br>
          &gt; <br>
          &gt; Subject: Digest Footer<br>
          &gt; <br>
          &gt; _______________________________________________<br>
          &gt; users mailing list<br>
          &gt; <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
          &gt; <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
          &gt; <br>
          &gt; ------------------------------<br>
          &gt; <br>
          &gt; End of users Digest, Vol 3074, Issue 1<br>
          &gt; **************************************<br>
        </div>
      </div>
      <br>
      <fieldset class="mimeAttachmentHeader"></fieldset>
      <br>
      <pre wrap="">_______________________________________________
users mailing list
<a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
Subscription: <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
Link to this post: <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2014/12/26048.php">http://www.open-mpi.org/community/lists/users/2014/12/26048.php</a></pre>
    </blockquote>
    <br>
  </body>
</html>

