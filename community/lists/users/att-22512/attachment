<div dir="ltr"><div>Firstly, I would like my program to dynamically assign it self to one of the cores it pleases and remain bound to it until it later reschedules itself.</div><i><div><i><br></i></div>Ralph Castain wrote:</i><div>

<div><i>&gt;&gt; &quot;If you just want mpirun to respect an external cpuset limitation, it already does so when binding - it will bind within the external limitation&quot;</i><br></div><div><br></div><div>In my case, the limitation is enforced &quot;internally&quot;, by the application once in begins execution. I enforce this during program execution, after the mpirun has finished &quot;binding within the external limitation&quot;. </div>

<div><br></div><div><br></div><div><i>Brice Goglin said</i>:</div><div><i>&gt;&gt; <span style="font-family:arial,sans-serif;font-size:13px"> &quot;</span><span style="font-family:arial,sans-serif;font-size:13px">MPI can bind at two different times: inside mpirun after ssh before running the actual program (this one would ignore your cpuset), later at MPI_Init inside your program (this one will ignore your cpuset only if you call MPI_Init before creating the cpuset).&quot;</span></i></div>

<div><div><br></div><div>Noted. In that case, during program execution, whose binding is respected - mpirun&#39;s or MPI_Init()&#39;s? From the above, is my understanding correct? That MPI_Init() will be responsible for the 2nd round of attempting to bind processes to cores and can override what mpirun or the programmer had enforced before its call (using hwloc/cpuset/sched_load_balance()<font color="#006000" face="monospace, courier" size="3"><i> </i></font>and other <i>compatible</i> cousins) ? </div>

<div><br></div><div><br></div><div>--------------------------------------------</div><div>If this is so, in my case the flow of events is thus:</div></div><div><br></div><div>1. mpirun binds an MPI process which is yet to begin execution. So mpirun says: &quot;Bind to some core - A&quot; (I don&#39;t use any hostfile/rankfile. but I do use the --bind-to-core flag) </div>

<div><br></div><div>2. Process begins execution on core A</div><div><br></div><div>3. I enforce: &quot;Bind to core B&quot;. (we must remember, it is only at runtime that  I know what core I want to be bound to and not while launching the processes using mpirun). So my process shifts over to core B</div>

<div><br></div><div>4. MPI_Init() once again honors rankfile mapping(if any, default policy, otherwise ) and rebinds my process to core A</div><div><br></div><div>5. process finished execution and calls MPI_Finalize(), all the time on core A</div>

<div><br></div><div>6. mpirun exits</div><div>--------------------------------------------<br></div><div><br></div><div>So if I place step-3 above after step-4, my request will hold for the rest of the execution. Please do let me know, if my understanding is correct.</div>

<div><br></div><div>Thanks for all the help</div><div><br></div><div>Sincerely,</div><div>Siddhartha Jana</div><div>HPCTools</div><div><br></div><div><br></div><div><br></div><div><br></div><div><br></div><div><div class="h5">

<br></div></div><div class="gmail_extra"><br><br><div class="gmail_quote">On 18 August 2013 10:49, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br>

<blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-color:rgb(204,204,204);border-left-style:solid;padding-left:1ex"><div style="word-wrap:break-word">If you require that a specific rank go to a specific core, then use the rankfile mapper - you can see explanations on the syntax in &quot;man mpirun&quot;<div>

<br></div><div>If you just want mpirun to respect an external cpuset limitation, it already does so when binding - it will bind within the external limitation</div><div><div class="h5"><div><br></div><div><br><div><div>On Aug 18, 2013, at 6:09 AM, Siddhartha Jana &lt;<a href="mailto:siddharthajana24@gmail.com" target="_blank">siddharthajana24@gmail.com</a>&gt; wrote:</div>

<br><blockquote type="cite"><div dir="ltr">So my question really boils down to:<div><span style="font-family:arial,sans-serif;font-size:13px">How does one ensure that mpirun launches the processes on the &quot;specific&quot; cores that are expected of them to be bound to. </span></div>



<div><span style="font-family:arial,sans-serif;font-size:13px">As I mentioned, i</span><span style="font-family:arial,sans-serif;font-size:13px">f there were a way to specify the cores through the hostfile, this problem should be solved. </span></div>



<div><div class="gmail_extra"><br></div><div class="gmail_extra">Thanks for all the quick replies,</div><div class="gmail_extra">-- Sid<br><br><div class="gmail_quote">On 18 August 2013 09:04, Siddhartha Jana <span dir="ltr">&lt;<a href="mailto:siddharthajana24@gmail.com" target="_blank">siddharthajana24@gmail.com</a>&gt;</span> wrote:<br>



<blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-color:rgb(204,204,204);border-left-style:solid;padding-left:1ex"><div dir="ltr">Thanks John. But I have an incredibly small system. 2 nodes - 16 cores each.<div>



2-4 MPI processes. :-)<br></div><div><br></div><div class="gmail_extra"><div class="gmail_quote"><div><div>On 18 August 2013 09:03, John Hearns <span dir="ltr">&lt;<a href="mailto:hearnsj@googlemail.com" target="_blank">hearnsj@googlemail.com</a>&gt;</span> wrote:<br>




</div></div><blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-color:rgb(204,204,204);border-left-style:solid;padding-left:1ex"><div><div><p>You really should install a job scheduler.<br>




There are free versions.</p><p>I&#39;m not sure about cpuset support in Gridengine. Anyone?</p>
<br></div></div><div>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></div></blockquote></div><br></div></div>
</blockquote></div><br></div></div></div>
_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></blockquote>

</div><br></div></div></div></div><br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></div><br></div></div></div>

