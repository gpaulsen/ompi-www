<? 
if (preg_match("/\/[12][0-9][0-9][0-9]\/[01][0-9]\//", $_SERVER["REQUEST_URI"])) {
    include("../../include/index-header.inc");
} else {
    include("include/index-header.inc");
}
?>
<div class="center">
<table border="2" width="100%" class="links">
<tr>
<th><a href="date.php">Date view</a></th>
<th><a href="index.php">Thread view</a></th>
<th><a href="subject.php">Subject view</a></th>
</tr><tr><th><a href="http://www.open-mpi.org/community/lists/users/2015/12/author.php">Previous Folder, Author view</a></th><th><a href="http://www.open-mpi.org/community/lists/users/2016/02/author.php">Next Folder, Author view</a></th><th><a href="http://www.open-mpi.org/community/lists/users/index.php">List of Folders</a></th></tr>
</table>
</div>
<div class="center">
<table>
<tr>
<th colspan="4">210 Messages</th>
</tr>
<tr>
  <th>Starting:</th><td><em>2005-01-11 11:35:37</em></td>
  <th>Ending:</th><td><em>2016-07-27 12:01:45</em></td>
</tr>
</table>
</div>
<hr>
<ul>
<li><strong>Au Eelis</strong>
<ul><li><a href="28240.php">Re: [OMPI users] Singleton process spawns additional thread</a>&nbsp;<a name="28240"><em>(2016-01-08 00:32:32)</em></a></li></ul>
<ul><li><a href="28237.php">[OMPI users] Singleton process spawns additional thread</a>&nbsp;<a name="28237"><em>(2016-01-07 07:09:43)</em></a></li></ul>
<li><strong>Ben Menadue</strong>
<ul><li><a href="28407.php">Re: [OMPI users] Any changes to rmaps in 1.10.2?</a>&nbsp;<a name="28407"><em>(2016-01-28 23:16:59)</em></a></li></ul>
<ul><li><a href="28405.php">Re: [OMPI users] Any changes to rmaps in 1.10.2?</a>&nbsp;<a name="28405"><em>(2016-01-28 21:43:10)</em></a></li></ul>
<ul><li><a href="28402.php">Re: [OMPI users] Any changes to rmaps in 1.10.2?</a>&nbsp;<a name="28402"><em>(2016-01-28 21:08:56)</em></a></li></ul>
<ul><li><a href="28401.php">Re: [OMPI users] Any changes to rmaps in 1.10.2?</a>&nbsp;<a name="28401"><em>(2016-01-28 21:00:33)</em></a></li></ul>
<ul><li><a href="28397.php">Re: [OMPI users] Any changes to rmaps in 1.10.2?</a>&nbsp;<a name="28397"><em>(2016-01-28 15:57:27)</em></a></li></ul>
<ul><li><a href="28393.php">[OMPI users] Any changes to rmaps in 1.10.2?</a>&nbsp;<a name="28393"><em>(2016-01-27 17:57:38)</em></a></li></ul>
<li><strong>Bennet Fauber</strong>
<ul><li><a href="28246.php">Re: [OMPI users] Global settings</a>&nbsp;<a name="28246"><em>(2016-01-11 09:51:52)</em></a></li></ul>
<ul><li><a href="28243.php">[OMPI users] Global settings</a>&nbsp;<a name="28243"><em>(2016-01-11 08:32:09)</em></a></li></ul>
<li><strong>CUDENNEC Loic</strong>
<ul><li><a href="28264.php">[OMPI users] Call for Papers: 4th Alchemy Workshop on Manycore programming</a>&nbsp;<a name="28264"><em>(2016-01-13 08:58:57)</em></a></li></ul>
<li><strong>Dave Love</strong>
<ul><li><a href="28388.php">[OMPI users] Fortran features and interfaces (was: Strange behaviour OpenMPI in Fortran)</a>&nbsp;<a name="28388"><em>(2016-01-26 11:15:27)</em></a></li></ul>
<ul><li><a href="28386.php">Re: [OMPI users] cleaning up old ROMIO (MPI-IO) drivers</a>&nbsp;<a name="28386"><em>(2016-01-26 10:32:18)</em></a></li></ul>
<ul><li><a href="28385.php">[OMPI users] build failure with NAG Fortran</a>&nbsp;<a name="28385"><em>(2016-01-26 10:26:43)</em></a></li></ul>
<ul><li><a href="28384.php">[OMPI users] many return codes not checked in the source</a>&nbsp;<a name="28384"><em>(2016-01-26 09:53:06)</em></a></li></ul>
<ul><li><a href="28383.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28383"><em>(2016-01-26 09:52:14)</em></a></li></ul>
<ul><li><a href="28366.php">Re: [OMPI users] MPI, Fortran, and GET_ENVIRONMENT_VARIABLE</a>&nbsp;<a name="28366"><em>(2016-01-25 07:24:17)</em></a></li></ul>
<ul><li><a href="28365.php">Re: [OMPI users] Strange behaviour OpenMPI in Fortran</a>&nbsp;<a name="28365"><em>(2016-01-25 07:21:51)</em></a></li></ul>
<ul><li><a href="28364.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28364"><em>(2016-01-25 07:14:35)</em></a></li></ul>
<ul><li><a href="28326.php">Re: [OMPI users] MPI, Fortran, and GET_ENVIRONMENT_VARIABLE</a>&nbsp;<a name="28326"><em>(2016-01-21 07:24:42)</em></a></li></ul>
<ul><li><a href="28325.php">Re: [OMPI users] Openmpi 1.8.8 and affinty</a>&nbsp;<a name="28325"><em>(2016-01-21 07:15:00)</em></a></li></ul>
<ul><li><a href="28324.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28324"><em>(2016-01-21 07:07:16)</em></a></li></ul>
<ul><li><a href="28323.php">Re: [OMPI users] cleaning up old ROMIO (MPI-IO) drivers</a>&nbsp;<a name="28323"><em>(2016-01-21 06:59:20)</em></a></li></ul>
<li><strong>Diego Avesani</strong>
<ul><li><a href="28419.php">Re: [OMPI users] difference between OpenMPI - intel MPI mpi_waitall</a>&nbsp;<a name="28419"><em>(2016-01-29 09:43:53)</em></a></li></ul>
<ul><li><a href="28416.php">Re: [OMPI users] difference between OpenMPI - intel MPI mpi_waitall</a>&nbsp;<a name="28416"><em>(2016-01-29 07:55:46)</em></a></li></ul>
<ul><li><a href="28413.php">Re: [OMPI users] difference between OpenMPI - intel MPI mpi_waitall</a>&nbsp;<a name="28413"><em>(2016-01-29 06:11:27)</em></a></li></ul>
<ul><li><a href="28410.php">[OMPI users] difference between OpenMPI - intel MPI mpi_waitall</a>&nbsp;<a name="28410"><em>(2016-01-29 05:45:24)</em></a></li></ul>
<li><strong>Edgar Gabriel</strong>
<ul><li><a href="28381.php">Re: [OMPI users] Error building openmpi-v2.x-dev-1020-ge2a53b3 on Solaris</a>&nbsp;<a name="28381"><em>(2016-01-26 09:44:48)</em></a></li></ul>
<ul><li><a href="28379.php">Re: [OMPI users] Error building openmpi-v2.x-dev-1020-ge2a53b3 on Solaris</a>&nbsp;<a name="28379"><em>(2016-01-26 09:13:03)</em></a></li></ul>
<li><strong>Emani, Murali</strong>
<ul><li><a href="28348.php">[OMPI users] Error in BTL with larger number of nodes</a>&nbsp;<a name="28348"><em>(2016-01-23 00:13:59)</em></a></li></ul>
<li><strong>Erik Schnetter</strong>
<ul><li><a href="28218.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28218"><em>(2016-01-06 14:48:51)</em></a></li></ul>
<li><strong>Eugene Loh</strong>
<ul><li><a href="28239.php">Re: [OMPI users] OpenMPI Profiling</a>&nbsp;<a name="28239"><em>(2016-01-07 18:37:41)</em></a></li></ul>
<li><strong>Eva</strong>
<ul><li><a href="28375.php">Re: [OMPI users] openmpi-1.10.2 cores at mca_coll_libnbc.so</a>&nbsp;<a name="28375"><em>(2016-01-26 01:44:38)</em></a></li></ul>
<ul><li><a href="28373.php">[OMPI users] openmpi-1.10.2 cores at mca_coll_libnbc.so</a>&nbsp;<a name="28373"><em>(2016-01-26 00:35:24)</em></a></li></ul>
<ul><li><a href="28333.php">Re: [OMPI users] MPI hangs on poll_device() with rdma</a>&nbsp;<a name="28333"><em>(2016-01-22 03:32:22)</em></a></li></ul>
<ul><li><a href="28327.php">Re: [OMPI users] MPI hangs on poll_device() with rdma</a>&nbsp;<a name="28327"><em>(2016-01-21 07:40:01)</em></a></li></ul>
<ul><li><a href="28320.php">Re: [OMPI users] MPI hangs on poll_device() with rdma</a>&nbsp;<a name="28320"><em>(2016-01-21 04:49:13)</em></a></li></ul>
<ul><li><a href="28318.php">Re: [OMPI users] MPI hangs on poll_device() with rdma</a>&nbsp;<a name="28318"><em>(2016-01-21 04:03:18)</em></a></li></ul>
<ul><li><a href="28316.php">Re: [OMPI users] MPI hangs on poll_device() with rdma</a>&nbsp;<a name="28316"><em>(2016-01-21 03:25:40)</em></a></li></ul>
<ul><li><a href="28313.php">Re: [OMPI users] MPI hangs on poll_device() with rdma</a>&nbsp;<a name="28313"><em>(2016-01-21 00:10:32)</em></a></li></ul>
<ul><li><a href="28312.php">[OMPI users] MPI hangs on poll_device() with rdma</a>&nbsp;<a name="28312"><em>(2016-01-20 22:24:25)</em></a></li></ul>
<li><strong>George Bosilca</strong>
<ul><li><a href="28280.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28280"><em>(2016-01-14 22:33:13)</em></a></li></ul>
<ul><li><a href="28277.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28277"><em>(2016-01-14 18:05:14)</em></a></li></ul>
<ul><li><a href="28255.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28255"><em>(2016-01-12 21:06:56)</em></a></li></ul>
<li><strong>Gilles Gouaillardet</strong>
<ul><li><a href="28418.php">Re: [OMPI users] difference between OpenMPI - intel MPI mpi_waitall</a>&nbsp;<a name="28418"><em>(2016-01-29 08:09:49)</em></a></li></ul>
<ul><li><a href="28415.php">Re: [OMPI users] OpenMPI against multiple, evolving SLURM versions</a>&nbsp;<a name="28415"><em>(2016-01-29 06:59:38)</em></a></li></ul>
<ul><li><a href="28412.php">Re: [OMPI users] OpenMPI against multiple, evolving SLURM versions</a>&nbsp;<a name="28412"><em>(2016-01-29 06:11:25)</em></a></li></ul>
<ul><li><a href="28411.php">Re: [OMPI users] difference between OpenMPI - intel MPI mpi_waitall</a>&nbsp;<a name="28411"><em>(2016-01-29 05:58:53)</em></a></li></ul>
<ul><li><a href="28406.php">Re: [OMPI users] Any changes to rmaps in 1.10.2?</a>&nbsp;<a name="28406"><em>(2016-01-28 21:53:40)</em></a></li></ul>
<ul><li><a href="28404.php">Re: [OMPI users] Any changes to rmaps in 1.10.2?</a>&nbsp;<a name="28404"><em>(2016-01-28 21:33:07)</em></a></li></ul>
<ul><li><a href="28403.php">Re: [OMPI users] Any changes to rmaps in 1.10.2?</a>&nbsp;<a name="28403"><em>(2016-01-28 21:08:53)</em></a></li></ul>
<ul><li><a href="28400.php">Re: [OMPI users] Any changes to rmaps in 1.10.2?</a>&nbsp;<a name="28400"><em>(2016-01-28 19:06:52)</em></a></li></ul>
<ul><li><a href="28395.php">Re: [OMPI users] Using MPI_Type_create_resized is leading to segfault when one-sided communication is used (ungarbled)</a>&nbsp;<a name="28395"><em>(2016-01-28 02:53:59)</em></a></li></ul>
<ul><li><a href="28394.php">Re: [OMPI users] Using MPI_Type_create_resized is leading to segfault when one-sided communication is used (ungarbled)</a>&nbsp;<a name="28394"><em>(2016-01-27 20:11:13)</em></a></li></ul>
<ul><li><a href="28390.php">Re: [OMPI users] OMPI users] segmentation fault with java MPI</a>&nbsp;<a name="28390"><em>(2016-01-27 04:12:42)</em></a></li></ul>
<ul><li><a href="28389.php">Re: [OMPI users] build failure with NAG Fortran</a>&nbsp;<a name="28389"><em>(2016-01-26 17:23:55)</em></a></li></ul>
<ul><li><a href="28382.php">Re: [OMPI users] Error building openmpi-v2.x-dev-1020-ge2a53b3 on Solaris</a>&nbsp;<a name="28382"><em>(2016-01-26 09:50:09)</em></a></li></ul>
<ul><li><a href="28380.php">Re: [OMPI users] Error building openmpi-v2.x-dev-1020-ge2a53b3 on Solaris</a>&nbsp;<a name="28380"><em>(2016-01-26 09:39:15)</em></a></li></ul>
<ul><li><a href="28378.php">Re: [OMPI users] Error building openmpi-v2.x-dev-1020-ge2a53b3 on Solaris</a>&nbsp;<a name="28378"><em>(2016-01-26 07:27:47)</em></a></li></ul>
<ul><li><a href="28376.php">Re: [OMPI users] openmpi-1.10.2 cores at mca_coll_libnbc.so</a>&nbsp;<a name="28376"><em>(2016-01-26 02:08:01)</em></a></li></ul>
<ul><li><a href="28374.php">Re: [OMPI users] openmpi-1.10.2 cores at mca_coll_libnbc.so</a>&nbsp;<a name="28374"><em>(2016-01-26 00:48:17)</em></a></li></ul>
<ul><li><a href="28367.php">Re: [OMPI users] Strange behaviour OpenMPI in Fortran</a>&nbsp;<a name="28367"><em>(2016-01-25 08:02:27)</em></a></li></ul>
<ul><li><a href="28363.php">Re: [OMPI users] segmentation fault with java MPI</a>&nbsp;<a name="28363"><em>(2016-01-25 05:34:39)</em></a></li></ul>
<ul><li><a href="28360.php">Re: [OMPI users] segmentation fault with java MPI</a>&nbsp;<a name="28360"><em>(2016-01-24 19:04:59)</em></a></li></ul>
<ul><li><a href="28351.php">Re: [OMPI users] Raspberry Pi 2 Beowulf Cluster for OpenFOAM</a>&nbsp;<a name="28351"><em>(2016-01-24 08:25:53)</em></a></li></ul>
<ul><li><a href="28347.php">Re: [OMPI users] Strange behaviour OpenMPI in Fortran</a>&nbsp;<a name="28347"><em>(2016-01-22 18:37:16)</em></a></li></ul>
<ul><li><a href="28321.php">Re: [OMPI users] MPI hangs on poll_device() with rdma</a>&nbsp;<a name="28321"><em>(2016-01-21 05:54:46)</em></a></li></ul>
<ul><li><a href="28319.php">Re: [OMPI users] OMPI users] MPI hangs on poll_device() with rdma</a>&nbsp;<a name="28319"><em>(2016-01-21 04:41:35)</em></a></li></ul>
<ul><li><a href="28317.php">Re: [OMPI users] MPI hangs on poll_device() with rdma</a>&nbsp;<a name="28317"><em>(2016-01-21 03:31:25)</em></a></li></ul>
<ul><li><a href="28315.php">Re: [OMPI users] MPI hangs on poll_device() with rdma</a>&nbsp;<a name="28315"><em>(2016-01-21 02:12:36)</em></a></li></ul>
<ul><li><a href="28314.php">Re: [OMPI users] MPI hangs on poll_device() with rdma</a>&nbsp;<a name="28314"><em>(2016-01-21 01:52:34)</em></a></li></ul>
<ul><li><a href="28310.php">Re: [OMPI users] How to allocate more memory to java OpenMPI</a>&nbsp;<a name="28310"><em>(2016-01-20 17:11:35)</em></a></li></ul>
<ul><li><a href="28306.php">Re: [OMPI users] problem withexecstackandopenmpi-v1.10.1-140-g31ff573</a>&nbsp;<a name="28306"><em>(2016-01-19 21:59:32)</em></a></li></ul>
<ul><li><a href="28283.php">Re: [OMPI users] runtime error with openmpi-v2.x-dev-958-g7e94425</a>&nbsp;<a name="28283"><em>(2016-01-15 02:03:45)</em></a></li></ul>
<ul><li><a href="28282.php">Re: [OMPI users] problem with execstack and openmpi-v1.10.1-140-g31ff573</a>&nbsp;<a name="28282"><em>(2016-01-15 02:01:33)</em></a></li></ul>
<ul><li><a href="28281.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28281"><em>(2016-01-15 00:10:08)</em></a></li></ul>
<ul><li><a href="28279.php">Re: [OMPI users] MPI_Type_free and non-blocking operations</a>&nbsp;<a name="28279"><em>(2016-01-14 21:07:09)</em></a></li></ul>
<ul><li><a href="28270.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28270"><em>(2016-01-13 19:28:16)</em></a></li></ul>
<ul><li><a href="28265.php">[OMPI users]  MPI_Type_free and non-blocking operations</a>&nbsp;<a name="28265"><em>(2016-01-13 09:00:15)</em></a></li></ul>
<ul><li><a href="28262.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28262"><em>(2016-01-13 00:44:25)</em></a></li></ul>
<ul><li><a href="28260.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28260"><em>(2016-01-12 23:25:00)</em></a></li></ul>
<ul><li><a href="28256.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28256"><em>(2016-01-12 21:16:51)</em></a></li></ul>
<ul><li><a href="28252.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28252"><em>(2016-01-12 19:46:29)</em></a></li></ul>
<ul><li><a href="28250.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28250"><em>(2016-01-12 19:18:39)</em></a></li></ul>
<ul><li><a href="28235.php">Re: [OMPI users] runtime errors with openmpi-v2.x-dev-950-g995993b</a>&nbsp;<a name="28235"><em>(2016-01-07 00:57:00)</em></a></li></ul>
<ul><li><a href="28232.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28232"><em>(2016-01-06 19:20:56)</em></a></li></ul>
<li><strong>Gus Correa</strong>
<ul><li><a href="28213.php">Re: [OMPI users] cleaning up old ROMIO (MPI-IO) drivers</a>&nbsp;<a name="28213"><em>(2016-01-05 12:43:22)</em></a></li></ul>
<li><strong>Howard Pritchard</strong>
<ul><li><a href="28345.php">Re: [OMPI users] Issues Building Open MPI static with Intel Fortran 16</a>&nbsp;<a name="28345"><em>(2016-01-22 14:47:44)</em></a></li></ul>
<ul><li><a href="28302.php">Re: [OMPI users] How to allocate more memory to java OpenMPI</a>&nbsp;<a name="28302"><em>(2016-01-19 11:48:24)</em></a></li></ul>
<ul><li><a href="28276.php">Re: [OMPI users] problem with execstack and openmpi-v1.10.1-140-g31ff573</a>&nbsp;<a name="28276"><em>(2016-01-14 12:40:08)</em></a></li></ul>
<ul><li><a href="28269.php">Re: [OMPI users] RMA operations with java buffers</a>&nbsp;<a name="28269"><em>(2016-01-13 13:46:16)</em></a></li></ul>
<li><strong>Ibrahim Ikhlawi</strong>
<ul><li><a href="28355.php">Re: [OMPI users] how to benchmark a server with openmpi?</a>&nbsp;<a name="28355"><em>(2016-01-24 14:51:33)</em></a></li></ul>
<ul><li><a href="28352.php">[OMPI users] how to benchmark a server with openmpi?</a>&nbsp;<a name="28352"><em>(2016-01-24 09:38:13)</em></a></li></ul>
<ul><li><a href="28308.php">Re: [OMPI users] How to allocate more memory to java OpenMPI</a>&nbsp;<a name="28308"><em>(2016-01-20 09:49:28)</em></a></li></ul>
<ul><li><a href="28301.php">[OMPI users] How to allocate more memory to java OpenMPI</a>&nbsp;<a name="28301"><em>(2016-01-19 10:03:12)</em></a></li></ul>
<li><strong>Jed Brown</strong>
<ul><li><a href="28372.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28372"><em>(2016-01-25 18:41:46)</em></a></li></ul>
<li><strong>Jeff Hammond</strong>
<ul><li><a href="28421.php">Re: [OMPI users] difference between OpenMPI - intel MPI mpi_waitall</a>&nbsp;<a name="28421"><em>(2016-01-29 18:11:23)</em></a></li></ul>
<ul><li><a href="28338.php">Re: [OMPI users] Strange behaviour OpenMPI in Fortran</a>&nbsp;<a name="28338"><em>(2016-01-22 10:44:58)</em></a></li></ul>
<ul><li><a href="28329.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28329"><em>(2016-01-21 09:51:42)</em></a></li></ul>
<ul><li><a href="28305.php">Re: [OMPI users] Using OpenMPI Thread Multiple mode</a>&nbsp;<a name="28305"><em>(2016-01-19 19:49:31)</em></a></li></ul>
<ul><li><a href="28278.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28278"><em>(2016-01-14 19:49:01)</em></a></li></ul>
<ul><li><a href="28267.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28267"><em>(2016-01-13 10:23:35)</em></a></li></ul>
<ul><li><a href="28261.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28261"><em>(2016-01-13 00:15:26)</em></a></li></ul>
<ul><li><a href="28259.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28259"><em>(2016-01-12 22:22:40)</em></a></li></ul>
<ul><li><a href="28253.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28253"><em>(2016-01-12 19:59:41)</em></a></li></ul>
<ul><li><a href="28251.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28251"><em>(2016-01-12 19:37:15)</em></a></li></ul>
<ul><li><a href="28242.php">Re: [OMPI users] Put/Get semantics</a>&nbsp;<a name="28242"><em>(2016-01-08 17:01:15)</em></a></li></ul>
<ul><li><a href="28234.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28234"><em>(2016-01-06 19:52:43)</em></a></li></ul>
<ul><li><a href="28230.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28230"><em>(2016-01-06 18:48:47)</em></a></li></ul>
<li><strong>Jeff Squyres (jsquyres)</strong>
<ul><li><a href="28420.php">Re: [OMPI users] difference between OpenMPI - intel MPI mpi_waitall</a>&nbsp;<a name="28420"><em>(2016-01-29 11:25:22)</em></a></li></ul>
<ul><li><a href="28417.php">Re: [OMPI users] difference between OpenMPI - intel MPI mpi_waitall</a>&nbsp;<a name="28417"><em>(2016-01-29 08:02:35)</em></a></li></ul>
<ul><li><a href="28414.php">Re: [OMPI users] difference between OpenMPI - intel MPI mpi_waitall</a>&nbsp;<a name="28414"><em>(2016-01-29 06:43:46)</em></a></li></ul>
<ul><li><a href="28369.php">Re: [OMPI users] Strange behaviour OpenMPI in Fortran</a>&nbsp;<a name="28369"><em>(2016-01-25 09:53:21)</em></a></li></ul>
<ul><li><a href="28339.php">Re: [OMPI users] Strange behaviour OpenMPI in Fortran</a>&nbsp;<a name="28339"><em>(2016-01-22 10:48:17)</em></a></li></ul>
<ul><li><a href="28328.php">Re: [OMPI users] MPI hangs on poll_device() with rdma</a>&nbsp;<a name="28328"><em>(2016-01-21 07:59:14)</em></a></li></ul>
<ul><li><a href="28322.php">Re: [OMPI users] MPI hangs on poll_device() with rdma</a>&nbsp;<a name="28322"><em>(2016-01-21 06:10:13)</em></a></li></ul>
<ul><li><a href="28245.php">Re: [OMPI users] Global settings</a>&nbsp;<a name="28245"><em>(2016-01-11 09:47:28)</em></a></li></ul>
<li><strong>Jim Edwards</strong>
<ul><li><a href="28289.php">Re: [OMPI users] MPI, Fortran, and GET_ENVIRONMENT_VARIABLE</a>&nbsp;<a name="28289"><em>(2016-01-15 10:02:43)</em></a></li></ul>
<ul><li><a href="28271.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28271"><em>(2016-01-13 19:57:00)</em></a></li></ul>
<ul><li><a href="28266.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28266"><em>(2016-01-13 09:11:53)</em></a></li></ul>
<ul><li><a href="28258.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28258"><em>(2016-01-12 22:14:36)</em></a></li></ul>
<ul><li><a href="28257.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28257"><em>(2016-01-12 21:55:10)</em></a></li></ul>
<ul><li><a href="28254.php">Re: [OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28254"><em>(2016-01-12 20:25:29)</em></a></li></ul>
<ul><li><a href="28249.php">[OMPI users] MPI_DATATYPE_NULL and MPI_AlltoallW</a>&nbsp;<a name="28249"><em>(2016-01-12 18:27:50)</em></a></li></ul>
<li><strong>John Hearns</strong>
<ul><li><a href="28350.php">Re: [OMPI users] Raspberry Pi 2 Beowulf Cluster for OpenFOAM</a>&nbsp;<a name="28350"><em>(2016-01-24 04:27:43)</em></a></li></ul>
<li><strong>Kuhl, Spencer J</strong>
<ul><li><a href="28368.php">Re: [OMPI users] Raspberry Pi 2 Beowulf Cluster for OpenFOAM</a>&nbsp;<a name="28368"><em>(2016-01-25 09:47:19)</em></a></li></ul>
<ul><li><a href="28343.php">Re: [OMPI users] configuring open mpi 10.1.2 with cuda on NVIDIA TK1</a>&nbsp;<a name="28343"><em>(2016-01-22 13:11:10)</em></a></li></ul>
<ul><li><a href="28341.php">Re: [OMPI users] configuring open mpi 10.1.2 with cuda on NVIDIA TK1</a>&nbsp;<a name="28341"><em>(2016-01-22 13:01:03)</em></a></li></ul>
<ul><li><a href="28335.php">Re: [OMPI users] configuring open mpi 10.1.2 with cuda on NVIDIA TK1</a>&nbsp;<a name="28335"><em>(2016-01-22 09:48:45)</em></a></li></ul>
<ul><li><a href="28331.php">[OMPI users] configuring open mpi 10.1.2 with cuda on NVIDIA TK1</a>&nbsp;<a name="28331"><em>(2016-01-21 17:45:18)</em></a></li></ul>
<li><strong>Mark Santcroos</strong>
<ul><li><a href="28362.php">Re: [OMPI users] how to benchmark a server with openmpi?</a>&nbsp;<a name="28362"><em>(2016-01-25 05:13:35)</em></a></li></ul>
<li><strong>Marko Blatzheim</strong>
<ul><li><a href="28361.php">Re: [OMPI users] segmentation fault with java MPI</a>&nbsp;<a name="28361"><em>(2016-01-25 04:32:21)</em></a></li></ul>
<ul><li><a href="28359.php">[OMPI users] segmentation fault with java MPI</a>&nbsp;<a name="28359"><em>(2016-01-24 18:23:02)</em></a></li></ul>
<ul><li><a href="28268.php">[OMPI users] RMA operations with java buffers</a>&nbsp;<a name="28268"><em>(2016-01-13 11:04:40)</em></a></li></ul>
<li><strong>Matt Thompson</strong>
<ul><li><a href="28346.php">Re: [OMPI users] Issues Building Open MPI static with Intel Fortran 16</a>&nbsp;<a name="28346"><em>(2016-01-22 15:37:35)</em></a></li></ul>
<ul><li><a href="28344.php">[OMPI users] Issues Building Open MPI static with Intel Fortran 16</a>&nbsp;<a name="28344"><em>(2016-01-22 14:15:46)</em></a></li></ul>
<ul><li><a href="28296.php">Re: [OMPI users] MPI, Fortran, and GET_ENVIRONMENT_VARIABLE</a>&nbsp;<a name="28296"><em>(2016-01-15 12:00:54)</em></a></li></ul>
<ul><li><a href="28291.php">Re: [OMPI users] MPI, Fortran, and GET_ENVIRONMENT_VARIABLE</a>&nbsp;<a name="28291"><em>(2016-01-15 10:56:07)</em></a></li></ul>
<ul><li><a href="28287.php">[OMPI users] MPI, Fortran, and GET_ENVIRONMENT_VARIABLE</a>&nbsp;<a name="28287"><em>(2016-01-15 09:53:20)</em></a></li></ul>
<ul><li><a href="28233.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28233"><em>(2016-01-06 19:36:59)</em></a></li></ul>
<ul><li><a href="28223.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28223"><em>(2016-01-06 15:33:37)</em></a></li></ul>
<ul><li><a href="28220.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28220"><em>(2016-01-06 15:17:12)</em></a></li></ul>
<ul><li><a href="28217.php">[OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28217"><em>(2016-01-06 14:46:13)</em></a></li></ul>
<li><strong>Nick Papior</strong>
<ul><li><a href="28387.php">Re: [OMPI users] build failure with NAG Fortran</a>&nbsp;<a name="28387"><em>(2016-01-26 10:47:43)</em></a></li></ul>
<ul><li><a href="28353.php">Re: [OMPI users] how to benchmark a server with openmpi?</a>&nbsp;<a name="28353"><em>(2016-01-24 09:41:37)</em></a></li></ul>
<ul><li><a href="28336.php">Re: [OMPI users] Strange behaviour OpenMPI in Fortran</a>&nbsp;<a name="28336"><em>(2016-01-22 10:06:45)</em></a></li></ul>
<ul><li><a href="28294.php">Re: [OMPI users] MPI, Fortran, and GET_ENVIRONMENT_VARIABLE</a>&nbsp;<a name="28294"><em>(2016-01-15 11:35:03)</em></a></li></ul>
<ul><li><a href="28231.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28231"><em>(2016-01-06 18:52:00)</em></a></li></ul>
<ul><li><a href="28229.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28229"><em>(2016-01-06 16:04:44)</em></a></li></ul>
<ul><li><a href="28227.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28227"><em>(2016-01-06 15:58:35)</em></a></li></ul>
<ul><li><a href="28224.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28224"><em>(2016-01-06 15:48:58)</em></a></li></ul>
<ul><li><a href="28222.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28222"><em>(2016-01-06 15:20:36)</em></a></li></ul>
<ul><li><a href="28219.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28219"><em>(2016-01-06 15:14:46)</em></a></li></ul>
<li><strong>Novosielski, Ryan</strong>
<ul><li><a href="28332.php">Re: [OMPI users] configuring open mpi 10.1.2 with cuda on NVIDIA TK1</a>&nbsp;<a name="28332"><em>(2016-01-22 02:20:35)</em></a></li></ul>
<li><strong>Palmer, Bruce J</strong>
<ul><li><a href="28248.php">Re: [OMPI users] Put/Get semantics</a>&nbsp;<a name="28248"><em>(2016-01-11 13:54:01)</em></a></li></ul>
<ul><li><a href="28216.php">[OMPI users] Put/Get semantics</a>&nbsp;<a name="28216"><em>(2016-01-06 11:51:02)</em></a></li></ul>
<li><strong>Pawe&#197;&#130; Jarz&#196;&#153;bski</strong>
<ul><li><a href="28337.php">Re: [OMPI users] Strange behaviour OpenMPI in Fortran</a>&nbsp;<a name="28337"><em>(2016-01-22 10:12:47)</em></a></li></ul>
<ul><li><a href="28334.php">[OMPI users] Strange behaviour OpenMPI in Fortran</a>&nbsp;<a name="28334"><em>(2016-01-22 09:37:49)</em></a></li></ul>
<li><strong>Ralph Castain</strong>
<ul><li><a href="28409.php">Re: [OMPI users] OpenMPI against multiple, evolving SLURM versions</a>&nbsp;<a name="28409"><em>(2016-01-29 05:02:43)</em></a></li></ul>
<ul><li><a href="28399.php">Re: [OMPI users] Any changes to rmaps in 1.10.2?</a>&nbsp;<a name="28399"><em>(2016-01-28 18:32:20)</em></a></li></ul>
<ul><li><a href="28396.php">Re: [OMPI users] Any changes to rmaps in 1.10.2?</a>&nbsp;<a name="28396"><em>(2016-01-28 11:46:04)</em></a></li></ul>
<ul><li><a href="28303.php">Re: [OMPI users] Singleton process spawns additional thread</a>&nbsp;<a name="28303"><em>(2016-01-19 12:08:45)</em></a></li></ul>
<ul><li><a href="28298.php">Re: [OMPI users] [EXT] Re:  Openmpi 1.8.8 and affinty</a>&nbsp;<a name="28298"><em>(2016-01-15 12:20:06)</em></a></li></ul>
<ul><li><a href="28295.php">Re: [OMPI users] MPI, Fortran, and GET_ENVIRONMENT_VARIABLE</a>&nbsp;<a name="28295"><em>(2016-01-15 11:46:06)</em></a></li></ul>
<ul><li><a href="28293.php">Re: [OMPI users] Openmpi 1.8.8 and affinty</a>&nbsp;<a name="28293"><em>(2016-01-15 11:32:38)</em></a></li></ul>
<ul><li><a href="28292.php">Re: [OMPI users] MPI, Fortran, and GET_ENVIRONMENT_VARIABLE</a>&nbsp;<a name="28292"><em>(2016-01-15 11:27:22)</em></a></li></ul>
<ul><li><a href="28290.php">Re: [OMPI users] MPI, Fortran, and GET_ENVIRONMENT_VARIABLE</a>&nbsp;<a name="28290"><em>(2016-01-15 10:48:54)</em></a></li></ul>
<ul><li><a href="28247.php">Re: [OMPI users] Global settings</a>&nbsp;<a name="28247"><em>(2016-01-11 10:09:38)</em></a></li></ul>
<ul><li><a href="28244.php">Re: [OMPI users] Global settings</a>&nbsp;<a name="28244"><em>(2016-01-11 09:39:57)</em></a></li></ul>
<ul><li><a href="28241.php">Re: [OMPI users] Singleton process spawns additional thread</a>&nbsp;<a name="28241"><em>(2016-01-08 00:38:15)</em></a></li></ul>
<ul><li><a href="28228.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28228"><em>(2016-01-06 16:03:00)</em></a></li></ul>
<ul><li><a href="28226.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28226"><em>(2016-01-06 15:54:29)</em></a></li></ul>
<ul><li><a href="28225.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28225"><em>(2016-01-06 15:51:21)</em></a></li></ul>
<ul><li><a href="28221.php">Re: [OMPI users] Open MPI MPI-OpenMP Hybrid Binding Question</a>&nbsp;<a name="28221"><em>(2016-01-06 15:19:09)</em></a></li></ul>
<li><strong>Ramsey, James J CIV USARMY RDECOM ARL (US)</strong>
<ul><li><a href="28392.php">[OMPI users] Using MPI_Type_create_resized is leading to segfault when one-sided communication is used (ungarbled)</a>&nbsp;<a name="28392"><em>(2016-01-27 11:46:52)</em></a></li></ul>
<ul><li><a href="28391.php">[OMPI users] Using MPI_Type_create_resized is leading to segfault when one-sided communication is used</a>&nbsp;<a name="28391"><em>(2016-01-27 10:53:19)</em></a></li></ul>
<li><strong>Rob Latham</strong>
<ul><li><a href="28371.php">Re: [OMPI users] cleaning up old ROMIO (MPI-IO) drivers</a>&nbsp;<a name="28371"><em>(2016-01-25 15:02:26)</em></a></li></ul>
<ul><li><a href="28214.php">Re: [OMPI users] [mpich-discuss] cleaning up old ROMIO (MPI-IO) drivers</a>&nbsp;<a name="28214"><em>(2016-01-05 13:47:11)</em></a></li></ul>
<ul><li><a href="28212.php">[OMPI users] cleaning up old ROMIO (MPI-IO) drivers</a>&nbsp;<a name="28212"><em>(2016-01-05 12:31:37)</em></a></li></ul>
<li><strong>Saliya Ekanayake</strong>
<ul><li><a href="28356.php">Re: [OMPI users] how to benchmark a server with openmpi?</a>&nbsp;<a name="28356"><em>(2016-01-24 14:57:13)</em></a></li></ul>
<ul><li><a href="28354.php">Re: [OMPI users] how to benchmark a server with openmpi?</a>&nbsp;<a name="28354"><em>(2016-01-24 10:21:07)</em></a></li></ul>
<ul><li><a href="28311.php">Re: [OMPI users] How to allocate more memory to java OpenMPI</a>&nbsp;<a name="28311"><em>(2016-01-20 17:42:00)</em></a></li></ul>
<ul><li><a href="28309.php">Re: [OMPI users] How to allocate more memory to java OpenMPI</a>&nbsp;<a name="28309"><em>(2016-01-20 11:27:02)</em></a></li></ul>
<li><strong>Sasso, John (GE Power, Non-GE)</strong>
<ul><li><a href="28238.php">Re: [OMPI users] Singleton process spawns additional thread</a>&nbsp;<a name="28238"><em>(2016-01-07 09:27:54)</em></a></li></ul>
<li><strong>Siegmar Gross</strong>
<ul><li><a href="28377.php">[OMPI users] Error building openmpi-v2.x-dev-1020-ge2a53b3 on Solaris</a>&nbsp;<a name="28377"><em>(2016-01-26 06:37:12)</em></a></li></ul>
<ul><li><a href="28307.php">Re: [OMPI users] problemwithexecstackandopenmpi-v1.10.1-140-g31ff573</a>&nbsp;<a name="28307"><em>(2016-01-20 07:22:34)</em></a></li></ul>
<ul><li><a href="28300.php">Re: [OMPI users] problem withexecstackandopenmpi-v1.10.1-140-g31ff573</a>&nbsp;<a name="28300"><em>(2016-01-19 09:19:59)</em></a></li></ul>
<ul><li><a href="28286.php">Re: [OMPI users] problem with execstackandopenmpi-v1.10.1-140-g31ff573</a>&nbsp;<a name="28286"><em>(2016-01-15 09:31:30)</em></a></li></ul>
<ul><li><a href="28285.php">Re: [OMPI users] problem with execstackandopenmpi-v1.10.1-140-g31ff573</a>&nbsp;<a name="28285"><em>(2016-01-15 08:05:28)</em></a></li></ul>
<ul><li><a href="28284.php">Re: [OMPI users] problem with execstackandopenmpi-v1.10.1-140-g31ff573</a>&nbsp;<a name="28284"><em>(2016-01-15 04:05:50)</em></a></li></ul>
<ul><li><a href="28275.php">[OMPI users] problem with execstack and openmpi-v1.10.1-140-g31ff573</a>&nbsp;<a name="28275"><em>(2016-01-14 09:30:19)</em></a></li></ul>
<ul><li><a href="28274.php">[OMPI users] runtime errors with openmpi-dev-3356-ge5cf2db</a>&nbsp;<a name="28274"><em>(2016-01-14 09:12:40)</em></a></li></ul>
<ul><li><a href="28273.php">[OMPI users] runtime error with openmpi-v2.x-dev-958-g7e94425</a>&nbsp;<a name="28273"><em>(2016-01-14 09:06:34)</em></a></li></ul>
<ul><li><a href="28272.php">[OMPI users] runtime error with openmpi-v1.10.1-140-g31ff573</a>&nbsp;<a name="28272"><em>(2016-01-14 08:43:28)</em></a></li></ul>
<ul><li><a href="28236.php">[OMPI users] warnings building openmpi-v2.x-dev-950-g995993b</a>&nbsp;<a name="28236"><em>(2016-01-07 05:08:16)</em></a></li></ul>
<ul><li><a href="28215.php">[OMPI users] runtime errors with openmpi-v2.x-dev-950-g995993b</a>&nbsp;<a name="28215"><em>(2016-01-06 07:57:20)</em></a></li></ul>
<li><strong>Steve O'Hara</strong>
<ul><li><a href="28370.php">Re: [OMPI users] Raspberry Pi 2 Beowulf Cluster for OpenFOAM</a>&nbsp;<a name="28370"><em>(2016-01-25 10:04:09)</em></a></li></ul>
<ul><li><a href="28358.php">Re: [OMPI users] Raspberry Pi 2 Beowulf Cluster for OpenFOAM</a>&nbsp;<a name="28358"><em>(2016-01-24 15:39:28)</em></a></li></ul>
<ul><li><a href="28357.php">Re: [OMPI users] Raspberry Pi 2 Beowulf Cluster for OpenFOAM</a>&nbsp;<a name="28357"><em>(2016-01-24 15:21:58)</em></a></li></ul>
<ul><li><a href="28349.php">[OMPI users] Raspberry Pi 2 Beowulf Cluster for OpenFOAM</a>&nbsp;<a name="28349"><em>(2016-01-23 15:47:10)</em></a></li></ul>
<li><strong>Sylvain Jeaugey</strong>
<ul><li><a href="28342.php">Re: [OMPI users] configuring open mpi 10.1.2 with cuda on NVIDIA TK1</a>&nbsp;<a name="28342"><em>(2016-01-22 13:07:33)</em></a></li></ul>
<ul><li><a href="28340.php">Re: [OMPI users] configuring open mpi 10.1.2 with cuda on NVIDIA TK1</a>&nbsp;<a name="28340"><em>(2016-01-22 12:34:37)</em></a></li></ul>
<li><strong>Thomas Jahns</strong>
<ul><li><a href="28330.php">Re: [OMPI users] MPI, Fortran, and GET_ENVIRONMENT_VARIABLE</a>&nbsp;<a name="28330"><em>(2016-01-21 10:53:47)</em></a></li></ul>
<li><strong>Thomas Ponweiser</strong>
<ul><li><a href="28263.php">[OMPI users] MPI_Type_free and non-blocking operations</a>&nbsp;<a name="28263"><em>(2016-01-13 08:33:28)</em></a></li></ul>
<li><strong>tmishima_at_[hidden]</strong>
<ul><li><a href="28398.php">Re: [OMPI users] Any changes to rmaps in 1.10.2?</a>&nbsp;<a name="28398"><em>(2016-01-28 18:19:02)</em></a></li></ul>
<li><strong>Tom Wurgler</strong>
<ul><li><a href="28297.php">Re: [OMPI users] [EXT] Re:  Openmpi 1.8.8 and affinty</a>&nbsp;<a name="28297"><em>(2016-01-15 12:07:07)</em></a></li></ul>
<li><strong>twurgl_at_[hidden]</strong>
<ul><li><a href="28288.php">[OMPI users] Openmpi 1.8.8 and affinty</a>&nbsp;<a name="28288"><em>(2016-01-15 09:53:57)</em></a></li></ul>
<li><strong>Udayanga Wickramasinghe</strong>
<ul><li><a href="28304.php">[OMPI users] Using OpenMPI Thread Multiple mode</a>&nbsp;<a name="28304"><em>(2016-01-19 19:13:14)</em></a></li></ul>
<li><strong>William Law</strong>
<ul><li><a href="28408.php">[OMPI users] OpenMPI against multiple, evolving SLURM versions</a>&nbsp;<a name="28408"><em>(2016-01-29 01:12:21)</em></a></li></ul>
<li><strong>&#168;q&#161;&#239;&#168;s</strong>
<ul><li><a href="28299.php">[OMPI users] (no subject)</a>&nbsp;<a name="28299"><em>(2016-01-18 09:24:52)</em></a></li></ul>
</ul>
<hr>
<div class="center">
<table>
<tr><th><a name="end">Last message date: </a></th><td><em>2016-07-27 12:01:45</em></td>
<th>Archived on: </th><td><em>2016-07-27 12:02:19 EDT</em></td>
</table>
</div>
<div class="center">
<table border="2" width="100%" class="links">
<tr>
<th><a href="date.php">Date view</a></th>
<th><a href="index.php">Thread view</a></th>
<th><a href="subject.php">Subject view</a></th>
</tr><tr><th><a href="http://www.open-mpi.org/community/lists/users/2015/12/author.php">Previous Folder, Author view</a></th><th><a href="http://www.open-mpi.org/community/lists/users/2016/02/author.php">Next Folder, Author view</a></th><th><a href="http://www.open-mpi.org/community/lists/users/index.php">List of Folders</a></th></tr>
</table>
</div>
<!-- trailer="footer" -->
<? 
if (preg_match("/\/[12][0-9][0-9][0-9]\/[01][0-9]\//", $_SERVER{'REQUEST_URI'})) {
    include("../../include/index-footer.inc");
} else {
    include("include/index-footer.inc");
}
?>
