<html><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; ">Your command line may have just come across with a typo, but something isn't right:<div><br></div><div><span class="Apple-style-span" style="font-size: 10px; ">-hostfile /home/sysgen/infiniband-mpi-test/machine/usr/mpi/gcc4/openmpi-1.2.2-1/tests/IMB-2.3/IMB-MPI1</span></div><div><font class="Apple-style-span" size="2"><span class="Apple-style-span" style="font-size: 10px;"><br></span></font></div><div><font class="Apple-style-span" size="2"><span class="Apple-style-span" style="font-size: 10px;"><font class="Apple-style-span" size="3"><span class="Apple-style-span" style="font-size: 12px;">That looks more like a path to a binary than a path to a hostfile. Is there a missing space or filename somewhere?</span></font></span></font></div><div><br></div><div><font class="Apple-style-span" size="2"><span class="Apple-style-span" style="font-size: 10px;"><font class="Apple-style-span" size="3"><span class="Apple-style-span" style="font-size: 12px;">If not, then I would have expected this to error out since the argument would be taken as the hostfile, leaving no executable specified.</span></font></span></font></div><div><br></div><div><font class="Apple-style-span" size="2"><span class="Apple-style-span" style="font-size: 10px;"><font class="Apple-style-span" size="3"><span class="Apple-style-span" style="font-size: 12px;">If you get that straightened out, then try adding -mca btl openib,sm,self to the cmd line. This will direct mpirun to use only the OpenIB, shared memory, and loopback transports, so you shouldn't pick up uDAPL any more.</span></font></span></font></div><div><br></div><div><font class="Apple-style-span" size="2"><span class="Apple-style-span" style="font-size: 10px;"><font class="Apple-style-span" size="3"><span class="Apple-style-span" style="font-size: 12px;">Ralph</span></font></span></font></div><div><br></div><div><font class="Apple-style-span" size="2"><span class="Apple-style-span" style="font-size: 10px;"><font class="Apple-style-span" size="3"><span class="Apple-style-span" style="font-size: 12px;"><br></span></font></span></font><div><div>On Nov 20, 2008, at 12:38 PM, Michael Oevermann wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"> <div bgcolor="#ffffff" text="#000000"> <pre wrap="">Hi all,

I have "inherited" a small cluster with a head node and four compute
nodes which I have to administer.  The nodes are connected via infiniband (OFED), but the head is not. 
I am a complete novice to the infiniband stuff and here is my problem:

The infiniband configuration seems to be OK. The usual tests suggested in the OFED install guide give 
the expected output, e.g.

</pre><p><big><big><tt>ibv_devinfo on the nodes:</tt></big></big><br> </p> <tt><br> <small>************************* oscar_cluster *************************<br> --------- n01---------<br> hca_id: mthca0<br> fw_ver: 1.2.0<br> node_guid: 0002:c902:0025:930c<br> sys_image_guid: 0002:c902:0025:930f<br> vendor_id: 0x02c9<br> vendor_part_id: 25204<br> hw_ver: 0xA0<br> board_id: MT_03B0140001<br> phys_port_cnt: 1<br> port: 1<br> state: PORT_ACTIVE (4)<br> max_mtu: 2048 (4)<br> active_mtu: 2048 (4)<br> sm_lid: 2<br> port_lid: 1<br> port_lmc: 0x00<br> </small></tt><br> etc. for the other nodes.<br> <br> <big><big>sminfo on the nodes:</big></big><br> <br> *<small>************************ oscar_cluster *************************<br> --------- n01---------<br> sminfo: sm lid 2 sm guid 0x2c90200259201, activity count 6881 priority 0 state 3 SMINFO_MASTER<br> --------- n02---------<br> sminfo: sm lid 2 sm guid 0x2c90200259201, activity count 6882 priority 0 state 3 SMINFO_MASTER<br> --------- n03---------<br> sminfo: sm lid 2 sm guid 0x2c90200259201, activity count 6883 priority 0 state 3 SMINFO_MASTER<br> --------- n04---------<br> sminfo: sm lid 2 sm guid 0x2c90200259201, activity count 6884 priority 0 state 3 SMINFO_MASTER<br> <br> </small><br> <br> However, when I directly start a mpi job (without using a scheduler) via:<br> <br> <small>/usr/mpi/gcc4/openmpi-1.2.2-1/bin/mpirun -np 4 -hostfile /home/sysgen/infiniband-mpi-test/machine/usr/mpi/gcc4/openmpi-1.2.2-1/tests/IMB-2.3/IMB-MPI1<br> <br> <big>I get the error message:<br> <br> </big></small> <pre wrap=""><small>0,1,0]: uDAPL on host n01 was unable to find any NICs.
Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
[0,1,2]: uDAPL on host n01 was unable to find any NICs.
Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
[0,1,3]: uDAPL on host n02 was unable to find any NICs.
Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
[0,1,1]: uDAPL on host n02 was unable to find any NICs.
Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------</small></pre> <small><big>MPI with normal GB Etherrnet and IP networking just works fine, but the infinband doesn't. The MPI libs I am using<br> for the test are definitely compiled with IB support and the tests have been run successfully on<br> the cluster before. <br> <br> Any suggestions what is going wrong here?<br> <br> Best regards and thanks for any help!<br> <br> Michael<br> </big><br> <br> <br> </small><br> </div>  _______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>http://www.open-mpi.org/mailman/listinfo.cgi/users</blockquote></div><br></div></body></html>
