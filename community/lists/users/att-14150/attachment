<html><head></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; ">It's not a bug - that is normal behavior. The processes are polling hard to establish the connections as quickly as possible.<div><br></div><div><br><div><div>On Sep 1, 2010, at 7:24 PM, lyb wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite">
<div bgcolor="#ffffff" text="#000000">
Hi, All,<br>
<br>
I tested two sample applications on Windows 2003 Server, one use
MPI_Comm_accept and other use MPI_Comm_connect, <br>
when run into MPI_Comm_accept or MPI_Comm_connect, the application use
100% one cpu core.&nbsp; Is it a bug or some wrong?<br>
<br>
I tested with three version including <a href="http://www.open-mpi.org/software/ompi/v1.4/" class="navbarsub2">Version
1.4 (stable)</a>, <a href="http://www.open-mpi.org/software/ompi/v1.5/" class="navbarsub2">Version 1.5 (prerelease)</a> and trunk 23706
version.<br>
<br>
...<br>
MPI_Open_port(MPI_INFO_NULL, port);<br>
MPI_Comm_accept( port, MPI_INFO_NULL, 0, MPI_COMM_WORLD,&nbsp;&nbsp;&nbsp; &amp;client
);<br>
...<br>
<br>
...<br>
MPI_Comm_connect( port, MPI_INFO_NULL, 0, MPI_COMM_WORLD,&nbsp;&nbsp;&nbsp;
&amp;server );<br>
...<br>
<br>
thanks a lot.<br>
<br>
lyb<br>
<br>
<br>
<br>
<br>
<br>
</div>

_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>http://www.open-mpi.org/mailman/listinfo.cgi/users</blockquote></div><br></div></body></html>
