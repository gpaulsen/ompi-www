Thanks a lot for your reply, Doug. <div>  <div><div>There is one more thing I forgot to mention. For 500 nodes test, I observe if I use SGE, it runs only almost half of our cluster, like 35-38 nodes, not uniformly distributed on the whole cluster but the running time is still good.  So I guess it is not a hyperthreading problem. </div>
<div><br></div><div>Linbao<br><br><div class="gmail_quote">On Mon, Oct 4, 2010 at 12:06 PM, Doug Reeder <span dir="ltr">&lt;<a href="mailto:dlr1@cox.net">dlr1@cox.net</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;">
<div style="word-wrap:break-word">In my experience hyperthreading can&#39;t really deliver two cores worth of processing simultaneously for processes expecting sole use of a core. Since you really have 512 cores I&#39;m not surprised that you see a performance hit when requesting &gt; 512 compute units. We should really get input from a hyperthreading expert, preferably form intel.<div>
<br></div><div>Doug Reeder<br><div><div><div></div><div class="h5"><div>On Oct 4, 2010, at 9:53 AM, Storm Zhang wrote:</div><br></div></div><blockquote type="cite"><div><div></div><div class="h5"><span style="font-family:arial, sans-serif;font-size:13px;border-collapse:collapse"><div>
<span style="font-family:arial, sans-serif;font-size:13px;border-collapse:collapse">We have 64 compute nodes which are dual qual-core and hyperthreaded CPUs. So we have 1024 compute units shown in the ROCKS 5.3 system. I&#39;m trying to scatter an array from the master node to the compute nodes using mpiCC and mpirun using C++. </span></div>

<div><span style="font-family:arial, sans-serif;font-size:13px;border-collapse:collapse"><br></span></div><div><span style="font-family:arial, sans-serif;font-size:13px;border-collapse:collapse">Here is my test:</span></div>

<div><span style="font-family:arial, sans-serif;font-size:13px;border-collapse:collapse"><br></span></div><div><span style="font-family:arial, sans-serif;font-size:13px;border-collapse:collapse">The array size is 18KB * Number of compute nodes and is scattered to the compute nodes 5000 times repeatly. </span></div>

<div><span style="font-family:arial, sans-serif;font-size:13px;border-collapse:collapse"><br></span></div><div><span style="font-family:arial, sans-serif;font-size:13px;border-collapse:collapse">The average running time(seconds):</span></div>

<div><span style="font-family:arial, sans-serif;font-size:13px;border-collapse:collapse"><br></span></div><div><span style="font-family:arial, sans-serif;font-size:13px;border-collapse:collapse">100 nodes: 170,</span></div>

<div>400 nodes: 690,</div><div>500 nodes: 855,</div><div>600 nodes: 2550,</div><div>700 nodes: 2720,</div><div>800 nodes: 2900,</div><div><br></div><div>There is a big jump of running time from 500 nodes to 600 nodes. <span style="font-size:small">Don&#39;t know what&#39;s the problem. </span></div>

<div>Tried both in OMPI 1.3.2 and OMPI 1.4.2. Running time is a little faster for all the tests in 1.4.2 but the jump still exists. </div><div>Tried using either Bcast function or simply Send/Recv which give very close results. </div>

<div>Tried both in running it directly or using SGE and got the same results.</div><div><span style="font-size:small"><br></span></div><div><span style="font-size:small"><span style="font-size:13px"><div>
<span style="font-size:small">The code and ompi_info are attached to this email. The direct running command is :</span></div><div><span style="font-size:small"><div>
/opt/openmpi/bin/mpirun --mca btl_tcp_if_include eth0 --machinefile ../machines -np 600 scatttest</div><div><br></div><div>The ifconfig of head node for eth0 is:</div><div><div>eth0      Link encap:Ethernet  HWaddr 00:26:B9:56:8B:44  </div>

<div>          inet addr:192.168.1.1  Bcast:192.168.1.255  Mask:255.255.255.0</div><div>          inet6 addr: fe80::226:b9ff:fe56:8b44/64 Scope:Link</div><div>          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</div>

<div>          RX packets:1096060373 errors:0 dropped:2512622 overruns:0 frame:0</div><div>          TX packets:513387679 errors:0 dropped:0 overruns:0 carrier:0</div><div>          collisions:0 txqueuelen:1000 </div><div>

          RX bytes:832328807459 (775.1 GiB)  TX bytes:250824621959 (233.5 GiB)</div><div>          Interrupt:106 Memory:d6000000-d6012800 </div></div><div><br></div><div>A typical ifconfig of a compute node is:</div><div>

<div>eth0      Link encap:Ethernet  HWaddr 00:21:9B:9A:15:AC  </div><div>          inet addr:192.168.1.253  Bcast:192.168.1.255  Mask:255.255.255.0</div><div>          inet6 addr: fe80::221:9bff:fe9a:15ac/64 Scope:Link</div>

<div>          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</div><div>          RX packets:362716422 errors:0 dropped:0 overruns:0 frame:0</div><div>          TX packets:349967746 errors:0 dropped:0 overruns:0 carrier:0</div>

<div>          collisions:0 txqueuelen:1000 </div><div>          RX bytes:139699954685 (130.1 GiB)  TX bytes:338207741480 (314.9 GiB)</div><div>          Interrupt:82 Memory:d6000000-d6012800 </div></div><div><br></div></span></div>

</span></span></div><div><span style="font-size:small"><br></span></div><div><span style="font-size:small">Does anyone help me out of this? It bothers me a lot.</span></div>
<div><span style="font-size:small"><br></span></div><div><span style="font-size:small">Thank you very much.</span></div><div><span style="font-size:small"><br>
</span></div><div><span style="font-size:small">Linbao</span></div></span>
</div></div><span>&lt;scatttest.cpp&gt;</span><span>&lt;ompi_info&gt;</span>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></blockquote></div><br></div></div><br>_______________________________________________<br>

users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></div><br></div></div></div>

