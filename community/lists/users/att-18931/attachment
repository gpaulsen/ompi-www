Hi, <br><br>I am running a MPI program using cluster and tcp communication. <br><br>To run I am using:  <b>mpirun --prefix /usr/local/ --mca btl tcp,self --hostfile slaves -np 6 scatter</b><br><br><br>I am getting following output: <br>
<br>Process 0 on host host1 has elements 0 1 2 3<br>Process 1 on host host1 has elements 4 5 6 7<br>Process 2 on host host1 has elements 8 9 10 11<br>Process 3 on host host1 has elements 12 13 14 15<br>[slave1][[24708,1],5][btl_tcp_endpoint.c:486:mca_btl_tcp_endpoint_recv_connect_ack] received unexpected process identifier [[24708,1],4]<br>
<br>When trying to communicate with slave1 i get received unexpected process identifier error.<br><br>My PATH and LD_LIBRARY_PATH are correctly set in .bashrc file. <br><br><br><br>Source code - <br><br>     <br>#include &lt;stdlib.h&gt;
<br>#include &lt;stdio.h&gt;
<br>#include &quot;mpi.h&quot;
<br>#define MAXPROC 8    /* Max number of procsses */
<br>#define LENGTH 24    /* length of buffer */
<br> <br>int main(int argc, char* argv[]) {
<br>  int i, j, np, me;
<br>  const int nametag  = 40;    /* Tag value for sending name */
<br>  const int datatag  = 45;    /* Tag value for sending data */
<br>  const int root = 0;         /* Root process in scatter */
<br>  MPI_Status status;          /* Status object for receive */
<br> <br>  char myname[MPI_MAX_PROCESSOR_NAME];       /* Local host name string */
<br>  char hostname[MAXPROC][MPI_MAX_PROCESSOR_NAME];  /* Received host names */
<br>  int namelen;
<br> <br>  int x[LENGTH];        /* Send buffer */
<br>  int y[LENGTH];        /* Receive buffer */
<br> <br>  MPI_Init(&amp;argc, &amp;argv);                /* Initialize MPI */
<br>  MPI_Comm_size(MPI_COMM_WORLD, &amp;np);    /* Get nr of processes */
<br>  MPI_Comm_rank(MPI_COMM_WORLD, &amp;me);    /* Get own identifier */
<br>  
<br>  MPI_Get_processor_name(myname, &amp;namelen);  /* Get host name */
<br>  myname[namelen++] = (char)0;               /* Terminating null byte */
<br> <br>  /* Check that we have an even number of processes and at most MAXPROC */
<br>  if (np&gt;MAXPROC || np%2 != 0) {
<br>    if (me == 0) {
<br>      printf(&quot;You have to use an even number of processes (at most %d)\n&quot;, MAXPROC);
<br>    }
<br>    MPI_Finalize();
<br>    exit(0);
<br>  }
<br> <br>  if (me == 0) {    /* Process 0 does this */
<br>    
<br>    /* Initialize the array x with values 0 .. LENGTH-1 */
<br>    for (i=0; i&lt;LENGTH; i++) {
<br>      x[i] = i;
<br>    }
<br> <br>    printf(&quot;Process %d on host %s is distributing array x to all %d processes\n\n&quot;,
<br>       me, myname, np);
<br> <br>    /* Scatter the array x to all proceses, place it in y */
<br>    MPI_Scatter(x, LENGTH/np, MPI_INT, y, LENGTH/np, MPI_INT, root,
<br>        MPI_COMM_WORLD);
<br> <br>    /* Print out own portion of the scattered array */
<br>    printf(&quot;Process %d on host %s has elements&quot;, me, myname);
<br>    for (i=0; i&lt;LENGTH/np; i++) {
<br>      printf(&quot; %d&quot;, y[i]);
<br>    }
<br>    printf(&quot;\n&quot;);
<br> <br>    /* Receive messages with hostname and the scattered data */
<br>    /* from all other processes */
<br>    for (i=1; i&lt;np; i++) {
<br>      MPI_Recv (hostname[i], namelen, MPI_CHAR, i, nametag, MPI_COMM_WORLD,
<br>        &amp;status);
<br>      MPI_Recv (y, LENGTH/np, MPI_INT, i, datatag, MPI_COMM_WORLD, &amp;status);
<br>      printf(&quot;Process %d on host %s has elements&quot;, i, hostname[i]);
<br>      for (j=0; j&lt;LENGTH/np; j++) {
<br>    printf(&quot; %d&quot;, y[j]);
<br>      }
<br>      printf(&quot;\n&quot;);
<br>    }
<br>    
<br>    printf(&quot;Ready\n&quot;);
<br> <br> <br>  } else { /* all other processes do this */
<br> <br>    /* Receive the scattered array from process 0, place it in array y */
<br>    MPI_Scatter(x, LENGTH/np, MPI_INT, y, LENGTH/np, MPI_INT, root, \
<br>        MPI_COMM_WORLD);
<br>    /* Send own name back to process 0 */
<br>    MPI_Send (myname, namelen, MPI_CHAR, 0, nametag, MPI_COMM_WORLD);
<br>    /* Send the received array back to process 0 */
<br>    MPI_Send (y, LENGTH/np, MPI_INT, 0, datatag, MPI_COMM_WORLD);
<br> <br>  }
<br> <br>  MPI_Finalize();
<br>  exit(0);
<br>}<br><br>Any idea what could be wrong? <br><br clear="all"><br>Thanks<br><div><span style="font-size:13px;border-collapse:collapse"><font color="#000099" face="verdana, sans-serif"><font></font></font></span></div><br>
<br><div><span style="font-size:13px"><br><font color="#666666" face="georgia, serif"><br></font></span></div><br>

