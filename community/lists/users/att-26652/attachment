<html><head><meta http-equiv="Content-Type" content="text/html charset=utf-8"></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;" class="">Hmmm…could you try 1.8.5rc1? We’ve done some thread-related stuff on it, but we may not have solved this level of use just yet. We are working on the new1.9 series that we hope to make more thread friendly<div class=""><br class=""></div><div class=""><a href="http://www.open-mpi.org/software/ompi/v1.8/" class="">http://www.open-mpi.org/software/ompi/v1.8/</a></div><div class=""><br class=""></div><div class=""><br class=""><div><blockquote type="cite" class=""><div class="">On Apr 7, 2015, at 11:16 AM, Thomas Klimpel &lt;<a href="mailto:jacques.gentzen@gmail.com" class="">jacques.gentzen@gmail.com</a>&gt; wrote:</div><br class="Apple-interchange-newline"><div class=""><div dir="ltr" class="">Here is a stackdump from inside the debugger (because it gives filenames and line numbers):<br class=""><br class="">Program received signal SIGSEGV, Segmentation fault.<br class="">[Switching to Thread 0x7f1eb6bfd700 (LWP 24847)]<br class="">0x000000366aa79252 in _int_malloc () from /lib64/libc.so.6<br class=""><div class="gmail_extra">(gdb) bt<br class="">#0&nbsp; 0x000000366aa79252 in _int_malloc () from /lib64/libc.so.6<br class="">#1&nbsp; 0x000000366aa7b7da in _int_realloc () from /lib64/libc.so.6<br class="">#2&nbsp; 0x000000366aa7baf5 in realloc () from /lib64/libc.so.6<br class="">#3&nbsp; 0x00007f1ee005d0a8 in epoll_dispatch (base=&lt;value optimized out&gt;, arg=0x13d1310, tv=&lt;value optimized out&gt;)<br class="">&nbsp;&nbsp;&nbsp; at ../../../../../package/openmpi-1.6.5/opal/event/epoll.c:271<br class="">#4&nbsp; 0x00007f1ee005f1cf in opal_event_base_loop (base=0x13d1e50, flags=&lt;value optimized out&gt;)<br class="">&nbsp;&nbsp;&nbsp; at ../../../../../package/openmpi-1.6.5/opal/event/event.c:838<br class="">#5&nbsp; 0x00007f1ee00842f9 in opal_progress () at ../../../../package/openmpi-1.6.5/opal/runtime/opal_progress.c:189<br class="">#6&nbsp; 0x00007f1ecd43cd7f in mca_pml_ob1_iprobe (src=&lt;value optimized out&gt;, tag=-1, comm=0x164dd40, matched=0x7f1eb6bfb8ac, status=0x7f1eb6bfb8b0)<br class="">&nbsp;&nbsp;&nbsp; at ../../../../../../../package/openmpi-1.6.5/ompi/mca/pml/ob1/pml_ob1_iprobe.c:48<br class="">#7&nbsp; 0x00007f1edffe3427 in PMPI_Iprobe (source=227, tag=-1, comm=0x164dd40, flag=&lt;value optimized out&gt;, status=&lt;value optimized out&gt;)<br class="">&nbsp;&nbsp;&nbsp; at piprobe.c:79<br class="">#8&nbsp; 0x00007f1eebb518e7 in OMPIConnection::Receive (this=0x13c7950, rMessage_p=std::vector of length 0, capacity 0, <br class="">&nbsp;&nbsp;&nbsp; rMessageId_p=@0x7f1eb6bfc26c, NodeId_p=227)<br class=""></div></div>
_______________________________________________<br class="">users mailing list<br class=""><a href="mailto:users@open-mpi.org" class="">users@open-mpi.org</a><br class="">Subscription: http://www.open-mpi.org/mailman/listinfo.cgi/users<br class="">Link to this post: http://www.open-mpi.org/community/lists/users/2015/04/26642.php</div></blockquote></div><br class=""></div></body></html>
