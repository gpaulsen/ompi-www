Collecting MPI Profile information might help narrow down the issue. You  could use some of the tools mentioned here - <a href="http://www.open-mpi.org/faq/?category=perftools">http://www.open-mpi.org/faq/?category=perftools</a><br>
<br>--Nysal<br><br><div class="gmail_quote">On Wed, Dec 1, 2010 at 11:59 PM, Price, Brian M (N-KCI) <span dir="ltr">&lt;<a href="mailto:brian.m.price@lmco.com">brian.m.price@lmco.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; border-left: 1px solid rgb(204, 204, 204); padding-left: 1ex;">









<div link="blue" vlink="purple" lang="EN-US">

<div>

<p class="MsoNormal">OpenMPI version: 1.4.3</p>

<p class="MsoNormal">Platform: IBM P5, 32 processors, 256 GB memory, Symmetric
Multi-Threading (SMT) enabled</p>

<p class="MsoNormal">Application: starts up 48 processes and does MPI using
MPI_Barrier, MPI_Get, MPI_Put (lots of transfers, large amounts of data)</p>

<p class="MsoNormal">Issue:  When implemented using Open MPI vs. IBM’s
MPI (‘poe’ from HPC Toolkit), the application runs 3-5 times
slower.</p>

<p class="MsoNormal">I suspect that IBM’s MPI implementation must take
advantage of some knowledge that it has about data transfers that Open MPI is
not taking advantage of.</p>

<p class="MsoNormal">Any suggestions?</p>

<p class="MsoNormal">Thanks,</p>

<p class="MsoNormal">Brian Price</p>

<p class="MsoNormal"> </p>

</div>

</div>


<br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></div><br>

