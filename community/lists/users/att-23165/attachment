<font size=2 face="sans-serif">Thanks to Ralph, Gus and Georg for your
input!</font>
<br>
<br><font size=2 face="sans-serif">I was diverted to other things for a
week, but now back on track...</font>
<br>
<br><font size=2 face="sans-serif">You deserve to have the question marks
straightened out first: The two application are (1) a commercial solver
and (2) an in-house code handling some special physics. The two codes will
run sequentially, taking turns one time step at a time. The commercial
solver runs one time step, outputs some data to file, then waits for the
in-house code to do some work, then goes to next time step. The in-house
code is actually restarted each time it has work to do. (This is what I
mean with &quot;loosely coupled&quot;.)</font>
<br>
<br><font size=2 face="sans-serif">As the two codes never work at the same
time, I would like them to use the same hardware. The commercial solver
may be reluctant to release its cores to other processes (&quot;agressive&quot;),
but I hope it will at the end of time steps... The commercial code will
just be started as usual, using the full allocation of the MOAB job. The
in-house code is the one using openmpi, and I want it to use all of the
cores in the first node of the allocation, and only those.</font>
<br>
<br><font size=2 face="sans-serif">As Ralph suggests, it seems very convenient
to use the -host option with relative node syntax. I also found some other
references on how mpirun handles host info from the resources managers.
Starting the two codes as background jobs, like Georg does, sounds good.
I will simply give it a spin and see how it works...</font>
<br>
<br><font size=2 face="sans-serif">Thanks again for your time,</font>
<br>
<br><font size=2 face="sans-serif">Ola</font>
<br><font size=2 face="sans-serif"><br>
</font>
