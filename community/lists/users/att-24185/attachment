<div dir="ltr">to get help :)<br><br></div><div class="gmail_extra"><br><br><div class="gmail_quote">On Mon, Apr 14, 2014 at 3:11 PM, Djordje Romanic <span dir="ltr">&lt;<a href="mailto:djordje8@gmail.com" target="_blank">djordje8@gmail.com</a>&gt;</span> wrote:<br>

<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir="ltr">Yes, but I was hoping to get. :) <br></div><div class="HOEnZb"><div class="h5"><div class="gmail_extra">

<br><br><div class="gmail_quote">On Mon, Apr 14, 2014 at 3:02 PM, Jeff Squyres (jsquyres) <span dir="ltr">&lt;<a href="mailto:jsquyres@cisco.com" target="_blank">jsquyres@cisco.com</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">If you didn&#39;t use Open MPI, then this is the wrong mailing list for you.  :-)<br>
<br>
(this is the Open MPI users&#39; support mailing list)<br>
<div><div><br>
<br>
On Apr 14, 2014, at 2:58 PM, Djordje Romanic &lt;<a href="mailto:djordje8@gmail.com" target="_blank">djordje8@gmail.com</a>&gt; wrote:<br>
<br>
&gt; I didn&#39;t use OpenMPI.<br>
&gt;<br>
&gt;<br>
&gt; On Mon, Apr 14, 2014 at 2:37 PM, Jeff Squyres (jsquyres) &lt;<a href="mailto:jsquyres@cisco.com" target="_blank">jsquyres@cisco.com</a>&gt; wrote:<br>
&gt; This can also happen when you compile your application with one MPI implementation (e.g., Open MPI), but then mistakenly use the &quot;mpirun&quot; (or &quot;mpiexec&quot;) from a different MPI implementation (e.g., MPICH).<br>



&gt;<br>
&gt;<br>
&gt; On Apr 14, 2014, at 2:32 PM, Djordje Romanic &lt;<a href="mailto:djordje8@gmail.com" target="_blank">djordje8@gmail.com</a>&gt; wrote:<br>
&gt;<br>
&gt; &gt; I compiled it with: x86_64 Linux, gfortran compiler with gcc   (dmpar). dmpar - distributed memory option.<br>
&gt; &gt;<br>
&gt; &gt; Attached is the self-generated configuration file. The architecture specification settings start at line 107. I didn&#39;t use Open MPI (shared memory option).<br>
&gt; &gt;<br>
&gt; &gt;<br>
&gt; &gt; On Mon, Apr 14, 2014 at 1:23 PM, Dave Goodell (dgoodell) &lt;<a href="mailto:dgoodell@cisco.com" target="_blank">dgoodell@cisco.com</a>&gt; wrote:<br>
&gt; &gt; On Apr 14, 2014, at 12:15 PM, Djordje Romanic &lt;<a href="mailto:djordje8@gmail.com" target="_blank">djordje8@gmail.com</a>&gt; wrote:<br>
&gt; &gt;<br>
&gt; &gt; &gt; When I start wrf with mpirun -np 4 ./wrf.exe, I get this:<br>
&gt; &gt; &gt; -------------------------------------------------<br>
&gt; &gt; &gt;  starting wrf task            0  of            1<br>
&gt; &gt; &gt;  starting wrf task            0  of            1<br>
&gt; &gt; &gt;  starting wrf task            0  of            1<br>
&gt; &gt; &gt;  starting wrf task            0  of            1<br>
&gt; &gt; &gt; -------------------------------------------------<br>
&gt; &gt; &gt; This indicates that it is not using 4 processors, but 1.<br>
&gt; &gt; &gt;<br>
&gt; &gt; &gt; Any idea what might be the problem?<br>
&gt; &gt;<br>
&gt; &gt; It could be that you compiled WRF with a different MPI implementation than you are using to run it (e.g., MPICH vs. Open MPI).<br>
&gt; &gt;<br>
&gt; &gt; -Dave<br>
&gt; &gt;<br>
&gt; &gt; _______________________________________________<br>
&gt; &gt; users mailing list<br>
&gt; &gt; <a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
&gt; &gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; &gt;<br>
&gt; &gt; &lt;configure.wrf&gt;_______________________________________________<br>
&gt; &gt; users mailing list<br>
&gt; &gt; <a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
&gt; &gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt;<br>
&gt;<br>
&gt; --<br>
&gt; Jeff Squyres<br>
&gt; <a href="mailto:jsquyres@cisco.com" target="_blank">jsquyres@cisco.com</a><br>
&gt; For corporate legal information go to: <a href="http://www.cisco.com/web/about/doing_business/legal/cri/" target="_blank">http://www.cisco.com/web/about/doing_business/legal/cri/</a><br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
<br>
--<br>
Jeff Squyres<br>
<a href="mailto:jsquyres@cisco.com" target="_blank">jsquyres@cisco.com</a><br>
For corporate legal information go to: <a href="http://www.cisco.com/web/about/doing_business/legal/cri/" target="_blank">http://www.cisco.com/web/about/doing_business/legal/cri/</a><br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div>

