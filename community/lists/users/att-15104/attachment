<div>
I don&#39;t understand 1 thing though and would appreciate your comments.</div>
<div>
&nbsp;</div>
<div>
In various interfaces, like network sockets, or threads waiting for data from somewhere, there are various solutions based on _not_ checking the state of the socket or some sort of &nbsp;queue continuously, but sort of getting _interrupted_ when there is data around, or like condition variables for threads.</div>
<div>
I am not very clear on these points, but it seems that in these contexts, continuous polling is avoided and so actual CPU usage is usually not close to 100%.</div>
<div>
&nbsp;</div>
<div>
Why can&#39;t something similar be implemented with broadcast for e.g.?</div>
<div>
&nbsp;</div>
<div>
-----Original Message-----<br />
<b>From: &quot;</b>Jeff Squyres&quot; [jsquyres@cisco.com]<br />
<b>Date: </b>13/12/2010 03:55 PM<br />
<b>To: </b>&quot;Open MPI Users&quot; <users@open-mpi.org><br />
<b>Subject: </b>Re: [OMPI users] curious behavior during wait for broadcast: 100% cpu<br />
<br />
I think there *was* a decision and it effectively changed how sched_yield() effectively operates, and that it may not do what we expect any more.<br />
<br />
See this thread (the discussion of Linux/sched_yield() comes in the later messages):<br />
<br />
<a href="http://www.open-mpi.org/community/lists/users/2010/07/13729.php" target="_blank">http://www.open-mpi.org/community/lists/users/2010/07/13729.php</a><br />
<br />
I believe there&#39;s similar threads in the MPICH mailing list archives; that&#39;s why Dave posted on the OMPI list about it.<br />
<br />
We briefly discussed replacing OMPI&#39;s sched_yield() with a usleep(1), but it was shot down.<br />
<br />
<br />
<br />
</users@open-mpi.org></div>

