<html><head><meta http-equiv="Content-Type" content="text/html charset=windows-1252"></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;"><br><div><div>On Nov 23, 2013, at 01:18 , Pierre Jolivet &lt;<a href="mailto:jolivet@ann.jussieu.fr">jolivet@ann.jussieu.fr</a>&gt; wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><div style="font-family: CourierNewPSMT; font-size: 12px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px; word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;">George,<div><br><div><div>On Nov 22, 2013, at 5:21 AM, George Bosilca &lt;<a href="mailto:bosilca@icl.utk.edu">bosilca@icl.utk.edu</a>&gt; wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><div style="font-size: 12px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;">Pierre,<br><br>On Nov 22, 2013, at 02:39 , Pierre Jolivet &lt;<a href="mailto:jolivet@ann.jussieu.fr">jolivet@ann.jussieu.fr</a>&gt; wrote:<br><br><blockquote type="cite">George,<br>I completely agree that the code I sent was a good example of what NOT to do with collective and non-blocking communications, so I’m sending a better one.<br>1. I’m setting MPI_DATATYPE_NULL only on non-root processes. The root has a real datatype. Why should both match when using MPI_IN_PLACE ?<br></blockquote><br>Because it is a strong requirement of the MPI standard: the typemap of a send should be matched by its corresponding receive. Otherwise, it is legal to raise an exception of type MPI_ERR_TYPE.<br><br><blockquote type="cite">2-3-4. Yes, all these points are valid, this is of course just a minimalist example.<br><br>My question is, if you are indeed saying that it is not a OpenMPI bug, what is the rationale for changing the behavior between MPI_Scatter and MPI_Iscatter when it comes down to the send type on non-root processes.<br></blockquote><br>Different algorithms implemented by different people. Some of them are more robust, while others less. In this case Scatter translate the count = 0 to a message length = 0, while the Iscatter always look for the extent of the datatype.<br><br><blockquote type="cite">I don’t see any remark on that matter on the MPI 3.0 documentation.<br></blockquote><br>Indeed, and there is at least one example where MPI_DATATYPE_NULL is explicitly used for calls where the datatype does not matter (4.23 as an example). Horrible!!!<br></div></blockquote><div><br></div><div>That’s what I don’t get, why are you saying it’s horrible ? It is clearly written in the spec. that the data type is only significant at root (for Scatter), and that Iscatter is nothing else than a nonblocking variant of Scatter (so the value should also be significant only at root).</div></div></div></div></blockquote><br><div>Because this is mixing two concepts: non-existence and non-significance.&nbsp;</div><div><br></div><blockquote type="cite"><div style="font-family: CourierNewPSMT; font-size: 12px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px; word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;"><div><div><div>Moreover, there is at least one thing that is wrong in the sources:</div><div>1) in ompi/mca/coll/libnbc/nbc_igather.c, line 55 should read:</div><div>&nbsp; if (MPI_SUCCESS != res) { printf("MPI Error in MPI_Comm_size() (%i)\n", res); return res; }</div><div>instead of:</div><div>&nbsp; if (MPI_SUCCESS != res) { printf("MPI Error in MPI_Comm_rank() (%i)\n", res); return res; }</div><div><br></div><div>And I still have a hard time believing that the test line 56 in ompi/mca/coll/libnbc/nbc_igather.c — if (rank == root) — is not missing in ompi/mca/coll/libnbc/nbc_iscatter.c line 58, but I guess I will have to trust you on this one.</div></div></div></div></blockquote><div><br></div><div>A patch has been submitted (r29736). Thanks for the bug report.</div><div><br></div><div>&nbsp; George.</div><div><br></div><br><blockquote type="cite"><div style="font-family: CourierNewPSMT; font-size: 12px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px; word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;"><div><div><div><br></div><div>You should probably specify somewhere that you differ from the standard for that function, other MPI implementations don’t have this limitation, c.f.<a href="http://pic.dhe.ibm.com/infocenter/zos/v1r12/index.jsp?topic=/com.ibm.zos.r12.fomp200/ipezps0025.htm">http://pic.dhe.ibm.com/infocenter/zos/v1r12/index.jsp?topic=%2Fcom.ibm.zos.r12.fomp200%2Fipezps0025.htm</a>&nbsp;or&nbsp;<a href="http://trac.mpich.org/projects/mpich/browser/src/mpi/coll/iscatter.c#L601">http://trac.mpich.org/projects/mpich/browser/src/mpi/coll/iscatter.c#L601</a></div><div><br></div><div>Pierre</div><br><blockquote type="cite"><div style="font-size: 12px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;">&nbsp;George.<br><br><blockquote type="cite"><br>Thanks.<br><br>#include &lt;mpi.h&gt;<br><br>int main(int argc, char** argv) {<br>&nbsp;&nbsp;int &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskid, ntasks;<br>&nbsp;&nbsp;MPI_Init(&amp;argc, &amp;argv);<br>&nbsp;&nbsp;MPI_Request rq;<br><br>&nbsp;&nbsp;MPI_Comm_rank(MPI_COMM_WORLD,&amp;taskid);<br>&nbsp;&nbsp;MPI_Comm_size(MPI_COMM_WORLD,&amp;ntasks);<br>&nbsp;&nbsp;double* r;<br>&nbsp;&nbsp;int l = 0;<br>&nbsp;&nbsp;// This will run fine. MPI_DOUBLE<br>&nbsp;&nbsp;if(taskid &gt; 0)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MPI_Iscatter(NULL, 0, MPI_DOUBLE, r, l, MPI_DOUBLE, 0, MPI_COMM_WORLD, &amp;rq);<br>&nbsp;&nbsp;else<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MPI_Iscatter(r, l, MPI_DOUBLE, MPI_IN_PLACE, 0, MPI_DATATYPE_NULL, 0, MPI_COMM_WORLD, &amp;rq);<br>&nbsp;&nbsp;MPI_Wait(&amp;rq, MPI_STATUS_IGNORE);<br>&nbsp;&nbsp;// This will run fine. MPI_DATATYPE_NULL<br>&nbsp;&nbsp;if(taskid &gt; 0)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MPI_Scatter(NULL, 0, MPI_DATATYPE_NULL, r, l, MPI_DOUBLE, 0, MPI_COMM_WORLD);<br>&nbsp;&nbsp;else<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MPI_Scatter(r, l, MPI_DOUBLE, MPI_IN_PLACE, 0, MPI_DATATYPE_NULL, 0, MPI_COMM_WORLD);<br>&nbsp;&nbsp;// This will not run fine. MPI_DATATYPE_NULL<br>&nbsp;&nbsp;if(taskid &gt; 0)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MPI_Iscatter(NULL, 0, MPI_DATATYPE_NULL, r, l, MPI_DOUBLE, 0, MPI_COMM_WORLD, &amp;rq);<br>&nbsp;&nbsp;else<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MPI_Iscatter(r, l, MPI_DOUBLE, MPI_IN_PLACE, 0, MPI_DATATYPE_NULL, 0, MPI_COMM_WORLD, &amp;rq);<br>&nbsp;&nbsp;MPI_Wait(&amp;rq, MPI_STATUS_IGNORE);<br>&nbsp;&nbsp;MPI_Finalize();<br>}<br><br>On Nov 21, 2013, at 4:34 PM, George Bosilca &lt;<a href="mailto:bosilca@icl.utk.edu">bosilca@icl.utk.edu</a>&gt; wrote:<br><br><blockquote type="cite">Pierre,<br>There are several issues with the code you provided.<br><br>1. You can’t use an MPI_DATATYPE_NULL as the send datatype, not even when count is zero. At least the root must provide a real datatype. In fact the type signature of the send message (datatype and count) should match the type signature of the receiving datatype.<br><br>2. I know your count is zero, and no data will be transmitted but your code is difficult to read and understand.<br><br>3. MPI_Iscatter is a collective communication. As such all processes in the associated communicator (MPI_COMM_WORLD in your case) must participate to the collective. Thus, calling MPI_Iscatter only where tasked &gt; 0 is incorrect (you explicitly excluded 0).<br><br>4. From the MPI standard perspective your example is not correct, as you are not allowed to call MPI_Finalize while there are messages pending. Now, Open MPI tolerate this, but it is clearly not standard behavior.<br><br>#include &lt;mpi.h&gt;<br><br>int main(int argc, char** argv)<br>{<br>&nbsp;int &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskid, ntasks;<br>&nbsp;MPI_Init(&amp;argc, &amp;argv);<br>&nbsp;MPI_Request rq;<br>&nbsp;MPI_Comm_rank(MPI_COMM_WORLD,&amp;taskid);<br>&nbsp;MPI_Comm_size(MPI_COMM_WORLD,&amp;ntasks);<br>&nbsp;double r;<br>&nbsp;int l = 0;<br><br>&nbsp;MPI_Iscatter(NULL, 0, MPI_DOUBLE, &amp;r, l, MPI_DOUBLE, 0, MPI_COMM_WORLD, &amp;rq);<br>&nbsp;MPI_Wait(&amp;rq, MPI_STATUS_IGNORE);<br><br>&nbsp;MPI_Finalize();<br>}<br><br>George.<br><br><br>On Nov 21, 2013, at 23:19 , Pierre Jolivet &lt;<a href="mailto:jolivet@ann.jussieu.fr">jolivet@ann.jussieu.fr</a>&gt; wrote:<br><br><blockquote type="cite">Hello,<br>The following code doesn’t execute properly :<br>#include &lt;mpi.h&gt;<br><br>int main(int argc, char** argv) {<br>int &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskid, ntasks;<br>MPI_Init(&amp;argc, &amp;argv);<br>MPI_Request rq;<br><br>MPI_Comm_rank(MPI_COMM_WORLD,&amp;taskid);<br>MPI_Comm_size(MPI_COMM_WORLD,&amp;ntasks);<br>double* r;<br>int l = 0;<br>if(taskid &gt; 0)<br>&nbsp;&nbsp;&nbsp;&nbsp;MPI_Iscatter(NULL, 0, MPI_DATATYPE_NULL, r, l, MPI_DOUBLE, 0, MPI_COMM_WORLD, &amp;rq);<br>MPI_Finalize();<br>}<br><br>Outcome:<br>*** An error occurred in MPI_Type_extent<br>*** MPI_ERR_TYPE: invalid datatype<br><br>Hotfix: change MPI_DATATYPE_NULL to something else.<br><br>Thanks for a quick fix.<br>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote><br>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote><br>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote><br>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></div></blockquote></div><br></div>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></div></blockquote></div><br></body></html>
