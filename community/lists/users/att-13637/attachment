Hi all,<br><br>I am setting up a 7+1 nodes cluster for MD simulation, specifically using GROMACS. I am using Ubuntu Lucid 64-bit on all machines. Installed gromacs, gromacs-openmpi, and gromacs-mpich from the repository. MPICH version of gromacs runs fine without any error. However, when I ran OpenMPI version of gromacs by<br>
<br>###########################################################################<br>mpirun.openmpi -np 8 -wdir /home/birg/Desktop/nfs/ -hostfile ~/Desktop/mpi_settings/hostfile mdrun_mpi.openmpi -v<br>###########################################################################<br>
<br>an error occur, something like this<br><br>###########################################################################<br>[birg-desktop-10:02101] Error: unknown option &quot;--daemonize&quot;<br>Usage: orted [OPTION]...<br>
Start an Open RTE Daemon<br><br>   --bootproxy &lt;arg0&gt;    Run as boot proxy for &lt;job-id&gt;<br>-d|--debug               Debug the OpenRTE<br>-d|--spin                Have the orted spin until we can connect a debugger<br>
                         to it<br>   --debug-daemons       Enable debugging of OpenRTE daemons<br>   --debug-daemons-file  Enable debugging of OpenRTE daemons, storing output<br>                         in files<br>   --gprreplica &lt;arg0&gt;   Registry contact information.<br>
-h|--help                This help message<br>   --mpi-call-yield &lt;arg0&gt;  <br>                         Have MPI (or similar) applications call yield when<br>                         idle<br>   --name &lt;arg0&gt;         Set the orte process name<br>
   --no-daemonize        Don&#39;t daemonize into the background<br>   --nodename &lt;arg0&gt;     Node name as specified by host/resource<br>                         description.<br>   --ns-nds &lt;arg0&gt;       set sds/nds component to use for daemon (normally<br>
                         not needed)<br>   --nsreplica &lt;arg0&gt;    Name service contact information.<br>   --num_procs &lt;arg0&gt;    Set the number of process in this job<br>   --persistent          Remain alive after the application process<br>
                         completes<br>   --report-uri &lt;arg0&gt;   Report this process&#39; uri on indicated pipe<br>   --scope &lt;arg0&gt;        Set restrictions on who can connect to this<br>                         universe<br>
   --seed                Host replicas for the core universe services<br>   --set-sid             Direct the orted to separate from the current<br>                         session<br>   --tmpdir &lt;arg0&gt;       Set the root for the session directory tree<br>
   --universe &lt;arg0&gt;     Set the universe name as<br>                         username@hostname:universe_name for this<br>                         application<br>   --vpid_start &lt;arg0&gt;   Set the starting vpid for this job<br>
--------------------------------------------------------------------------<br>A daemon (pid 5598) died unexpectedly with status 251 while attempting<br>to launch so we are aborting.<br><br>There may be more information reported by the environment (see above).<br>
<br>This may be because the daemon was unable to find all the needed shared<br>libraries on the remote node. You may set your LD_LIBRARY_PATH to have the<br>location of the shared libraries on the remote nodes and this will<br>
automatically be forwarded to the remote nodes.<br>--------------------------------------------------------------------------<br>--------------------------------------------------------------------------<br>mpirun.openmpi noticed that the job aborted, but has no info as to the process<br>
that caused that situation.<br>--------------------------------------------------------------------------<br>--------------------------------------------------------------------------<br>mpirun.openmpi was unable to cleanly terminate the daemons on the nodes shown<br>
below. Additional manual cleanup may be required - please refer to<br>the &quot;orte-clean&quot; tool for assistance.<br>--------------------------------------------------------------------------<br>    birg-desktop-04 - daemon did not report back when launched<br>
    birg-desktop-07 - daemon did not report back when launched<br>    birg-desktop-10 - daemon did not report back when launched<br>###########################################################################<br clear="all">
<br>It is strange that it only happen on one of the compute node (birg-desktop-10). If I remove birg-desktop-10 from the hostfile, I can run OpenMPI gromacs successfully. Any idea?<br><br>Thanks.<br><br>-- <br>Regards,<br>
THChew<br>

