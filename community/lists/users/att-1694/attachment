Here (attached) is a programm that reproduce the error reported...<br><br>Now I updated trunk , but got the same... (output attached again)<br><br>I also tested with 1.1 stable release... <br>With 1.1 the program blocks without any error output...
<br><br>The program try to send 512K messages of 8bytes.<br>If reduced to 1k messages of 8bytes, it works fine... <br><br><br>Thanks <br>Marcelo<br><br><br><div><span class="gmail_quote">On 7/28/06, <b class="gmail_sendername">
Jeff Squyres</b> &lt;<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a>&gt; wrote:</span><blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
Marcelo --<br><br>Can you send your code that is failing?&nbsp;&nbsp;I'm unable to reproduce with some<br>toy programs here.<br><br>I also notice that you're running a somewhat old version of and OMPI SVN<br>checkout of the trunk.&nbsp;&nbsp;Can you update to the most recent version?&nbsp;&nbsp;The
<br>trunk is not guaranteed to be stable, and we did have some stability<br>problems recently -- you might want to upgrade to the most recent version<br>(today seems to be ok) and/or try one of the nightly or prerelease tarballs
<br>in the 1.1 branch.<br><br><br>On 7/26/06 6:18 PM, &quot;Marcelo Stival&quot; &lt;<a href="mailto:marstival@gmail.com">marstival@gmail.com</a>&gt; wrote:<br><br>&gt; Hi,<br>&gt;<br>&gt; I got a problem with ompi when sending large number of messages from
<br>&gt; process&nbsp;&nbsp;A to process B.<br>&gt; Process A only send... and B only receive (the buffers are reused)<br>&gt;<br>&gt; int n = 4 * 1024;//number of iterations (messages to be sent) consecutively<br>&gt; int len = 8; //len of each message
<br>&gt;<br>&gt; Process A (rank 0):<br>&gt; for (i=0; i &lt; n; i++){<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Send( sbuffer, len, MPI_BYTE,to,i,MPI_COMM_WORLD);<br>&gt; }<br>&gt; Process B (rank 1):<br>&gt; for (i=0; i &lt; n; i++){<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Recv(rbuffer,len,MPI_BYTE,recv_from , i,MPI_COMM_WORLD, &amp;status);
<br>&gt; }<br>&gt; (It's a benchmark program... will run with increasing messages sizes.. )<br>&gt; (I tried with the same tag on all iterations - and got the same)<br>&gt;<br>&gt; It works fine for n (number of messages) equals to 3k (for example), but do
<br>&gt; not work with n equals to 4k (for messages of 8 bytes 4k iterations seems to<br>&gt; be the treshould).<br>&gt;<br>&gt; The error messages (complete output attached):<br>&gt; malloc debug: Request for 8396964 bytes failed (class/ompi_free_list.c, 142)
<br>&gt; mpptest: btl_tcp_endpoint.c:624: mca_btl_tcp_endpoint_recv_handler:<br>&gt; Assertion `0<br>&gt;&nbsp;&nbsp;== btl_endpoint-&gt;endpoint_cache_length' failed.<br>&gt; Signal:6 info.si_errno:0(Success) si_code:-6()<br>&gt;<br>
&gt;<br>&gt; Considerations:<br>&gt; It works for synchronous send (MPI_Ssend).<br>&gt; It&nbsp;&nbsp;works with MPICH2 ( 1.0.3).<br>&gt; It is a benchmark program, I want to flood the network to measure the<br>&gt; bandwidth ... (for different message sizes)
<br>&gt;<br>&gt;<br>&gt; Thanks<br>&gt;<br>&gt; Marcelo<br>&gt; _______________________________________________<br>&gt; users mailing list<br>&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">
http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br><br><br>--<br>Jeff Squyres<br>Server Virtualization Business Unit<br>Cisco Systems<br>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">
users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></div><br>

