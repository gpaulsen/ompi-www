
<br><font size=2 face="sans-serif">Tony </font>
<br>
<br><font size=2 face="sans-serif">You are depending on luck. The MPI Standard
allows the implementation to assume that send and recv buffers are distinct
unless MPI_IN_PLACE is used. &nbsp;Any MPI implementation may have more
than one algorithm for a given MPI collective communication operation and
the policy for switching algorithm is not documented.</font>
<br>
<br><font size=2 face="sans-serif">It is entirely possible that something
like going from 32 to 64 processes or changing interconnects will cause
a different algorithm to be used. Applying a patch could also cause the
algorithm to be changed.</font>
<br>
<br><font size=2 face="sans-serif">In theory one algorithm could let you
get away with the violation while another trips on it and a change you
do not even realize you made cause bad answers to show up. Perhaps some
algorithm uses space in the receive buffer as scratch.</font>
<br>
<br><font size=2 face="sans-serif">Standards compliant code is safer.</font>
<br>
<br><font size=2 face="sans-serif">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Dick </font>
<br>
<br>
<br><font size=2 face="sans-serif">Dick Treumann &nbsp;- &nbsp;MPI Team
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br>
IBM Systems &amp; Technology Group<br>
Dept X2ZA / MS P963 -- 2455 South Road -- Poughkeepsie, NY 12601<br>
Tele (845) 433-7846 &nbsp; &nbsp; &nbsp; &nbsp; Fax (845) 433-8363<br>
</font>
<br>
<br>
<br>
<table width=100%>
<tr valign=top>
<td><font size=1 color=#5f5f5f face="sans-serif">From:</font>
<td><font size=1 face="sans-serif">Tom Rosmond &lt;rosmond@reachone.com&gt;</font>
<tr valign=top>
<td><font size=1 color=#5f5f5f face="sans-serif">To:</font>
<td><font size=1 face="sans-serif">users@open-mpi.org</font>
<tr valign=top>
<td><font size=1 color=#5f5f5f face="sans-serif">Date:</font>
<td><font size=1 face="sans-serif">09/16/2010 12:05 PM</font>
<tr valign=top>
<td><font size=1 color=#5f5f5f face="sans-serif">Subject:</font>
<td><font size=1 face="sans-serif">[OMPI users] send and receive buffer
the same &nbsp;on root</font>
<tr valign=top>
<td><font size=1 color=#5f5f5f face="sans-serif">Sent by:</font>
<td><font size=1 face="sans-serif">users-bounces@open-mpi.org</font></table>
<br>
<hr noshade>
<br>
<br>
<br><tt><font size=2>I am working with a Fortran 90 code with many MPI
calls like this:<br>
<br>
call mpi_gatherv(x,nsize(rank+1),<br>
 &nbsp; &nbsp; mpi_real,x,nsize,nstep,mpi_real,root,mpi_comm_world,mstat)<br>
<br>
'x' is allocated on root to be large enough to hold the results of the<br>
gather, other arrays and parameters are defined correctly, and the code<br>
runs as it should. &nbsp;However, I am concerned that having the same send<br>
and receive buffer on root is a violation of the MPI standard. &nbsp;Am
I<br>
correct? &nbsp;I am aware of the MPI_IN_PLACE feature that can be used
in<br>
this situation, by defining it as the send buffer at root. &nbsp;<br>
<br>
The fact that the code as written seems to work on most system we run on<br>
(some with OpenMPI, some with proprietary MPI's) indicates that in spite<br>
of the standard, implementations allow it. &nbsp;Is this correct, or are
we<br>
just lucky.<br>
<br>
T. Rosmond<br>
<br>
<br>
<br>
_______________________________________________<br>
users mailing list<br>
users@open-mpi.org<br>
</font></tt><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users"><tt><font size=2>http://www.open-mpi.org/mailman/listinfo.cgi/users</font></tt></a><tt><font size=2><br>
</font></tt>
<br>
<br>
