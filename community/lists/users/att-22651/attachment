<div dir="ltr">Dear All, <div><br></div><div>I have a question about using MPI_send and MPI_recv. </div><div><br></div><div><font color="#ff0000"><b>The object  is as follows:</b></font></div><div>I would like to send an array Q from rank=1, N-1 to rank=0, and then rank 0 receives the Q from all other processors. Q will be put into a new array Y in rank 0. (of couse this is not realized by MPI). and then MPI_bcast is used (from rank 0) to broadcast the Y to all the processors. <br>

</div><div><br></div><div><font color="#ff0000"><b>Fortran Code is like:</b></font></div><div style>if(myrank .eq. 0) then</div><div style>     itag = myrank</div><div style>     call mpi_send(Q.............., 0, itag, .................)</div>

<div style>else </div><div style>     do i=1, N-1</div><div style>          itag = i</div><div style>         call mpi_recv(QRECS......., i, itag, .................)</div><div style>     enddo</div><div style>   </div><div style>

endif</div><div style><br></div><div style>call mpi_bcast(YVAR............., 0, ..............)<br></div><div style><br></div><div style><font color="#ff0000"><b>Problem I met is:</b></font></div><div style>In my simulation, time marching is performed, These mpi_send and recv are fine for the first three time steps. However, for the fourth time step, the looping is only finished from i=1 to i=13, (totally 48 processors). That mean after 14th processors, the mpi_recv did not receive the date from them. Thus the code hangs there forever. Does deadlock occur for this situation? How can I figure out this problem?</div>

<div style><br></div><div style>Thank you so much if anyone can give me some suggestions. </div><div><br clear="all"><div><div dir="ltr"><div>best regards,<br>Huangwei</div><div><span style="font-family:&#39;Monotype Corsiva&#39;;font-size:12pt"><br>

</span></div><div> </div><div><br> </div><span></span><span></span><span></span></div></div>
</div></div>

