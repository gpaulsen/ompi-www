<html><head></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; ">In my experience hyperthreading can't really deliver two cores worth of processing simultaneously for processes expecting sole use of a core. Since you really have 512 cores I'm not surprised that you see a performance hit when requesting &gt; 512 compute units. We should really get input from a hyperthreading expert, preferably form intel.<div><br></div><div>Doug Reeder<br><div><div>On Oct 4, 2010, at 9:53 AM, Storm Zhang wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><meta charset="utf-8"><span class="Apple-style-span" style="font-family: arial, sans-serif; font-size: 13px; border-collapse: collapse; "><div><span class="Apple-style-span" style="font-family: arial, sans-serif; font-size: 13px; border-collapse: collapse; ">We have 64 compute nodes which are dual qual-core and hyperthreaded CPUs. So we have 1024 compute units shown in the ROCKS 5.3 system. I'm trying to scatter an array from the master node to the compute nodes using mpiCC and mpirun using C++.&nbsp;</span></div>
<div><span class="Apple-style-span" style="font-family: arial, sans-serif; font-size: 13px; border-collapse: collapse; "><br></span></div><div><span class="Apple-style-span" style="font-family: arial, sans-serif; font-size: 13px; border-collapse: collapse; ">Here is my test:</span></div>
<div><span class="Apple-style-span" style="font-family: arial, sans-serif; font-size: 13px; border-collapse: collapse; "><br></span></div><div><span class="Apple-style-span" style="font-family: arial, sans-serif; font-size: 13px; border-collapse: collapse; ">The array size is 18KB * Number of compute nodes and is scattered to the compute nodes 5000 times repeatly.&nbsp;</span></div>
<div><span class="Apple-style-span" style="font-family: arial, sans-serif; font-size: 13px; border-collapse: collapse; "><br></span></div><div><span class="Apple-style-span" style="font-family: arial, sans-serif; font-size: 13px; border-collapse: collapse; ">The average running time(seconds):</span></div>
<div><span class="Apple-style-span" style="font-family: arial, sans-serif; font-size: 13px; border-collapse: collapse; "><br></span></div><div><span class="Apple-style-span" style="font-family: arial, sans-serif; font-size: 13px; border-collapse: collapse; ">100 nodes: 170,</span></div>
<div>400 nodes: 690,</div><div>500 nodes: 855,</div><div>600 nodes: 2550,</div><div>700 nodes: 2720,</div><div>800 nodes: 2900,</div><div><br></div><div>There is a big jump of running time from 500 nodes to 600 nodes.&nbsp;<span class="Apple-style-span" style="font-size: small; ">Don't know what's the problem.&nbsp;</span></div>
<div>Tried both in OMPI 1.3.2 and OMPI 1.4.2. Running time is a little faster for all the tests in 1.4.2 but the jump still exists.&nbsp;</div><div>Tried using either Bcast function or simply Send/Recv which give very close results.&nbsp;</div>
<div>Tried both in running it directly or using SGE and got the same results.</div><div><span class="Apple-style-span" style="font-size: small; "><br></span></div><div><span class="Apple-style-span" style="font-size: small; "><span class="Apple-style-span" style="font-size: 13px; "><div>
<span class="Apple-style-span" style="font-size: small; ">The code and ompi_info are attached to this email. The direct running command is :</span></div><div><span class="Apple-style-span" style="font-size: small; "><div>
/opt/openmpi/bin/mpirun --mca btl_tcp_if_include eth0 --machinefile ../machines -np 600 scatttest</div><div><br></div><div>The ifconfig of head node for eth0 is:</div><div><div>eth0 &nbsp; &nbsp; &nbsp;Link encap:Ethernet &nbsp;HWaddr 00:26:B9:56:8B:44 &nbsp;</div>
<div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;inet addr:192.168.1.1 &nbsp;Bcast:192.168.1.255 &nbsp;Mask:255.255.255.0</div><div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;inet6 addr: fe80::226:b9ff:fe56:8b44/64 Scope:Link</div><div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;UP BROADCAST RUNNING MULTICAST &nbsp;MTU:1500 &nbsp;Metric:1</div>
<div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;RX packets:1096060373 errors:0 dropped:2512622 overruns:0 frame:0</div><div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;TX packets:513387679 errors:0 dropped:0 overruns:0 carrier:0</div><div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;collisions:0 txqueuelen:1000&nbsp;</div><div>
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;RX bytes:832328807459 (775.1 GiB) &nbsp;TX bytes:250824621959 (233.5 GiB)</div><div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Interrupt:106 Memory:d6000000-d6012800&nbsp;</div></div><div><br></div><div>A typical ifconfig of a compute node is:</div><div>
<div>eth0 &nbsp; &nbsp; &nbsp;Link encap:Ethernet &nbsp;HWaddr 00:21:9B:9A:15:AC &nbsp;</div><div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;inet addr:192.168.1.253 &nbsp;Bcast:192.168.1.255 &nbsp;Mask:255.255.255.0</div><div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;inet6 addr: fe80::221:9bff:fe9a:15ac/64 Scope:Link</div>
<div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;UP BROADCAST RUNNING MULTICAST &nbsp;MTU:1500 &nbsp;Metric:1</div><div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;RX packets:362716422 errors:0 dropped:0 overruns:0 frame:0</div><div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;TX packets:349967746 errors:0 dropped:0 overruns:0 carrier:0</div>
<div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;collisions:0 txqueuelen:1000&nbsp;</div><div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;RX bytes:139699954685 (130.1 GiB) &nbsp;TX bytes:338207741480 (314.9 GiB)</div><div>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Interrupt:82 Memory:d6000000-d6012800&nbsp;</div></div><div><br></div></span></div>
</span></span></div><div><span class="Apple-style-span" style="font-size: small; "><br></span></div><div><span class="Apple-style-span" style="font-size: small; ">Does anyone help me out of this? It bothers me a lot.</span></div>
<div><span class="Apple-style-span" style="font-size: small; "><br></span></div><div><span class="Apple-style-span" style="font-size: small; ">Thank you very much.</span></div><div><span class="Apple-style-span" style="font-size: small; "><br>
</span></div><div><span class="Apple-style-span" style="font-size: small; ">Linbao</span></div></span>
<span>&lt;scatttest.cpp&gt;</span><span>&lt;ompi_info&gt;</span>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></blockquote></div><br></div></body></html>
