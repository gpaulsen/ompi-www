<html><head><meta http-equiv="Content-Type" content="text/html charset=utf-8"></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;" class="">We used to do so, but don’t currently support that model - folks are working on restoring it. No timetable, though I don’t think it will be too much longer before it is in master. Can’t say when it will hit release<div class=""><br class=""><div><blockquote type="cite" class=""><div class="">On May 16, 2016, at 8:25 AM, Zabiziz Zaz &lt;<a href="mailto:zabiziz@gmail.com" class="">zabiziz@gmail.com</a>&gt; wrote:</div><br class="Apple-interchange-newline"><div class=""><div dir="ltr" class="">Hi&nbsp;Llolsten,<div class="">the problem is not a firewall issue. The simplest way to reproduce the problem is rebooting a node in the middle of the job. It's possible to configure the openmpi to not terminate the job if, in the middle of the job, one node is rebooted?</div><div class=""><br class=""></div><div class="">Thanks again for your help.</div><div class=""><br class=""></div><div class="">Regards,</div><div class="">Guilherme</div></div><div class="gmail_extra"><br class=""><div class="gmail_quote">On Mon, May 16, 2016 at 12:11 PM, Llolsten Kaonga <span dir="ltr" class="">&lt;<a href="mailto:llk@soft-forge.com" target="_blank" class="">llk@soft-forge.com</a>&gt;</span> wrote:<br class=""><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div lang="EN-US" link="#0563C1" vlink="#954F72" class=""><div class=""><p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,sans-serif" class="">Hello Guilherme,<u class=""></u><u class=""></u></span></p><p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,sans-serif" class=""><u class=""></u>&nbsp;<u class=""></u></span></p><p class="MsoNormal"><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,sans-serif" class="">This may be off but try running your mpirun command with the option </span>“–tag-output”. If you see a “broken pipe”, then your issue may be firewall related. You could then check the thread “<b class="">Re: [OMPI users] mpirun command won't run unless the firewalld daemon is disabled</b>” for how to get around this from Gilles or Jeff.<u class=""></u><u class=""></u></p><p class="MsoNormal"><u class=""></u>&nbsp;<u class=""></u></p><p class="MsoNormal">I thank you.<u class=""></u><u class=""></u></p><p class="MsoNormal">--<u class=""></u><u class=""></u></p><p class="MsoNormal">Llolsten<u class=""></u><u class=""></u></p><p class="MsoNormal"><a name="m_3555192236463516660__MailEndCompose" class=""><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,sans-serif" class=""><u class=""></u>&nbsp;<u class=""></u></span></a></p><span class=""></span><p class="MsoNormal"><b class=""><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,sans-serif" class="">From:</span></b><span style="font-size:11.0pt;font-family:&quot;Calibri&quot;,sans-serif" class=""> users [mailto:<a href="mailto:users-bounces@open-mpi.org" target="_blank" class="">users-bounces@open-mpi.org</a>] <b class="">On Behalf Of </b>Zabiziz Zaz<br class=""><b class="">Sent:</b> Monday, May 16, 2016 10:46 AM<br class=""><b class="">To:</b> <a href="mailto:users@open-mpi.org" target="_blank" class="">users@open-mpi.org</a><br class=""><b class="">Subject:</b> [OMPI users] ORTE has lost communication<u class=""></u><u class=""></u></span></p><div class=""><div class="h5"><p class="MsoNormal"><u class=""></u>&nbsp;<u class=""></u></p><div class=""><p class="MsoNormal">Hi,<u class=""></u><u class=""></u></p><div class=""><p class="MsoNormal">I'm using&nbsp;openmpi-1.10.2 and sometimes I'm receiving the message below:<u class=""></u><u class=""></u></p></div><div class=""><div class=""><p class="MsoNormal">--------------------------------------------------------------------------<u class=""></u><u class=""></u></p></div><div class=""><p class="MsoNormal">ORTE has lost communication with its daemon located on node:<u class=""></u><u class=""></u></p></div><div class=""><p class="MsoNormal"><u class=""></u>&nbsp;<u class=""></u></p></div><div class=""><p class="MsoNormal">&nbsp; hostname: &nbsp;xxxx<u class=""></u><u class=""></u></p></div><div class=""><p class="MsoNormal"><u class=""></u>&nbsp;<u class=""></u></p></div><div class=""><p class="MsoNormal">This is usually due to either a failure of the TCP network<u class=""></u><u class=""></u></p></div><div class=""><p class="MsoNormal">connection to the node, or possibly an internal failure of<u class=""></u><u class=""></u></p></div><div class=""><p class="MsoNormal">the daemon itself. We cannot recover from this failure, and<u class=""></u><u class=""></u></p></div><div class=""><p class="MsoNormal">therefore will terminate the job.<u class=""></u><u class=""></u></p></div><div class=""><p class="MsoNormal"><u class=""></u>&nbsp;<u class=""></u></p></div><div class=""><p class="MsoNormal">--------------------------------------------------------------------------<u class=""></u><u class=""></u></p></div></div><div class=""><p class="MsoNormal"><u class=""></u>&nbsp;<u class=""></u></p></div><div class=""><p class="MsoNormal">My applications are fault tolerant and the jobs usually takes weeks to finish. Sometimes a hardware problem occurs with one node, for example, the node shutdown. I don't want mpi to terminate the job, my jobs usually have hundreds of nodes and I don't care if 1 node lost communication.<u class=""></u><u class=""></u></p></div><div class=""><p class="MsoNormal"><u class=""></u>&nbsp;<u class=""></u></p></div><div class=""><p class="MsoNormal">It's possible to change this behavior of openmpi? I tried to set&nbsp;orte_abort_on_non_zero_status to 0 but it didn't work.&nbsp;<u class=""></u><u class=""></u></p></div><div class=""><p class="MsoNormal"><u class=""></u>&nbsp;<u class=""></u></p></div><div class=""><p class="MsoNormal">Thanks for your help.<u class=""></u><u class=""></u></p></div><div class=""><p class="MsoNormal"><u class=""></u>&nbsp;<u class=""></u></p></div><div class=""><p class="MsoNormal">Regards,<u class=""></u><u class=""></u></p></div><div class=""><p class="MsoNormal">Guilherme.<u class=""></u><u class=""></u></p></div></div></div></div></div></div><br class="">_______________________________________________<br class="">
users mailing list<br class="">
<a href="mailto:users@open-mpi.org" class="">users@open-mpi.org</a><br class="">
Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/users" rel="noreferrer" target="_blank" class="">https://www.open-mpi.org/mailman/listinfo.cgi/users</a><br class="">
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2016/05/29214.php" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/community/lists/users/2016/05/29214.php</a><br class=""></blockquote></div><br class=""></div>
_______________________________________________<br class="">users mailing list<br class=""><a href="mailto:users@open-mpi.org" class="">users@open-mpi.org</a><br class="">Subscription: https://www.open-mpi.org/mailman/listinfo.cgi/users<br class="">Link to this post: http://www.open-mpi.org/community/lists/users/2016/05/29218.php</div></blockquote></div><br class=""></div></body></html>
