<html><head><meta http-equiv="Content-Type" content="text/html charset=utf-8"></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;" class="">With an OMPI that old, it’s anyone’s guess - I have no idea.<div class=""><br class=""></div><div class=""><br class=""><div style=""><blockquote type="cite" class=""><div class="">On Apr 15, 2015, at 4:12 AM, cristian &lt;<a href="mailto:cristian.ruiz@inria.fr" class="">cristian.ruiz@inria.fr</a>&gt; wrote:</div><br class="Apple-interchange-newline"><div class="">
  

    <meta http-equiv="content-type" content="text/html; charset=utf-8" class="">
  
  <div text="#000000" bgcolor="#FFFFFF" class="">
    Hello,<br class="">
    <br class="">
    I noticed when performing a profiling of an application that the
    MPI_init() function takes a considerable amount of time. <br class="">
    There is a big difference when running 32 processes over 32 machines
    and 32 processes over 8 machines (Each machine has 8 cores).<br class="">
    These are the results of the profiling:<br class="">
    <br class="">
    <br class="">
    Results for 32 cores (8 machines)<br class="">
    <br class="">
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Group.1 percent&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; usec<br class="">
    38&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SSOR 79.1125 2557445.625<br class="">
    7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; EXCHANGE_1 31.8125&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 33.250<br class="">
    24&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Recv() 26.0750&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 33.375<br class="">
    2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; BLTS 24.7500&nbsp;&nbsp;&nbsp;&nbsp; 103.125<br class="">
    3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; BUTS 22.2375&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 92.500<br class="">
    12&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; INIT_COMM 19.8500 1311003.375<br class="">
    <b class="">22&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Init() 19.8500 1310925.750</b><br class="">
    33&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; RHS 18.4000&nbsp;&nbsp;&nbsp; 4690.500<br class="">
    8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; EXCHANGE_3&nbsp; 9.2750&nbsp;&nbsp;&nbsp; 1179.000<br class="">
    26&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Wait()&nbsp; 7.2250&nbsp;&nbsp;&nbsp;&nbsp; 565.125<br class="">
    13&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; JACLD&nbsp; 6.4875&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 27.000<br class="">
    25&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Send()&nbsp; 6.3500&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8.000<br class="">
    14&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; JACU&nbsp; 6.2500&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 26.000<br class="">
    37&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SETIV&nbsp; 0.6625&nbsp;&nbsp; 20908.500<br class="">
    6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; EXACT&nbsp; 0.2188&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.000<br class="">
    4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ERHS&nbsp; 0.2000&nbsp;&nbsp; 11499.000<br class="">
    <br class="">
    Results for 32 machines<br class="">
    <br class="">
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Group.1&nbsp; percent&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; usec<br class="">
    38&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SSOR 97.28889 2573471.0000<br class="">
    7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; EXCHANGE_1 39.25556&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 33.3333<br class="">
    2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; BLTS 29.11111&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 98.7778<br class="">
    3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; BUTS 27.96667&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 95.0000<br class="">
    24&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Recv() 27.48889&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 28.7778<br class="">
    33&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; RHS 23.98889&nbsp;&nbsp;&nbsp; 5018.6667<br class="">
    25&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Send() 13.51111&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 14.0000<br class="">
    8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; EXCHANGE_3 13.06667&nbsp;&nbsp;&nbsp; 1361.1111<br class="">
    26&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Wait()&nbsp; 9.37778&nbsp;&nbsp;&nbsp;&nbsp; 599.0000<br class="">
    13&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; JACLD&nbsp; 7.72222&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 26.0000<br class="">
    14&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; JACU&nbsp; 7.37778&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 25.0000<br class="">
    12&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; INIT_COMM&nbsp; 1.46667&nbsp;&nbsp; 76713.6667<br class="">
    <b class="">22&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MPI_Init()&nbsp; 1.45556&nbsp;&nbsp; 76253.4444</b><br class="">
    37&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SETIV&nbsp; 0.80000&nbsp;&nbsp; 20914.0000<br class="">
    6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; EXACT&nbsp; 0.25000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0000<br class="">
    4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ERHS&nbsp; 0.21111&nbsp;&nbsp; 10458.3333<br class="">
    <br class="">
    The function MPI_init() in the first case (4 processes per machine)
    was 17 times slower than the second case (1 process per machine). Is
    this behaviour normal? <br class="">
    The command I used for running the application was:<br class="">
    <br class="">
    First case:<br class="">
    <br class="">
    mpirun&nbsp; --machinefile machine_file -npernode 4 --mca btl
    self,sm,tcp&nbsp; lu.A.32<br class="">
    <br class="">
    Second case:<br class="">
    <br class="">
    mpirun&nbsp; --machinefile machine_file&nbsp; --mca btl self,sm,tcp&nbsp; lu.A.32<br class="">
    <br class="">
    I used the version of mpi: <br class="">
    <br class="">
    mpirun --V<br class="">
    mpirun (Open MPI) 1.4.5<br class="">
    <br class="">
    and the system I used is the following:<br class="">
    <br class="">
    Linux kameleon-debian 3.2.0-4-amd64 #1 SMP Debian 3.2.65-1+deb7u2
    x86_64 GNU/Linux<br class="">
    <br class="">
    I will appreciate any feedback, thank you.<br class="">
    <br class="">
    <br class="">
  </div>

_______________________________________________<br class="">users mailing list<br class=""><a href="mailto:users@open-mpi.org" class="">users@open-mpi.org</a><br class="">Subscription: http://www.open-mpi.org/mailman/listinfo.cgi/users<br class="">Link to this post: http://www.open-mpi.org/community/lists/users/2015/04/26735.php</div></blockquote></div><br class=""></div></body></html>
