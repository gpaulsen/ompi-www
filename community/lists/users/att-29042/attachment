<html>
  <head>
    <meta content="text/html; charset=windows-1252"
      http-equiv="Content-Type">
  </head>
  <body bgcolor="#FFFFFF" text="#000000">
    <p>Siegmar,</p>
    <p><br>
    </p>
    <p>can you please also post the source of spawn_slave ?</p>
    <p><br>
    </p>
    <p>Cheers,</p>
    <p>Gilles<br>
    </p>
    <br>
    <div class="moz-cite-prefix">On 4/28/2016 1:17 AM, Siegmar Gross
      wrote:<br>
    </div>
    <blockquote
      cite="mid:a8d0facb-7b67-2a79-8fba-015819983e68@informatik.hs-fulda.de"
      type="cite">Hi Gilles,
      <br>
      <br>
      it is not necessary to have a heterogeneous environment to
      reproduce
      <br>
      the error as you can see below. All machines are 64 bit.
      <br>
      <br>
      tyr spawn 119 ompi_info | grep -e "OPAL repo revision" -e "C
      compiler absolute"
      <br>
            OPAL repo revision: v2.x-dev-1290-gbd0e4e1
      <br>
           C compiler absolute: /usr/local/gcc-5.1.0/bin/gcc
      <br>
      tyr spawn 120 uname -a
      <br>
      SunOS tyr.informatik.hs-fulda.de 5.10 Generic_150400-11 sun4u
      sparc SUNW,A70 Solaris
      <br>
      tyr spawn 121 mpiexec -np 1 --host tyr,tyr,tyr,tyr
      spawn_multiple_master
      <br>
      <br>
      Parent process 0 running on tyr.informatik.hs-fulda.de
      <br>
        I create 3 slave processes.
      <br>
      <br>
      [tyr.informatik.hs-fulda.de:27286] PMIX ERROR: UNPACK-PAST-END in
      file
../../../../../../openmpi-v2.x-dev-1290-gbd0e4e1/opal/mca/pmix/pmix112/pmix/src/server/pmix_server_ops.c
      at line 829
      <br>
      [tyr.informatik.hs-fulda.de:27286] PMIX ERROR: UNPACK-PAST-END in
      file
../../../../../../openmpi-v2.x-dev-1290-gbd0e4e1/opal/mca/pmix/pmix112/pmix/src/server/pmix_server.c
      at line 2176
      <br>
      [tyr:27288] *** An error occurred in MPI_Comm_spawn_multiple
      <br>
      [tyr:27288] *** reported by process [3434086401,0]
      <br>
      [tyr:27288] *** on communicator MPI_COMM_WORLD
      <br>
      [tyr:27288] *** MPI_ERR_SPAWN: could not spawn processes
      <br>
      [tyr:27288] *** MPI_ERRORS_ARE_FATAL (processes in this
      communicator will now abort,
      <br>
      [tyr:27288] ***    and potentially your MPI job)
      <br>
      tyr spawn 122
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      sunpc1 fd1026 105 ompi_info | grep -e "OPAL repo revision" -e "C
      compiler absolute"
      <br>
            OPAL repo revision: v2.x-dev-1290-gbd0e4e1
      <br>
           C compiler absolute: /usr/local/gcc-5.1.0/bin/gcc
      <br>
      sunpc1 fd1026 106 uname -a
      <br>
      SunOS sunpc1 5.10 Generic_147441-21 i86pc i386 i86pc Solaris
      <br>
      sunpc1 fd1026 107 mpiexec -np 1 --host sunpc1,sunpc1,sunpc1,sunpc1
      spawn_multiple_master
      <br>
      <br>
      Parent process 0 running on sunpc1
      <br>
        I create 3 slave processes.
      <br>
      <br>
      [sunpc1:00368] PMIX ERROR: UNPACK-PAST-END in file
../../../../../../openmpi-v2.x-dev-1290-gbd0e4e1/opal/mca/pmix/pmix112/pmix/src/server/pmix_server_ops.c
      at line 829
      <br>
      [sunpc1:00368] PMIX ERROR: UNPACK-PAST-END in file
../../../../../../openmpi-v2.x-dev-1290-gbd0e4e1/opal/mca/pmix/pmix112/pmix/src/server/pmix_server.c
      at line 2176
      <br>
      [sunpc1:370] *** An error occurred in MPI_Comm_spawn_multiple
      <br>
      [sunpc1:370] *** reported by process [43909121,0]
      <br>
      [sunpc1:370] *** on communicator MPI_COMM_WORLD
      <br>
      [sunpc1:370] *** MPI_ERR_SPAWN: could not spawn processes
      <br>
      [sunpc1:370] *** MPI_ERRORS_ARE_FATAL (processes in this
      communicator will now abort,
      <br>
      [sunpc1:370] ***    and potentially your MPI job)
      <br>
      sunpc1 fd1026 108
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      linpc1 fd1026 105 ompi_info | grep -e "OPAL repo revision" -e "C
      compiler absolute"
      <br>
            OPAL repo revision: v2.x-dev-1290-gbd0e4e1
      <br>
           C compiler absolute: /usr/local/gcc-5.1.0/bin/gcc
      <br>
      linpc1 fd1026 106 uname -a
      <br>
      Linux linpc1 3.1.10-1.29-desktop #1 SMP PREEMPT Fri May 31
      20:10:04 UTC 2013 (2529847) x86_64 x86_64 x86_64 GNU/Linux
      <br>
      linpc1 fd1026 107 mpiexec -np 1 --host linpc1,linpc1,linpc1,linpc1
      spawn_multiple_master
      <br>
      <br>
      Parent process 0 running on linpc1
      <br>
        I create 3 slave processes.
      <br>
      <br>
      [linpc1:21502] PMIX ERROR: UNPACK-PAST-END in file
../../../../../../openmpi-v2.x-dev-1290-gbd0e4e1/opal/mca/pmix/pmix112/pmix/src/server/pmix_server_ops.c
      at line 829
      <br>
      [linpc1:21502] PMIX ERROR: UNPACK-PAST-END in file
../../../../../../openmpi-v2.x-dev-1290-gbd0e4e1/opal/mca/pmix/pmix112/pmix/src/server/pmix_server.c
      at line 2176
      <br>
      [linpc1:21507] *** An error occurred in MPI_Comm_spawn_multiple
      <br>
      [linpc1:21507] *** reported by process [1005518849,0]
      <br>
      [linpc1:21507] *** on communicator MPI_COMM_WORLD
      <br>
      [linpc1:21507] *** MPI_ERR_SPAWN: could not spawn processes
      <br>
      [linpc1:21507] *** MPI_ERRORS_ARE_FATAL (processes in this
      communicator will now abort,
      <br>
      [linpc1:21507] ***    and potentially your MPI job)
      <br>
      linpc1 fd1026 108
      <br>
      <br>
      <br>
      I used the following configure command.
      <br>
      <br>
      ../openmpi-v2.x-dev-1290-gbd0e4e1/configure \
      <br>
        --prefix=/usr/local/openmpi-2.0.0_64_gcc \
      <br>
        --libdir=/usr/local/openmpi-2.0.0_64_gcc/lib64 \
      <br>
        --with-jdk-bindir=/usr/local/jdk1.8.0/bin \
      <br>
        --with-jdk-headers=/usr/local/jdk1.8.0/include \
      <br>
        JAVA_HOME=/usr/local/jdk1.8.0 \
      <br>
        LDFLAGS="-m64" CC="gcc" CXX="g++" FC="gfortran" \
      <br>
        CFLAGS="-m64" CXXFLAGS="-m64" FCFLAGS="-m64" \
      <br>
        CPP="cpp" CXXCPP="cpp" \
      <br>
        --enable-mpi-cxx \
      <br>
        --enable-cxx-exceptions \
      <br>
        --enable-mpi-java \
      <br>
        --enable-heterogeneous \
      <br>
        --enable-mpi-thread-multiple \
      <br>
        --with-hwloc=internal \
      <br>
        --without-verbs \
      <br>
        --with-wrapper-cflags="-std=c11 -m64" \
      <br>
        --with-wrapper-cxxflags="-m64" \
      <br>
        --with-wrapper-fcflags="-m64" \
      <br>
        --enable-debug \
      <br>
        |&amp; tee log.configure.$SYSTEM_ENV.$MACHINE_ENV.64_gcc
      <br>
      <br>
      <br>
      Kind regards
      <br>
      <br>
      Siegmar
      <br>
      <br>
      <br>
      <br>
      Am 27.04.2016 um 13:21 schrieb Gilles Gouaillardet:
      <br>
      <blockquote type="cite">Siegmar,
        <br>
        <br>
        please add this to your CFLAGS for the time being.
        <br>
        <br>
        configure tries to detect which flags must be added for C99
        support, and it seems
        <br>
        the test is not working for Solaris 10 and Oracle compilers.
        <br>
        this is no more a widely used environment, and I am not sure I
        can find the
        <br>
        time to fix this
        <br>
        in a near future.
        <br>
        <br>
        <br>
        regarding the runtime issue, can you please describe your 4
        hosts (os,
        <br>
        endianness and bitness)
        <br>
        <br>
        Cheers,
        <br>
        <br>
        Gilles
        <br>
        <br>
        On Wednesday, April 27, 2016, Siegmar Gross
        <br>
        &lt;<a class="moz-txt-link-abbreviated" href="mailto:siegmar.gross@informatik.hs-fulda.de">siegmar.gross@informatik.hs-fulda.de</a>
        <br>
<a class="moz-txt-link-rfc2396E" href="javascript:_e(%7B%7D,'cvml','siegmar.gross@informatik.hs-fulda.de');">&lt;javascript:_e(%7B%7D,'cvml','siegmar.gross@informatik.hs-fulda.de');&gt;</a>&gt;
        wrote:
        <br>
        <br>
            Hi Gilles,
        <br>
        <br>
            adding "-std=c99" to CFLAGS solves the problem with the
        missing library.
        <br>
            Shall I add it permanently to my configure command or will
        you add it,
        <br>
            so that I will not run into problems if you need the C11
        standard later?
        <br>
        <br>
            "spawn_multiple_master" breaks with the same error that I
        reported
        <br>
            yesterday for my gcc-version of Open MPI. Hopefully you can
        solve the
        <br>
            problem as well.
        <br>
        <br>
        <br>
            Kind regards and thank you very much for your help
        <br>
        <br>
            Siegmar
        <br>
        <br>
        <br>
            Am 27.04.2016 um 08:05 schrieb Gilles Gouaillardet:
        <br>
        <br>
                Siegmar,
        <br>
        <br>
        <br>
                here is the error :
        <br>
        <br>
                configure:17969: cc -o conftest -m64 -D_REENTRANT -g  -g
        <br>
               
        -I/export2/src/openmpi-2.0.0/openmpi-v2.x-dev-1290-gbd0e4e1
        <br>
               
-I/export2/src/openmpi-2.0.0/openmpi-v2.x-dev-1290-gbd0e4e1-SunOS.sparc.64_cc<br>
               
        -I/export2/src/openmpi-2.0.0/openmpi-v2.x-dev-1290-gbd0e4e1/opal/include
        <br>
               
-I/export2/src/openmpi-2.0.0/openmpi-v2.x-dev-1290-gbd0e4e1-SunOS.sparc.64_cc/opal/include<br>
                -D_REENTRANT
        <br>
               
-I/export2/src/openmpi-2.0.0/openmpi-v2.x-dev-1290-gbd0e4e1/opal/mca/hwloc/hwloc1112/hwloc/include<br>
               
-I/export2/src/openmpi-2.0.0/openmpi-v2.x-dev-1290-gbd0e4e1-SunOS.sparc.64_cc/opal/mca/hwloc/hwloc1112/hwloc/include<br>
               
-I/export2/src/openmpi-2.0.0/openmpi-v2.x-dev-1290-gbd0e4e1/opal/mca/event/libevent2022/libevent<br>
               
-I/export2/src/openmpi-2.0.0/openmpi-v2.x-dev-1290-gbd0e4e1/opal/mca/event/libevent2022/libevent/include<br>
               
-I/export2/src/openmpi-2.0.0/openmpi-v2.x-dev-1290-gbd0e4e1-SunOS.sparc.64_cc/opal/mca/event/libevent2022/libevent/include<br>
                -m64 conftest.c  &gt;&amp;5
        <br>
                "/usr/include/stdbool.h", line 42: #error: "Use of
        &lt;stdbool.h&gt; is
        <br>
                valid only
        <br>
                in a c99 compilation environment."
        <br>
        <br>
        <br>
                i cannot reproduce this on solaris 11 with oracle studio
        5.3 compiler,
        <br>
                and i
        <br>
                do not have solaris 10 yet.
        <br>
        <br>
                could you please re-configure with '-std=c99' appended
        to your CFLAGS
        <br>
                and see
        <br>
                if it helps ?
        <br>
        <br>
        <br>
                Cheers,
        <br>
        <br>
        <br>
                Gilles
        <br>
        <br>
        <br>
                On 4/26/2016 7:57 PM, Siegmar Gross wrote:
        <br>
        <br>
                    Hi Gilles and Ralph,
        <br>
        <br>
                    I was able to sort out my mess. In my last email I
        compared the
        <br>
                    files from
        "SunOS_sparc/openmpi-2.0.0_64_gcc/lib64/openmpi" from
        <br>
                    the attachment of my email to Ralph with the files
        from
        <br>
                    "SunOS_sparc/openmpi-2.0.0_64_cc/lib64/openmpi" from
        my current
        <br>
                    file system. That's the reason while I have had
        different
        <br>
                    timestamps. The other problem was that Ralph didn't
        recognize
        <br>
                    that "mca_pmix_pmix112.so" wasn't built on Solaris
        with the
        <br>
                    Sun C compiler. I've removed most of the files from
        the attachment
        <br>
                    of my email so that it is easier to see the relevant
        files. Below
        <br>
                    I try to give you more information that may be
        relevant to track
        <br>
                    down the problem. I still get an error running one
        of my small
        <br>
                    test programs, when I use my gcc-version of Open
        MPI.
        <br>
                    "mca_pmix_pmix112.so" is a 64 bits library.
        <br>
        <br>
                    Linux_x86_64/openmpi-2.0.0_64_cc/lib64/openmpi:
        <br>
                    ...
        <br>
                    -rwxr-xr-x 1 root root  261327 Apr 19 16:46
        mca_plm_slurm.so
        <br>
                    -rwxr-xr-x 1 root root    1002 Apr 19 16:45
        mca_pmix_pmix112.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://mca_pmix_pmix112.la">&lt;http://mca_pmix_pmix112.la&gt;</a>
        <br>
                    -rwxr-xr-x 1 root root 3906526 Apr 19 16:45
        mca_pmix_pmix112.so
        <br>
                    -rwxr-xr-x 1 root root     966 Apr 19 16:51
        mca_pml_cm.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://mca_pml_cm.la">&lt;http://mca_pml_cm.la&gt;</a>
        <br>
                    -rwxr-xr-x 1 root root 1574265 Apr 19 16:51
        mca_pml_cm.so
        <br>
                    ...
        <br>
        <br>
                    Linux_x86_64/openmpi-2.0.0_64_gcc/lib64/openmpi:
        <br>
                    ...
        <br>
                    -rwxr-xr-x 1 root root   70371 Apr 19 16:43
        mca_plm_slurm.so
        <br>
                    -rwxr-xr-x 1 root root    1008 Apr 19 16:42
        mca_pmix_pmix112.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://mca_pmix_pmix112.la">&lt;http://mca_pmix_pmix112.la&gt;</a>
        <br>
                    -rwxr-xr-x 1 root root 1029005 Apr 19 16:42
        mca_pmix_pmix112.so
        <br>
                    -rwxr-xr-x 1 root root     972 Apr 19 16:46
        mca_pml_cm.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://mca_pml_cm.la">&lt;http://mca_pml_cm.la&gt;</a>
        <br>
                    -rwxr-xr-x 1 root root  284858 Apr 19 16:46
        mca_pml_cm.so
        <br>
                    ...
        <br>
        <br>
                    SunOS_sparc/openmpi-2.0.0_64_cc/lib64/openmpi:
        <br>
                    ...
        <br>
                    -rwxr-xr-x 1 root root  319816 Apr 19 19:58
        mca_plm_rsh.so
        <br>
                    -rwxr-xr-x 1 root root     970 Apr 19 20:00
        mca_pml_cm.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://mca_pml_cm.la">&lt;http://mca_pml_cm.la&gt;</a>
        <br>
                    -rwxr-xr-x 1 root root 1507440 Apr 19 20:00
        mca_pml_cm.so
        <br>
                    ...
        <br>
        <br>
                    SunOS_sparc/openmpi-2.0.0_64_gcc/lib64/openmpi:
        <br>
                    ...
        <br>
                    -rwxr-xr-x 1 root root  153280 Apr 19 19:49
        mca_plm_rsh.so
        <br>
                    -rwxr-xr-x 1 root root    1007 Apr 19 19:47
        mca_pmix_pmix112.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://mca_pmix_pmix112.la">&lt;http://mca_pmix_pmix112.la&gt;</a>
        <br>
                    -rwxr-xr-x 1 root root 1400512 Apr 19 19:47
        mca_pmix_pmix112.so
        <br>
                    -rwxr-xr-x 1 root root     971 Apr 19 19:52
        mca_pml_cm.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://mca_pml_cm.la">&lt;http://mca_pml_cm.la&gt;</a>
        <br>
                    -rwxr-xr-x 1 root root  342440 Apr 19 19:52
        mca_pml_cm.so
        <br>
                    ...
        <br>
        <br>
                    SunOS_x86_64/openmpi-2.0.0_64_cc/lib64/openmpi:
        <br>
                    ...
        <br>
                    -rwxr-xr-x 1 root root  300096 Apr 19 17:18
        mca_plm_rsh.so
        <br>
                    -rwxr-xr-x 1 root root     970 Apr 19 17:23
        mca_pml_cm.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://mca_pml_cm.la">&lt;http://mca_pml_cm.la&gt;</a>
        <br>
                    -rwxr-xr-x 1 root root 1458816 Apr 19 17:23
        mca_pml_cm.so
        <br>
                    ...
        <br>
        <br>
                    SunOS_x86_64/openmpi-2.0.0_64_gcc/lib64/openmpi:
        <br>
                    ...
        <br>
                    -rwxr-xr-x 1 root root  133096 Apr 19 17:42
        mca_plm_rsh.so
        <br>
                    -rwxr-xr-x 1 root root    1007 Apr 19 17:41
        mca_pmix_pmix112.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://mca_pmix_pmix112.la">&lt;http://mca_pmix_pmix112.la&gt;</a>
        <br>
                    -rwxr-xr-x 1 root root 1320240 Apr 19 17:41
        mca_pmix_pmix112.so
        <br>
                    -rwxr-xr-x 1 root root     971 Apr 19 17:46
        mca_pml_cm.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://mca_pml_cm.la">&lt;http://mca_pml_cm.la&gt;</a>
        <br>
                    -rwxr-xr-x 1 root root  419848 Apr 19 17:46
        mca_pml_cm.so
        <br>
                    ...
        <br>
        <br>
        <br>
                    Yesterday I've installed
        openmpi-v2.x-dev-1290-gbd0e4e1 so that we
        <br>
                    have a current version for the investigation of the
        problem. Once
        <br>
                    more mca_pmix_pmix112.so isn't available on Solaris
        if I use the
        <br>
                    Sun C compiler.
        <br>
        <br>
                    "config.log" for gcc-5.1.0 shows the following.
        <br>
        <br>
                    ...
        <br>
                    configure:127799: /bin/bash
        <br>
                   
        '../../../../../../openmpi-v2.x-dev-1290-gbd0e4e1/opal/mca/pmix/pmix112/
        <br>
                    pmix/configure' succeeded for
        opal/mca/pmix/pmix112/pmix
        <br>
                    configure:127916: checking if MCA component
        pmix:pmix112 can compile
        <br>
                    configure:127918: result: yes
        <br>
                    configure:5637: --- MCA component pmix:external (m4
        configuration
        <br>
                    macro)
        <br>
                    configure:128523: checking for MCA component
        pmix:external compile
        <br>
                    mode
        <br>
                    configure:128529: result: dso
        <br>
                    configure:129054: checking if MCA component
        pmix:external can compile
        <br>
                    configure:129056: result: no
        <br>
                    ...
        <br>
                    config.status:3897: creating opal/mca/pmix/Makefile
        <br>
                    config.status:3897: creating
        opal/mca/pmix/s1/Makefile
        <br>
                    config.status:3897: creating
        opal/mca/pmix/cray/Makefile
        <br>
                    config.status:3897: creating
        opal/mca/pmix/s2/Makefile
        <br>
                    config.status:3897: creating
        opal/mca/pmix/pmix112/Makefile
        <br>
                    config.status:3897: creating
        opal/mca/pmix/external/Makefile
        <br>
                    ...
        <br>
                    MCA_BUILD_opal_pmix_cray_DSO_FALSE='#'
        <br>
                    MCA_BUILD_opal_pmix_cray_DSO_TRUE=''
        <br>
                    MCA_BUILD_opal_pmix_external_DSO_FALSE='#'
        <br>
                    MCA_BUILD_opal_pmix_external_DSO_TRUE=''
        <br>
                    MCA_BUILD_opal_pmix_pmix112_DSO_FALSE='#'
        <br>
                    MCA_BUILD_opal_pmix_pmix112_DSO_TRUE=''
        <br>
                    MCA_BUILD_opal_pmix_s1_DSO_FALSE='#'
        <br>
                    MCA_BUILD_opal_pmix_s1_DSO_TRUE=''
        <br>
                    MCA_BUILD_opal_pmix_s2_DSO_FALSE='#'
        <br>
                    MCA_BUILD_opal_pmix_s2_DSO_TRUE=''
        <br>
                    ...
        <br>
                    MCA_opal_FRAMEWORKS='common  allocator backtrace btl
        dl event hwloc if
        <br>
                    installdirs memchecker memcpy memory mpool pmix
        pstat rcache sec
        <br>
                    shmem timer'
        <br>
                    MCA_opal_FRAMEWORKS_SUBDIRS='mca/common 
        mca/allocator
        <br>
                    mca/backtrace mca/btl
        <br>
                    mca/dl mca/event mca/hwloc mca/if mca/installdirs
        mca/memchecker
        <br>
                    mca/memcpy
        <br>
                    mca/memory mca/mpool mca/pmix mca/pstat mca/rcache
        mca/sec
        <br>
                    mca/shmem mca/timer'
        <br>
                   
        MCA_opal_FRAMEWORK_COMPONENT_ALL_SUBDIRS='$(MCA_opal_common_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_allocator_ALL_SUBDIRS)
        $(MCA_opal_backtrace_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_btl_ALL_SUBDIRS)
        $(MCA_opal_dl_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_event_ALL_SUBDIRS)
        $(MCA_opal_hwloc_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_if_ALL_SUBDIRS)
        $(MCA_opal_installdirs_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_memchecker_ALL_SUBDIRS)
        $(MCA_opal_memcpy_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_memory_ALL_SUBDIRS)
        $(MCA_opal_mpool_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_pmix_ALL_SUBDIRS)
        $(MCA_opal_pstat_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_rcache_ALL_SUBDIRS)
        $(MCA_opal_sec_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_shmem_ALL_SUBDIRS)
        $(MCA_opal_timer_ALL_SUBDIRS)'
        <br>
                   
        MCA_opal_FRAMEWORK_COMPONENT_DSO_SUBDIRS='$(MCA_opal_common_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_allocator_DSO_SUBDIRS)
        $(MCA_opal_backtrace_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_btl_DSO_SUBDIRS)
        $(MCA_opal_dl_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_event_DSO_SUBDIRS)
        $(MCA_opal_hwloc_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_if_DSO_SUBDIRS)
        $(MCA_opal_installdirs_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_memchecker_DSO_SUBDIRS)
        $(MCA_opal_memcpy_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_memory_DSO_SUBDIRS)
        $(MCA_opal_mpool_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_pmix_DSO_SUBDIRS)
        $(MCA_opal_pstat_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_rcache_DSO_SUBDIRS)
        $(MCA_opal_sec_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_shmem_DSO_SUBDIRS)
        $(MCA_opal_timer_DSO_SUBDIRS)'
        <br>
                   
MCA_opal_FRAMEWORK_COMPONENT_STATIC_SUBDIRS='$(MCA_opal_common_STATIC_SUBDIRS)<br>
                     $(MCA_opal_allocator_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_backtrace_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_btl_STATIC_SUBDIRS)
        $(MCA_opal_dl_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_event_STATIC_SUBDIRS)
        $(MCA_opal_hwloc_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_if_STATIC_SUBDIRS)
        $(MCA_opal_installdirs_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_memchecker_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_memcpy_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_memory_STATIC_SUBDIRS)
        $(MCA_opal_mpool_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_pmix_STATIC_SUBDIRS)
        $(MCA_opal_pstat_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_rcache_STATIC_SUBDIRS)
        $(MCA_opal_sec_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_shmem_STATIC_SUBDIRS)
        $(MCA_opal_timer_STATIC_SUBDIRS)'
        <br>
                    MCA_opal_FRAMEWORK_LIBS='
        $(MCA_opal_common_STATIC_LTLIBS)
        <br>
                    mca/allocator/libmca_allocator.la
        <a class="moz-txt-link-rfc2396E" href="http://libmca_allocator.la">&lt;http://libmca_allocator.la&gt;</a>
        <br>
                    $(MCA_opal_allocator_STATIC_LTLIBS)
        <br>
                    mca/backtrace/libmca_backtrace.la
        <a class="moz-txt-link-rfc2396E" href="http://libmca_backtrace.la">&lt;http://libmca_backtrace.la&gt;</a>
        <br>
                    $(MCA_opal_backtrace_STATIC_LTLIBS)
        <br>
                    mca/btl/libmca_btl.la <a class="moz-txt-link-rfc2396E" href="http://libmca_btl.la">&lt;http://libmca_btl.la&gt;</a>
        <br>
                    $(MCA_opal_btl_STATIC_LTLIBS) mca/dl/libmca_dl.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_dl.la">&lt;http://libmca_dl.la&gt;</a>
        <br>
                    $(MCA_opal_dl_STATIC_LTLIBS)
        mca/event/libmca_event.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_event.la">&lt;http://libmca_event.la&gt;</a>
        <br>
                    $(MCA_opal_event_STATIC_LTLIBS)
        mca/hwloc/libmca_hwloc.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_hwloc.la">&lt;http://libmca_hwloc.la&gt;</a>
        <br>
                    $(MCA_opal_hwloc_STATIC_LTLIBS) mca/if/libmca_if.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_if.la">&lt;http://libmca_if.la&gt;</a>
        <br>
                    $(MCA_opal_if_STATIC_LTLIBS)
        mca/installdirs/libmca_installdirs.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_installdirs.la">&lt;http://libmca_installdirs.la&gt;</a>
        <br>
                    $(MCA_opal_installdirs_STATIC_LTLIBS)
        <br>
                    mca/memchecker/libmca_memchecker.la
        <a class="moz-txt-link-rfc2396E" href="http://libmca_memchecker.la">&lt;http://libmca_memchecker.la&gt;</a>
        <br>
                    $(MCA_opal_memchecker_STATIC_LTLIBS)
        mca/memcpy/libmca_memcpy.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_memcpy.la">&lt;http://libmca_memcpy.la&gt;</a>
        <br>
                    $(MCA_opal_memcpy_STATIC_LTLIBS)
        mca/memory/libmca_memory.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_memory.la">&lt;http://libmca_memory.la&gt;</a>
        <br>
                    $(MCA_opal_memory_STATIC_LTLIBS)
        mca/mpool/libmca_mpool.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_mpool.la">&lt;http://libmca_mpool.la&gt;</a>
        <br>
                    $(MCA_opal_mpool_STATIC_LTLIBS)
        mca/pmix/libmca_pmix.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_pmix.la">&lt;http://libmca_pmix.la&gt;</a>
        <br>
                    $(MCA_opal_pmix_STATIC_LTLIBS)
        mca/pstat/libmca_pstat.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_pstat.la">&lt;http://libmca_pstat.la&gt;</a>
        <br>
                    $(MCA_opal_pstat_STATIC_LTLIBS)
        mca/rcache/libmca_rcache.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_rcache.la">&lt;http://libmca_rcache.la&gt;</a>
        <br>
                    $(MCA_opal_rcache_STATIC_LTLIBS)
        mca/sec/libmca_sec.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_sec.la">&lt;http://libmca_sec.la&gt;</a>
        <br>
                    $(MCA_opal_sec_STATIC_LTLIBS)
        mca/shmem/libmca_shmem.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_shmem.la">&lt;http://libmca_shmem.la&gt;</a>
        <br>
                    $(MCA_opal_shmem_STATIC_LTLIBS)
        mca/timer/libmca_timer.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_timer.la">&lt;http://libmca_timer.la&gt;</a>
        <br>
                    $(MCA_opal_timer_STATIC_LTLIBS)'
        <br>
                    ...
        <br>
                    MCA_opal_pmix_ALL_COMPONENTS=' s1 cray s2 pmix112
        external'
        <br>
                    MCA_opal_pmix_ALL_SUBDIRS=' mca/pmix/s1
        mca/pmix/cray mca/pmix/s2
        <br>
                    mca/pmix/pmix112 mca/pmix/external'
        <br>
                    MCA_opal_pmix_DSO_COMPONENTS=' pmix112'
        <br>
                    MCA_opal_pmix_DSO_SUBDIRS=' mca/pmix/pmix112'
        <br>
                    MCA_opal_pmix_STATIC_COMPONENTS=''
        <br>
                    MCA_opal_pmix_STATIC_LTLIBS=''
        <br>
                    MCA_opal_pmix_STATIC_SUBDIRS=''
        <br>
                    ...
        <br>
                    opal_pmix_ext_CPPFLAGS=''
        <br>
                    opal_pmix_ext_LDFLAGS=''
        <br>
                    opal_pmix_ext_LIBS=''
        <br>
                   
opal_pmix_pmix112_CPPFLAGS='-I$(OPAL_TOP_BUILDDIR)/opal/mca/pmix/pmix112/pmix/include/pmix<br>
                   
        -I$(OPAL_TOP_BUILDDIR)/opal/mca/pmix/pmix112/pmix/include
        <br>
                    -I$(OPAL_TOP_BUILDDIR)/opal/mca/pmix/pmix112/pmix
        <br>
                    -I$(OPAL_TOP_SRCDIR)/opal/mca/pmix/pmix112/pmix'
        <br>
                   
opal_pmix_pmix112_LIBS='$(OPAL_TOP_BUILDDIR)/opal/mca/pmix/pmix112/pmix/libpmix.la<br>
                    <a class="moz-txt-link-rfc2396E" href="http://libpmix.la">&lt;http://libpmix.la&gt;</a>'
        <br>
        <br>
                    ...
        <br>
        <br>
        <br>
        <br>
                    "config.log" for Sun C 5.13 shows the following.
        <br>
        <br>
                    ...
        <br>
                    configure:127803: /bin/bash
        <br>
                   
        '../../../../../../openmpi-v2.x-dev-1290-gbd0e4e1/opal/mca/pmix/pmix112/
        <br>
                    pmix/configure' *failed* for
        opal/mca/pmix/pmix112/pmix
        <br>
                    configure:128379: checking if MCA component
        pmix:pmix112 can compile
        <br>
                    configure:128381: result: no
        <br>
                    configure:5637: --- MCA component pmix:external (m4
        configuration
        <br>
                    macro)
        <br>
                    configure:128523: checking for MCA component
        pmix:external compile
        <br>
                    mode
        <br>
                    configure:128529: result: dso
        <br>
                    configure:129054: checking if MCA component
        pmix:external can compile
        <br>
                    configure:129056: result: no
        <br>
                    ...
        <br>
                    config.status:3887: creating opal/mca/pmix/Makefile
        <br>
                    config.status:3887: creating
        opal/mca/pmix/s1/Makefile
        <br>
                    config.status:3887: creating
        opal/mca/pmix/cray/Makefile
        <br>
                    config.status:3887: creating
        opal/mca/pmix/s2/Makefile
        <br>
                    config.status:3887: creating
        opal/mca/pmix/pmix112/Makefile
        <br>
                    config.status:3887: creating
        opal/mca/pmix/external/Makefile
        <br>
                    ...
        <br>
                    MCA_BUILD_opal_pmix_cray_DSO_FALSE='#'
        <br>
                    MCA_BUILD_opal_pmix_cray_DSO_TRUE=''
        <br>
                    MCA_BUILD_opal_pmix_external_DSO_FALSE='#'
        <br>
                    MCA_BUILD_opal_pmix_external_DSO_TRUE=''
        <br>
                    MCA_BUILD_opal_pmix_pmix112_DSO_FALSE='#'
        <br>
                    MCA_BUILD_opal_pmix_pmix112_DSO_TRUE=''
        <br>
                    MCA_BUILD_opal_pmix_s1_DSO_FALSE='#'
        <br>
                    MCA_BUILD_opal_pmix_s1_DSO_TRUE=''
        <br>
                    MCA_BUILD_opal_pmix_s2_DSO_FALSE='#'
        <br>
                    MCA_BUILD_opal_pmix_s2_DSO_TRUE=''
        <br>
                    ...
        <br>
                    MCA_opal_FRAMEWORKS='common  allocator backtrace btl
        dl event hwloc if
        <br>
                    installdirs memchecker memcpy memory mpool pmix
        pstat rcache sec
        <br>
                    shmem timer'
        <br>
                    MCA_opal_FRAMEWORKS_SUBDIRS='mca/common 
        mca/allocator
        <br>
                    mca/backtrace mca/btl
        <br>
                    mca/dl mca/event mca/hwloc mca/if mca/installdirs
        mca/memchecker
        <br>
                    mca/memcpy
        <br>
                    mca/memory mca/mpool mca/pmix mca/pstat mca/rcache
        mca/sec
        <br>
                    mca/shmem mca/timer'
        <br>
                   
        MCA_opal_FRAMEWORK_COMPONENT_ALL_SUBDIRS='$(MCA_opal_common_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_allocator_ALL_SUBDIRS)
        $(MCA_opal_backtrace_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_btl_ALL_SUBDIRS)
        $(MCA_opal_dl_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_event_ALL_SUBDIRS)
        $(MCA_opal_hwloc_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_if_ALL_SUBDIRS)
        $(MCA_opal_installdirs_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_memchecker_ALL_SUBDIRS)
        $(MCA_opal_memcpy_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_memory_ALL_SUBDIRS)
        $(MCA_opal_mpool_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_pmix_ALL_SUBDIRS)
        $(MCA_opal_pstat_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_rcache_ALL_SUBDIRS)
        $(MCA_opal_sec_ALL_SUBDIRS)
        <br>
                    $(MCA_opal_shmem_ALL_SUBDIRS)
        $(MCA_opal_timer_ALL_SUBDIRS)'
        <br>
                   
        MCA_opal_FRAMEWORK_COMPONENT_DSO_SUBDIRS='$(MCA_opal_common_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_allocator_DSO_SUBDIRS)
        $(MCA_opal_backtrace_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_btl_DSO_SUBDIRS)
        $(MCA_opal_dl_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_event_DSO_SUBDIRS)
        $(MCA_opal_hwloc_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_if_DSO_SUBDIRS)
        $(MCA_opal_installdirs_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_memchecker_DSO_SUBDIRS)
        $(MCA_opal_memcpy_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_memory_DSO_SUBDIRS)
        $(MCA_opal_mpool_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_pmix_DSO_SUBDIRS)
        $(MCA_opal_pstat_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_rcache_DSO_SUBDIRS)
        $(MCA_opal_sec_DSO_SUBDIRS)
        <br>
                    $(MCA_opal_shmem_DSO_SUBDIRS)
        $(MCA_opal_timer_DSO_SUBDIRS)'
        <br>
                   
MCA_opal_FRAMEWORK_COMPONENT_STATIC_SUBDIRS='$(MCA_opal_common_STATIC_SUBDIRS)<br>
                     $(MCA_opal_allocator_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_backtrace_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_btl_STATIC_SUBDIRS)
        $(MCA_opal_dl_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_event_STATIC_SUBDIRS)
        $(MCA_opal_hwloc_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_if_STATIC_SUBDIRS)
        $(MCA_opal_installdirs_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_memchecker_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_memcpy_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_memory_STATIC_SUBDIRS)
        $(MCA_opal_mpool_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_pmix_STATIC_SUBDIRS)
        $(MCA_opal_pstat_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_rcache_STATIC_SUBDIRS)
        $(MCA_opal_sec_STATIC_SUBDIRS)
        <br>
                    $(MCA_opal_shmem_STATIC_SUBDIRS)
        $(MCA_opal_timer_STATIC_SUBDIRS)'
        <br>
                    MCA_opal_FRAMEWORK_LIBS='
        $(MCA_opal_common_STATIC_LTLIBS)
        <br>
                    mca/allocator/libmca_allocator.la
        <a class="moz-txt-link-rfc2396E" href="http://libmca_allocator.la">&lt;http://libmca_allocator.la&gt;</a>
        <br>
                    $(MCA_opal_allocator_STATIC_LTLIBS)
        <br>
                    mca/backtrace/libmca_backtrace.la
        <a class="moz-txt-link-rfc2396E" href="http://libmca_backtrace.la">&lt;http://libmca_backtrace.la&gt;</a>
        <br>
                    $(MCA_opal_backtrace_STATIC_LTLIBS)
        <br>
                    mca/btl/libmca_btl.la <a class="moz-txt-link-rfc2396E" href="http://libmca_btl.la">&lt;http://libmca_btl.la&gt;</a>
        <br>
                    $(MCA_opal_btl_STATIC_LTLIBS) mca/dl/libmca_dl.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_dl.la">&lt;http://libmca_dl.la&gt;</a>
        <br>
                    $(MCA_opal_dl_STATIC_LTLIBS)
        mca/event/libmca_event.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_event.la">&lt;http://libmca_event.la&gt;</a>
        <br>
                    $(MCA_opal_event_STATIC_LTLIBS)
        mca/hwloc/libmca_hwloc.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_hwloc.la">&lt;http://libmca_hwloc.la&gt;</a>
        <br>
                    $(MCA_opal_hwloc_STATIC_LTLIBS) mca/if/libmca_if.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_if.la">&lt;http://libmca_if.la&gt;</a>
        <br>
                    $(MCA_opal_if_STATIC_LTLIBS)
        mca/installdirs/libmca_installdirs.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_installdirs.la">&lt;http://libmca_installdirs.la&gt;</a>
        <br>
                    $(MCA_opal_installdirs_STATIC_LTLIBS)
        <br>
                    mca/memchecker/libmca_memchecker.la
        <a class="moz-txt-link-rfc2396E" href="http://libmca_memchecker.la">&lt;http://libmca_memchecker.la&gt;</a>
        <br>
                    $(MCA_opal_memchecker_STATIC_LTLIBS)
        mca/memcpy/libmca_memcpy.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_memcpy.la">&lt;http://libmca_memcpy.la&gt;</a>
        <br>
                    $(MCA_opal_memcpy_STATIC_LTLIBS)
        mca/memory/libmca_memory.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_memory.la">&lt;http://libmca_memory.la&gt;</a>
        <br>
                    $(MCA_opal_memory_STATIC_LTLIBS)
        mca/mpool/libmca_mpool.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_mpool.la">&lt;http://libmca_mpool.la&gt;</a>
        <br>
                    $(MCA_opal_mpool_STATIC_LTLIBS)
        mca/pmix/libmca_pmix.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_pmix.la">&lt;http://libmca_pmix.la&gt;</a>
        <br>
                    $(MCA_opal_pmix_STATIC_LTLIBS)
        mca/pstat/libmca_pstat.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_pstat.la">&lt;http://libmca_pstat.la&gt;</a>
        <br>
                    $(MCA_opal_pstat_STATIC_LTLIBS)
        mca/rcache/libmca_rcache.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_rcache.la">&lt;http://libmca_rcache.la&gt;</a>
        <br>
                    $(MCA_opal_rcache_STATIC_LTLIBS)
        mca/sec/libmca_sec.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_sec.la">&lt;http://libmca_sec.la&gt;</a>
        <br>
                    $(MCA_opal_sec_STATIC_LTLIBS)
        mca/shmem/libmca_shmem.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_shmem.la">&lt;http://libmca_shmem.la&gt;</a>
        <br>
                    $(MCA_opal_shmem_STATIC_LTLIBS)
        mca/timer/libmca_timer.la
        <br>
                    <a class="moz-txt-link-rfc2396E" href="http://libmca_timer.la">&lt;http://libmca_timer.la&gt;</a>
        <br>
                    $(MCA_opal_timer_STATIC_LTLIBS)'
        <br>
                    ...
        <br>
                    MCA_opal_pmix_ALL_COMPONENTS=' s1 cray s2 pmix112
        external'
        <br>
                    MCA_opal_pmix_ALL_SUBDIRS=' mca/pmix/s1
        mca/pmix/cray mca/pmix/s2
        <br>
                    mca/pmix/pmix112 mca/pmix/external'
        <br>
                    MCA_opal_pmix_DSO_COMPONENTS=''
        <br>
                    MCA_opal_pmix_DSO_SUBDIRS=''
        <br>
                    MCA_opal_pmix_STATIC_COMPONENTS=''
        <br>
                    MCA_opal_pmix_STATIC_LTLIBS=''
        <br>
                    MCA_opal_pmix_STATIC_SUBDIRS=''
        <br>
                    ...
        <br>
                    opal_pmix_ext_CPPFLAGS=''
        <br>
                    opal_pmix_ext_LDFLAGS=''
        <br>
                    opal_pmix_ext_LIBS=''
        <br>
                    opal_pmix_pmix112_CPPFLAGS=''
        <br>
                    opal_pmix_pmix112_LIBS=''
        <br>
                    ...
        <br>
        <br>
        <br>
        <br>
        <br>
                    I've attached the config.log files for pmix.
        <br>
        <br>
                    tyr openmpi-2.0.0 142 tar zvft
        pmix_config.log.tar.gz
        <br>
                    -rw-r--r-- root/root    136291 2016-04-25 08:05:34
        <br>
                   
openmpi-v2.x-dev-1290-gbd0e4e1-SunOS.sparc.64_cc/opal/mca/pmix/pmix112/pmix/config.log<br>
                    -rw-r--r-- root/root    528808 2016-04-25 08:07:54
        <br>
                   
openmpi-v2.x-dev-1290-gbd0e4e1-SunOS.sparc.64_gcc/opal/mca/pmix/pmix112/pmix/config.log<br>
                    tyr openmpi-2.0.0 143
        <br>
        <br>
        <br>
        <br>
                    I've also attached the output for the broken
        execution of
        <br>
                    "spawn_multiple_master" for my gcc-version of Open
        MPI.
        <br>
                    "spawn_master" works as expected with my gcc-version
        of Open MPI.
        <br>
        <br>
                    Hopefully you can fix the problem.
        <br>
        <br>
        <br>
                    Kind regards and thank you very much for your help
        <br>
        <br>
                    Siegmar
        <br>
        <br>
        <br>
        <br>
                    Am 23.04.2016 um 21:34 schrieb Siegmar Gross:
        <br>
        <br>
                        Hi Gilles,
        <br>
        <br>
                        I don't know what happened, but the files are
        not available now
        <br>
                        and they were definitely available when I
        answered the email from
        <br>
                        Ralph. The files also have a different timestamp
        now. This is an
        <br>
                        extract from my email to Ralph for Solaris
        Sparc.
        <br>
        <br>
                        -rwxr-xr-x 1 root root     977 Apr 19 19:49
        mca_plm_rsh.la
        <br>
                        <a class="moz-txt-link-rfc2396E" href="http://mca_plm_rsh.la">&lt;http://mca_plm_rsh.la&gt;</a>
        <br>
                        -rwxr-xr-x 1 root root  153280 Apr 19 19:49
        mca_plm_rsh.so
        <br>
                        -rwxr-xr-x 1 root root    1007 Apr 19 19:47
        <br>
                        mca_pmix_pmix112.la
        <a class="moz-txt-link-rfc2396E" href="http://mca_pmix_pmix112.la">&lt;http://mca_pmix_pmix112.la&gt;</a>
        <br>
                        -rwxr-xr-x 1 root root 1400512 Apr 19 19:47
        mca_pmix_pmix112.so
        <br>
                        -rwxr-xr-x 1 root root     971 Apr 19 19:52
        mca_pml_cm.la
        <br>
                        <a class="moz-txt-link-rfc2396E" href="http://mca_pml_cm.la">&lt;http://mca_pml_cm.la&gt;</a>
        <br>
                        -rwxr-xr-x 1 root root  342440 Apr 19 19:52
        mca_pml_cm.so
        <br>
        <br>
                        Now I have the following output for these files.
        <br>
        <br>
                        -rwxr-xr-x 1 root root     976 Apr 19 19:58
        mca_plm_rsh.la
        <br>
                        <a class="moz-txt-link-rfc2396E" href="http://mca_plm_rsh.la">&lt;http://mca_plm_rsh.la&gt;</a>
        <br>
                        -rwxr-xr-x 1 root root  319816 Apr 19 19:58
        mca_plm_rsh.so
        <br>
                        -rwxr-xr-x 1 root root     970 Apr 19 20:00
        mca_pml_cm.la
        <br>
                        <a class="moz-txt-link-rfc2396E" href="http://mca_pml_cm.la">&lt;http://mca_pml_cm.la&gt;</a>
        <br>
                        -rwxr-xr-x 1 root root 1507440 Apr 19 20:00
        mca_pml_cm.so
        <br>
        <br>
                        I'll try to find out what happened next week
        when I'm back in
        <br>
                        my office.
        <br>
        <br>
        <br>
                        Kind regards
        <br>
        <br>
                        Siegmar
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
                        Am 23.04.16 um 02:12 schrieb Gilles
        Gouaillardet:
        <br>
        <br>
                            Siegmar,
        <br>
        <br>
                            I will try to reproduce this on my solaris11
        x86_64 vm
        <br>
        <br>
                            In the mean time, can you please double
        check
        <br>
                            mca_pmix_pmix_pmix112.so
        <br>
                            is a 64 bits library ?
        <br>
                            (E.g, confirm "-m64" was correctly passed to
        pmix)
        <br>
        <br>
                            Cheers,
        <br>
        <br>
                            Gilles
        <br>
        <br>
                            On Friday, April 22, 2016, Siegmar Gross
        <br>
                            &lt;<a class="moz-txt-link-abbreviated" href="mailto:siegmar.gross@informatik.hs-fulda.de">siegmar.gross@informatik.hs-fulda.de</a>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="mailto:siegmar.gross@informatik.hs-fulda.de">&lt;mailto:siegmar.gross@informatik.hs-fulda.de&gt;</a>&gt; wrote:
        <br>
        <br>
                                Hi Ralph,
        <br>
        <br>
                                I've already used "-enable-debug".
        "SYSTEM_ENV" is
        <br>
                            "SunOS" or
        <br>
                                "Linux" and "MACHINE_ENV" is "sparc" or
        "x86_84".
        <br>
        <br>
                                mkdir
        <br>
                           
        openmpi-v2.x-dev-1280-gc110ae8-${SYSTEM_ENV}.${MACHINE_ENV}.64_gcc
        <br>
                                cd
        <br>
                           
        openmpi-v2.x-dev-1280-gc110ae8-${SYSTEM_ENV}.${MACHINE_ENV}.64_gcc
        <br>
        <br>
                               
        ../openmpi-v2.x-dev-1280-gc110ae8/configure \
        <br>
                                 
        --prefix=/usr/local/openmpi-2.0.0_64_gcc \
        <br>
                                 
        --libdir=/usr/local/openmpi-2.0.0_64_gcc/lib64 \
        <br>
                                 
        --with-jdk-bindir=/usr/local/jdk1.8.0/bin \
        <br>
                                 
        --with-jdk-headers=/usr/local/jdk1.8.0/include \
        <br>
                                  JAVA_HOME=/usr/local/jdk1.8.0 \
        <br>
                                  LDFLAGS="-m64" CC="gcc" CXX="g++"
        FC="gfortran" \
        <br>
                                  CFLAGS="-m64" CXXFLAGS="-m64"
        FCFLAGS="-m64" \
        <br>
                                  CPP="cpp" CXXCPP="cpp" \
        <br>
                                  --enable-mpi-cxx \
        <br>
                                  --enable-cxx-exceptions \
        <br>
                                  --enable-mpi-java \
        <br>
                                  --enable-heterogeneous \
        <br>
                                  --enable-mpi-thread-multiple \
        <br>
                                  --with-hwloc=internal \
        <br>
                                  --without-verbs \
        <br>
                                  --with-wrapper-cflags="-std=c11 -m64"
        \
        <br>
                                  --with-wrapper-cxxflags="-m64" \
        <br>
                                  --with-wrapper-fcflags="-m64" \
        <br>
                                  --enable-debug \
        <br>
                                  |&amp; tee
        log.configure.$SYSTEM_ENV.$MACHINE_ENV.64_gcc
        <br>
        <br>
        <br>
                                mkdir
        <br>
                           
        openmpi-v2.x-dev-1280-gc110ae8-${SYSTEM_ENV}.${MACHINE_ENV}.64_cc
        <br>
                                cd
        <br>
                           
        openmpi-v2.x-dev-1280-gc110ae8-${SYSTEM_ENV}.${MACHINE_ENV}.64_cc
        <br>
        <br>
                               
        ../openmpi-v2.x-dev-1280-gc110ae8/configure \
        <br>
                                 
        --prefix=/usr/local/openmpi-2.0.0_64_cc \
        <br>
                                 
        --libdir=/usr/local/openmpi-2.0.0_64_cc/lib64 \
        <br>
                                 
        --with-jdk-bindir=/usr/local/jdk1.8.0/bin \
        <br>
                                 
        --with-jdk-headers=/usr/local/jdk1.8.0/include \
        <br>
                                  JAVA_HOME=/usr/local/jdk1.8.0 \
        <br>
                                  LDFLAGS="-m64" CC="cc" CXX="CC"
        FC="f95" \
        <br>
                                  CFLAGS="-m64" CXXFLAGS="-m64
        -library=stlport4"
        <br>
                            FCFLAGS="-m64" \
        <br>
                                  CPP="cpp" CXXCPP="cpp" \
        <br>
                                  --enable-mpi-cxx \
        <br>
                                  --enable-cxx-exceptions \
        <br>
                                  --enable-mpi-java \
        <br>
                                  --enable-heterogeneous \
        <br>
                                  --enable-mpi-thread-multiple \
        <br>
                                  --with-hwloc=internal \
        <br>
                                  --without-verbs \
        <br>
                                  --with-wrapper-cflags="-m64" \
        <br>
                                  --with-wrapper-cxxflags="-m64
        -library=stlport4" \
        <br>
                                  --with-wrapper-fcflags="-m64" \
        <br>
                                  --with-wrapper-ldflags="" \
        <br>
                                  --enable-debug \
        <br>
                                  |&amp; tee
        log.configure.$SYSTEM_ENV.$MACHINE_ENV.64_cc
        <br>
        <br>
        <br>
                                Kind regards
        <br>
        <br>
                                Siegmar
        <br>
        <br>
                                Am 21.04.2016 um 18:18 schrieb Ralph
        Castain:
        <br>
        <br>
                                    Can you please rebuild OMPI with
        -enable-debug in
        <br>
                            the configure
        <br>
                                    cmd? It will let us see more error
        output
        <br>
        <br>
        <br>
                                        On Apr 21, 2016, at 8:52 AM,
        Siegmar Gross
        <br>
                                       
        <a class="moz-txt-link-rfc2396E" href="mailto:siegmar.gross@informatik.hs-fulda.de">&lt;siegmar.gross@informatik.hs-fulda.de&gt;</a> wrote:
        <br>
        <br>
                                        Hi Ralph,
        <br>
        <br>
                                        I don't see any additional
        information.
        <br>
        <br>
                                        tyr hello_1 108 mpiexec -np 4
        --host
        <br>
                                        tyr,sunpc1,linpc1,ruester -mca
        <br>
                                       
        mca_base_component_show_load_errors 1 hello_1_mpi
        <br>
                                       
        [tyr.informatik.hs-fulda.de:06211
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de:06211">&lt;http://tyr.informatik.hs-fulda.de:06211&gt;</a>
        <br>
                                       
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de:06211">&lt;http://tyr.informatik.hs-fulda.de:06211&gt;</a>]
        <br>
                            [[48741,0],0]
        <br>
                                        ORTE_ERROR_LOG: Not found in
        file
        <br>
        <br>
                           
../../../../../openmpi-v2.x-dev-1280-gc110ae8/orte/mca/ess/hnp/ess_hnp_module.c<br>
        <br>
                                        at line 638
        <br>
        <br>
                           
--------------------------------------------------------------------------<br>
                                        It looks like orte_init failed
        for some
        <br>
                            reason; your
        <br>
                                        parallel process is
        <br>
                                        likely to abort.  There are many
        reasons that
        <br>
                            a parallel
        <br>
                                        process can
        <br>
                                        fail during orte_init; some of
        which are due
        <br>
                            to configuration or
        <br>
                                        environment problems.  This
        failure appears to
        <br>
                            be an
        <br>
                                        internal failure;
        <br>
                                        here's some additional
        information (which may
        <br>
                            only be
        <br>
                                        relevant to an
        <br>
                                        Open MPI developer):
        <br>
        <br>
                                         opal_pmix_base_select failed
        <br>
                                         --&gt; Returned value Not found
        (-13) instead of
        <br>
                            ORTE_SUCCESS
        <br>
        <br>
                           
--------------------------------------------------------------------------<br>
        <br>
        <br>
                                        tyr hello_1 109 mpiexec -np 4
        --host
        <br>
                                        tyr,sunpc1,linpc1,ruester -mca
        <br>
                                       
        mca_base_component_show_load_errors 1 -mca
        <br>
                            pmix_base_verbose
        <br>
                                        10 -mca pmix_server_verbose 5
        hello_1_mpi
        <br>
                                       
        [tyr.informatik.hs-fulda.de:06212
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de:06212">&lt;http://tyr.informatik.hs-fulda.de:06212&gt;</a>
        <br>
                                       
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de:06212">&lt;http://tyr.informatik.hs-fulda.de:06212&gt;</a>]
        <br>
                            mca: base:
        <br>
                                        components_register: registering
        framework
        <br>
                            pmix components
        <br>
                                       
        [tyr.informatik.hs-fulda.de:06212
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de:06212">&lt;http://tyr.informatik.hs-fulda.de:06212&gt;</a>
        <br>
                                       
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de:06212">&lt;http://tyr.informatik.hs-fulda.de:06212&gt;</a>]
        <br>
                            mca: base:
        <br>
                                        components_open: opening pmix
        components
        <br>
                                       
        [tyr.informatik.hs-fulda.de:06212
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de:06212">&lt;http://tyr.informatik.hs-fulda.de:06212&gt;</a>
        <br>
                                       
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de:06212">&lt;http://tyr.informatik.hs-fulda.de:06212&gt;</a>]
        <br>
                            mca:base:select:
        <br>
                                        Auto-selecting pmix components
        <br>
                                       
        [tyr.informatik.hs-fulda.de:06212
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de:06212">&lt;http://tyr.informatik.hs-fulda.de:06212&gt;</a>
        <br>
                                       
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de:06212">&lt;http://tyr.informatik.hs-fulda.de:06212&gt;</a>]
        <br>
                            mca:base:select:(
        <br>
                                        pmix) No component selected!
        <br>
                                       
        [tyr.informatik.hs-fulda.de:06212
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de:06212">&lt;http://tyr.informatik.hs-fulda.de:06212&gt;</a>
        <br>
                                       
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de:06212">&lt;http://tyr.informatik.hs-fulda.de:06212&gt;</a>]
        <br>
                            [[48738,0],0]
        <br>
                                        ORTE_ERROR_LOG: Not found in
        file
        <br>
        <br>
                           
../../../../../openmpi-v2.x-dev-1280-gc110ae8/orte/mca/ess/hnp/ess_hnp_module.c<br>
        <br>
                                        at line 638
        <br>
        <br>
                           
--------------------------------------------------------------------------<br>
                                        It looks like orte_init failed
        for some
        <br>
                            reason; your
        <br>
                                        parallel process is
        <br>
                                        likely to abort.  There are many
        reasons that
        <br>
                            a parallel
        <br>
                                        process can
        <br>
                                        fail during orte_init; some of
        which are due
        <br>
                            to configuration or
        <br>
                                        environment problems.  This
        failure appears to
        <br>
                            be an
        <br>
                                        internal failure;
        <br>
                                        here's some additional
        information (which may
        <br>
                            only be
        <br>
                                        relevant to an
        <br>
                                        Open MPI developer):
        <br>
        <br>
                                         opal_pmix_base_select failed
        <br>
                                         --&gt; Returned value Not found
        (-13) instead of
        <br>
                            ORTE_SUCCESS
        <br>
        <br>
                           
--------------------------------------------------------------------------<br>
                                        tyr hello_1 110
        <br>
        <br>
        <br>
                                        Kind regards
        <br>
        <br>
                                        Siegmar
        <br>
        <br>
        <br>
                                        Am 21.04.2016 um 17:24 schrieb
        Ralph Castain:
        <br>
        <br>
                                            Hmmmit looks like you built
        the right
        <br>
                            components, but
        <br>
                                            they are not being picked
        up. Can you run
        <br>
                            your mpiexec
        <br>
                                            command again, adding -mca
        <br>
                                           
        mca_base_component_show_load_errors 1 to
        <br>
                            the cmd line?
        <br>
        <br>
        <br>
                                                On Apr 21, 2016, at 8:16
        AM, Siegmar Gross
        <br>
                                               
        <a class="moz-txt-link-rfc2396E" href="mailto:siegmar.gross@informatik.hs-fulda.de">&lt;siegmar.gross@informatik.hs-fulda.de&gt;</a>
        <br>
                            wrote:
        <br>
        <br>
                                                Hi Ralph,
        <br>
        <br>
                                                I have attached
        ompi_info output for
        <br>
                            both compilers
        <br>
                                                from my
        <br>
                                                sparc machine and the
        listings for
        <br>
                            both compilers
        <br>
                                                from the
        <br>
                                               
        &lt;prefix&gt;/lib/openmpi directories.
        <br>
                            Hopefully that
        <br>
                                                helps to
        <br>
                                                find the problem.
        <br>
        <br>
                                                hermes tmp 3 tar zvft
        <br>
                            openmpi-2.x_info.tar.gz
        <br>
                                                -rw-r--r-- root/root    
        10969
        <br>
                            2016-04-21 17:06
        <br>
                                               
        ompi_info_SunOS_sparc_cc.txt
        <br>
                                                -rw-r--r-- root/root    
        11044
        <br>
                            2016-04-21 17:06
        <br>
                                               
        ompi_info_SunOS_sparc_gcc.txt
        <br>
                                                -rw-r--r-- root/root    
        71252
        <br>
                            2016-04-21 17:02
        <br>
                                                lib64_openmpi.txt
        <br>
                                                hermes tmp 4
        <br>
        <br>
        <br>
                                                Kind regards and thank
        you very much
        <br>
                            once more for
        <br>
                                                your help
        <br>
        <br>
                                                Siegmar
        <br>
        <br>
        <br>
                                                Am 21.04.2016 um 15:54
        schrieb Ralph
        <br>
                            Castain:
        <br>
        <br>
                                                    Odd - it would
        appear that none of
        <br>
                            the pmix
        <br>
                                                    components built?
        Can you send
        <br>
                                                    along the output
        from ompi_info?
        <br>
                            Or just send a
        <br>
                                                    listing of the files
        in the
        <br>
                                                   
        &lt;prefix&gt;/lib/openmpi directory?
        <br>
        <br>
        <br>
                                                        On Apr 21, 2016,
        at 1:27 AM,
        <br>
                            Siegmar Gross
        <br>
        <br>
                            &lt;<a class="moz-txt-link-abbreviated" href="mailto:Siegmar.Gross@informatik.hs-fulda.de">Siegmar.Gross@informatik.hs-fulda.de</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="mailto:Siegmar.Gross@informatik.hs-fulda.de">&lt;mailto:Siegmar.Gross@informatik.hs-fulda.de&gt;</a>&gt;
        <br>
                                                        wrote:
        <br>
        <br>
                                                        Hi Ralph,
        <br>
        <br>
                                                        Am 21.04.2016 um
        00:18 schrieb
        <br>
                            Ralph Castain:
        <br>
        <br>
                                                            Could you
        please rerun
        <br>
                            these test and
        <br>
                                                            add -mca
        pmix_base_verbose 10
        <br>
                                                            -mca
        pmix_server_verbose
        <br>
                            5 to your cmd
        <br>
                                                            line? I need
        to see why the
        <br>
                                                            pmix
        components failed.
        <br>
        <br>
        <br>
        <br>
                                                        tyr spawn 111
        mpiexec -np 1 --host
        <br>
                                                       
        tyr,sunpc1,linpc1,ruester -mca
        <br>
                                                       
        pmix_base_verbose 10 -mca
        <br>
                                                       
        pmix_server_verbose 5
        <br>
                            spawn_multiple_master
        <br>
                                                       
        [tyr.informatik.hs-fulda.de
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de/">&lt;http://tyr.informatik.hs-fulda.de/&gt;</a>:26652] mca:
        <br>
                                                        base:
        components_register:
        <br>
                            registering
        <br>
                                                        framework pmix
        components
        <br>
                                                       
        [tyr.informatik.hs-fulda.de
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de/">&lt;http://tyr.informatik.hs-fulda.de/&gt;</a>:26652] mca:
        <br>
                                                        base:
        components_open: opening
        <br>
                            pmix components
        <br>
                                                       
        [tyr.informatik.hs-fulda.de
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de/">&lt;http://tyr.informatik.hs-fulda.de/&gt;</a>:26652]
        <br>
                                                        mca:base:select:
        <br>
                            Auto-selecting pmix components
        <br>
                                                       
        [tyr.informatik.hs-fulda.de
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de/">&lt;http://tyr.informatik.hs-fulda.de/&gt;</a>:26652]
        <br>
                                                       
        mca:base:select:( pmix) No
        <br>
                            component selected!
        <br>
                                                       
        [tyr.informatik.hs-fulda.de
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de/">&lt;http://tyr.informatik.hs-fulda.de/&gt;</a>:26652]
        <br>
                                                        [[52794,0],0]
        ORTE_ERROR_LOG:
        <br>
                            Not found in file
        <br>
        <br>
                           
../../../../../openmpi-v2.x-dev-1280-gc110ae8/orte/mca/ess/hnp/ess_hnp_module.c<br>
        <br>
                                                        at line 638
        <br>
        <br>
                           
--------------------------------------------------------------------------<br>
                                                        It looks like
        orte_init failed
        <br>
                            for some
        <br>
                                                        reason; your
        parallel process is
        <br>
                                                        likely to
        abort.  There are
        <br>
                            many reasons
        <br>
                                                        that a parallel
        process can
        <br>
                                                        fail during
        orte_init; some of
        <br>
                            which are due
        <br>
                                                        to configuration
        or
        <br>
                                                        environment
        problems.  This
        <br>
                            failure appears
        <br>
                                                        to be an
        internal failure;
        <br>
                                                        here's some
        additional
        <br>
                            information (which
        <br>
                                                        may only be
        relevant to an
        <br>
                                                        Open MPI
        developer):
        <br>
        <br>
                                                       
        opal_pmix_base_select failed
        <br>
                                                        --&gt; Returned
        value Not found
        <br>
                            (-13) instead
        <br>
                                                        of ORTE_SUCCESS
        <br>
        <br>
                           
--------------------------------------------------------------------------<br>
                                                        tyr spawn 112
        <br>
        <br>
        <br>
        <br>
        <br>
                                                        tyr hello_1 116
        mpiexec -np 1
        <br>
                            --host
        <br>
                                                       
        tyr,sunpc1,linpc1,ruester -mca
        <br>
                                                       
        pmix_base_verbose 10 -mca
        <br>
                                                       
        pmix_server_verbose 5 hello_1_mpi
        <br>
                                                       
        [tyr.informatik.hs-fulda.de
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de/">&lt;http://tyr.informatik.hs-fulda.de/&gt;</a>:27261] mca:
        <br>
                                                        base:
        components_register:
        <br>
                            registering
        <br>
                                                        framework pmix
        components
        <br>
                                                       
        [tyr.informatik.hs-fulda.de
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de/">&lt;http://tyr.informatik.hs-fulda.de/&gt;</a>:27261] mca:
        <br>
                                                        base:
        components_open: opening
        <br>
                            pmix components
        <br>
                                                       
        [tyr.informatik.hs-fulda.de
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de/">&lt;http://tyr.informatik.hs-fulda.de/&gt;</a>:27261]
        <br>
                                                        mca:base:select:
        <br>
                            Auto-selecting pmix components
        <br>
                                                       
        [tyr.informatik.hs-fulda.de
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de/">&lt;http://tyr.informatik.hs-fulda.de/&gt;</a>:27261]
        <br>
                                                       
        mca:base:select:( pmix) No
        <br>
                            component selected!
        <br>
                                                       
        [tyr.informatik.hs-fulda.de
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de/">&lt;http://tyr.informatik.hs-fulda.de/&gt;</a>:27261]
        <br>
                                                        [[52315,0],0]
        ORTE_ERROR_LOG:
        <br>
                            Not found in file
        <br>
        <br>
                           
../../../../../openmpi-v2.x-dev-1280-gc110ae8/orte/mca/ess/hnp/ess_hnp_module.c<br>
        <br>
                                                        at line 638
        <br>
        <br>
                           
--------------------------------------------------------------------------<br>
                                                        It looks like
        orte_init failed
        <br>
                            for some
        <br>
                                                        reason; your
        parallel process is
        <br>
                                                        likely to
        abort.  There are
        <br>
                            many reasons
        <br>
                                                        that a parallel
        process can
        <br>
                                                        fail during
        orte_init; some of
        <br>
                            which are due
        <br>
                                                        to configuration
        or
        <br>
                                                        environment
        problems.  This
        <br>
                            failure appears
        <br>
                                                        to be an
        internal failure;
        <br>
                                                        here's some
        additional
        <br>
                            information (which
        <br>
                                                        may only be
        relevant to an
        <br>
                                                        Open MPI
        developer):
        <br>
        <br>
                                                       
        opal_pmix_base_select failed
        <br>
                                                        --&gt; Returned
        value Not found
        <br>
                            (-13) instead
        <br>
                                                        of ORTE_SUCCESS
        <br>
        <br>
                           
--------------------------------------------------------------------------<br>
                                                        tyr hello_1 117
        <br>
        <br>
        <br>
        <br>
                                                        Thank you very
        much for your help.
        <br>
        <br>
        <br>
                                                        Kind regards
        <br>
        <br>
                                                        Siegmar
        <br>
        <br>
        <br>
        <br>
        <br>
                                                            Thanks
        <br>
                                                            Ralph
        <br>
        <br>
                                                                On Apr
        20, 2016, at
        <br>
                            10:12 AM,
        <br>
                                                                Siegmar
        Gross
        <br>
        <br>
                            &lt;<a class="moz-txt-link-abbreviated" href="mailto:Siegmar.Gross@informatik.hs-fulda.de">Siegmar.Gross@informatik.hs-fulda.de</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="mailto:Siegmar.Gross@informatik.hs-fulda.de">&lt;mailto:Siegmar.Gross@informatik.hs-fulda.de&gt;</a>&gt;
        <br>
                                                                wrote:
        <br>
        <br>
                                                                Hi,
        <br>
        <br>
                                                                I have
        built
        <br>
        <br>
                            openmpi-v2.x-dev-1280-gc110ae8 on my
        <br>
                                                                machines
        <br>
                                                                (Solaris
        10 Sparc,
        <br>
                            Solaris 10
        <br>
                                                                x86_64,
        and openSUSE Linux
        <br>
                                                                12.1
        x86_64) with
        <br>
                            gcc-5.1.0 and Sun
        <br>
                                                                C 5.13.
        Unfortunately
        <br>
                            I get
        <br>
                                                                runtime
        errors for
        <br>
                            some programs.
        <br>
        <br>
        <br>
                                                                Sun C
        5.13:
        <br>
                                                               
        ===========
        <br>
        <br>
                                                                For all
        my test
        <br>
                            programs I get the
        <br>
                                                                same
        error on Solaris
        <br>
                            Sparc and
        <br>
                                                                Solaris
        x86_64, while
        <br>
                            the programs
        <br>
                                                                work
        fine on Linux.
        <br>
        <br>
                                                                tyr
        hello_1 115
        <br>
                            mpiexec -np 2
        <br>
                                                               
        hello_1_mpi
        <br>
        <br>
                            [tyr.informatik.hs-fulda.de
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>:22373]
        <br>
                                                               
        [[61763,0],0]
        <br>
                            ORTE_ERROR_LOG: Not
        <br>
                                                                found in
        file
        <br>
        <br>
                           
../../../../../openmpi-v2.x-dev-1280-gc110ae8/orte/mca/ess/hnp/ess_hnp_module.c<br>
        <br>
                                                                at line
        638
        <br>
        <br>
                           
--------------------------------------------------------------------------<br>
                                                                It looks
        like
        <br>
                            orte_init failed for
        <br>
                                                                some
        reason; your
        <br>
                            parallel process is
        <br>
                                                                likely
        to abort.
        <br>
                            There are many
        <br>
                                                                reasons
        that a
        <br>
                            parallel process can
        <br>
                                                                fail
        during orte_init;
        <br>
                            some of which
        <br>
                                                                are due
        to
        <br>
                            configuration or
        <br>
                                                               
        environment problems.
        <br>
                            This failure
        <br>
                                                                appears
        to be an
        <br>
                            internal failure;
        <br>
                                                                here's
        some additional
        <br>
                            information
        <br>
                                                                (which
        may only be
        <br>
                            relevant to an
        <br>
                                                                Open MPI
        developer):
        <br>
        <br>
                                                               
        opal_pmix_base_select
        <br>
                            failed
        <br>
                                                                --&gt;
        Returned value Not
        <br>
                            found (-13)
        <br>
                                                                instead
        of ORTE_SUCCESS
        <br>
        <br>
                           
--------------------------------------------------------------------------<br>
                                                                tyr
        hello_1 116
        <br>
        <br>
        <br>
        <br>
        <br>
                                                               
        GCC-5.1.0:
        <br>
                                                               
        ==========
        <br>
        <br>
                                                                tyr
        spawn 121 mpiexec
        <br>
                            -np 1 --host
        <br>
                                                               
        tyr,sunpc1,linpc1,ruester
        <br>
                                                               
        spawn_multiple_master
        <br>
        <br>
                                                                Parent
        process 0
        <br>
                            running on
        <br>
        <br>
                            tyr.informatik.hs-fulda.de
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
                                                                I create
        3 slave
        <br>
                            processes.
        <br>
        <br>
        <br>
                            [tyr.informatik.hs-fulda.de
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>:25366]
        <br>
                                                                PMIX
        ERROR:
        <br>
                            UNPACK-PAST-END in file
        <br>
        <br>
                           
../../../../../../openmpi-v2.x-dev-1280-gc110ae8/opal/mca/pmix/pmix112/pmix/src/server/pmix_server_ops.c<br>
        <br>
        <br>
                                                                at line
        829
        <br>
        <br>
                            [tyr.informatik.hs-fulda.de
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>
        <br>
        <br>
                           
        <a class="moz-txt-link-rfc2396E" href="http://tyr.informatik.hs-fulda.de">&lt;http://tyr.informatik.hs-fulda.de&gt;</a>:25366]
        <br>
                                                                PMIX
        ERROR:
        <br>
                            UNPACK-PAST-END in file
        <br>
        <br>
                           
../../../../../../openmpi-v2.x-dev-1280-gc110ae8/opal/mca/pmix/pmix112/pmix/src/server/pmix_server.c<br>
        <br>
        <br>
                                                                at line
        2176
        <br>
                                                               
        [tyr:25377] *** An
        <br>
                            error occurred in
        <br>
                                                               
        MPI_Comm_spawn_multiple
        <br>
                                                               
        [tyr:25377] ***
        <br>
                            reported by process
        <br>
                                                               
        [3308257281,0]
        <br>
                                                               
        [tyr:25377] *** on
        <br>
                            communicator
        <br>
                                                               
        MPI_COMM_WORLD
        <br>
                                                               
        [tyr:25377] ***
        <br>
                            MPI_ERR_SPAWN: could
        <br>
                                                                not
        spawn processes
        <br>
                                                               
        [tyr:25377] ***
        <br>
                            MPI_ERRORS_ARE_FATAL
        <br>
                                                               
        (processes in this
        <br>
                            communicator will
        <br>
                                                                now
        abort,
        <br>
                                                               
        [tyr:25377] ***    and
        <br>
                            potentially
        <br>
                                                                your MPI
        job)
        <br>
                                                                tyr
        spawn 122
        <br>
        <br>
        <br>
                                                                I would
        be grateful if
        <br>
                            somebody can
        <br>
                                                                fix the
        problems.
        <br>
                            Thank you very
        <br>
                                                                much for
        any help in
        <br>
                            advance.
        <br>
        <br>
        <br>
                                                                Kind
        regards
        <br>
        <br>
                                                                Siegmar
        <br>
        <br>
                           
&lt;hello_1_mpi.c&gt;&lt;spawn_multiple_master.c&gt;_______________________________________________<br>
        <br>
        <br>
                                                                users
        mailing list
        <br>
                                                               
        <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="mailto:users@open-mpi.org">&lt;mailto:users@open-mpi.org&gt;</a>
        <br>
                                                               
        Subscription:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
        <br>
                                                                Link to
        this post:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/04/28983.php">http://www.open-mpi.org/community/lists/users/2016/04/28983.php</a>
        <br>
        <br>
        <br>
        <br>
                           
        _______________________________________________
        <br>
                                                            users
        mailing list
        <br>
                                                           
        <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="mailto:users@open-mpi.org">&lt;mailto:users@open-mpi.org&gt;</a>
        <br>
                                                           
        Subscription:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
        <br>
                                                            Link to this
        <br>
                                                            post:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/04/28986.php">http://www.open-mpi.org/community/lists/users/2016/04/28986.php</a>
        <br>
        <br>
        <br>
        <br>
                           
        _______________________________________________
        <br>
                                                        users mailing
        list
        <br>
                                                       
        <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
        <br>
                            <a class="moz-txt-link-rfc2396E" href="mailto:users@open-mpi.org">&lt;mailto:users@open-mpi.org&gt;</a>
        <br>
                                                        Subscription:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
        <br>
                                                        Link to this
        <br>
                                                        post:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/04/28987.php">http://www.open-mpi.org/community/lists/users/2016/04/28987.php</a>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
                           
        _______________________________________________
        <br>
                                                    users mailing list
        <br>
                                                    <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
        <br>
                                                    Subscription:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
        <br>
                                                    Link to this post:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/04/28988.php">http://www.open-mpi.org/community/lists/users/2016/04/28988.php</a>
        <br>
        <br>
        <br>
                           
&lt;openmpi-2.x_info.tar.gz&gt;_______________________________________________<br>
                                                users mailing list
        <br>
                                                <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
        <br>
                                                Subscription:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
        <br>
                                                Link to this post:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/04/28989.php">http://www.open-mpi.org/community/lists/users/2016/04/28989.php</a>
        <br>
        <br>
        <br>
        <br>
                           
        _______________________________________________
        <br>
                                            users mailing list
        <br>
                                            <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
        <br>
                                            Subscription:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
        <br>
                                            Link to this post:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/04/28990.php">http://www.open-mpi.org/community/lists/users/2016/04/28990.php</a>
        <br>
        <br>
        <br>
                                       
        _______________________________________________
        <br>
                                        users mailing list
        <br>
                                        <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
        <br>
                                        Subscription:
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
        <br>
                                        Link to this post:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/04/28991.php">http://www.open-mpi.org/community/lists/users/2016/04/28991.php</a>
        <br>
        <br>
        <br>
                                   
        _______________________________________________
        <br>
                                    users mailing list
        <br>
                                    <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
        <br>
                                    Subscription:
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
        <br>
                                    Link to this post:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/04/28992.php">http://www.open-mpi.org/community/lists/users/2016/04/28992.php</a>
        <br>
        <br>
                               
        _______________________________________________
        <br>
                                users mailing list
        <br>
                                <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
        <br>
                                Subscription:
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
        <br>
                                Link to this post:
        <br>
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/04/28993.php">http://www.open-mpi.org/community/lists/users/2016/04/28993.php</a>
        <br>
        <br>
        <br>
        <br>
                           
        _______________________________________________
        <br>
                            users mailing list
        <br>
                            <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
        <br>
                            Subscription:
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
        <br>
                            Link to this post:
        <br>
                           
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/04/28999.php">http://www.open-mpi.org/community/lists/users/2016/04/28999.php</a>
        <br>
        <br>
                        _______________________________________________
        <br>
                        users mailing list
        <br>
                        <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
        <br>
                        Subscription:
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
        <br>
                        Link to this post:
        <br>
                       
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/04/29009.php">http://www.open-mpi.org/community/lists/users/2016/04/29009.php</a>
        <br>
        <br>
        <br>
        <br>
                    _______________________________________________
        <br>
                    users mailing list
        <br>
                    <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
        <br>
                    Subscription:
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a>
        <br>
                    Link to this post:
        <br>
                   
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/04/29033.php">http://www.open-mpi.org/community/lists/users/2016/04/29033.php</a>
        <br>
        <br>
        <br>
        <br>
        <br>
                _______________________________________________
        <br>
                users mailing list
        <br>
                <a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
        <br>
                Subscription:
        <a class="moz-txt-link-freetext" href="https://www.open-mpi.org/mailman/listinfo.cgi/users">https://www.open-mpi.org/mailman/listinfo.cgi/users</a>
        <br>
                Link to this post:
        <br>
               
        <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/04/29038.php">http://www.open-mpi.org/community/lists/users/2016/04/29038.php</a>
        <br>
      </blockquote>
      <br>
      <fieldset class="mimeAttachmentHeader"></fieldset>
      <br>
      <pre wrap="">_______________________________________________
users mailing list
<a class="moz-txt-link-abbreviated" href="mailto:users@open-mpi.org">users@open-mpi.org</a>
Subscription: <a class="moz-txt-link-freetext" href="https://www.open-mpi.org/mailman/listinfo.cgi/users">https://www.open-mpi.org/mailman/listinfo.cgi/users</a>
Link to this post: <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/users/2016/04/29041.php">http://www.open-mpi.org/community/lists/users/2016/04/29041.php</a></pre>
    </blockquote>
    <br>
  </body>
</html>

