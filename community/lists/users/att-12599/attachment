Thanks, <div>now i get mixed results and everything seems to be working ok with mixed mpi xecution</div><div><br></div><div>is it normal that after receiving the results, the hosts remain busy like 15 seconds ??</div><div>

example</div><div><div>master:common master$ qrsh -verbose -pe orte 10 /opt/openmpi-1.4.1/bin/mpirun -np 10 hostname</div><div>Your job 65 (&quot;mpirun&quot;) has been submitted</div><div>waiting for interactive job to be scheduled ...</div>

<div>Your interactive job 65 has been successfully scheduled.</div><div>Establishing builtin session to host worker00.local ...</div><div>worker00.local</div><div>worker00.local</div><div>worker00.local</div><div>worker00.local</div>

<div>worker00.local</div><div>master.local</div><div>master.local</div><div>master.local</div><div>master.local</div><div>master.local</div><div><span class="Apple-style-span" style="font-weight: bold;">#after some seconds, i query the hosts status and slots are still used</span></div>

<div>master:common master$ qstat -f</div><div>queuename                      qtype resv/used/tot. load_avg arch          states</div><div>---------------------------------------------------------------------------------</div>

<div>all.q@master.local             BIP   0/5/16         0.02     darwin-x86    </div><div>     65 0.55500 mpirun     master       r     04/09/2010 17:44:36     5        </div><div>---------------------------------------------------------------------------------</div>

<div>all.q@worker00.local           BIP   0/5/16         0.01     darwin-x86    </div><div>     65 0.55500 mpirun     master       r     04/09/2010 17:44:36     5        </div><div>master:common master$ </div><div><br></div>

<div><span class="Apple-style-span" style="font-weight: bold;">but after waiting more time, they get free again</span></div><div>master:common master$ qstat -f<div>queuename                      qtype resv/used/tot. load_avg arch          states</div>

<div>---------------------------------------------------------------------------------</div><div>all.q@master.local             BIP   0/0/16         0.01     darwin-x86    </div><div>---------------------------------------------------------------------------------</div>

all.q@worker00.local           BIP   0/0/16         0.01     darwin-x86 </div><div><span class="Apple-style-span" style="font-weight: bold;"><br></span></div><div><span class="Apple-style-span" style="font-weight: bold;">anyways these are just details, thanks to your help the important aspects are working.</span></div>

</div><div>Cristobal<br><br><br>
<br><br><div class="gmail_quote">On Fri, Apr 9, 2010 at 1:34 PM, Reuti <span dir="ltr">&lt;<a href="mailto:reuti@staff.uni-marburg.de">reuti@staff.uni-marburg.de</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;">

Am 09.04.2010 um 18:57 schrieb Cristobal Navarro:<br>
<div class="im"><br>
&gt; sorry the command was missing a number<br>
&gt;<br>
&gt; as you said it should be<br>
&gt;<br>
&gt; qrsh -verbose -pe pempi 6 mpirun -np 6 hostname<br>
&gt; waiting for interactive job to be scheduled ...<br>
&gt;<br>
&gt; Your &quot;qrsh&quot; request could not be scheduled, try again later.<br>
&gt; ---<br>
&gt; this is my parallel enviroment<br>
&gt; qconf -sp pempi<br>
&gt; pe_name            pempi<br>
&gt; slots              210<br>
&gt; user_lists         NONE<br>
&gt; xuser_lists        NONE<br>
&gt; start_proc_args    /usr/bin/true<br>
&gt; stop_proc_args     /usr/bin/true<br>
&gt; allocation_rule    $pe_slots<br>
<br>
</div>$pe_slots means that all slots must come from one and the same machine (e.g. for smp jobs). You can try $round_robin.<br>
<font color="#888888"><br>
-- Reuti<br>
</font><div><div></div><div class="h5"><br>
<br>
&gt; control_slaves     TRUE<br>
&gt; job_is_first_task  FALSE<br>
&gt; urgency_slots      min<br>
&gt; accounting_summary TRUE<br>
&gt;<br>
&gt; this is the queue<br>
&gt; qconf -sq cola.q<br>
&gt; qname                 cola.q<br>
&gt; hostlist              @allhosts<br>
&gt; seq_no                0<br>
&gt; load_thresholds       np_load_avg=1.75<br>
&gt; suspend_thresholds    NONE<br>
&gt; nsuspend              1<br>
&gt; suspend_interval      00:05:00<br>
&gt; priority              0<br>
&gt; min_cpu_interval      00:05:00<br>
&gt; processors            UNDEFINED<br>
&gt; qtype                 BATCH INTERACTIVE<br>
&gt; ckpt_list             NONE<br>
&gt; pe_list               make pempi<br>
&gt; rerun                 FALSE<br>
&gt; slots                 2<br>
&gt; tmpdir                /tmp<br>
&gt; shell                 /bin/csh<br>
&gt;<br>
&gt; i noticed that if i put 2 slots (since the queue has 2 slots) on the -pe pempi N   argument and also the full path to mpirun as you guys pointed, it works!!!<br>
&gt; cristobal@neoideo:~$ qrsh -verbose -pe pempi 2 /opt/openmpi-1.4.1/bin/mpirun -np 6 hostname<br>
&gt; Your job 125 (&quot;mpirun&quot;) has been submitted<br>
&gt; waiting for interactive job to be scheduled ...<br>
&gt; Your interactive job 125 has been successfully scheduled.<br>
&gt; Establishing builtin session to host ijorge.local ...<br>
&gt; ijorge.local<br>
&gt; ijorge.local<br>
&gt; ijorge.local<br>
&gt; ijorge.local<br>
&gt; ijorge.local<br>
&gt; ijorge.local<br>
&gt; cristobal@neoideo:~$ qrsh -verbose -pe pempi 2 /opt/openmpi-1.4.1/bin/mpirun -np 6 hostname<br>
&gt; Your job 126 (&quot;mpirun&quot;) has been submitted<br>
&gt; waiting for interactive job to be scheduled ...<br>
&gt; Your interactive job 126 has been successfully scheduled.<br>
&gt; Establishing builtin session to host neoideo ...<br>
&gt; neoideo<br>
&gt; neoideo<br>
&gt; neoideo<br>
&gt; neoideo<br>
&gt; neoideo<br>
&gt; neoideo<br>
&gt; cristobal@neoideo:~$<br>
&gt;<br>
&gt; i just wonder why i didnt get mixed hostnames? like<br>
&gt; neoideo<br>
&gt; neoideo<br>
&gt; ijorge.local<br>
&gt; ijorge.local<br>
&gt; neoideo<br>
&gt; ijorge.local<br>
&gt;<br>
&gt; ??<br>
&gt;<br>
&gt; thanks for the help already!!!<br>
&gt;<br>
&gt; Cristobal<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; On Fri, Apr 9, 2010 at 8:58 AM, Huynh Thuc Cuoc &lt;<a href="mailto:htcuoc@gmail.com">htcuoc@gmail.com</a>&gt; wrote:<br>
&gt; Dear friend,<br>
&gt; 1.<br>
&gt; I prefer to use sge qsub cmd, for examples:<br>
&gt;<br>
&gt; [huong@ioitg2 MyPhylo]$ qsub -pe orte 3 myphylo.qsub<br>
&gt; Your job 35 (&quot;myphylo.qsub&quot;) has been submitted<br>
&gt; [huong@ioitg2 MyPhylo]$ qstat<br>
&gt; job-ID  prior   name       user         state submit/start at     queue                          slots ja-task-ID<br>
&gt; -----------------------------------------------------------------------------------------------------------------<br>
&gt;      35 0.55500 myphylo.qs huong        r     04/09/2010 19:28:59 <a href="mailto:all.q@node2.ioit-grid.ac.vn">all.q@node2.ioit-grid.ac.vn</a>        3<br>
&gt; [huong@ioitg2 MyPhylo]$ qstat<br>
&gt; [huong@ioitg2 MyPhylo]$<br>
&gt;<br>
&gt; This job is running on node2 of my cluster.<br>
&gt; My softs as following:<br>
&gt; headnode: 4 CPUs. $GRAM, CentOS 5.4 + sge 6.2u4 (qmaster and also execd host) + openmpi 1.4.1<br>
&gt; nodes 4CPUs, 1GRAM, CentOS 5.4 + sgeexecd + openmpi1.4.1<br>
&gt; PE=orte and set to 4 slots.<br>
&gt; The app myphylo.qsub has the long cmd in the shell:<br>
&gt; /opt/openmpi/bin/mpirun -np 10 $HOME/MyPhylo/bin/par-phylo-builder --data . . . .<br>
&gt; Try to set PE as orte, use default PE = make instead.<br>
&gt;<br>
&gt; 2. I test your cmd on my sytem as:<br>
&gt; a.<br>
&gt; [huong@ioitg2 MyPhylo]$ qrsh -verbose -pe make mpirun -np 6 hostname<br>
&gt; error: Numerical value invalid!<br>
&gt; The initial portion of string &quot;mpirun&quot; contains no decimal number<br>
&gt; [huong@ioitg2 MyPhylo]$ qrsh -verbose -pe orte 2 mpirun -np 6 hostname<br>
&gt; Your job 36 (&quot;mpirun&quot;) has been submitted<br>
&gt;<br>
&gt; waiting for interactive job to be scheduled ...<br>
&gt; Your interactive job 36 has been successfully scheduled.<br>
&gt; Establishing builtin session to host <a href="http://ioitg2.ioit-grid.ac.vn" target="_blank">ioitg2.ioit-grid.ac.vn</a> ...<br>
&gt; bash: mpirun: command not found<br>
&gt; [huong@ioitg2 MyPhylo]$<br>
&gt;<br>
&gt; ERROR ! So I try:<br>
&gt; [huong@ioitg2 MyPhylo]$ qrsh -verbose -pe orte 2 /opt/openmpi/bin/mpirun -np 6 hostname<br>
&gt; Your job 38 (&quot;mpirun&quot;) has been submitted<br>
&gt;<br>
&gt; waiting for interactive job to be scheduled ...<br>
&gt; Your interactive job 38 has been successfully scheduled.<br>
&gt; Establishing builtin session to host <a href="http://ioitg2.ioit-grid.ac.vn" target="_blank">ioitg2.ioit-grid.ac.vn</a> ...<br>
&gt; <a href="http://ioitg2.ioit-grid.ac.vn" target="_blank">ioitg2.ioit-grid.ac.vn</a><br>
&gt; <a href="http://ioitg2.ioit-grid.ac.vn" target="_blank">ioitg2.ioit-grid.ac.vn</a><br>
&gt; <a href="http://ioitg2.ioit-grid.ac.vn" target="_blank">ioitg2.ioit-grid.ac.vn</a><br>
&gt; <a href="http://ioitg2.ioit-grid.ac.vn" target="_blank">ioitg2.ioit-grid.ac.vn</a><br>
&gt; <a href="http://ioitg2.ioit-grid.ac.vn" target="_blank">ioitg2.ioit-grid.ac.vn</a><br>
&gt; <a href="http://ioitg2.ioit-grid.ac.vn" target="_blank">ioitg2.ioit-grid.ac.vn</a><br>
&gt; [huong@ioitg2 MyPhylo]$<br>
&gt;<br>
&gt; This OK.<br>
&gt; What is: the PATH points to where mpirun is located.<br>
&gt;<br>
&gt; TRY.<br>
&gt;<br>
&gt; Good chance<br>
&gt; HT Cuoc<br>
&gt;<br>
&gt;<br>
&gt; On Fri, Apr 9, 2010 at 11:02 AM, Cristobal Navarro &lt;<a href="mailto:axischire@gmail.com">axischire@gmail.com</a>&gt; wrote:<br>
&gt; Hello,<br>
&gt;<br>
&gt; after some days of work and testing, i managed to install SGE on two machines, also installed openMPI 1.4.1 for each one.<br>
&gt;<br>
&gt; SGE is working, i can submit jobs and it schedules the jobs to the available cores total of 6,<br>
&gt;<br>
&gt; my problem is that im trying to run an openMPI job and i cant.<br>
&gt;<br>
&gt; this is an example of what i am trying.<br>
&gt;<br>
&gt;<br>
&gt; $qrsh -verbose -pe pempi mpirun -np 6 hostname<br>
&gt; Your job 105 (&quot;mpirun&quot;) has been submitted<br>
&gt; waiting for interactive job to be scheduled ...<br>
&gt;<br>
&gt; Your &quot;qrsh&quot; request could not be scheduled, try again later.<br>
&gt;<br>
&gt; im not sure what this can be,<br>
&gt; in the ompi_info i have gridengine support.<br>
&gt;<br>
&gt; where do you recommend to look ??<br>
&gt; thanks in advance<br>
&gt;<br>
&gt; Cristobal<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt;<br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
<br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</div></div></blockquote></div><br></div>

