<html><head><meta http-equiv="Content-Type" content="text/html charset=utf-8"></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;" class="">You can also get info specifically on the openib params by:<div class=""><br class=""></div><div class="">ompi_info —param btl openib —level 9</div><div class=""><br class=""></div><div class="">Your error indicates that udcm may not be enabled on your infiniband network, and I don’t see it listed in your IB modules - we require it for use of the opneib btl.</div><div class=""><br class=""></div><div class="">Ralph</div><div class=""><br class=""><div><blockquote type="cite" class=""><div class="">On Oct 2, 2015, at 2:49 PM, Surivinta Surivinta &lt;<a href="mailto:surivinta@gmail.com" class="">surivinta@gmail.com</a>&gt; wrote:</div><br class="Apple-interchange-newline"><div class=""><div dir="ltr" class=""><div class="">Maybe here you found what need:<br class=""><a href="https://www.open-mpi.org/faq/?category=tuning#setting-mca-params" class="">https://www.open-mpi.org/faq/?category=tuning#setting-mca-params</a><br class="">also&nbsp; you can try run gdb via mpirun to get debug info:<br class=""></div><div class="">mpirun -np 2 xterm -e gdb ./your_program<br class=""></div><div class=""><br class=""></div></div><div class="gmail_extra"><br class=""><div class="gmail_quote">2015-09-28 14:43 GMT+03:00 Sven Schumacher <span dir="ltr" class="">&lt;<a href="mailto:schumacher@tfd.uni-hannover.de" target="_blank" class="">schumacher@tfd.uni-hannover.de</a>&gt;</span>:<br class=""><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Hello,<br class="">
<br class="">
I've set up our new cluster using Infiniband using a combination of:<br class="">
Debian, Torque/Maui, BeeGeeFS (formerly FHGFS)<br class="">
<br class="">
Every node has two infiniband-ports, both of them having an IP-Adress.<br class="">
One port shall be used for BeeGeeFS (which is working well) and the<br class="">
other one for MPI-Communication.<br class="">
<br class="">
I'm using openmpi in version 1.8.5, compiled with gcc/gfortran 4.9.2 and<br class="">
ibverbs support.<br class="">
Configure command was the following:<br class="">
<br class="">
Output of "ompi_info --parsable&nbsp; -a -c" is attached as txt-file (all<br class="">
nodes are configured the same)<br class="">
<br class="">
<br class="">
The following infiniband-related kernel-modules are loaded:<br class="">
&gt; mlx4_core&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;206165&nbsp; 1 mlx4_ib<br class="">
&gt; rdma_ucm&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;22055&nbsp; 0<br class="">
&gt; ib_uverbs&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 44693&nbsp; 1 rdma_ucm<br class="">
&gt; rdma_cm&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 39518&nbsp; 2 ib_iser,rdma_ucm<br class="">
&gt; iw_cm&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 31011&nbsp; 1 rdma_cm<br class="">
&gt; ib_umad&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 17311&nbsp; 0<br class="">
&gt; mlx4_ib&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;136293&nbsp; 0<br class="">
&gt; ib_cm&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 39055&nbsp; 3 rdma_cm,ib_srp,ib_ipoib<br class="">
&gt; ib_sa&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 26986&nbsp; 6<br class="">
&gt; rdma_cm,ib_cm,mlx4_ib,ib_srp,rdma_ucm,ib_ipoib<br class="">
&gt; ib_mad&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;39969&nbsp; 4 ib_cm,ib_sa,mlx4_ib,ib_umad<br class="">
&gt; ib_core&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 68904&nbsp; 12<br class="">
&gt; rdma_cm,ib_cm,ib_sa,iw_cm,mlx4_ib,ib_mad,ib_srp,ib_iser,ib_umad,ib_uverbs,rdma_ucm,ib_ipoib<br class="">
&gt; ib_addr&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 17148&nbsp; 3 rdma_cm,ib_core,rdma_ucm<br class="">
&gt; ib_iser&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 44204&nbsp; 0<br class="">
&gt; iscsi_tcp&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 17580&nbsp; 0<br class="">
&gt; libiscsi_tcp&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;21554&nbsp; 1 iscsi_tcp<br class="">
&gt; libiscsi&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;48004&nbsp; 3 libiscsi_tcp,iscsi_tcp,ib_iser<br class="">
&gt; scsi_transport_iscsi&nbsp; &nbsp; 77478&nbsp; 4 iscsi_tcp,ib_iser,libiscsi<br class="">
&gt; ib_ipoib&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;85167&nbsp; 0<br class="">
&gt; ib_srp&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;39710&nbsp; 0<br class="">
&gt; scsi_transport_srp&nbsp; &nbsp; &nbsp;18194&nbsp; 1 ib_srp<br class="">
&gt; scsi_tgt&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;17698&nbsp; 1 scsi_transport_srp<br class="">
<br class="">
When using mpiexec to execute a job running on a single node using 8<br class="">
cores everything works fine, but when mpiexec has to start a second<br class="">
process on another node it doesn't start that process.<br class="">
What I already did:<br class="">
<br class="">
Testing ssh-logins: Works (without a password using ssh-keys).<br class="">
Testing name-resolution: works<br class="">
<br class="">
Used a "hello Word"-mpi-Program:<br class="">
&gt; #include &lt;mpi.h&gt;<br class="">
&gt; #include &lt;stdio.h&gt;<br class="">
&gt;<br class="">
&gt; int main(int argc, char** argv) {<br class="">
&gt;&nbsp; &nbsp; &nbsp;// Initialize the MPI environment<br class="">
&gt;&nbsp; &nbsp; &nbsp;MPI_Init(NULL, NULL);<br class="">
&gt;<br class="">
&gt;&nbsp; &nbsp; &nbsp;// Get the number of processes<br class="">
&gt;&nbsp; &nbsp; &nbsp;int world_size;<br class="">
&gt;&nbsp; &nbsp; &nbsp;MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size);<br class="">
&gt;<br class="">
&gt;&nbsp; &nbsp; &nbsp;// Get the rank of the process<br class="">
&gt;&nbsp; &nbsp; &nbsp;int world_rank;<br class="">
&gt;&nbsp; &nbsp; &nbsp;MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank);<br class="">
&gt;<br class="">
&gt;&nbsp; &nbsp; &nbsp;// Get the name of the processor<br class="">
&gt;&nbsp; &nbsp; &nbsp;char processor_name[MPI_MAX_PROCESSOR_NAME];<br class="">
&gt;&nbsp; &nbsp; &nbsp;int name_len;<br class="">
&gt;&nbsp; &nbsp; &nbsp;MPI_Get_processor_name(processor_name, &amp;name_len);<br class="">
&gt;<br class="">
&gt;&nbsp; &nbsp; &nbsp;// Print off a hello world message<br class="">
&gt;&nbsp; &nbsp; &nbsp;printf("Hello world from processor %s, rank %d"<br class="">
&gt;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; " out of %d processors\n",<br class="">
&gt;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; processor_name, world_rank, world_size);<br class="">
&gt;<br class="">
&gt;&nbsp; &nbsp; &nbsp;// Finalize the MPI environment.<br class="">
&gt;&nbsp; &nbsp; &nbsp;MPI_Finalize();<br class="">
&gt; }<br class="">
<br class="">
<br class="">
This throws an error (on a single node it produces the following error<br class="">
messages, but doesn't produce any output , when run on two nodes):<br class="">
&gt; [hydra001:20324] 1 more process has sent help message<br class="">
&gt; help-mpi-btl-openib-cpc-base.txt / no cpcs for port<br class="">
&gt; [hydra001:20324] Set MCA parameter "orte_base_help_aggregate" to 0 to<br class="">
&gt; see all help / error messages<br class="">
<br class="">
&gt; --------------------------------------------------------------------------<br class="">
&gt; No OpenFabrics connection schemes reported that they were able to be<br class="">
&gt; used on a specific port.&nbsp; As such, the openib BTL (OpenFabrics<br class="">
&gt; support) will be disabled for this port.<br class="">
&gt;<br class="">
&gt;&nbsp; &nbsp;Local host:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;hydra001<br class="">
&gt;&nbsp; &nbsp;Local device:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mlx4_0<br class="">
&gt;&nbsp; &nbsp;Local port:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1<br class="">
&gt;&nbsp; &nbsp;CPCs attempted:&nbsp; &nbsp; &nbsp; &nbsp;udcm<br class="">
&gt; --------------------------------------------------------------------------<br class="">
&gt; Hello world from processor hydra001, rank 0 out of 1 processors<br class="">
<br class="">
So, where can I find a documented list of all these MCA parameters? It<br class="">
doesn't seem there is such a list on <a href="http://open-mpi.org/" rel="noreferrer" target="_blank" class="">open-mpi.org</a> or I didn't find it...<br class="">
so thanks in advance for directing me to right place<br class="">
<span class="HOEnZb"><font color="#888888" class=""><br class="">
Sven Schumacher<br class="">
<br class="">
<br class="">
<br class="">
<br class="">
<br class="">
<br class="">
--<br class="">
Sven Schumacher - Systemadministrator Tel: (0511)762-2753<br class="">
Leibniz Universitaet Hannover<br class="">
Institut für Turbomaschinen und Fluid-Dynamik&nbsp; &nbsp; &nbsp; &nbsp;- TFD<br class="">
Appelstraße 9 - 30167 Hannover<br class="">
Institut für Kraftwerkstechnik und Wärmeübertragung - IKW<br class="">
Callinstraße 36 - 30167 Hannover<br class="">
<br class="">
</font></span><br class="">_______________________________________________<br class="">
users mailing list<br class="">
<a href="mailto:users@open-mpi.org" class="">users@open-mpi.org</a><br class="">
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br class="">
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2015/09/27695.php" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/community/lists/users/2015/09/27695.php</a><br class=""></blockquote></div><br class=""><br clear="all" class=""><br class="">-- <br class=""><div class="gmail_signature"><div dir="ltr" class="">-- <br class="">С уважением.</div></div>
</div>
_______________________________________________<br class="">users mailing list<br class=""><a href="mailto:users@open-mpi.org" class="">users@open-mpi.org</a><br class="">Subscription: http://www.open-mpi.org/mailman/listinfo.cgi/users<br class="">Link to this post: http://www.open-mpi.org/community/lists/users/2015/10/27773.php</div></blockquote></div><br class=""></div></body></html>
