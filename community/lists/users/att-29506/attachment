Thanks for the info, I updated <a href="https://github.com/open-mpi/ompi/issues/1809">https://github.com/open-mpi/ompi/issues/1809</a> accordingly.<div><br></div><div>fwiw, the bug occurs when addresses do not fit in 32 bits.</div><div>for some reasons, I always run into it on OSX but not on Linux, ubless I use dmalloc.</div><div>I replaced malloc with alloca (and remove free) so I always hit the bug on Linux.</div><div><br></div><div>Cheers,</div><div><br></div><div>Gilles</div><div><br>On Wednesday, June 22, 2016, Nicolas Joly &lt;<a href="mailto:njoly@pasteur.fr">njoly@pasteur.fr</a>&gt; wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">On Wed, Jun 22, 2016 at 11:58:25AM +0900, Gilles Gouaillardet wrote:<br>
&gt; Nicolas,<br>
&gt;<br>
&gt; can you please give the attached patch a try ?<br>
&gt;<br>
&gt; in my environment, it fixes your test case.<br>
<br>
Yes ! It does here too ...<br>
<br>
Just patched ADIOI_NFS_WriteStrided() using the same fix. And the<br>
original tool that crashed first on read, and later on write with<br>
MPI_BOTTOM now succeed.<br>
<br>
&gt; based on previous tests posted here, it is likely a similar bug should<br>
&gt; be fixed for other filesystems.<br>
<br>
Thanks a lot.<br>
<br>
&gt; Gilles<br>
&gt;<br>
&gt;<br>
&gt; On 6/15/2016 12:42 AM, Nicolas Joly wrote:<br>
&gt; &gt;Hi,<br>
&gt; &gt;<br>
&gt; &gt;At work, i do have some mpi codes that make use of custom datatypes to<br>
&gt; &gt;call MPI_File_read with MPI_BOTTOM ... It mostly works, except when<br>
&gt; &gt;the underlying filesystem is NFS where if crash with SIGSEGV.<br>
&gt; &gt;<br>
&gt; &gt;The attached sample (code + data) works just fine with 1.10.1 on my<br>
&gt; &gt;NetBSD/amd64 workstation using the UFS romio backend, but crash if<br>
&gt; &gt;switched to NFS :<br>
&gt; &gt;<br>
&gt; &gt;njoly@issan [~]&gt; mpirun --version<br>
&gt; &gt;mpirun (Open MPI) 1.10.1<br>
&gt; &gt;njoly@issan [~]&gt; mpicc -g -Wall -o sample sample.c<br>
&gt; &gt;njoly@issan [~]&gt; mpirun -n 2 ./sample ufs:data.txt<br>
&gt; &gt;rank1 ... 111111111133333333335555555555<br>
&gt; &gt;rank0 ... 000000000022222222224444444444<br>
&gt; &gt;njoly@issan [~]&gt; mpirun -n 2 ./sample nfs:data.txt<br>
&gt; &gt;[issan:20563] *** Process received signal ***<br>
&gt; &gt;[issan:08879] *** Process received signal ***<br>
&gt; &gt;[issan:20563] Signal: Segmentation fault (11)<br>
&gt; &gt;[issan:20563] Signal code: Address not mapped (1)<br>
&gt; &gt;[issan:20563] Failing at address: 0xffffffffb1309240<br>
&gt; &gt;[issan:08879] Signal: Segmentation fault (11)<br>
&gt; &gt;[issan:08879] Signal code: Address not mapped (1)<br>
&gt; &gt;[issan:08879] Failing at address: 0xffffffff881b0420<br>
&gt; &gt;[issan:08879] [ 0] [issan:20563] [ 0] 0x7dafb14a52b0<br>
&gt; &gt;&lt;__sigtramp_siginfo_2&gt; at /usr/lib/libc.so.12<br>
&gt; &gt;[issan:20563] *** End of error message ***<br>
&gt; &gt;0x78b9886a52b0 &lt;__sigtramp_siginfo_2&gt; at /usr/lib/libc.so.12<br>
&gt; &gt;[issan:08879] *** End of error message ***<br>
&gt; &gt;--------------------------------------------------------------------------<br>
&gt; &gt;mpirun noticed that process rank 0 with PID 20563 on node issan exited on<br>
&gt; &gt;signal 11 (Segmentation fault).<br>
&gt; &gt;--------------------------------------------------------------------------<br>
&gt; &gt;njoly@issan [~]&gt; gdb sample sample.core<br>
&gt; &gt;GNU gdb (GDB) 7.10.1<br>
&gt; &gt;[...]<br>
&gt; &gt;Core was generated by `sample&#39;.<br>
&gt; &gt;Program terminated with signal SIGSEGV, Segmentation fault.<br>
&gt; &gt;#0  0x000078b98871971f in memcpy () from /usr/lib/libc.so.12<br>
&gt; &gt;[Current thread is 1 (LWP 1)]<br>
&gt; &gt;(gdb) bt<br>
&gt; &gt;#0  0x000078b98871971f in memcpy () from /usr/lib/libc.so.12<br>
&gt; &gt;#1  0x000078b974010edf in ADIOI_NFS_ReadStrided () from<br>
&gt; &gt;/usr/pkg/lib/openmpi/mca_io_romio.so<br>
&gt; &gt;#2  0x000078b97400bacf in MPIOI_File_read () from<br>
&gt; &gt;/usr/pkg/lib/openmpi/mca_io_romio.so<br>
&gt; &gt;#3  0x000078b97400bc72 in mca_io_romio_dist_MPI_File_read () from<br>
&gt; &gt;/usr/pkg/lib/openmpi/mca_io_romio.so<br>
&gt; &gt;#4  0x000078b988e72b38 in PMPI_File_read () from /usr/pkg/lib/libmpi.so.12<br>
&gt; &gt;#5  0x00000000004013a4 in main (argc=2, argv=0x7f7fff7b0f00) at sample.c:63<br>
&gt; &gt;<br>
&gt; &gt;Thanks.<br>
&gt; &gt;<br>
&gt; &gt;<br>
&gt; &gt;<br>
&gt; &gt;_______________________________________________<br>
&gt; &gt;users mailing list<br>
&gt; &gt;<a href="javascript:;" onclick="_e(event, &#39;cvml&#39;, &#39;users@open-mpi.org&#39;)">users@open-mpi.org</a><br>
&gt; &gt;Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">https://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; &gt;Link to this post:<br>
&gt; &gt;<a href="http://www.open-mpi.org/community/lists/users/2016/06/29434.php" target="_blank">http://www.open-mpi.org/community/lists/users/2016/06/29434.php</a><br>
&gt;<br>
<br>
&gt; diff --git a/ompi/mca/io/romio/romio/adio/ad_nfs/ad_nfs_read.c b/ompi/mca/io/romio/romio/adio/ad_nfs/ad_nfs_read.c<br>
&gt; index 16f3a4d..2577f13 100644<br>
&gt; --- a/ompi/mca/io/romio/romio/adio/ad_nfs/ad_nfs_read.c<br>
&gt; +++ b/ompi/mca/io/romio/romio/adio/ad_nfs/ad_nfs_read.c<br>
&gt; @@ -457,13 +457,14 @@ void ADIOI_NFS_ReadStrided(ADIO_File fd, void *buf, int count,<br>
&gt;       }<br>
&gt;       else {<br>
&gt;  /* noncontiguous in memory as well as in file */<br>
&gt; +            ADIO_Offset i;<br>
&gt;<br>
&gt;           ADIOI_Flatten_datatype(datatype);<br>
&gt;           flat_buf = ADIOI_Flatlist;<br>
&gt;           while (flat_buf-&gt;type != datatype) flat_buf = flat_buf-&gt;next;<br>
&gt;<br>
&gt;           k = num = buf_count = 0;<br>
&gt; -         i = (int) (flat_buf-&gt;indices[0]);<br>
&gt; +         i = flat_buf-&gt;indices[0];<br>
&gt;           j = st_index;<br>
&gt;           off = offset;<br>
&gt;           n_filetypes = st_n_filetypes;<br>
&gt; @@ -508,8 +509,8 @@ void ADIOI_NFS_ReadStrided(ADIO_File fd, void *buf, int count,<br>
&gt;<br>
&gt;                   k = (k + 1)%flat_buf-&gt;count;<br>
&gt;                   buf_count++;<br>
&gt; -                 i = (int) (buftype_extent*(buf_count/flat_buf-&gt;count) +<br>
&gt; -                     flat_buf-&gt;indices[k]);<br>
&gt; +                 i = buftype_extent*(buf_count/flat_buf-&gt;count) +<br>
&gt; +                     flat_buf-&gt;indices[k];<br>
&gt;                   new_brd_size = flat_buf-&gt;blocklens[k];<br>
&gt;                   if (size != frd_size) {<br>
&gt;                       off += size;<br>
<br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="javascript:;" onclick="_e(event, &#39;cvml&#39;, &#39;users@open-mpi.org&#39;)">users@open-mpi.org</a><br>
&gt; Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">https://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2016/06/29494.php" target="_blank">http://www.open-mpi.org/community/lists/users/2016/06/29494.php</a><br>
<br>
--<br>
Nicolas Joly<br>
<br>
Cluster &amp; Computing Group<br>
Biology IT Center<br>
Institut Pasteur, Paris.<br>
_______________________________________________<br>
users mailing list<br>
<a href="javascript:;" onclick="_e(event, &#39;cvml&#39;, &#39;users@open-mpi.org&#39;)">users@open-mpi.org</a><br>
Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">https://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2016/06/29504.php" target="_blank">http://www.open-mpi.org/community/lists/users/2016/06/29504.php</a><br>
</blockquote></div>

