<html>
  <head>

    <meta http-equiv="content-type" content="text/html; charset=utf-8">
  </head>
  <body text="#000000" bgcolor="#FFFFFF">
    Hello,<br>
    <br>
    I noticed when performing a profiling of an application that the
    MPI_init() function takes a considerable amount of time. <br>
    There is a big difference when running 32 processes over 32 machines
    and 32 processes over 8 machines (Each machine has 8 cores).<br>
    These are the results of the profiling:<br>
    <br>
    <br>
    Results for 32 cores (8 machines)<br>
    <br>
               Group.1 percent        usec<br>
    38            SSOR 79.1125 2557445.625<br>
    7       EXCHANGE_1 31.8125      33.250<br>
    24      MPI_Recv() 26.0750      33.375<br>
    2             BLTS 24.7500     103.125<br>
    3             BUTS 22.2375      92.500<br>
    12       INIT_COMM 19.8500 1311003.375<br>
    <b>22      MPI_Init() 19.8500 1310925.750</b><br>
    33             RHS 18.4000    4690.500<br>
    8       EXCHANGE_3  9.2750    1179.000<br>
    26      MPI_Wait()  7.2250     565.125<br>
    13           JACLD  6.4875      27.000<br>
    25      MPI_Send()  6.3500       8.000<br>
    14            JACU  6.2500      26.000<br>
    37           SETIV  0.6625   20908.500<br>
    6            EXACT  0.2188       0.000<br>
    4             ERHS  0.2000   11499.000<br>
    <br>
    Results for 32 machines<br>
    <br>
               Group.1  percent         usec<br>
    38            SSOR 97.28889 2573471.0000<br>
    7       EXCHANGE_1 39.25556      33.3333<br>
    2             BLTS 29.11111      98.7778<br>
    3             BUTS 27.96667      95.0000<br>
    24      MPI_Recv() 27.48889      28.7778<br>
    33             RHS 23.98889    5018.6667<br>
    25      MPI_Send() 13.51111      14.0000<br>
    8       EXCHANGE_3 13.06667    1361.1111<br>
    26      MPI_Wait()  9.37778     599.0000<br>
    13           JACLD  7.72222      26.0000<br>
    14            JACU  7.37778      25.0000<br>
    12       INIT_COMM  1.46667   76713.6667<br>
    <b>22      MPI_Init()  1.45556   76253.4444</b><br>
    37           SETIV  0.80000   20914.0000<br>
    6            EXACT  0.25000       0.0000<br>
    4             ERHS  0.21111   10458.3333<br>
    <br>
    The function MPI_init() in the first case (4 processes per machine)
    was 17 times slower than the second case (1 process per machine). Is
    this behaviour normal? <br>
    The command I used for running the application was:<br>
    <br>
    First case:<br>
    <br>
    mpirun  --machinefile machine_file -npernode 4 --mca btl
    self,sm,tcp  lu.A.32<br>
    <br>
    Second case:<br>
    <br>
    mpirun  --machinefile machine_file  --mca btl self,sm,tcp  lu.A.32<br>
    <br>
    I used the version of mpi: <br>
    <br>
    mpirun --V<br>
    mpirun (Open MPI) 1.4.5<br>
    <br>
    and the system I used is the following:<br>
    <br>
    Linux kameleon-debian 3.2.0-4-amd64 #1 SMP Debian 3.2.65-1+deb7u2
    x86_64 GNU/Linux<br>
    <br>
    I will appreciate any feedback, thank you.<br>
    <br>
    <br>
  </body>
</html>

