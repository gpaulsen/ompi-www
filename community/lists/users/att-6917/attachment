<div dir="ltr"><br><br><div class="gmail_quote">On Thu, Oct 9, 2008 at 2:39 AM, Brian Dobbins <span dir="ltr">&lt;<a href="mailto:bdobbins@gmail.com">bdobbins@gmail.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
<div dir="ltr"><br>Hi guys,<br><br>[From Eugene Loh:]<br><div class="gmail_quote"><div class="Ih2E3d"><blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
<div><div>
<blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">OpenMPI - 25 m 39 s.<br>
MPICH2 &nbsp;- &nbsp;15 m 53 s.<br>
</blockquote>
</div></div></blockquote></div><div><blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">With
regards to your issue, do you have any indication when you get that
25m39s timing if there is a grotesque amount of time being spent in MPI
calls? &nbsp;Or, is the slowdown due to non-MPI portions?</blockquote><br>&nbsp; Just to add my two cents: if this job <i>can</i> be run on less than 8 processors (ideally, even on just 1), then I&#39;d recommend doing so.&nbsp; That is, run it with OpenMPI and with MPICH2 on 1, 2 and 4 processors as well.&nbsp; If the single-processor jobs still give vastly different timings, then perhaps Eugene is on the right track and it comes down to various computational optimizations and not so much the message-passing that&#39;s make a difference.&nbsp; Timings from 2 and 4 process runs might be interesting as well to see how this difference changes with process counts.<br>

<br>&nbsp; I&#39;ve seen differences between various MPI libraries before, but nothing quite this severe either.&nbsp; If I get the time, maybe I&#39;ll try to set up Gromacs tonight -- I&#39;ve got both MPICH2 and OpenMPI installed here and can try to duplicate the runs.&nbsp;&nbsp; Sangamesh, is this a standard benchmark case that anyone can download and run?</div>
</div></div></blockquote><div>Yes.<br><a href="ftp://ftp.gromacs.org/pub/benchmarks/gmxbench-3.0.tar.gz">ftp://ftp.gromacs.org/pub/benchmarks/gmxbench-3.0.tar.gz</a><br>&nbsp;<br></div><blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
<div dir="ltr"><div class="gmail_quote"><div><br>
<br>&nbsp; Cheers,<br>&nbsp; - Brian<br><br><br>Brian Dobbins<br>Yale Engineering HPC</div></div><br></div>
<br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></div><br></div>

