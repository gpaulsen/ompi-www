<html><body><div style="color:#000; background-color:#fff; font-family:times new roman, new york, times, serif;font-size:12pt"><div><span>Hi,</span></div><div><br><span></span></div><div><span>The
 only example that works is hello_c.c. All others (that use MPI_Send and
 MPI_Recv)(connectivity_c.c and ring_c.c) block after the first MPI_Send
 / MPI_Recv (although the first Send/Receive pair works well for all 
processes, subsequent Send/Receive pairs block). My slurm version is 
2.1.0. It is also worth mentioning that all examples work when not using
 SLURM (launching with "mpirun -np 5 &lt;exaple_app&gt;"). Blocking 
occurs only when I try to run on multiple hosts with SLURM ("salloc -N5 
mpirun &lt;example_app&gt;").</span></div><div><br><span></span></div><div><span>Adrian</span></div><div><br></div>  <div style="font-family: times new roman, new york, times, serif; font-size: 12pt;"> <div style="font-family: times new roman, new york, times, serif; font-size: 12pt;"> <div dir="ltr"> <font size="2" face="Arial"> <hr size="1">  <b><span style="font-weight:bold;">From:</span></b> Jeff Squyres &lt;jsquyres@cisco.com&gt;<br> <b><span style="font-weight: bold;">To:</span></b> adrian sabou &lt;adrian.sabou@yahoo.com&gt;; Open MPI Users &lt;users@open-mpi.org&gt; <br> <b><span style="font-weight: bold;">Sent:</span></b> Wednesday, February 1, 2012 10:32 PM<br> <b><span style="font-weight: bold;">Subject:</span></b> Re: [OMPI users]  OpenMPI / SLURM -&gt; Send/Recv blocking<br> </font> </div> <br>
On Jan 31, 2012, at 11:16 AM, adrian sabou wrote:<br><br>&gt; Like I said, a very simple program.<br>&gt; When launching this application with SLURM (using "salloc -N2 mpirun ./&lt;my_app&gt;"), it hangs at the barrier.<br><br>Are you able to run the MPI example programs in examples/ ?<br><br>&gt; However, it passes the barrier if I launch it without SLURM (using "mpirun -np 2 ./&lt;my_app&gt;"). I first noticed this problem when my application hanged if I tried to send two successive messages from a process to another. Only the first MPI_Send would work. The second MPI_Send would block indefinitely. I was wondering whether any of you have encountered a similar problem, or may have an ideea as to what is causing the Send/Receive pair to block when using SLURM. The exact output in my console is as follows:<br>&gt;&nbsp; <br>&gt;&nbsp; &nbsp; &nbsp; &nbsp;  salloc: Granted job allocation 1138<br>&gt;&nbsp; &nbsp; &nbsp; &nbsp;  Process 0 -
 Sending...<br>&gt;&nbsp; &nbsp; &nbsp; &nbsp;  Process 1 - Receiving...<br>&gt;&nbsp; &nbsp; &nbsp; &nbsp;  Process 1 - Received.<br>&gt;&nbsp; &nbsp; &nbsp; &nbsp;  Process 1 - Barrier reached.<br>&gt;&nbsp; &nbsp; &nbsp; &nbsp;  Process 0 - Sent.<br>&gt;&nbsp; &nbsp; &nbsp; &nbsp;  Process 0 - Barrier reached.<br>&gt;&nbsp; &nbsp; &nbsp; &nbsp;  (it just hangs here)<br>&gt;&nbsp; <br>&gt; I am new to MPI programming and to OpenMPI and would greatly appreciate any help. My OpenMPI version is 1.4.4 (although I have also tried it on 1.5.4), my SLURM version is 0.3.3-1 (slurm-llnl 2.1.0-1),<br><br>I'm not sure what SLURM version that is -- my "srun --version" shows 2.2.4.&nbsp; 0.3.3 would be pretty ancient, no?<br><br>-- <br>Jeff Squyres<br><a ymailto="mailto:jsquyres@cisco.com" href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a><br>For corporate legal information go to:<br>http://www.cisco.com/web/about/doing_business/legal/cri/<br><br><br><br>
 </div> </div>  </div></body></html>
