<html><head><style type="text/css"><!-- DIV {margin:0px;} --></style></head><body><div style="font-family:times new roman,new york,times,serif;font-size:12pt"><div>Hi Jeff Squyres,<br>We have Dell powerconnect 2724 Gigabit switches to connect the nodes in our cluster.<br>As you said, may be the speed of PCI bus is a bottleneck.<br>How can check it in practical? <br>What is your suggestion for the problem?<br><br>Thank you!<br>Axida<br><br></div><div style="font-family: times new roman,new york,times,serif; font-size: 12pt;"><br><div style="font-family: arial,helvetica,sans-serif; font-size: 13px;"><font size="2" face="Tahoma"><hr size="1"><b><span style="font-weight: bold;">From:</span></b> Jeff Squyres &lt;jsquyres@cisco.com&gt;<br><b><span style="font-weight: bold;">To:</span></b> Open MPI Users &lt;users@open-mpi.org&gt;<br><b><span style="font-weight: bold;">Sent:</span></b> Tuesday, June 2, 2009 10:15:39 AM<br><b><span style="font-weight:
 bold;">Subject:</span></b> Re: [OMPI users] How to use Multiple links withOpenMPI??????????????????<br></font><br>
Note that striping doesn't really help you much until data sizes get large.&nbsp; For example, networks tend to have an elbow in the graph where the size of the message starts to matter (clearly evident on your graphs).<br><br>Additionally, you have your network marked as with "hubs" not "switches" -- if you really do have hubs and not switches, you may run into serious contention issues if you start loading up the network.<br><br>With both of these factors, even though you have 4 links, you likely aren't going to see much of a performance benefit until you send large messages (which will be limited by your bus speeds -- can you feed all 4 of your links from a single machine at line rate, or will you be limited by PCI bus speeds and contention?), and you may run into secondary performance issues due to contention on your hubs.<br><br><br>On May 28, 2009, at 11:06 PM, shan axida wrote:<br><br>&gt; Thank you! Mr. Jeff Squyres,<br>&gt; I have conducted a
 simple MPI_Bcast experiment in out cluster.<br>&gt; The results are shown in the file attached on this e-mail.<br>&gt; The hostfile is :<br>&gt; -----------------<br>&gt; hostname1 slots=4<br>&gt; hostname2 slots=4<br>&gt; hostname3 slots=4<br>&gt; ....<br>&gt; ....<br>&gt; hostname16 slots=4<br>&gt; -----------------<br>&gt; As we can see in the figure, it is little faster than single link<br>&gt; when we use 2,3,4 links between nodes.<br>&gt; My question is what would be the reason to make almost the same<br>&gt; performance when we use 2,3,4 links ?<br>&gt; <br>&gt; Thank you!<br>&gt; <br>&gt; Axida<br>&gt; <br>&gt; <br>&gt; <br>&gt; <br>&gt; From: Jeff Squyres &lt;<a ymailto="mailto:jsquyres@cisco.com" href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a>&gt;<br>&gt; To: Open MPI Users &lt;<a ymailto="mailto:users@open-mpi.org" href="mailto:users@open-mpi.org">users@open-mpi.org</a>&gt;<br>&gt; Sent: Wednesday, May 27, 2009 11:28:42 PM<br>&gt;
 Subject: Re: [OMPI users] How to use Multiple links with OpenMPI??????????????????<br>&gt; <br>&gt; Open MPI considers hosts differently than network links.<br>&gt; <br>&gt; So you should only list the actual hostname in the hostfile, with slots equal to the number of processors (4 in your case, I think?).<br>&gt; <br>&gt; Once the MPI processes are launched, they each look around on the host that they're running and find network paths to each of their peers.&nbsp; If they are multiple paths between pairs of peers, Open MPI will round-robin stripe messages across each of the links.&nbsp; We don't really have an easy setting for each peer pair only using 1 link.&nbsp; Indeed, since connectivity is bidirectional, the traffic patterns become less obvious if you want MPI_COMM_WORLD rank X to only use link Y -- what does that mean to the other 4 MPI processes on the other host (with whom you have assumedly assigned their own individual links as
 well)?<br>&gt; <br>&gt; <br>&gt; On May 26, 2009, at 12:24 AM, shan axida wrote:<br>&gt; <br>&gt; &gt; Hi everyone,<br>&gt; &gt; I want to ask how to use multiple links (multiple NICs) with OpenMPI.<br>&gt; &gt; For example, how can I assign a link to each process, if there are 4 links<br>&gt; &gt; and 4 processors on each node in our cluster?<br>&gt; &gt; Is this a correct way?<br>&gt; &gt; hostfile:<br>&gt; &gt; ----------------------<br>&gt; &gt; host1-eth0 slots=1<br>&gt; &gt; host1-eth1 slots=1<br>&gt; &gt; host1-eth2 slots=1<br>&gt; &gt; host1-eth3 slots=1<br>&gt; &gt; host2-eth0 slots=1<br>&gt; &gt; host2-eth1 slots=1<br>&gt; &gt; host2-eth2 slots=1<br>&gt; &gt; host2-eth3 slots=1<br>&gt; &gt; ...&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ...<br>&gt; &gt; ...&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ...<br>&gt; &gt; host16-eth0 slots=1<br>&gt; &gt; host16-eth1 slots=1<br>&gt; &gt; host16-eth2 slots=1<br>&gt; &gt; host16-eth3 slots=1<br>&gt; &gt;
 ------------------------<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt; _______________________________________________<br>&gt; &gt; users mailing list<br>&gt; &gt; <a ymailto="mailto:users@open-mpi.org" href="mailto:users@open-mpi.org">users@open-mpi.org</a><br><span>&gt; &gt; <a target="_blank" href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a></span><br>&gt; <br>&gt; <br>&gt; --Jeff Squyres<br>&gt; Cisco Systems<br>&gt; <br>&gt; _______________________________________________<br>&gt; users mailing list<br>&gt; <a ymailto="mailto:users@open-mpi.org" href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>&gt; <br>&gt;
 &lt;MPI_Bcast-ypc05xx.pdf&gt;_______________________________________________<br>&gt; users mailing list<br>&gt; <a ymailto="mailto:users@open-mpi.org" href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br><br><br>--Jeff Squyres<br>Cisco Systems<br><br>_______________________________________________<br>users mailing list<br><a ymailto="mailto:users@open-mpi.org" href="mailto:users@open-mpi.org">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></div></div></div><br>

      </body></html>
