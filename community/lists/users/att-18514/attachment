<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<HTML><HEAD>
<META http-equiv=Content-Type content="text/html; charset=utf-8">
<META content="MSHTML 6.00.6001.18444" name=GENERATOR>
<STYLE></STYLE>
</HEAD>
<BODY bgColor=#ffffff>
<DIV><FONT face=Arial size=2>I had exactly the same problem.</FONT></DIV>
<DIV><FONT face=Arial size=2>Trying to run mpi between 2 separate machines, with 
each machine having</FONT></DIV>
<DIV><FONT face=Arial size=2>2 ethernet ports, causes really weird behaviour on 
the most basic code.</FONT></DIV>
<DIV><FONT face=Arial size=2>I had to disable one of the ethernet&nbsp;ports on 
each of the machines</FONT></DIV>
<DIV><FONT face=Arial size=2>and it worked just fine after that. No idea why 
though !</FONT></DIV>
<DIV><FONT face=Arial size=2></FONT>&nbsp;</DIV>
<BLOCKQUOTE 
style="PADDING-RIGHT: 0px; PADDING-LEFT: 5px; MARGIN-LEFT: 5px; BORDER-LEFT: #000000 2px solid; MARGIN-RIGHT: 0px">
  <DIV style="FONT: 10pt arial">----- Original Message ----- </DIV>
  <DIV 
  style="BACKGROUND: #e4e4e4; FONT: 10pt arial; font-color: black"><B>From:</B> 
  <A title=pukkimonkey@gmail.com href="mailto:pukkimonkey@gmail.com">Jingcha 
  Joba</A> </DIV>
  <DIV style="FONT: 10pt arial"><B>To:</B> <A title=users@open-mpi.org 
  href="mailto:users@open-mpi.org">users@open-mpi.org</A> </DIV>
  <DIV style="FONT: 10pt arial"><B>Sent:</B> Thursday, February 16, 2012 8:43 
  PM</DIV>
  <DIV style="FONT: 10pt arial"><B>Subject:</B> [OMPI users] Problem running an 
  mpi applicatio​n on nodes with more than one interface</DIV>
  <DIV><BR></DIV>
  <DIV>Hello Everyone,</DIV>
  <DIV>This is my 1st post in open-mpi forum. </DIV>
  <DIV></DIV>
  <DIV>I am trying to run a simple program which does Sendrecv between two nodes 
  having 2 interface cards on each of two nodes. 
  <DIV>Both the nodes are running RHEL6, with open-mpi 1.4.4 on a 8 core Xeon 
  processor.</DIV>
  <DIV></DIV></DIV>
  <DIV>What I noticed was that when using two or more interface on both the 
  nodes, the mpi "hangs" attempting to connect. </DIV>
  <DIV>These details might help,</DIV>
  <DIV>Node 1 - Denver has a single port "A" card (<STRONG>eth21</STRONG> - 
  25.192.xx.xx - which I use to ssh to that machine), and a double port "B" card 
  (<STRONG>eth23</STRONG> - 10.3.1.1 &amp; <STRONG>eth24</STRONG> - 10.3.1.2). 
  </DIV>
  <DIV>Node 2 - Chicago also the same single port A card (<STRONG>eth19</STRONG> 
  - 25.192.xx.xx - again uses for ssh) and a double port B card ( 
  <STRONG>eth29</STRONG> - 10.3.1.3 &amp; <STRONG>eth30</STRONG> - 
  10.3.1.4).</DIV>
  <DIV></DIV>
  <DIV>My /etc/host looks like</DIV>
  <DIV>25.192.xx.xx <A href="http://denver.xxx.com/" 
  target=_blank>denver.xxx.com</A> denver</DIV>
  <DIV>10.3.1.1 <A href="http://denver.xxx.com/" 
  target=_blank>denver.xxx.com</A> denver</DIV>
  <DIV>10.3.1.2 <A href="http://denver.xxx.com/" 
  target=_blank>denver.xxx.com</A> denver</DIV>
  <DIV></DIV>
  <DIV>25.192.xx.xx <A href="http://chicago.xxx.com/" 
  target=_blank>chicago.xxx.com</A> chicago</DIV>
  <DIV>10.3.1.3 <A href="http://chicago.xxx.com/" 
  target=_blank>chicago.xxx.com</A> chicago</DIV>
  <DIV>10.3.1.4 <A href="http://chicago.xxx.com/" 
  target=_blank>chicago.xxx.com</A> chicago</DIV>
  <DIV>...</DIV>
  <DIV>...</DIV>
  <DIV>...</DIV>
  <DIV></DIV>
  <DIV></DIV>
  <DIV></DIV>
  <DIV>This is how I run, </DIV>
  <DIV>mpirun --hostfile host1 --mca btl tcp,sm,self --mca btl_tcp_if_exclude 
  eth21,eth19,lo,virbr0 --mca btl_base_verbose 30 -np 4 ./Sendrecv </DIV>
  <DIV></DIV>
  <DIV>I get bunch of things from both chicago and denver, which says its has 
  found components like tcp, sm, self and stuffs, and then hangs at </DIV>
  <DIV></DIV>
  <DIV><STRONG>[<A href="http://denver.xxx.com:21682/" 
  target=_blank>denver.xxx.com:21682</A>] btl: tcp: attempting to connect() to 
  address 10.3.1.3 on port 4<BR>[<A href="http://denver.xxx.com:21682/" 
  target=_blank>denver.xxx.com:21682</A>] btl: tcp: attempting to connect() to 
  address 10.3.1.4 on port 4<BR></STRONG></DIV>
  <DIV>However, if I run the same program by excluding eth29 or eth30, then it 
  works fine. Something like this:</DIV>
  <DIV>
  <DIV>mpirun --hostfile host1 --mca btl tcp,sm,self --mca btl_tcp_if_exclude 
  eth21,eth19,<STRONG>eth29</STRONG>,lo,virbr0 --mca btl_base_verbose 30 -np 4 
  ./Sendrecv </DIV>
  <DIV></DIV>
  <DIV></DIV>
  <DIV>My hostfile looks like this</DIV>
  <DIV>[sshuser@denver Sendrecv]$ cat host1<BR>denver slots=2<BR>chicago 
  slots=2<BR></DIV>
  <DIV></DIV>
  <DIV></DIV>
  <DIV>I am not sure if I have to provide somethbing else. Please if I have to, 
  please feel to ask me..</DIV>
  <DIV></DIV>
  <DIV>thanks,</DIV>
  <DIV>--</DIV>
  <DIV>Joba</DIV></DIV>
  <P>
  <HR>

  <P></P>_______________________________________________<BR>users mailing 
  list<BR>users@open-mpi.org<BR>http://www.open-mpi.org/mailman/listinfo.cgi/users</BLOCKQUOTE></BODY></HTML>
