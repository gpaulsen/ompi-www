<div dir="ltr">Thanks Jeff! That&#39;s very helpful.<div><br></div><div style>Cheers!</div><div style><br></div><div style>Jacky</div></div><div class="gmail_extra"><br><br><div class="gmail_quote">On Wed, Apr 24, 2013 at 10:56 AM, Jeff Squyres (jsquyres) <span dir="ltr">&lt;<a href="mailto:jsquyres@cisco.com" target="_blank">jsquyres@cisco.com</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div class="im">On Apr 24, 2013, at 10:24 AM, Thomas Watson &lt;<a href="mailto:exascale.system@gmail.com">exascale.system@gmail.com</a>&gt; wrote:<br>

<br>
&gt; I still have a couple of questions to ask:<br>
&gt;<br>
&gt; 1. In both MPI_THREAD_FUNNELED and MPI_THREAD_SERIALIZED modes, the MPI calls are serialized at only one thread (in the former case, only the rank main thread can make MPI calls, while in the latter case the threads need to be coordinated so that only one thread makes MPI calls at a time). So are there any performance implications associated with choosing between FUNNELED or SERIALIZED?<br>

<br>
</div>In Open MPI, no.<br>
<div class="im"><br>
&gt; 2. My current code uses many MPI collective calls (gather/scatter/broadcast, etc.). It seems that these collective calls have some negative impact on performance because ALL MPI processes need to wait on each of these calls. I would like to explore the idea of decoupling computation from MPI communication - so if one thread of each MPI rank is blocked at a MPI call, the other threads can still make progress. I am wondering if I could still make MPI calls from the other non-blocked threads using  MPI_THREAD_FUNNELED or MPI_THREAD_SERIALIZED mode (assuming that the blocked thread is the main thread in the rank)?<br>

<br>
</div>MPI-3 introduced the concept of non-blocking collectives (e.g., MPI_Igather).  Open MPI 1.7.x has preliminary versions of these, but the implementations concentrated on correctness: they haven&#39;t been optimized yet.  You might need to check how well MPI_Gather performs in a separate thread vs. MPI_Igather.<br>

<br>
Also, be aware that not all collectives are synchronizing.  Depending on the back-end algorithm that is used to implement any given collective, one MPI process may return much earlier from a collective call than one of its peers in the same collective call.  For example, with MPI_Gather of a short message, all non-root processes might do an eager send and return more-or-less immediately.  The root will need to block, however, until all messages are received.<br>

<br>
Make sense?<br>
<span class="HOEnZb"><font color="#888888"><br>
--<br>
Jeff Squyres<br>
<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a><br>
For corporate legal information go to: <a href="http://www.cisco.com/web/about/doing_business/legal/cri/" target="_blank">http://www.cisco.com/web/about/doing_business/legal/cri/</a><br>
</font></span><div class="HOEnZb"><div class="h5"><br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</div></div></blockquote></div><br></div>

