<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
<HEAD>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="MS Exchange Server version 6.5.7651.59">
<TITLE>RE: [OMPI users] SGE error: executing task of job 22966 failed:</TITLE>
</HEAD>
<BODY>
<!-- Converted from text/plain format -->

<P><FONT SIZE=2>I followed your direction and it works fine now.&nbsp; Thank you very much.&nbsp; Appreciate it.<BR>
<BR>
Prakashan<BR>
<BR>
<BR>
<BR>
i01:~ {1005}$ qconf -sp orte<BR>
pe_name&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; orte<BR>
slots&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 360<BR>
user_lists&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NONE<BR>
xuser_lists&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NONE<BR>
start_proc_args&nbsp;&nbsp; /bin/true<BR>
stop_proc_args&nbsp;&nbsp;&nbsp; /bin/true<BR>
allocation_rule&nbsp;&nbsp; $round_robin<BR>
control_slaves&nbsp;&nbsp;&nbsp; TRUE<BR>
job_is_first_task FALSE<BR>
urgency_slots&nbsp;&nbsp;&nbsp;&nbsp; min<BR>
<BR>
<BR>
-----Original Message-----<BR>
From: users-bounces@open-mpi.org on behalf of Pak Lui<BR>
Sent: Thu 4/3/2008 1:37 PM<BR>
To: Open MPI Users<BR>
Subject: Re: [OMPI users] SGE error: executing task of job 22966 failed:<BR>
<BR>
Hi Prakashan,<BR>
<BR>
I believe it might be something from PE setting. Could you try this:<BR>
<BR>
Change this parameter in the 'orte' parallel environment from:<BR>
&nbsp;&gt; job_is_first_task TRUE<BR>
to:<BR>
&nbsp;&gt; job_is_first_task FALSE<BR>
<BR>
If you have this set to true, it would take away an available slot in<BR>
your job, so it might prevent an SGE 'task' from launching to one of<BR>
your SGE nodes.<BR>
<BR>
Korambath, Prakashan wrote:<BR>
&gt; Hi,<BR>
&gt;<BR>
&gt;&nbsp;&nbsp; I just compiled OpenMPI version 1.2.5 with the option<BR>
&gt;<BR>
&gt;<BR>
&gt; ./configure --prefix=/u/local/mpi/openmpi/1.2.5<BR>
&gt; --with-openib=/usr/local&nbsp; --enable-static --disable-shared CC=icc<BR>
&gt; CXX=icpc F77=ifort FC=ifort --with-sge<BR>
&gt;<BR>
&gt; on a X86_64 machine with Infiniband Interconnect and OFED software and<BR>
&gt; CentOS 5 OS<BR>
&gt;<BR>
&gt; Everything works fine on command line job submission, but when I submit<BR>
&gt; through SGE 6.1U3 I am getting following error<BR>
&gt;<BR>
&gt; error: executing task of job 23081 failed:<BR>
&gt; [n99:01442] ERROR: A daemon on node n99 failed to start as expected.<BR>
&gt; [n99:01442] ERROR: There may be more information available from<BR>
&gt; [n99:01442] ERROR: the 'qstat -t' command on the Grid Engine tasks.<BR>
&gt; [n99:01442] ERROR: If the problem persists, please restart the<BR>
&gt; [n99:01442] ERROR: Grid Engine PE job<BR>
&gt; [n99:01442] ERROR: The daemon exited unexpectedly with status 1.<BR>
&gt;<BR>
&gt;<BR>
&gt; In my command script for SGE I have<BR>
&gt; #$ -pe orte 2<BR>
&gt;<BR>
&gt;<BR>
&gt; /u/local/mpi/openmpi/1.2.5/bin/mpiexec -n 2 -machinefile $TMPDIR/nodefile&nbsp; \<BR>
&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /u/home2/ppk/MPI/C/executablename&nbsp; &gt;&amp; output<BR>
&gt;<BR>
&gt;<BR>
&gt;<BR>
&gt; n99:/work/23081.1.campus.q {1002}$ cat nodefile<BR>
&gt; n99&nbsp; slots=1<BR>
&gt; n15&nbsp; slots=1<BR>
&gt;<BR>
&gt;<BR>
&gt; n99:/work/23081.1.campus.q {1003}$ qconf -sp orte<BR>
&gt; pe_name&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; orte<BR>
&gt; slots&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 360<BR>
&gt; user_lists&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NONE<BR>
&gt; xuser_lists&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NONE<BR>
&gt; start_proc_args&nbsp;&nbsp; /bin/true<BR>
&gt; stop_proc_args&nbsp;&nbsp;&nbsp; /bin/true<BR>
&gt; allocation_rule&nbsp;&nbsp; $round_robin<BR>
&gt; control_slaves&nbsp;&nbsp;&nbsp; TRUE<BR>
&gt; job_is_first_task TRUE<BR>
&gt; urgency_slots&nbsp;&nbsp;&nbsp;&nbsp; min<BR>
&gt;<BR>
&gt;<BR>
&gt; I am combing through the archives to look for similar errors.&nbsp; I have<BR>
&gt; seen some of it, but no satisfactory answer. Anyone knows why?<BR>
&gt;<BR>
&gt;<BR>
&gt;<BR>
&gt; i02:/u/local/mpi/openmpi/1.2.5/bin {1049}$ ./ompi_info | grep tm<BR>
&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MCA memory: ptmalloc2 (MCA v1.0, API v1.0, Component v1.2.5)<BR>
&gt;<BR>
&gt; I also tried pre-relese 1.2.6rc3 same results.<BR>
&gt;<BR>
&gt;<BR>
&gt; Prakashan<BR>
&gt;<BR>
&gt;<BR>
&gt;&nbsp;<BR>
&gt;<BR>
&gt;<BR>
&gt;<BR>
&gt;<BR>
&gt; ------------------------------------------------------------------------<BR>
&gt;<BR>
&gt; _______________________________________________<BR>
&gt; users mailing list<BR>
&gt; users@open-mpi.org<BR>
&gt; <A HREF="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</A><BR>
<BR>
<BR>
--<BR>
<BR>
<BR>
- Pak Lui<BR>
pak.lui@sun.com<BR>
_______________________________________________<BR>
users mailing list<BR>
users@open-mpi.org<BR>
<A HREF="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</A><BR>
<BR>
</FONT>
</P>

</BODY>
</HTML>
