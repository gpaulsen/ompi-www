<p dir="ltr"><br>
On Jul 8, 2016 3:16 PM, &quot;Juan Francisco Martínez&quot; &lt;<a href="mailto:juan.francisco.martinez@est.fib.upc.edu">juan.francisco.martinez@est.fib.upc.edu</a>&gt; wrote:<br>
&gt;<br>
&gt; Hi everybody!<br>
&gt;<br>
&gt; First of all I want to congratulate all of you because the quality of<br>
&gt; the community, I have solved a lot of doubts just reading the mailing<br>
&gt; list.<br>
&gt;<br>
&gt; However I have a question that I can not solve... Until now I though<br>
&gt; that all the collective operations have an implicit sincronization, but<br>
&gt; I can see that this is not true at all (because optimizations?). Then,<br>
&gt; after searching a little bit on the web I saw that there are several<br>
&gt; implementations of the reduction in openmpi, in fact there are 6<br>
&gt; possible algorithm (at least on OMPI 1.6) that you can use by mean of<br>
&gt; the mca parameters...<br>
&gt;<br>
&gt; I thought that one of them behaves as a synchronization but after<br>
&gt; execute a test with each one, no one behaves as it. Then my question<br>
&gt; is, there is any possibility, by tuning ompi, the reduce operation<br>
&gt; syncrhonize all the ranks that are involved at the end of the<br>
&gt; operation?</p>
<p dir="ltr">The straightforward answer is that the reduction provides a logical synchronization only between the root of the reduction and each one of the participants individually. </p>
<p dir="ltr">As you already noticed this is not the case from a practical perspective because different underlying algorithms can be used,  and they use different communication patterns. Thus, you cannot,  and you should not, make a parallel between a reduction and a synchronization. </p>
<p dir="ltr">If you really need the synchronization behavior why don&#39;t you use allreduce instead? Or at least a bcast of a single byte after the reduction (it also works with a barrier but as already have 1/2 of the synchronization, aka. all-to-root, this will be an overkill). </p>
<p dir="ltr">&gt;<br>
&gt; Also I would like to know if there is any mechanism to know at runtime<br>
&gt; which algorithm is being used.</p>
<p dir="ltr">Again,  there is no simple answer. Even if the tuned collective module could expose the algorithm, how do you know that a particular collective will be using the tuned module? We order the collective modules by priority,  and the decision of which module will handle each collective is dynamic, based on the many factors. </p>
<p dir="ltr">George </p>
<p dir="ltr">&gt;<br>
&gt; Thanks for all!<br>
&gt; - Fran<br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
&gt; Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/users">https://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2016/07/29606.php">http://www.open-mpi.org/community/lists/users/2016/07/29606.php</a><br>
</p>

