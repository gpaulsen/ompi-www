<html><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; ">Josh,<div><br></div><div>It sounds like . is not in your path. That would prevent mpirun from seeing the binary in the current directory.</div><div><br></div><div>Doug Reeder<br><div><div>On Jan 22, 2009, at 10:48 AM, Josh Hursey wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><div>As a followup.<br><br>I can confirm that --preload-files is not working as it should.<br><br>I was able to use --preload-binary with a full path to the binary without a problem though. The following commands worked fine (where /tmp is not mounted on all machines):<br> &nbsp;&nbsp;shell$ mpirun -np 2 --preload-binary /tmp/hello<br> &nbsp;&nbsp;shell$ mpirun -np 2 -s /tmp/hello<br><br>However if I referred directly to the binary in the current directory I saw the same failure:<br>shell$ cd /tmp<br>shell$ mpirun -np 2 -s hello<br>--------------------------------------------------------------------------<br>mpirun was unable to launch the specified application as it could not find an executable:<br><br>Executable: hello<br>Node: odin101<br><br>while attempting to start process rank 0.<br>--------------------------------------------------------------------------<br><br><br>I'll keep digging into this bug, and let you know when I have a fix. I filed a ticket (below) that you can use to track the progress on this bug.<br> &nbsp;<a href="https://svn.open-mpi.org/trac/ompi/ticket/1770">https://svn.open-mpi.org/trac/ompi/ticket/1770</a><br><br>Thanks again for the bug report, I'll try to resolve this soon.<br><br>Josh<br><br>On Jan 22, 2009, at 10:49 AM, Josh Hursey wrote:<br><br><blockquote type="cite">The warning is to be expected if the file already exists on the remote side. Open MPI has a policy not to replace the file if it already exists.<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">The segv is concerning. :/<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">I will take a look and see if I can diagnose what is going on here. Probably in the next day or two.<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">Thanks for the bug report,<br></blockquote><blockquote type="cite">Josh<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">On Jan 22, 2009, at 10:11 AM, Geoffroy Pignot wrote:<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite"><blockquote type="cite">Hello,<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">As you can notice , I am trying the work done on this new release. preload-files and preload-binary options are very interesting to me because I work on a cluster without any shared space between nodes.<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">I tried those basically , but no success . You will find below the error messages.<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">If I did things wrong, &nbsp;would it be possible to get simple examples showing how these options work.<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Thanks<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Geoffroy<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">/tmp/openmpi-1.3/bin/mpirun --preload-files hello.c --hostfile /tmp/hostlist -np 2 hostname<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">--------------------------------------------------------------------------<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">WARNING: Could not preload specified file: File already exists.<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Fileset: /tmp/hello.c<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Host: compil03<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Will continue attempting to launch the process.<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">--------------------------------------------------------------------------<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] filem:rsh: get(): Failed to preare the request structure (-1)<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">--------------------------------------------------------------------------<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">WARNING: Could not preload the requested files and directories.<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Fileset:<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Fileset: hello.c<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Will continue attempting to launch the process.<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">--------------------------------------------------------------------------<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [[13938,0],0] ORTE_ERROR_LOG: Error in file base/odls_base_state.c at line 127<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [[13938,0],0] ORTE_ERROR_LOG: Error in file base/odls_base_default_fns.c at line 831<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] *** Process received signal ***<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] Signal: Segmentation fault (11)<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] Signal code: Address not mapped (1)<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] Failing at address: 0x395eb15000<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [ 0] /lib64/tls/libpthread.so.0 [0x395f80c420]<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [ 1] /lib64/tls/libc.so.6(memcpy+0x3f) [0x395ed718df]<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [ 2] /tmp/openmpi-1.3/lib64/libopen-pal.so.0 [0x2a956b0a10]<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [ 3] /tmp/openmpi-1.3/lib64/libopen-rte.so.0(orte_odls_base_default_launch_local+0x55c) [0x2a955809cc]<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [ 4] /tmp/openmpi-1.3/lib64/openmpi/mca_odls_default.so [0x2a963655f2]<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [ 5] /tmp/openmpi-1.3/lib64/libopen-rte.so.0(orte_daemon_cmd_processor+0x57d) [0x2a9557812d]<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [ 6] /tmp/openmpi-1.3/lib64/libopen-pal.so.0 [0x2a956b9828]<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [ 7] /tmp/openmpi-1.3/lib64/libopen-pal.so.0(opal_progress+0xb0) [0x2a956ae820]<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [ 8] /tmp/openmpi-1.3/lib64/libopen-rte.so.0(orte_plm_base_launch_apps+0x1ed) [0x2a95584e7d]<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [ 9] /tmp/openmpi-1.3/lib64/openmpi/mca_plm_rsh.so [0x2a95c3ed98]<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [10] /tmp/openmpi-1.3/bin/mpirun [0x403330]<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [11] /tmp/openmpi-1.3/bin/mpirun [0x402ad3]<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [12] /lib64/tls/libc.so.6(__libc_start_main+0xdb) [0x395ed1c4bb]<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] [13] /tmp/openmpi-1.3/bin/mpirun [0x402a2a]<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[compil03:26657] *** End of error message ***<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Segmentation fault<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">And it's not better with --preload-binary . a.out_32<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">compil03% /tmp/openmpi-1.3/bin/mpirun -s --hostfile /tmp/hostlist -wdir /tmp -np 2 a.out_32<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">--------------------------------------------------------------------------<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">mpirun was unable to launch the specified application as it could not find an executable:<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Executable: a.out_32<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Node: compil02<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">while attempting to start process rank 1.<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">_______________________________________________<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">users mailing list<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">_______________________________________________<br></blockquote><blockquote type="cite">users mailing list<br></blockquote><blockquote type="cite"><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br></blockquote><blockquote type="cite"><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote><br>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></div></blockquote></div><br></div></body></html>
