<div dir="ltr"><div><div><div><div>Hi!<br><br></div>I want to convert the input/output of my program to MPI-IO routines. To write the same data, as is written in the already implement textmode routines, I need a custom datatype consisting of several integers and reals.<br><br></div>While investigating the functionality, I created a module, which cares for the type, and a small testprogram, which performs a mpi_scatter, a parallel write with mpi_file_write and finally a single read from the master with mpi_file_read, to compare the data with the original dataset.<br><br></div>My testtype for this particular problem is defined as an 8 byte real followed by a 4 byte integer. This way, the datasize is 12 byte, while the extent differs for different compilers (gfortran has an extent of 16 byte, while ifort has an extent of 12 byte). I know, that I can fix the extent with the help of mpi_type_create_resized after measuring the distance of the elements in an array, but this doesn&#39;t show the strange behaviour, I don&#39;t understand.<br><br>My problem is, that I don&#39;t really understand the way, how mpi_file_read uses this extent to perform file-io on arrays of this data. On the one hand, the data, which is written to the file, is only the data, which is actually used, i.e. no padding is written to the file and thus, only the mpi_type_size is interesting for the writing. On the other hand, the missing padding in the extent of ifort causes mpi_file_read to skip some of the last datasets. In my opinion, this would make some sense, if the padding of the datasets would cause corruption on the read data after the first padding, but this is not the case. If you execute the appended program with 4 processes, the last two of eight datasets stay uninitialized (keep their values of -1 for each member) what suggests that the amount of data is somehow related to the extent rather than the type_size.<br><br></div><div>What is the problem here? Do I misunderstand, how these routines should work?<br><br></div><div>Best regards,<br>Stefan<br><br></div><div>PS: Does the stat(1) variable mean anything? It returns 0 all the time.<br><br><br></div><div>### CODE ###<br><br>module mpiio<br>    !use mpi<br>    implicit none<br>    <br>    include &#39;mpif.h&#39;<br>    <br>    private<br>    public :: r1i1_iotype<br>    public :: r1i1_mpi<br>    public :: init_mpiio, get_mpiio_dtypes<br>    <br>    type, bind(c) :: r1i1_iotype<br>        real(8) :: r<br>        integer :: i<br>    end type<br><br>    integer :: r1i1_mpi<br><br>contains<br><br>    ! initializer, which creates datatypes for all types in this module<br>    subroutine init_mpiio()<br>        r1i1_mpi = get_r1i1_type()<br>    end subroutine<br>    <br>    ! inforoutine, which prints information about all types in this module<br>    subroutine get_mpiio_dtypes()<br>        write(*,&quot;(A80)&quot;) &quot;=== Available Datatypes ================&quot; // &amp;<br>            &amp; &quot;========================================&quot;<br>        call get_dtype_info(r1i1_mpi)<br>        write(*,&quot;(A80)&quot;) &quot;========================================&quot; // &amp;<br>            &amp; &quot;========================================&quot;<br>    end subroutine<br>    <br>    ! generic routine, which prints information about a datatype<br>    subroutine get_dtype_info(dt)<br>        integer :: dt<br>        integer :: ierror, nl, i, sz<br>        character(LEN=63) :: type_name<br>        integer(mpi_address_kind) :: lb, extent<br>        integer(mpi_address_kind) :: true_lb, true_extent<br>        integer :: comb<br>        integer :: num_int, num_addr, num_dt<br>        integer, dimension(:), allocatable :: aob<br>        integer(mpi_address_kind), dimension(:), allocatable :: aod<br>        integer, dimension(:), allocatable :: aot<br>        <br>        ! get name of datatype<br>        call mpi_type_get_name(dt, type_name, nl, ierror)<br>        <br>        write(*,*) &quot;Name: &quot;, type_name<br>        <br>        ! get start address and extent<br>        call mpi_type_get_extent(dt, lb, extent, ierror)<br>        call mpi_type_get_true_extent(dt, true_lb, true_extent, ierror)<br>        <br>        write(*,*) &quot;lb:     &quot;, lb,     &quot; true lb:     &quot;, true_lb<br>        write(*,*) &quot;extent: &quot;, extent, &quot; true extent: &quot;, true_extent<br>        <br>        ! get contents<br>        call mpi_type_get_envelope(dt, num_int, num_addr, num_dt, comb, ierror)<br>        <br>        allocate(aob(num_int))<br>        allocate(aod(num_addr))<br>        allocate(aot(num_dt))<br>        <br>        call mpi_type_get_contents(dt, num_int, num_addr, num_dt, aob, aod, aot, ierror)<br>        <br>        write(*,*) &quot;consists of: &quot;, num_int - 1, aob(1)<br>        <br>        do i = 1, num_int - 1<br>            call mpi_type_get_name(aot(i), type_name, nl, ierror)<br>            write(*,*) i, &quot;:&quot;, aob(i+1), aod(i), trim(type_name)<br>        end do<br>        <br>        call mpi_type_size(dt, sz, ierror)<br>        write(*,*) &quot;data size: &quot;, sz<br>    end subroutine<br><br>    function get_r1i1_type() result(dt)<br>        ! datatype<br>        integer :: dt<br>        type(r1i1_iotype) :: t<br>        integer :: ierror<br>        integer(mpi_address_kind) :: a_base, a_r, a_i<br>        ! number of blocks<br>        integer, parameter :: cnt = 2<br>        ! elements in each block<br>        integer, dimension(cnt) :: aob<br>        ! types in each block<br>        integer, dimension(cnt) :: aot<br>        ! displacements of each block<br>        integer(mpi_address_kind), dimension(cnt) :: aod<br>        <br>        aob = [1, 1]<br>        aot = [mpi_double_precision, mpi_integer]<br>        <br>        ! get base address and address of members<br>        call mpi_get_address(t, a_base, ierror)<br>        call mpi_get_address(t%r, a_r, ierror)<br>        call mpi_get_address(t%i, a_i, ierror)<br>        <br>        ! convert to offsets/displacements<br>        a_r = a_r - a_base<br>        a_i = a_i - a_base<br>        <br>        ! displacements<br>        aod = [a_r, a_i]<br>        <br>        ! create type<br>        call mpi_type_create_struct(cnt, aob, aod, aot, dt, ierror)<br>        ! name the type<br>        call mpi_type_set_name(dt, &quot;r1i1&quot;, ierror)<br>        <br>        ! commit type<br>        call mpi_type_commit(dt, ierror)<br>        <br>    end function<br>end module<br><br>program test<br>    use mpiio<br><br>    implicit none<br>    <br>    include &#39;mpif.h&#39;<br><br>    type(r1i1_iotype), dimension(:), allocatable :: v, w<br>    integer :: dt<br>    integer :: myrank, mpisize<br>    integer :: ierror<br>    real(8) :: ranarray(2)<br>    integer :: i, n, m<br>    integer :: fh<br>    integer, dimension(mpi_status_size) :: stat<br>    integer(mpi_offset_kind) :: fp, fs, fs2<br>    integer :: sz<br>    logical :: correct<br>    <br>    ! problem size<br>    m = 2<br>    <br>    ! initializer<br>    call mpi_init(ierror)<br>    call mpi_comm_rank(mpi_comm_world, myrank, ierror)<br>    call mpi_comm_size(mpi_comm_world, mpisize, ierror)<br>    ! initialize datatypes and print info<br>    call init_mpiio()<br>    if (myrank == 0) then<br>        call get_mpiio_dtypes()<br>    endif<br>    dt = r1i1_mpi<br>    <br>    ! synchronize to avoid mess of output<br>    call mpi_barrier(mpi_comm_world, ierror)<br>    <br>    ! create data<br>    n = mpisize * m<br>    allocate(w(m))<br>    ! root process will create a batch of values<br>    if (myrank == 0) then<br>        allocate(v(n))<br>        do i = 1, n<br>            call random_number(ranarray)<br>            v(i) % r = ranarray(1)<br>            v(i) % i = int(huge(v(i)%i) * ranarray(2))<br>        end do<br>    end if<br>    <br>    ! scatter across the processes<br>    call mpi_scatter(v, m, dt, w, m, dt, 0, mpi_comm_world, ierror)<br>    <br>    ! open collective file<br>    call mpi_file_open(mpi_comm_world, &quot;testfile&quot;, mpi_mode_create + mpi_mode_rdwr, mpi_info_null, fh, ierror)<br>    ! get size of datatype to calculate position in file<br>    call mpi_type_size(dt, sz, ierror)<br>    fs = n * sz<br>    fp = myrank * m * sz<br>    if (myrank == 0) then<br>        write(*,*) sz<br>    end if<br>    ! search position for each process<br>    call mpi_file_seek(fh, fp, mpi_seek_set, ierror)<br>    ! write personal part<br>    call mpi_file_write(fh, w, m, dt, stat, ierror)<br>    ! synchronize the file, so the master process can start reading<br>    call mpi_file_sync(fh, ierror)<br>    call mpi_barrier(mpi_comm_world, ierror)<br>    <br>    if (myrank == 0) then<br>        ! inquire the file size and compare with the previously calculated<br>        call mpi_file_get_size(fh, fs2, ierror)<br>        write(*,*) &quot;file size: &quot;, fs2, &quot;(&quot;, fs, &quot;)&quot;<br>        <br>        ! create space for read data<br>        deallocate(w)<br>        allocate(w(n))<br>        ! initialize all fields with -1<br>        do i = 1, n<br>            w(i) % r = -1<br>            w(i) % i = -1<br>        end do<br>        ! search the beginning<br>        call mpi_file_seek(fh, int(0,kind=mpi_offset_kind), mpi_seek_set, ierror)<br>        ! read all data<br>        call mpi_file_read(fh, w, n, dt, stat, ierror)<br>        write(*,*) ierror<br>        write(*,*) stat<br>        write(*,*)<br>        <br>        ! compare<br>        correct = .true.<br>        do i = 1, n<br>            correct = correct .and. (v(i) % r == w(i) % r)<br>            correct = correct .and. (v(i) % i == w(i) % i)<br>            write(*,*) i<br>            write(*,*) v(i) % r<br>            write(*,*) w(i) % r<br>            write(*,*) v(i) % i<br>            write(*,*) w(i) % i<br>            write(*,*)<br>        end do<br>        <br>        write(*,*) &quot;original and read data are the same: &quot;, correct<br>        <br>        deallocate(v)<br>    end if<br>    deallocate(w)<br>    <br>    ! close file<br>    call mpi_file_close(fh, ierror)<br>    <br>    ! finish<br>    call mpi_finalize(ierror)<br>    <br>end program<br><br></div></div>
