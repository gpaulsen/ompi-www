<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div bgcolor="#FFFFFF" text="#000000">
    <blockquote type="cite">
      <div dir="ltr">So, you mean that it guarantees the value received
        after the bcast call is consistent with value sent from root,
        but it doesn&#39;t have to wait till all the ranks have received it?
        <div><br>
        </div>
      </div>
    </blockquote>
    this is what i believe, double checking the standard might not hurt
    though ...<br></div></blockquote><div><br></div><div>No function has barrier semantics, except a barrier, although some functions have barrier semantics due to data-dependencies for non-zero counts (allgather, alltoall, allreduce).</div><div><br></div><div>Reduce, Bcast, gather, and scatter should never have barrier semantics and should not synchronize more than the explicit data decencies require. The send-only ranks may return long before the recv-only ranks do, particularly when the messages go via an eager protocol.</div><div><br></div><div>One can imagine barrier as a 1-byte allreduce, but there are more efficient implantations. Allreduce should never be faster than Bcast, as Gilles explained. <span></span></div><div><br></div><div>There&#39;s a nice paper on self-consistent performance of MPI implementations that has lots of details.</div><div><br></div><div>Jeff</div><br><br>-- <br>Jeff Hammond<br><a href="mailto:jeff.science@gmail.com" target="_blank">jeff.science@gmail.com</a><br><a href="http://jeffhammond.github.io/" target="_blank">http://jeffhammond.github.io/</a><br>

