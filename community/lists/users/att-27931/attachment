<div dir="ltr">If you want to remain in the traditional methods (complexity n^3), what you need is a GEMM (generalized matrix multiplication), and it is provided in C, for dense matrices, by ScaLAPACK. The implementation provided on your blog is indeed a rough cut, there are better solutions (matrices divided in blocks k-cyclic) proposed by the SUMMA and PUMMA algorithms.<div><br></div><div>  George.</div><div><br></div></div><div class="gmail_extra"><br><div class="gmail_quote">On Wed, Oct 28, 2015 at 9:14 AM, Ibrahim Ikhlawi <span dir="ltr">&lt;<a href="mailto:ibrahim_22s@hotmail.com" target="_blank">ibrahim_22s@hotmail.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">


<div><div dir="ltr">Hi,<br><br>what is the best way to multiply two matrices with java-openmpi.<br>Is the way in this link the right way to do that? Also split the first matrix row wise and multiply each one with the second matrix (each row on a processor) then collect the results.<br><br>Link: <a href="https://anjanavk.wordpress.com/2011/01/08/matrix-multiplication-in-parallel-using-open-mpi/" target="_blank">https://anjanavk.wordpress.com/2011/01/08/matrix-multiplication-in-parallel-using-open-mpi/</a><br><br>regards <br><span class="HOEnZb"><font color="#888888">Ibrahim<br> 		 	   		  </font></span></div></div>
<br>_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" rel="noreferrer" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2015/10/27930.php" rel="noreferrer" target="_blank">http://www.open-mpi.org/community/lists/users/2015/10/27930.php</a><br></blockquote></div><br></div>

