are you saying both IP are the ones of the VM on which mpirun is running ?<div>orted is only launched on all the machines *except* the one running mpirun.</div><div><br></div><div>can you double/triple check the IPs are ok and unique ?</div><div>for example, mpirun --host &lt;internal IP&gt; /sbin/ifconfig -a</div><div>can you also make sure Open MPI is installed on all your VMs in the same directory ?</div><div>also make sure Open MPI has all the dependencies on all the VMs</div>ssh xxx ldd `which orted`<div>should show no missing dependency<br><div><br></div><div>generally speaking, I recommend you configure Open MPI with</div><div>--enable-mpirun-prefix-by-default</div><div><br></div><div>you can also try to replace</div><div>mpirun</div><div>with</div><div>`which mpirun`</div><div>or</div><div>mpirun --prefix &lt;path to Open MPI&gt;</div><div><br></div><div>Cheers,</div><div><br></div><div>Gilles<br><br>On Thursday, June 2, 2016, Ping Wang &lt;<a href="mailto:ping.wang@asc-s.de">ping.wang@asc-s.de</a>&gt; wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Hi,<br>
<br>
I&#39;ve installed Open MPI v1.10.2. Every VM on the cloud has two IPs (internal IP, public IP).<br>
When I run: mpirun --host &lt;internal IP&gt; hostname, the output is the hostname of the VM.<br>
But when I run: mpirun --host &lt;public IP&gt; hostname, the output is<br>
<br>
bash: orted: command not found<br>
--------------------------------------------------------------------------<br>
ORTE was unable to reliably start one or more daemons.<br>
This usually is caused by:<br>
<br>
* not finding the required libraries and/or binaries on<br>
  one or more nodes. Please check your PATH and LD_LIBRARY_PATH<br>
  settings, or configure OMPI with --enable-orterun-prefix-by-default<br>
<br>
* lack of authority to execute on one or more specified nodes.<br>
  Please verify your allocation and authorities.<br>
<br>
* the inability to write startup files into /tmp (--tmpdir/orte_tmpdir_base).<br>
  Please check with your sys admin to determine the correct location to use.<br>
<br>
*  compilation of the orted with dynamic libraries when static are required<br>
  (e.g., on Cray). Please check your configure cmd line and consider using<br>
  one of the contrib/platform definitions for your system type.<br>
<br>
* an inability to create a connection back to mpirun due to a<br>
  lack of common network interfaces and/or no route found between<br>
  them. Please check network connectivity (including firewalls<br>
  and network routing requirements).<br>
<br>
Both IPs are the IP of the VM where MPI is running. Did I do something wrong in the configuration?<br>
<br>
Thanks for any help.<br>
<br>
Ping<br>
<br>
-----Ursprüngliche Nachricht-----<br>
Von: users [mailto:<a href="javascript:;" onclick="_e(event, &#39;cvml&#39;, &#39;users-bounces@open-mpi.org&#39;)">users-bounces@open-mpi.org</a>] Im Auftrag von Jeff Squyres (jsquyres)<br>
Gesendet: Mittwoch, 1. Juni 2016 15:02<br>
An: Open MPI User&#39;s List<br>
Betreff: Re: [OMPI users] Firewall settings for MPI communication<br>
<br>
In addition, you might want to consider upgrading to Open MPI v1.10.x (v1.6.x is fairly ancient).<br>
<br>
&gt; On Jun 1, 2016, at 7:46 AM, Gilles Gouaillardet &lt;<a href="javascript:;" onclick="_e(event, &#39;cvml&#39;, &#39;gilles.gouaillardet@gmail.com&#39;)">gilles.gouaillardet@gmail.com</a>&gt; wrote:<br>
&gt;<br>
&gt; which network are your VMs using for communications ?<br>
&gt; if this is tcp, then you also have to specify a restricted set of<br>
&gt; allowed ports for the tcp btl<br>
&gt;<br>
&gt; that would be something like<br>
&gt; mpirun --mca btl_tcp_dynamic_ports 49990-50010 ...<br>
&gt;<br>
&gt; please double check the Open MPI 1.6.5 parameter and syntax with<br>
&gt; ompi_info --all (or check the archives, I think I posted the correct<br>
&gt; command line a few weeks ago)<br>
&gt;<br>
&gt; Cheers,<br>
&gt;<br>
&gt; Gilles<br>
&gt;<br>
&gt; On Wednesday, June 1, 2016, Ping Wang &lt;<a href="javascript:;" onclick="_e(event, &#39;cvml&#39;, &#39;ping.wang@asc-s.de&#39;)">ping.wang@asc-s.de</a>&gt; wrote:<br>
&gt; I&#39;m using Open MPI 1.6.5 to run OpenFOAM in parallel on several VMs on<br>
&gt; a cloud. mpirun hangs without any error messages. I think this is a<br>
&gt; firewall issue. Because when I open all the TCP ports(1-65535) in the<br>
&gt; security group of VMs, mpirun works well. However I was suggested to<br>
&gt; open as less ports as possible. So I have to limit MPI to run on a<br>
&gt; range of ports. I opened the port range 49990-50010 for MPI<br>
&gt; communication. And use command<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; mpirun --mca oob_tcp_dynamic_ports 49990-50010 -np 4 --hostfile machines simpleFoam –parallel.<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; But it still hangs. How can I specify a port range that OpenMPI will use? I appreciate any help you can provide.<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; Best,<br>
&gt;<br>
&gt; Ping Wang<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; &lt;image001.png&gt;<br>
&gt;<br>
&gt; ------------------------------------------------------<br>
&gt;<br>
&gt; Ping Wang<br>
&gt;<br>
&gt; Automotive Simulation Center Stuttgart e.V.<br>
&gt;<br>
&gt; Nobelstraße 15<br>
&gt;<br>
&gt; D-70569 Stuttgart<br>
&gt;<br>
&gt; Telefon: +49 711 699659-14<br>
&gt;<br>
&gt; Fax: +49 711 699659-29<br>
&gt;<br>
&gt; E-Mail: <a href="javascript:;" onclick="_e(event, &#39;cvml&#39;, &#39;ping.wang@asc-s.de&#39;)">ping.wang@asc-s.de</a><br>
&gt;<br>
&gt; Web: <a href="http://www.asc-s.de" target="_blank">http://www.asc-s.de</a><br>
&gt;<br>
&gt; Social Media: &lt;image002.gif&gt;/asc.stuttgart<br>
&gt;<br>
&gt; ------------------------------------------------------<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; users mailing list<br>
&gt; <a href="javascript:;" onclick="_e(event, &#39;cvml&#39;, &#39;users@open-mpi.org&#39;)">users@open-mpi.org</a><br>
&gt; Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">https://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
&gt; Link to this post:<br>
&gt; <a href="http://www.open-mpi.org/community/lists/users/2016/06/29340.php" target="_blank">http://www.open-mpi.org/community/lists/users/2016/06/29340.php</a><br>
<br>
<br>
--<br>
Jeff Squyres<br>
<a href="javascript:;" onclick="_e(event, &#39;cvml&#39;, &#39;jsquyres@cisco.com&#39;)">jsquyres@cisco.com</a><br>
For corporate legal information go to: <a href="http://www.cisco.com/web/about/doing_business/legal/cri/" target="_blank">http://www.cisco.com/web/about/doing_business/legal/cri/</a><br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="javascript:;" onclick="_e(event, &#39;cvml&#39;, &#39;users@open-mpi.org&#39;)">users@open-mpi.org</a><br>
Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">https://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2016/06/29342.php" target="_blank">http://www.open-mpi.org/community/lists/users/2016/06/29342.php</a><br>
<br>
<br>
<br>
_______________________________________________<br>
users mailing list<br>
<a href="javascript:;" onclick="_e(event, &#39;cvml&#39;, &#39;users@open-mpi.org&#39;)">users@open-mpi.org</a><br>
Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">https://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/users/2016/06/29349.php" target="_blank">http://www.open-mpi.org/community/lists/users/2016/06/29349.php</a></blockquote></div></div>

