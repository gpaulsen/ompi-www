Unless your cluster has some weird connection topology and you&#39;re trying to take advantage of that, collective is the best bet.<br><br><div class="gmail_quote">On Mon, Dec 13, 2010 at 4:26 PM, Eugene Loh <span dir="ltr">&lt;<a href="mailto:eugene.loh@oracle.com">eugene.loh@oracle.com</a>&gt;</span> wrote:<br>

<blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; border-left: 1px solid rgb(204, 204, 204); padding-left: 1ex;"><div class="im">David Mathog wrote:<br>
<br>
<blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; border-left: 1px solid rgb(204, 204, 204); padding-left: 1ex;">
Is there a rule of thumb for when it is best to contact N workers with<br>
MPI_Bcast vs. when it is best to use a loop which cycles N times and<br>
moves the same information with MPI_Send to one worker at a time?<br>
 <br>
</blockquote></div>
The rule of thumb is to use a collective whenever you can.  The rationale is that the programming should be easier/cleaner and the underlying MPI implementation has the opportunity to do something clever.<div class="im">

<br>
<br>
<blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; border-left: 1px solid rgb(204, 204, 204); padding-left: 1ex;">
For that matter, other than the coding semantics, is there any real<br>
difference between the two approaches?  That is, does MPI_Bcast really<br>
broadcast, daisy chain, or use other similar methods to reduce bandwidth<br>
use when distributing its message, or does it just go ahead and run<br>
MPI_Send in a loop anyway, but hide the details from the programmer?<br>
<br>
</blockquote></div>
I believe most MPI implementations, including OMPI, make an attempt to &quot;do the right thing&quot;.  Multiple algorithms are available and the best one is chosen based on run-time conditions.<br>
<br>
With any luck, you&#39;re better off with collective calls.  Of course, there are no guarantees.<div><div></div><div class="h5"><br>
_______________________________________________<br>
users mailing list<br>
<a href="mailto:users@open-mpi.org" target="_blank">users@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>
</div></div></blockquote></div><br><br clear="all"><br>-- <br>David Zhang<br>University of California, San Diego<br>

