<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" xmlns="http://www.w3.org/TR/REC-html40">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="Generator" content="Microsoft Word 15 (filtered medium)">
<style><!--
/* Font Definitions */
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0in;
	margin-bottom:.0001pt;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:#0563C1;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-priority:99;
	color:#954F72;
	text-decoration:underline;}
span.EmailStyle17
	{mso-style-type:personal-compose;
	font-family:"Calibri","sans-serif";
	color:windowtext;}
.MsoChpDefault
	{mso-style-type:export-only;
	font-family:"Calibri","sans-serif";}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
--></style><!--[if gte mso 9]><xml>
<o:shapedefaults v:ext="edit" spidmax="1026" />
</xml><![endif]--><!--[if gte mso 9]><xml>
<o:shapelayout v:ext="edit">
<o:idmap v:ext="edit" data="1" />
</o:shapelayout></xml><![endif]-->
</head>
<body lang="EN-US" link="#0563C1" vlink="#954F72">
<div class="WordSection1">
<p class="MsoNormal">Hi, I'm trying to run an OpenMPI 1.6.5 job across a set of nodes, some with Mellanox cards and some with Qlogic cards.&nbsp; I'm getting errors indicating &quot;At least one pair of MPI processes are unable to reach each other for MPI communications&quot;.&nbsp;
 As far as I can tell all of the nodes are properly configured and able to reach each other, via IP and non-IP connections.<o:p></o:p></p>
<p class="MsoNormal">I've also discovered that even if I turn off the IB transport via &quot;--mca btl tcp,self&quot; I'm still getting the same issue.<o:p></o:p></p>
<p class="MsoNormal">The test works fine if I run it confined to hosts with identical IB cards.<o:p></o:p></p>
<p class="MsoNormal">I'd appreciate some assistance in figuring out what I'm doing wrong.<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">Thanks,<o:p></o:p></p>
<p class="MsoNormal">Kevin<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">Here's a log of a failed run:<br>
<br>
&gt; mpirun -d --debug-daemons --mca btl tcp,self --mca orte_base_help_aggregate 0 --mca btl_base_verbose 100 -np 2 -machinefile foo.hosts /homes/kevin/alltoall.mpi-1.6.5<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] procdir: /tmp/openmpi-sessions-kevin@compute-g18-5.deepthought.umd.edu_0/63142/0/0<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] jobdir: /tmp/openmpi-sessions-kevin@compute-g18-5.deepthought.umd.edu_0/63142/0<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] top: openmpi-sessions-kevin@compute-g18-5.deepthought.umd.edu_0<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] tmp: /tmp<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] mpirun: reset PATH: /cell_root/software/openmpi/1.6.5/gnu/4.8.1/threaded/sys/bin:/cell_root/software/openmpi/1.6.5/gnu/4.8.1/threaded/sys/bin:/cell_r&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ftware/gcc/4.8.1/sys/bin:/cell_root/software/moab/bin:/cell_root/software/gold/bin:/usr/local/ofed/1.5.4/sbin:/usr/local/ofed/1.5.4/bin:/homes/kevin/bin:/homes/kevin/bin/amd64:/dept/oit/glue/&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
 scripts:/usr/local/scripts:/usr/local/bin:/usr/bin:/bin:/sbin:/usr/sbin:/usr/afsws/bin:/usr/afsws/etc<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] mpirun: reset LD_LIBRARY_PATH: /cell_root/software/openmpi/1.6.5/gnu/4.8.1/threaded/sys/lib:/usr/local/ofed/1.5.4/lib64<o:p></o:p></p>
<p class="MsoNormal">Daemon was launched on compute-g17-33.deepthought.umd.edu - beginning to initialize<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] procdir: /tmp/openmpi-sessions-kevin@compute-g17-33.deepthought.umd.edu_0/63142/0/1<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] jobdir: /tmp/openmpi-sessions-kevin@compute-g17-33.deepthought.umd.edu_0/63142/0<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] top: openmpi-sessions-kevin@compute-g17-33.deepthought.umd.edu_0<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] tmp: /tmp<o:p></o:p></p>
<p class="MsoNormal">Daemon [[63142,0],1] checking in as pid 20174 on host compute-g17-33.deepthought.umd.edu<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] [[63142,0],1] orted: up and running - waiting for commands!<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] [[63142,0],0] orted_cmd: received add_local_procs<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] [[63142,0],1] node[0].name compute-g18-5 daemon 0<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] [[63142,0],1] node[1].name compute-g17-33 daemon 1<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] [[63142,0],1] orted_cmd: received add_local_procs<o:p></o:p></p>
<p class="MsoNormal">&nbsp; MPIR_being_debugged = 0<o:p></o:p></p>
<p class="MsoNormal">&nbsp; MPIR_debug_state = 1<o:p></o:p></p>
<p class="MsoNormal">&nbsp; MPIR_partial_attach_ok = 1<o:p></o:p></p>
<p class="MsoNormal">&nbsp; MPIR_i_am_starter = 0<o:p></o:p></p>
<p class="MsoNormal">&nbsp; MPIR_forward_output = 0<o:p></o:p></p>
<p class="MsoNormal">&nbsp; MPIR_proctable_size = 2<o:p></o:p></p>
<p class="MsoNormal">&nbsp; MPIR_proctable:<o:p></o:p></p>
<p class="MsoNormal">&nbsp;&nbsp;&nbsp; (i, host, exe, pid) = (0, compute-g18-5.deepthought.umd.edu, /homes/kevin/alltoall.mpi-1.6.5, 20576)<o:p></o:p></p>
<p class="MsoNormal">&nbsp;&nbsp;&nbsp; (i, host, exe, pid) = (1, compute-g17-33, /homes/kevin/alltoall.mpi-1.6.5, 20175)<o:p></o:p></p>
<p class="MsoNormal">MPIR_executable_path: NULL<o:p></o:p></p>
<p class="MsoNormal">MPIR_server_arguments: NULL<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20576] procdir: /tmp/openmpi-sessions-kevin@compute-g18-5.deepthought.umd.edu_0/63142/1/0<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20576] jobdir: /tmp/openmpi-sessions-kevin@compute-g18-5.deepthought.umd.edu_0/63142/1<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20576] top: openmpi-sessions-kevin@compute-g18-5.deepthought.umd.edu_0<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20576] tmp: /tmp<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] [[63142,0],0] orted_recv: received sync&#43;nidmap from local proc [[63142,1],0]<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20576] [[63142,1],0] node[0].name compute-g18-5 daemon 0<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20576] [[63142,1],0] node[1].name compute-g17-33 daemon 1<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20175] procdir: /tmp/openmpi-sessions-kevin@compute-g17-33.deepthought.umd.edu_0/63142/1/1<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20175] jobdir: /tmp/openmpi-sessions-kevin@compute-g17-33.deepthought.umd.edu_0/63142/1<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20175] top: openmpi-sessions-kevin@compute-g17-33.deepthought.umd.edu_0<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20175] tmp: /tmp<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] [[63142,0],1] orted_recv: received sync&#43;nidmap from local proc [[63142,1],1]<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20175] [[63142,1],1] node[0].name compute-g18-5 daemon 0<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20175] [[63142,1],1] node[1].name compute-g17-33 daemon 1<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.e:20576] mca: base: components_open: Looking for btl components<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.e:20576] mca: base: components_open: opening btl components<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.e:20576] mca: base: components_open: found loaded component self<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.e:20576] mca: base: components_open: component self has no register function<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.e:20576] mca: base: components_open: component self open function successful<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.e:20576] mca: base: components_open: found loaded component tcp<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.e:20576] mca: base: components_open: component tcp register function successful<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.e:20576] mca: base: components_open: component tcp open function successful<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.:20175] mca: base: components_open: Looking for btl components<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.:20175] mca: base: components_open: opening btl components<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.:20175] mca: base: components_open: found loaded component self<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.:20175] mca: base: components_open: component self has no register function<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.:20175] mca: base: components_open: component self open function successful<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.:20175] mca: base: components_open: found loaded component tcp<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.:20175] mca: base: components_open: component tcp register function successful<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.:20175] mca: base: components_open: component tcp open function successful<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.:20175] select: initializing btl component self<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.:20175] select: init of component self returned success<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.:20175] select: initializing btl component tcp<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.:20175] btl: tcp: Searching for exclude address&#43;prefix: 127.0.0.1 / 8<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.:20175] btl: tcp: Found match: 127.0.0.1 (lo)<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.:20175] select: init of component tcp returned success<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.e:20576] mca: base: close: component self closed<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.e:20576] mca: base: close: unloading component self<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.e:20576] mca: base: close: component tcp closed<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.e:20576] mca: base: close: unloading component tcp<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] [[63142,0],0] orted_cmd: received message_local_procs<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] [[63142,0],1] orted_cmd: received message_local_procs<o:p></o:p></p>
<p class="MsoNormal">--------------------------------------------------------------------------<o:p></o:p></p>
<p class="MsoNormal">It looks like MPI_INIT failed for some reason; your parallel process is<o:p></o:p></p>
<p class="MsoNormal">likely to abort.&nbsp; There are many reasons that a parallel process can<o:p></o:p></p>
<p class="MsoNormal">fail during MPI_INIT; some of which are due to configuration or environment<o:p></o:p></p>
<p class="MsoNormal">problems.&nbsp; This failure appears to be an internal failure; here's some<o:p></o:p></p>
<p class="MsoNormal">additional information (which may only be relevant to an Open MPI<o:p></o:p></p>
<p class="MsoNormal">developer):<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">&nbsp; PML add procs failed<o:p></o:p></p>
<p class="MsoNormal">&nbsp; --&gt; Returned &quot;Error&quot; (-1) instead of &quot;Success&quot; (0)<o:p></o:p></p>
<p class="MsoNormal">--------------------------------------------------------------------------<o:p></o:p></p>
<p class="MsoNormal">*** An error occurred in MPI_Init<o:p></o:p></p>
<p class="MsoNormal">*** on a NULL communicator<o:p></o:p></p>
<p class="MsoNormal">*** MPI_ERRORS_ARE_FATAL: your MPI job will now abort<o:p></o:p></p>
<p class="MsoNormal">--------------------------------------------------------------------------<o:p></o:p></p>
<p class="MsoNormal">An MPI process is aborting at a time when it cannot guarantee that all<o:p></o:p></p>
<p class="MsoNormal">of its peer processes in the job will be killed properly.&nbsp; You should<o:p></o:p></p>
<p class="MsoNormal">double check that everything has shut down cleanly.<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">&nbsp; Reason:&nbsp;&nbsp;&nbsp;&nbsp; Before MPI_INIT completed<o:p></o:p></p>
<p class="MsoNormal">&nbsp; Local host: compute-g18-5.deepthought.umd.edu<o:p></o:p></p>
<p class="MsoNormal">&nbsp; PID:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 20576<o:p></o:p></p>
<p class="MsoNormal">--------------------------------------------------------------------------<o:p></o:p></p>
<p class="MsoNormal">--------------------------------------------------------------------------<o:p></o:p></p>
<p class="MsoNormal">At least one pair of MPI processes are unable to reach each other for<o:p></o:p></p>
<p class="MsoNormal">MPI communications.&nbsp; This means that no Open MPI device has indicated<o:p></o:p></p>
<p class="MsoNormal">that it can be used to communicate between these processes.&nbsp; This is<o:p></o:p></p>
<p class="MsoNormal">an error; Open MPI requires that all MPI processes be able to reach<o:p></o:p></p>
<p class="MsoNormal">each other.&nbsp; This error can sometimes be the result of forgetting to<o:p></o:p></p>
<p class="MsoNormal">specify the &quot;self&quot; BTL.<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">&nbsp; Process 1 ([[63142,1],1]) is on host: compute-g17-33.deepthought.umd.edu<o:p></o:p></p>
<p class="MsoNormal">&nbsp; Process 2 ([[63142,1],0]) is on host: compute-g18-5<o:p></o:p></p>
<p class="MsoNormal">&nbsp; BTLs attempted: self tcp<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">Your MPI job is now going to abort; sorry.<o:p></o:p></p>
<p class="MsoNormal">--------------------------------------------------------------------------<o:p></o:p></p>
<p class="MsoNormal">*** An error occurred in MPI_Init<o:p></o:p></p>
<p class="MsoNormal">*** on a NULL communicator<o:p></o:p></p>
<p class="MsoNormal">*** MPI_ERRORS_ARE_FATAL: your MPI job will now abort<o:p></o:p></p>
<p class="MsoNormal">--------------------------------------------------------------------------<o:p></o:p></p>
<p class="MsoNormal">MPI_INIT has failed because at least one MPI process is unreachable<o:p></o:p></p>
<p class="MsoNormal">from another.&nbsp; This *usually* means that an underlying communication<o:p></o:p></p>
<p class="MsoNormal">plugin -- such as a BTL or an MTL -- has either not loaded or not<o:p></o:p></p>
<p class="MsoNormal">allowed itself to be used.&nbsp; Your MPI job will now abort.<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">You may wish to try to narrow down the problem;<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">* Check the output of ompi_info to see which BTL/MTL plugins are<o:p></o:p></p>
<p class="MsoNormal">&nbsp;&nbsp; available.<o:p></o:p></p>
<p class="MsoNormal">* Run your application with MPI_THREAD_SINGLE.<o:p></o:p></p>
<p class="MsoNormal">* Set the MCA parameter btl_base_verbose to 100 (or mtl_base_verbose,<o:p></o:p></p>
<p class="MsoNormal">&nbsp;&nbsp; if using MTL-based communications) to see exactly which<o:p></o:p></p>
<p class="MsoNormal">&nbsp;&nbsp; communication plugins were considered and/or discarded.<o:p></o:p></p>
<p class="MsoNormal">--------------------------------------------------------------------------<o:p></o:p></p>
<p class="MsoNormal">--------------------------------------------------------------------------<o:p></o:p></p>
<p class="MsoNormal">An MPI process is aborting at a time when it cannot guarantee that all<o:p></o:p></p>
<p class="MsoNormal">of its peer processes in the job will be killed properly.&nbsp; You should<o:p></o:p></p>
<p class="MsoNormal">double check that everything has shut down cleanly.<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">&nbsp; Reason:&nbsp;&nbsp;&nbsp;&nbsp; Before MPI_INIT completed<o:p></o:p></p>
<p class="MsoNormal">&nbsp; Local host: compute-g17-33.deepthought.umd.edu<o:p></o:p></p>
<p class="MsoNormal">&nbsp; PID:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 20175<o:p></o:p></p>
<p class="MsoNormal">--------------------------------------------------------------------------<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] [[63142,0],1] orted_cmd: received waitpid_fired cmd<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] [[63142,0],1] orted_cmd: received iof_complete cmd<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] sess_dir_finalize: proc session dir not empty - leaving<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] sess_dir_finalize: proc session dir not empty - leaving<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] [[63142,0],0] orted_cmd: received iof_complete cmd<o:p></o:p></p>
<p class="MsoNormal">--------------------------------------------------------------------------<o:p></o:p></p>
<p class="MsoNormal">mpirun has exited due to process rank 1 with PID 20175 on<o:p></o:p></p>
<p class="MsoNormal">node compute-g17-33 exiting improperly. There are two reasons this could occur:<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">1. this process did not call &quot;init&quot; before exiting, but others in<o:p></o:p></p>
<p class="MsoNormal">the job did. This can cause a job to hang indefinitely while it waits<o:p></o:p></p>
<p class="MsoNormal">for all processes to call &quot;init&quot;. By rule, if one process calls &quot;init&quot;,<o:p></o:p></p>
<p class="MsoNormal">then ALL processes must call &quot;init&quot; prior to termination.<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">2. this process called &quot;init&quot;, but exited without calling &quot;finalize&quot;.<o:p></o:p></p>
<p class="MsoNormal">By rule, all processes that call &quot;init&quot; MUST call &quot;finalize&quot; prior to<o:p></o:p></p>
<p class="MsoNormal">exiting or it will be considered an &quot;abnormal termination&quot;<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
<p class="MsoNormal">This may have caused other processes in the application to be<o:p></o:p></p>
<p class="MsoNormal">terminated by signals sent by mpirun (as reported here).<o:p></o:p></p>
<p class="MsoNormal">--------------------------------------------------------------------------<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] [[63142,0],0] orted_cmd: received exit cmd<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] [[63142,0],1] orted_cmd: received exit cmd<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] [[63142,0],1] orted: finalizing<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] sess_dir_finalize: job session dir not empty - leaving<o:p></o:p></p>
<p class="MsoNormal">[compute-g17-33.deepthought.umd.edu:20174] sess_dir_finalize: job session dir not empty - leaving<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] [[63142,0],0] Releasing job data for [63142,0]<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] [[63142,0],0] Releasing job data for [63142,1]<o:p></o:p></p>
<p class="MsoNormal">[compute-g18-5.deepthought.umd.edu:20574] sess_dir_finalize: proc session dir not empty - leaving<o:p></o:p></p>
<p class="MsoNormal">orterun: exiting with status 1<o:p></o:p></p>
<p class="MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
</body>
</html>

