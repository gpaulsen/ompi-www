Hi David<br><br>You are quite correct. IIRC, we didn&#39;t bother checking the local_err because we found it to be unreliable - all Torque checks is that the program exec&#39;s. It doesn&#39;t report back an error if it segfaults instantly, for example, or aborts because it fails to find a required library. So we added a simple timer that declares the launch a failure if the daemon(s) fail to report back in a specified time.<br>
Hi David<br><br>This didn&#39;t cause any problems, so I went ahead and put it in our devel trunk. Barring any subsequent error reports, I&#39;ll move it over to the 1.3 series.<br><br>Thanks!<br>Ralph<br><br><div><br> </div>
<blockquote style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" class="gmail_quote">However, it can&#39;t hurt to check the flag as well. I&#39;ll test it out first just to ensure we don&#39;t get false failures.<br>
<br>Thanks<br>Ralph<br><br><blockquote style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" class="gmail_quote">On Aug 12, 2009, at 11:33 PM, David Singleton wrote:<br><br><br>Maybe this should go to the devel list but I&#39;ll start here.<br>
<br>In tracking the way the PBS tm API propagates error information<br>back to clients, I noticed that Open MPI is making an incorrect<br>assumption.  (I&#39;m looking 1.3.2.) The relevant code in<br>orte/mca/plm/tm/plm_tm_module.c is:<br>
<br>  /* TM poll for all the spawns */<br>  for (i = 0; i &lt; launched; ++i) {<br>      rc = tm_poll(TM_NULL_EVENT, &amp;event, 1, &amp;local_err);<br>      if (TM_SUCCESS != rc) {<br>          errno = local_err;<br>          opal_output(0, &quot;plm:tm: failed to poll for a spawned daemon,&quot;<br>
                         &quot; return status = %d&quot;, rc);<br>          goto cleanup;<br>      }<br>  }<br><br>My reading of the way the tm API works is that tm_poll() can (will)<br>return TM_SUCCESS(0) even when the tm_spawn event being waited on failed,<br>
i.e. local_err needs to be checked even if rc=0.  It looks like TM_<br>errors (rc values) are from tm protocol failures or incorrect calls<br>to tm.  local_err is to do with why the actual requested action failed<br>and is usually some sort of internal PBSE_ error code.  In fact it&#39;s<br>
probably always PBSE_SYSTEM (15010) - I think it is for tm_spawn().<br><br>Something like the following is probably closer to what is needed.<br><br>  /* TM poll for all the spawns */<br>  for (i = 0; i &lt; launched; ++i) {<br>
      rc = tm_poll(TM_NULL_EVENT, &amp;event, 1, &amp;local_err);<br>      if (TM_SUCCESS != rc) {<br>          errno = local_err;<br>          opal_output(0, &quot;plm:tm: failed to poll for a spawned daemon,&quot;<br>                         &quot; return status = %d&quot;, rc);<br>
          goto cleanup;<br>      }<br>    if (local_err!=0) {<br>          errno = local_err;<br>          opal_output(0, &quot;plm:tm: failed to spawn daemon,&quot;<br>                         &quot; error code = %d&quot;, errno );<br>
          goto cleanup;<br>      }<br>  }<br><br>I checked torque 2.3.3 to confirm that it&#39;s tm behaviour is the same as<br>OpenPBS in this respect. No idea about PBSPro.<br><br><br>David<br>_______________________________________________<br>
users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br></blockquote></blockquote>
<br>

