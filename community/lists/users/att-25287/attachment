<html><head><meta http-equiv="Content-Type" content="text/html charset=us-ascii"></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;"><br><div><div>On Sep 5, 2014, at 10:44 AM, McGrattan, Kevin B. Dr. &lt;<a href="mailto:kevin.mcgrattan@nist.gov">kevin.mcgrattan@nist.gov</a>&gt; wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><div lang="EN-US" link="blue" vlink="purple" style="font-family: Helvetica; font-size: 12px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><div class="WordSection1" style="page: WordSection1;"><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><span style="font-size: 11pt; font-family: Calibri, sans-serif; color: rgb(31, 73, 125);">I am testing a new cluster that we just bought, which is why I am loading things this way. I am deliberately increasing network traffic. But in general, we submit jobs intermittently with various numbers of MPI processes. I have read that a good strategy is to map by socket, which in our case means that we assign 2 MPI processes to node1, which has two sockets, 2 MPI processes to node2, and so on. For my test cases, each has 16 MPI processes, which means that each job is spread out over 8 nodes. Yes, if I were to always load up the entire cluster, I could map the way you suggest, but I am looking for a strategy that gives me optimum performance for small cluster loads and for large too.<o:p></o:p></span></div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><span style="font-size: 11pt; font-family: Calibri, sans-serif; color: rgb(31, 73, 125);">&nbsp;</span></div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><span style="font-size: 11pt; font-family: Calibri, sans-serif; color: rgb(31, 73, 125);">Can anyone confirm whether or not it is best to map by socket in cases where you have a light load on your cluster?</span></div></div></div></blockquote><div><br></div>It would be about the worst thing you can do, to be honest. Reason is that each socket is typically a separate NUMA region, and so the shared memory system would be sub-optimized in that configuration. It would be much better to map-by core to avoid the NUMA issues.</div><div><br></div><div>If you want multiple cores per process (say for threading purposes), then you can use the pe option to assign them - something like this:</div><div><br></div><div>--map-by core:pe=2</div><div><br></div><div>would map procs by core, with each process being bound to 2 cores. You'd want to make the pe count work out so that no process was bound across a socket boundary as that is really bad.</div><div><br></div><div>HTH</div><div>Ralph</div><div><br><blockquote type="cite"><div lang="EN-US" link="blue" vlink="purple" style="font-family: Helvetica; font-size: 12px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><div class="WordSection1" style="page: WordSection1;"><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><span style="font-size: 11pt; font-family: Calibri, sans-serif; color: rgb(31, 73, 125);"><o:p></o:p></span></div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><span style="font-size: 11pt; font-family: Calibri, sans-serif; color: rgb(31, 73, 125);">&nbsp;</span></div><div><div style="border-style: solid none none; border-top-color: rgb(181, 196, 223); border-top-width: 1pt; padding: 3pt 0in 0in;"><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><b><span style="font-size: 10pt; font-family: Tahoma, sans-serif;">From:</span></b><span style="font-size: 10pt; font-family: Tahoma, sans-serif;"><span class="Apple-converted-space">&nbsp;</span>users [<a href="mailto:users-bounces@open-mpi.org" style="color: purple; text-decoration: underline;">mailto:users-bounces@open-mpi.org</a>]<span class="Apple-converted-space">&nbsp;</span><b>On Behalf Of<span class="Apple-converted-space">&nbsp;</span></b>Jeff Squyres (jsquyres)<br><b>Sent:</b><span class="Apple-converted-space">&nbsp;</span>Friday, September 05, 2014 10:37 AM<br><b>To:</b><span class="Apple-converted-space">&nbsp;</span>Open MPI User's List<br><b>Subject:</b><span class="Apple-converted-space">&nbsp;</span>Re: [OMPI users] How does binding option affect network traffic?<o:p></o:p></span></div></div></div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><o:p>&nbsp;</o:p></div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;">I'm confused, then: why you wouldn't want to minimize the number of servers that a single job runs on?<o:p></o:p></div><div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><o:p>&nbsp;</o:p></div></div><div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;">I ask because it sounds to me like you're running 12 jobs, each with 1 process per server. &nbsp;And therefore all 12 jobs are running on each server, like this:<o:p></o:p></div></div><div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><o:p>&nbsp;</o:p></div></div><div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><span>&lt;image001.jpg&gt;</span><o:p></o:p></div></div><div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;">With this layout, you're thrashing the server networking resources -- you're forcing the maximum use of the network.<o:p></o:p></div></div><div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><o:p>&nbsp;</o:p></div></div><div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;">Why don't you pack the jobs in to as few servers as possible, and therefore use shared memory as much as possible, and as little network as possible? &nbsp;This is the conventional wisdom. &nbsp;...perhaps I'm missing something in your setup?<o:p></o:p></div></div><div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><o:p>&nbsp;</o:p></div></div><div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><span>&lt;image002.jpg&gt;</span><o:p></o:p></div></div><div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><o:p>&nbsp;</o:p></div></div><div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><o:p>&nbsp;</o:p></div><div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><br>On Sep 3, 2014, at 10:02 AM, McGrattan, Kevin B. Dr. &lt;<a href="mailto:kevin.mcgrattan@nist.gov" style="color: purple; text-decoration: underline;">kevin.mcgrattan@nist.gov</a>&gt;&nbsp;wrote:<br><br><br><o:p></o:p></div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;">No, there are 12 cores per node, and 12 MPI processes are assigned to each node. The&nbsp;total RAM usage is about 10% of available. We suspect that the problem might be the&nbsp;combination of MPI message passing and disk I/O to the master node, both of which&nbsp;are handled by Infiniband. But I do not know how to monitor the traffic, and I do&nbsp;not know how much is too much. Ganglia reports Gigabit Ethernet usage, but we're&nbsp;primarily using IB.&nbsp;<br><br>-----Original Message-----<br>From: users [<a href="mailto:users-bounces@open-mpi.org" style="color: purple; text-decoration: underline;">mailto:users-bounces@open-mpi.org</a>] On Behalf Of Jeff Squyres (jsquyres)<br>Sent: Tuesday, September 02, 2014 5:41 PM<br>To: Open MPI User's List<br>Subject: Re: [OMPI users] How does binding option affect network traffic?<br><br>Ah, ok -- I think I missed this part of the thread: each of your individual MPI&nbsp;processes suck up huge gobbs of memory.<br><br>So just to be clear, in general: you don't intend to run more MPI processes than&nbsp;cores per server, *and* you intend to run fewer MPI processes per server than would&nbsp;consume the entire amount of RAM.<br><br>Are both of those always correct (at the same time)?<br><br>If so, it sounds like the first runs that you posted about were heavily overloading&nbsp;the servers in terms of RAM usage. &nbsp;Specifically: if you were running out of&nbsp;(registered) RAM, I can understand why Open MPI would hang. &nbsp;We have a few known&nbsp;issues that the openib BTL will hang if it runs out of registered memory -- but this&nbsp;is such a small corner case (because no one runs that way) that we've honestly never&nbsp;bothered to fix the issue (it's actually a really complicated resource exhaustion&nbsp;issue -- it's kinda hard to know what the Right Thing is to do when you've run out&nbsp;of memory...).<br><br><br><br>On Sep 2, 2014, at 9:37 AM, McGrattan, Kevin B. Dr. &lt;<a href="mailto:kevin.mcgrattan@nist.gov" style="color: purple; text-decoration: underline;">kevin.mcgrattan@nist.gov</a>&gt;&nbsp;wrote:<br><br><br><o:p></o:p></div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;">Thanks for the advice. Our jobs vary in size, from just a few MPI processes to&nbsp;about 64. Jobs are submitted at random, which is why I want to map by socket. If&nbsp;the cluster is empty, and someone submits a job with 16 MPI processes, I would&nbsp;think it would run most efficiently if it used 8 nodes, 2 processes per node. If we&nbsp;just fill up two nodes as you suggest, we overload the RAM on those two nodes.<br><br>-----Original Message-----<br>From: users [<a href="mailto:users-bounces@open-mpi.org" style="color: purple; text-decoration: underline;">mailto:users-bounces@open-mpi.org</a>] On Behalf Of&nbsp;<a href="mailto:tmishima@jcity.maeda.co.jp" style="color: purple; text-decoration: underline;">tmishima@jcity.maeda.co.jp</a><br>Sent: Friday, August 29, 2014 5:24 PM<br>To: Open MPI Users<br>Subject: Re: [OMPI users] How does binding option affect network traffic?<br><br>Hi,<br><br>Your cluster is very similar to ours where Torque and OpenMPI is installed.<br><br>I would use this cmd line:<br><br>#PBS -l nodes=2:ppn=12<br>mpirun --report-bindings -np 16 &lt;executable file name&gt;<br><br>Here --map-by socket:pe=1 and -bind-to core is assumed as default setting.<br>Then, you can run 10 jobs independently and simultaneously beacause you have 20&nbsp;nodes totally.<br><br>While each node in your cluser has 12 cores, the nprocs per node running on a node&nbsp;is 8, which means 66.666 % use, not 100%.<br>I think this loss can not be avoided as long as you use 16*N MPI per job.<br>It's a kind of mismatch with your cluster which has 12 cores per node.<br>If you can use 12*N MPI per job, then it's most effective.<br>Is there any reason why you use 16*N MPI per job?<br><br>Tetsuya<br><br>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" style="color: purple; text-decoration: underline;">users@open-mpi.org</a><br>Subscription:<span class="Apple-converted-space">&nbsp;</span><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" style="color: purple; text-decoration: underline;">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>Link to this post:<span class="Apple-converted-space">&nbsp;</span><a href="http://www.open-mpi.org/community/lists/users/2014/08/25201.php" style="color: purple; text-decoration: underline;">http://www.open-mpi.org/community/lists/users/2014/08/25201.php</a><br>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" style="color: purple; text-decoration: underline;">users@open-mpi.org</a><br>Subscription:<span class="Apple-converted-space">&nbsp;</span><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" style="color: purple; text-decoration: underline;">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>Link to this post:<span class="Apple-converted-space">&nbsp;</span><a href="http://www.open-mpi.org/community/lists/users/2014/09/25220.php" style="color: purple; text-decoration: underline;">http://www.open-mpi.org/community/lists/users/2014/09/25220.php</a><o:p></o:p></div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><br><br>--&nbsp;<br>Jeff Squyres<br><a href="mailto:jsquyres@cisco.com" style="color: purple; text-decoration: underline;">jsquyres@cisco.com</a><br>For corporate legal information go to:&nbsp;<a href="http://www.cisco.com/web/about/doing_business/legal/cri/" style="color: purple; text-decoration: underline;">http://www.cisco.com/web/about/doing_business/legal/cri/</a><br><br>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" style="color: purple; text-decoration: underline;">users@open-mpi.org</a><br>Subscription:<span class="Apple-converted-space">&nbsp;</span><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" style="color: purple; text-decoration: underline;">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>Link to this post:<span class="Apple-converted-space">&nbsp;</span><a href="http://www.open-mpi.org/community/lists/users/2014/09/25233.php" style="color: purple; text-decoration: underline;">http://www.open-mpi.org/community/lists/users/2014/09/25233.php</a><br>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org" style="color: purple; text-decoration: underline;">users@open-mpi.org</a><br>Subscription:<span class="Apple-converted-space">&nbsp;</span><a href="http://www.open-mpi.org/mailman/listinfo.cgi/users" style="color: purple; text-decoration: underline;">http://www.open-mpi.org/mailman/listinfo.cgi/users</a><br>Link to this post:<span class="Apple-converted-space">&nbsp;</span><a href="http://www.open-mpi.org/community/lists/users/2014/09/25249.php" style="color: purple; text-decoration: underline;">http://www.open-mpi.org/community/lists/users/2014/09/25249.php</a><o:p></o:p></div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><o:p>&nbsp;</o:p></div><div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><br>--&nbsp;<br>Jeff Squyres<br><a href="mailto:jsquyres@cisco.com" style="color: purple; text-decoration: underline;">jsquyres@cisco.com</a><br>For corporate legal information go to:&nbsp;<a href="http://www.cisco.com/web/about/doing_business/legal/cri/" style="color: purple; text-decoration: underline;">http://www.cisco.com/web/about/doing_business/legal/cri/</a><o:p></o:p></div></div><div style="margin: 0in 0in 0.0001pt; font-size: 12pt; font-family: 'Times New Roman', serif;"><o:p>&nbsp;</o:p></div></div></div></div>_______________________________________________<br>users mailing list<br><a href="mailto:users@open-mpi.org">users@open-mpi.org</a><br>Subscription: http://www.open-mpi.org/mailman/listinfo.cgi/users<br>Link to this post:<span class="Apple-converted-space">&nbsp;</span><a href="http://www.open-mpi.org/community/lists/users/2014/09/25281.php" style="color: purple; text-decoration: underline;">http://www.open-mpi.org/community/lists/users/2014/09/25281.php</a></div></blockquote></div><br></body></html>
