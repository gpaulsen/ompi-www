<div dir="ltr"><br><br>
<div class="gmail_quote">On Wed, Apr 15, 2009 at 3:51 AM, Jeff Squyres <span dir="ltr">&lt;<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">
<div class="im">On Apr 14, 2009, at 2:27 PM, Mike Dubman wrote:<br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">Ah, good point (python/java not perl).  But I think that lib/MTT/Reporter/GoogleDataStore.pm could still be a good thing -- we have invested a lot of time/effort into getting our particular mtt clients setup just the way we want them, setting up INI files, submitting to batch schedulers, etc.<br>
<br>A GoogleDataStore.pm reporter could well fork/exec a python/java executable to do the actual communication/storing of the data, right...?  More below.<br><br>completely agree, once we have external python/java/cobol scripts to manipulate GDS objects, we should wrap it by perl and call from MTT in same way like it works today for submitting to the postgress.<br>
</blockquote><br></div>So say we all!  :-)<br><br>(did they show Battlestar Gallactica in Israel?  :-) ) 
<div class="im"><br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">sounds good, we should introduce some guid (like pid) for mtt session, where all mtt results generated by this session will be referring to this guid.  Later we use this guid to submit partial results as they become ready and connect it to the appropriate mtt session object (see models.py)<br>
</blockquote><br></div>I *believe* have have 2 values like this in the MTT client already:<br><br>- an ID that represents a single MTT client run<br>- an ID that represents a single MTT mpi install-&gt;test build-&gt;test run tree 
<div class="im"><br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">I think that Ethan was asking was: can&#39;t MTT run Fluent and then use the normal Reporter mechanism to report the results into whatever back-end data store we have?  (postgres or GDS)<br>
<br>ahhh, okie, i see.<br><br>Correct me if Im wrong, the current mtt implementation allows following way of executing mpi test:<br>/path/to/mpirun &lt;mpirun options&gt; &lt;test&gt;<br></blockquote><br></div>Yes and no; it&#39;s controlled by the mpi details section, right?  You can put whatever you want in there. 
<div class="im"><br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">Many mpi based applications have embedded MPI libraries and non-standard way to start it, one should set env variable to point to desired mpi installation or pass it as cmd line argument, for example:<br>
<br>for fluent:<br><br>export OPENMPI_ROOT=/path/to/openmpi<br>fluent &lt;cmd line args&gt;<br><br><br>for pamcrash:<br>pamworld -np 2 -mpidir=/path/to/openmpi/dir ....<br><br>Im not sure if it is possible to express that execution semantic in mtt ini file. Please suggest.<br>
So far, it seems that such executions can be handled externally from mtt but using same object model.<br></blockquote><br></div>Understood.  I think you *could* get MTT to run these with specialized mpi details sections.  But it may or may not be worth it. 
<div class="im"><br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">For the attachment...<br><br>I can &quot;sorta read&quot; python, but I&#39;m not familiar with its intricacies and its internal APIs.<br>
<br>- models.py: looks good.  I don&#39;t know if *all* the fields we have are listed here; it looks fairly short to me.  Did you attempt to include all of the fields we submit through the various phases in Reporter are there, or did you intentionally leave some out?  (I honestly haven&#39;t checked; it just &quot;feels short&quot; to me compared to our SQL schema).<br>
<br>I listed only some of the fields in every object representing specific test result source (called phase in mtt language).<br></blockquote><br></div>Ok.  So that&#39;s only a sample -- just showing an example, not necessarily trying to be complete.  Per Ethan&#39;s comments, there are a bunch of other fields that we have and/or we might just be able to &quot;tie them together&quot; in GDS.  I.e., our data is hierarchical -- it worked well enough in SQL because you could just have one record about a test build refer to another record about the corresponding mpi install.  And so on.  Can we do something similar in GDS? 
<div class="im"></div></blockquote>
<div> </div>
<div> </div>
<div>yep, actually in GDS it should be much easier to have hierarchy, because it is OO storage. We just need to map all object relations and put it in models.py - gds will do the rest :)</div>
<div> </div>
<div> </div>
<div> </div>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">
<div class="im"><span id=""></span><br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">This is because every test result source object is derived from python provided db.Expando class. This gives us great flexibility, like adding dynamic attributes for every objects, for example:<br>
<br>obj = new MttBuildPhaseResult()<br>obj.my_favorite_dynamic_key = &quot;hello&quot;<br>obj.my_another_dynamic_key = 7<br><br>So, we can have all phase attributes in the phase object without defining it in the *sql schema way*. Also we can query object model by these dynamic keys.<br>
</blockquote><br></div>Hmm.  Ok, so you&#39;re saying that we define a &quot;phase object&quot; (for each phase) with all the fields that we expect to have, but if we need to, we can create fields on the fly, and google will just &quot;do the right thing&quot; and associate *all* the data (the &quot;expected&quot; fields and the &quot;dynamic&quot; fields) together? </blockquote>

<div> </div>
<div>yep. correct. We can define only static attributes (which we know for sure should present in every object of given type and leave phase specific attributes to stay dynamic)</div>
<div> </div>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid"><span id=""></span>
<div class="im"><br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">--&gt; meta question: is it in the zen of GDS to not have too many index fields like you would in SQL?  I.e., if you want to do an operation on GDS that you<br>
<br>as far as it seems now, gds creates indexes automatically and also provides API to define indexes manually.<br>would typically use an SQL index field for, is the idea that you would do a map/reduce to select the data instead of an index field?<br>
<br>yep. seems correct.<br></blockquote><br>K.<br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">- start_datastore.sh: hmm.  This script seems to imply that the datastore is *local*!  Don&#39;t we have to HTTP submit the results to Google?  More specifically: what is dev_appserver.py?  Is that, perchance, just a local proxy agent that will end up submitting our data to $datastore_path, which actually resides at Google?  Do we have to use a specific google username/URL to submit (and query) results?<br>
<br><br>You need to download google`s sdk (dev_appserver.py is a part of it). In order to develop for gds you  run your code inside sdk locally, and when feel comfortable with it - you upload it to the google cluster. In order to run attached example, you need to download sdk, put it in the following dir hierarchy:<br>
<br>somedir/sdk<br>somedir/vbench-dev<br><br>and run start_datastore.sh, which will run local instance of GDS on your machine.Then in another shell you need to run vbech-dev.py, which simulates mtt client accessing GDS, storing some objects in according to proposed models and then running some sql-like quires to fetch and manipulate results.<br>
<br>see <a href="http://code.google.com/appengine/docs/python/gettingstarted/devenvironment.html" target="_blank">http://code.google.com/appengine/docs/python/gettingstarted/devenvironment.html</a><br></blockquote><br></div>
Ah, I see.  Makes sense. 
<div class="im"><br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">- there&#39;s no comments in vbench-dev.py -- can you explain what&#39;s going on in there?  Can you explain how we would use these scripts?<br>
<br>This is a mtt simulator, it implements google appengine API to receive HTTP requests and call appropriate callbacks. (there is a map of specific urls to callbacks).<br><br>The main callback (which intercepts http GET requests to specific URL) runs the test code which creates objects defined in models.py, groups many test results into MTTSession and they run some queries to access previously created objects.<br>
<br>The real mtt client will use URL pointing to MTT python code running at google`s cluster, and use near same code to create/query/manipulate objects defined in models.py.<br></blockquote></div></blockquote>
<div> </div>
<div> </div>
<div> </div>
<div>The GDS API allows to specify onGET() and onPOST() callbacks which will be called by appengine on user requests.</div>
<div>I used that API in the attached samle just as a shortest way to play with GDS (create, save, query objects).</div>
<div>I think that GDS enabled mtt client will use smth like that:</div>
<div> </div>
<div>GOOGLE_PROVIDED_URL_FOR_MTT = <a href="http://mtt.google.com/db">http://mtt.google.com/db</a></div>
<div>db = new DB(GOOGLE_PROVIDED_URL_FOR_MTT)</div>
<div> </div>
<div>mttSessions = db.query(&quot;select * from TestSessions&quot;)</div>
<div>foreach session from mttSessions {</div>
<div>     // do smth, find sesion phase objects or whatever</div>
<div>}</div>
<div> </div>
<div> </div>
<div>So, we will not need explicit access by http GET/POST to the GDS. We will use GDS remote api. The remote api will wrap all its calls by post/get semantic.</div>
<div> </div>
<div>We will need GET/POST access only to implement mtt results viewer applet which will be hosted @google.</div>
<div> </div>
<div> </div>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">
<div class="im"><span id=""></span><br></div>Ok.  But this code should really be intercepting PUT (or POST) requests, not GET, right?<br><br>I ask because the MTT client currently POST&#39;s the data to send it via HTTP to the remote server. 
<div class="im"><br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">- it *looks* like these scripts are for storing data out in the GDS.  Have you looked at the querying side?  Do we know that storing data in the form you listed in models.py are easily retrievable in the ways that we want?  E.g., can you mock up queries that resemble the queries we currently have in our web-based query system today, just to show that storing the data in this way will actually allow us to do the kinds of queries that we want to do?<br>
<br>I think vbench-dev.py shows some querying capabilities for stored objects, there are many ways to query objects by object CLASS and Attributes.<br>see many examples here:<br><br>see <a href="http://code.google.com/appengine/docs/python/gettingstarted/usingdatastore.html" target="_blank">http://code.google.com/appengine/docs/python/gettingstarted/usingdatastore.html</a> for more querying examples we can use.<br>
</blockquote><br></div>Ok.<br><br>My only point is that we might want to think a little about the queries we want to do when designing the interfaces to stuff all the data into the GDS -- it may be helpful to have *some* structure to the data that goes into GDS if it helps the queries that we ultimately want to do.<br>
<br>Do you want to try making queries for the data that you&#39;re shoving into GDS that simulate some of the same queries that we can perform today?  This will just help validate a) that we can move current functionality up to GDS, and b) we can easily make up some new queries that we *can&#39;t* easily do on postgres today -- it might be fun/useful to see if GDS can handle such queries.</blockquote>

<div> </div>
<div>agree, the 1st milestone is to have script to submit results to GDS by using remote GDS API, also ptovide some basic query capabilities for text reporting (by using same remote API).</div>
<div> </div>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid"><span id=""></span><br><br>Maybe the first goal should be -- once you guys get a good understanding of using GDS -- will be to have an MTT Reporter that we can all start using to start stuffing data into GDS.  Once we have a bit of data out there, you can start trying to query the data and see what kinds of capabilities the query side has. Since we have basically limitless ability to generate data to submit into GDS :-), if we screw up the first few model definitions and end up wiping the data and starting over during this development process, it&#39;s no big deal -- just wait one day and the GDS will be populated again with new data from our MTT runs.  :-)<br>
<br>What do you think? 
<div class="im"><br></div></blockquote>
<div> </div>
<div> </div>
<div>actually, the attached example allows easy creation and quering of objects in GDS. We will rewrite it to use GDS remote API and will play with it.</div>
<div> </div>
<div> </div>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">
<div class="im"><span id=""></span><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">In short: I think I&#39;m missing much of the back-story / rationale of how the scripts in your tarball work / are to be used.<br>
<br>BTW -- if it&#39;s useful to have a teleconference about this kind of stuff, I can host a WebEx meeting.  WebEx has local dialins around the world, including Israel...<br><br><br>sure, what about next week?<br></blockquote>
<br></div>I have a Doodle account -- let&#39;s try that to do the scheduling:<br><br>   <a href="http://doodle.com/gzpgaun2ef4szt29" target="_blank">http://doodle.com/gzpgaun2ef4szt29</a><br><br>Ethan, Josh, and I are all in US Eastern timezone (I don&#39;t know if Josh will participate), so that might make scheduling *slightly* easier.  I started timeslots at 8am US Eastern and stopped as 2pm US Eastern -- that&#39;s already pretty late in Israel.  I also didn&#39;t list Friday, since that&#39;s the weekend in Israel.</blockquote>

<div> </div>
<div>can we do it on your morining? (our after noon) :)</div>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid"><span id=""></span><br><font color="#888888"><br>-- <br>Jeff Squyres<br>Cisco Systems<br><br></font></blockquote>
</div><br></div>

