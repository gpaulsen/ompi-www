Hi,<div><br></div><div>I&#39;ve noted that <span style="color:rgb(34,34,34);font-family:arial,sans-serif;font-size:12.800000190734863px;background-color:rgb(255,255,255)">hwloc_set_area_membind_</span><span style="color:rgb(34,34,34);font-family:arial,sans-serif;font-size:12.800000190734863px;background-color:rgb(255,255,255)">nodeset return -1 but errno is not equal to EXDEV or ENOSYS. I supposed that these two case was the two unique possibly.</span></div>
<div><font color="#222222" face="arial, sans-serif"><br></font></div><div><font color="#222222" face="arial, sans-serif">From the hwloc documentation:</font></div><div><font color="#222222" face="arial, sans-serif"><br></font></div>
<div><font color="#222222" face="arial, sans-serif"><div>-1 with errno set to ENOSYS if the action is not supported</div><div>-1 with errno set to EXDEV if the binding cannot be enforced</div><div><br></div><div><br></div>
<div>Any other binding failure reason? The memory available is enought.</div></font><br><div class="gmail_quote">2012/9/5 Brice Goglin <span dir="ltr">&lt;<a href="mailto:Brice.Goglin@inria.fr" target="_blank">Brice.Goglin@inria.fr</a>&gt;</span><br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
  
    
  
  <div bgcolor="#FFFFFF" text="#000000">
    Hello Gabriele,<br>
    <br>
    The only limit that I would think of is the available physical
    memory on each NUMA node (numactl -H will tell you how much of each
    NUMA node memory is still available).<br>
    malloc usually only fails (it returns NULL?) when there no *virtual*
    memory anymore, that&#39;s different. If you don&#39;t allocate tons of
    terabytes of virtual memory, this shouldn&#39;t happen easily.<br>
    <br>
    Brice<br>
    <br>
    <br>
    <br>
    <br>
    Le 05/09/2012 14:27, Gabriele Fatigati a écrit :
    <blockquote type="cite"><div><div class="h5">Dear Hwloc users and developers,
      <div><br>
      </div>
      <div><br>
      </div>
      <div>I&#39;m using hwloc 1.4.1 on a multithreaded program in a Linux
        platform, where each thread bind many non contiguos pieces of a
        big matrix using in a very intensive way
        hwloc_set_area_membind_nodeset function:</div>
      <div><br>
      </div>
      <div>hwloc_set_area_membind_nodeset(topology, punt+offset, len,
        nodeset, HWLOC_MEMBIND_BIND, HWLOC_MEMBIND_THREAD |
        HWLOC_MEMBIND_MIGRATE);</div>
      <div><br>
      </div>
      <div>Binding seems works well, since the returned code from
        function is 0 for every calls.</div>
      <div><br>
      </div>
      <div>The problems is that after binding, a simple little new
        malloc fails, without any apparent reason.</div>
      <div><br>
      </div>
      <div>Disabling memory binding, the allocations works well.  Is
        there any knows problem if  hwloc_set_area_membind_nodeset is
        used intensively?</div>
      <div><br>
      </div>
      <div>Is there some operating system limit for memory pages
        binding?</div>
      <div><br>
      </div>
      <div>Thanks in advance.</div>
      <div>
        <div><br>
        </div>
        -- <br>
        Ing. Gabriele Fatigati<br>
        <br>
        HPC specialist<br>
        <br>
        SuperComputing Applications and Innovation Department<br>
        <br>
        Via Magnanelli 6/3, Casalecchio di Reno (BO) Italy<br>
        <br>
        <a href="http://www.cineca.it" target="_blank">www.cineca.it</a>                    Tel:  
        <a href="tel:%2B39%20051%206171722" value="+390516171722" target="_blank">+39 051 6171722</a><br>
        <br>
        g.fatigati [AT] <a href="http://cineca.it" target="_blank">cineca.it</a>       
           <br>
      </div>
      <br>
      <fieldset></fieldset>
      <br>
      </div></div><pre>_______________________________________________
hwloc-users mailing list
<a href="mailto:hwloc-users@open-mpi.org" target="_blank">hwloc-users@open-mpi.org</a>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/hwloc-users" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/hwloc-users</a></pre>
    </blockquote>
    <br>
  </div>

</blockquote></div><br><br clear="all"><div><br></div>-- <br>Ing. Gabriele Fatigati<br><br>HPC specialist<br><br>SuperComputing Applications and Innovation Department<br><br>Via Magnanelli 6/3, Casalecchio di Reno (BO) Italy<br>
<br><a href="http://www.cineca.it" target="_blank">www.cineca.it</a>                    Tel:   +39 051 6171722<br><br>g.fatigati [AT] <a href="http://cineca.it" target="_blank">cineca.it</a>           <br>
</div>

