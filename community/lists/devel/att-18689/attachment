<div dir="ltr"><div><div><div><div><div><div>Hello Nathan, Mike and all<br><br></div>Thank you for your responses. Let me rephrase them to make sure I understood them correctly, and please correct me if I didn&#39;t:<br><br></div>1. Atomics are (have been) used in OSHMEM in the current (v1) release<br></div>2. They are (will be) used in the MPI RMA in v2 release, which has not happened yet<br><br></div>I am sorry if I sound like I am nitpicking, but the reason I ask is that I am trying to implement a new BTL that I am supposed to demo on a customer&#39;s existing OMPI code base (which is obviously v1) but I am doing the development out of the master branch (to avoid porting later), so I am in a bit of spaghetti situation.<br><br></div>Thank you<br></div>Durga<br></div><div class="gmail_extra"><br clear="all"><div><div class="gmail_signature">Life is complex. It has real and imaginary parts.</div></div>
<br><div class="gmail_quote">On Fri, Mar 4, 2016 at 11:06 AM, Nathan Hjelm <span dir="ltr">&lt;<a href="mailto:hjelmn@lanl.gov" target="_blank">hjelmn@lanl.gov</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><span class=""><br>
On Thu, Mar 03, 2016 at 05:26:45PM -0500, dpchoudh . wrote:<br>
&gt;    Hello all<br>
&gt;<br>
&gt;    Here is a 101 level question:<br>
&gt;<br>
&gt;    OpenMPI supports many transports, out of the box, and can be extended to<br>
&gt;    support those which it does not. Some of these transports, such as<br>
&gt;    infiniband, provide hardware atomic operations on remote memory, whereas<br>
&gt;    others, such as iWARP, do not.<br>
&gt;<br>
&gt;    My question is: how (and where in the code base) does openMPI use this<br>
&gt;    feature, on those hardware that support it? What is the penalty, in terms<br>
&gt;    of additional code, runtime performance and all other considerations, on a<br>
&gt;    hardware that does not support it?<br>
<br>
</span>Network atomics are used for oshmem (see Mike&#39;s email) and MPI RMA. For<br>
RMA they are exposed through the BTL 3.0 interface on the v2.x branch<br>
and master. So far we have only really implemented compare-and-swap,<br>
atomic add, and atomic fetch-and-add. Compare-and-swap and fetch-and-add<br>
are required by our optimized RMA component (ompi/mca/osc/rdma).<br>
<span class="HOEnZb"><font color="#888888"><br>
-Nathan<br>
<br>
</font></span><br>_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" rel="noreferrer" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2016/03/18688.php" rel="noreferrer" target="_blank">http://www.open-mpi.org/community/lists/devel/2016/03/18688.php</a><br></blockquote></div><br></div>

