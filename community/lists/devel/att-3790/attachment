<span class="gmail_quote"><br></span><br><br><div><span class="q"><span class="gmail_quote">On 5/1/08, <b class="gmail_sendername">Mukesh K Srivastava</b> &lt;<a href="mailto:srimks11@gmail.com" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">srimks11@gmail.com</a>&gt; wrote:</span><blockquote class="gmail_quote" style="margin-top: 0; margin-right: 0; margin-bottom: 0; margin-left: 0; margin-left: 0.80ex; border-left-color: #cccccc; border-left-width: 1px; border-left-style: solid; padding-left: 1ex">
<div>Hi Lenny.</div><div>&nbsp;</div><div>Thanks for responding. To correct more - would like to know few things.</div><div>&nbsp;</div><div>(a) I did modify make_mpich makefile present in IMB-3.1/src folder giving the path for openmpi. Here I am using same mpirun as built from openmpi(v-1.2.5) also did mention in PATH &amp; LD_LIBRARY_PATH.</div>
<div>&nbsp;</div><div>(b) What is the command on console to run any new additional file with MPI API contents call. Do I need to add in Makefile.base of IMB-3.1/src folder or mentioning in console as a command it takes care alongwith &quot;$mpirun IMB-MPI1&quot;&nbsp;</div>
<div>&nbsp;</div><div>(c) Does IMB-3.1 need INB(Infiniband) or TCP support to complete it&#39;s Benchmark routine call, means do I need to configure and build OpnMPI with Infiniband stack too?</div></blockquote><div><br></div>
</span> IMB is a set of benchmarks that can be run between 1 and more machines<br>it calls for MPI API that does all the communication<br>MPI decides how to run ( IB or TCP or shared memory ) according to priorities&nbsp;and&nbsp;all&nbsp;possible&nbsp;ways&nbsp;to&nbsp;be&nbsp;connected&nbsp;to&nbsp;another&nbsp;host.<br>
<br>you can make your own benchmark or test program, compile it with mpicc and run<br>ex:<br>#mpicc -o hello_world hello_world.c<br>#mpirun -np 2 -H host1,host2 ./hello_world<br><br><br>#cat hello_world.c<br>/*<br> *      Hewlett-Packard Co., High Performance Systems Division<br>
  *<br> *      Function:       - example: simple &quot;hello world&quot;<br> *<br> *      $Revision: <a href="http://1.1.2.1" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">1.1.2.1</a> $<br> */<br>
<br>#include &lt;stdio.h&gt;<br>#include &lt;mpi.h&gt;<br><br>main(argc, argv)<br><br>int                     argc;<br>char                    *argv[];<br><br>{<br>        int             rank, size, len;<br>        char            name[MPI_MAX_PROCESSOR_NAME];<br>
        int to_wait = 0, sleep_diff = 0, max_limit = 0;<br>         double sleep_start = 0.0, sleep_now = 0.0;<br><br>        MPI_Init(&amp;argc, &amp;argv);<br>        MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);<br>        MPI_Comm_size(MPI_COMM_WORLD, &amp;size);<br>
<br>        MPI_Get_processor_name(name, &amp;len);<br><br>        if (argc &gt; 1)<br>        {<br>                to_wait = atoi(argv[1]);<br>        }<br><br>        //busy loop for debuging needs<br>        if (to_wait)<br>
        {<br>                sleep_start=MPI_Wtime();<br>                 while(1)<br>                {<br>                        max_limit++;<br>                        if(max_limit &gt; 100000000)<br>                        {<br>
                                fprintf(stdout,&quot;--------  exit loop, to_wait: %d, \n&quot;, to_wait);<br>                                 break;<br>                        }<br><br>                        sleep_now = MPI_Wtime();<br>
                        sleep_diff = (int)(sleep_now - sleep_start);<br>                        if(sleep_diff &gt;= to_wait)<br>                         {<br>                                break;<br>                        }<br>
                }<br>        }<br><br>        if (rank == 0) //only the first will print this message<br>        {<br>                printf (&quot;Hello world! I&#39;m %d of %d on %s\n&quot;, rank, size, name);<br>         }<br>
<br>        MPI_Finalize();<br>        exit(0);<div><span class="e" id="q_119a4eddf3e4c82a_3"><br>}<br><br><br><br><br><br><br><blockquote class="gmail_quote" style="margin-top: 0; margin-right: 0; margin-bottom: 0; margin-left: 0; margin-left: 0.80ex; border-left-color: #cccccc; border-left-width: 1px; border-left-style: solid; padding-left: 1ex">
<div>(d) I don&#39;t see any README in IMB-3.1 or anu user-guide which tells how to execute rather it simply tells about each 17 benchmark and flags to be used.</div><div>&nbsp;</div><div>BR<br><br>&nbsp;</div><div><span><div><span class="gmail_quote">On 4/30/08, <b class="gmail_sendername">Lenny Verkhovsky</b> &lt;<a href="mailto:lenny.verkhovsky@gmail.com" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">lenny.verkhovsky@gmail.com</a>&gt; wrote:</span> <blockquote class="gmail_quote" style="padding-left: 1ex; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0.80ex; border-left-color: #cccccc; border-left-width: 1px; border-left-style: solid">
<span class="gmail_quote"><br></span><br><br><div><div><span><span class="gmail_quote">On 4/30/08, <b class="gmail_sendername">Mukesh K Srivastava</b> &lt;<a href="mailto:srimks11@gmail.com" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">srimks11@gmail.com</a>&gt; wrote:</span>  <blockquote class="gmail_quote" style="padding-left: 1ex; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0.80ex; border-left-color: #cccccc; border-left-width: 1px; border-left-style: solid">
 Hi.<br><br>I am using IMB-3.1, an Intel MPI Benchmark tool with OpenMPI(v-1.2.5). In /IMB-3.1/src/make_mpich file, I had only given the decalartion for MPI_HOME, which takes care for CC, OPTFLAGS &amp; CLINKER. Building IMB_MPI1, IMP-EXT &amp; IMB-IO happens succesfully. <br>
<br>I get proper results of IMB Benchmark with command &quot;-np 1&quot; as mpirun IMB-MPI1, but for &quot;-np 2&quot;, I get below errors -<br><br>-----<br>[mukesh@n161 src]$ mpirun -np 2 IMB-MPI1<br>[n161:13390] *** Process received signal ***<br>
  [n161:13390] Signal: Segmentation fault (11)<br>[n161:13390] Signal code: Address not mapped (1)<br>[n161:13390] Failing at address: (nil)<br>[n161:13390] [ 0] /lib64/tls/libpthread.so.0 [0x399e80c4f0]<br>[n161:13390] [ 1] /home/mukesh/openmpi/prefix/lib/openmpi/mca_btl_sm.so [0x2a9830f8b4]<br>
  [n161:13390] [ 2] /home/mukesh/openmpi/prefix/lib/openmpi/mca_btl_sm.so [0x2a983109e3]<br>[n161:13390] [ 3] /home/mukesh/openmpi/prefix/lib/openmpi/mca_btl_sm.so(mca_btl_sm_component_progress+0xbc) [0x2a9830fc50]<br>[n161:13390] [ 4] /home/mukesh/openmpi/prefix/lib/openmpi/mca_bml_r2.so(mca_bml_r2_progress+0x4b) [0x2a97fce447]<br>
  [n161:13390] [ 5] /home/mukesh/openmpi/prefix/lib/libopen-pal.so.0(opal_progress+0xbc) [0x2a958fc343]<br>[n161:13390] [ 6] /home/mukesh/openmpi/prefix/lib/openmpi/mca_oob_tcp.so(mca_oob_tcp_msg_wait+0x22) [0x2a962e9e22]<br>
  [n161:13390] [ 7] /home/mukesh/openmpi/prefix/lib/openmpi/mca_oob_tcp.so(mca_oob_tcp_recv+0x677) [0x2a962f1aab]<br>[n161:13390] [ 8] /home/mukesh/openmpi/prefix/lib/libopen-rte.so.0(mca_oob_recv_packed+0x46) [0x2a9579d243]<br>
  [n161:13390] [ 9] /home/mukesh/openmpi/prefix/lib/openmpi/mca_gpr_proxy.so(orte_gpr_proxy_put+0x2f3) [0x2a96508c8f]<br>[n161:13390] [10] /home/mukesh/openmpi/prefix/lib/libopen-rte.so.0(orte_smr_base_set_proc_state+0x425) [0x2a957c391d]<br>
  [n161:13390] [11] /home/mukesh/openmpi/prefix/lib/libmpi.so.0(ompi_mpi_init+0xa1e) [0x2a9559f042]<br>[n161:13390] [12] /home/mukesh/openmpi/prefix/lib/libmpi.so.0(PMPI_Init_thread+0xcb) [0x2a955e1c5b]<br>[n161:13390] [13] IMB-MPI1(main+0x33) [0x403543]<br>
  [n161:13390] [14] /lib64/tls/libc.so.6(__libc_start_main+0xdb) [0x399e11c3fb]<br>[n161:13390] [15] IMB-MPI1 [0x40347a]<br>[n161:13390] *** End of error message ***<br>[n161:13391] *** Process received signal ***<br>[n161:13391] Signal: Segmentation fault (11)<br>
  [n161:13391] Signal code: Address not mapped (1)<br>[n161:13391] Failing at address: (nil)<br>[n161:13391] [ 0] /lib64/tls/libpthread.so.0 [0x399e80c4f0]<br>[n161:13391] [ 1] /home/mukesh/openmpi/prefix/lib/openmpi/mca_btl_sm.so [0x2a9830f8b4]<br>
  [n161:13391] [ 2] /home/mukesh/openmpi/prefix/lib/openmpi/mca_btl_sm.so [0x2a983109e3]<br>[n161:13391] [ 3] /home/mukesh/openmpi/prefix/lib/openmpi/mca_btl_sm.so(mca_btl_sm_component_progress+0xbc) [0x2a9830fc50]<br>[n161:13391] [ 4] /home/mukesh/openmpi/prefix/lib/openmpi/mca_bml_r2.so(mca_bml_r2_progress+0x4b) [0x2a97fce447]<br>
  [n161:13391] [ 5] /home/mukesh/openmpi/prefix/lib/libopen-pal.so.0(opal_progress+0xbc) [0x2a958fc343]<br>[n161:13391] [ 6] /home/mukesh/openmpi/prefix/lib/openmpi/mca_oob_tcp.so(mca_oob_tcp_msg_wait+0x22) [0x2a962e9e22]<br>
  [n161:13391] [ 7] /home/mukesh/openmpi/prefix/lib/openmpi/mca_oob_tcp.so(mca_oob_tcp_recv+0x677) [0x2a962f1aab]<br>[n161:13391] [ 8] /home/mukesh/openmpi/prefix/lib/libopen-rte.so.0(mca_oob_recv_packed+0x46) [0x2a9579d243]<br>
  [n161:13391] [ 9] /home/mukesh/openmpi/prefix/lib/libopen-rte.so.0 [0x2a9579e910]<br>[n161:13391] [10] /home/mukesh/openmpi/prefix/lib/libopen-rte.so.0(mca_oob_xcast+0x140) [0x2a9579d824]<br>[n161:13391] [11] /home/mukesh/openmpi/prefix/lib/libmpi.so.0(ompi_mpi_init+0xaf1) [0x2a9559f115]<br>
  [n161:13391] [12] /home/mukesh/openmpi/prefix/lib/libmpi.so.0(PMPI_Init_thread+0xcb) [0x2a955e1c5b]<br>[n161:13391] [13] IMB-MPI1(main+0x33) [0x403543]<br>[n161:13391] [14] /lib64/tls/libc.so.6(__libc_start_main+0xdb) [0x399e11c3fb]<br>
  [n161:13391] [15] IMB-MPI1 [0x40347a]<br>[n161:13391] *** End of error message ***<br><br>-----<br><br>Query#1: Any clue for above?</blockquote></span></div><div><br>It worked for me.<br><br>1.&nbsp;maybe&nbsp;mpirun&nbsp;belongs&nbsp;to&nbsp;another&nbsp;MPI. <br>
 2. try to define hosts ( -H host1,host2 )<br><br>&nbsp;</div><span><br><br><blockquote class="gmail_quote" style="padding-left: 1ex; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0.80ex; border-left-color: #cccccc; border-left-width: 1px; border-left-style: solid">
 Query#2:&nbsp; How can I include seperate exe file and have the IMB for it, e.g, writing a hello.c with MPI elementary API calls, compiling with mpicc and performing IMB for the same exe.?</blockquote></span><div><br>you&nbsp;have&nbsp;all the&nbsp;sorces&nbsp;<br>
 maybe in IMB&#39;s README you can find something<br><br>Best Regards,<br>Lenny<br>&nbsp;</div><br><blockquote class="gmail_quote" style="padding-left: 1ex; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0.80ex; border-left-color: #cccccc; border-left-width: 1px; border-left-style: solid">
 BR<br><br>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank" onclick="return top.js.OpenExtLink(window,event,this)">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote></div><br></blockquote></div><br></span></div></blockquote></span></div></div><br>

