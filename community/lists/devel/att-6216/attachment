Much appreciated!<br><br>Per some of my other comments on this thread and on the referenced ticket, can you tell me what kernel you have on that machine? I assume you have NUMA support enabled, given that chipset?<br><br>Thanks!<br>
Ralph<br><br><div class="gmail_quote">On Wed, Jun 10, 2009 at 10:29 AM, Sylvain Jeaugey <span dir="ltr">&lt;<a href="mailto:sylvain.jeaugey@bull.net">sylvain.jeaugey@bull.net</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
Hum, very glad that padb works with Open MPI, I couldn&#39;t live without it. In my opinion, the best debug tool for parallel applications, and more importantly, the only one that scales.<br>
<br>
About the issue, I couldn&#39;t reproduce it on my platform (tried 2 nodes with 2 to 8 processes each, nodes are twin 2.93 GHz Nehalem, IB is Mellanox QDR).<br>
<br>
So my feeling about that is that is may be very hardware related. Especially if you use the hierarch component, some transactions will be done through RDMA on one side and read directly through shared memory on the other side, which can, depending on the hardware, produce very different timings and bugs. Did you try with a different collective component (i.e. not hierarch) ? Or with another interconnect ? [Yes, of course, if it is a race condition, we might well avoid the bug because timings will be different, but that&#39;s still information]<br>

<br>
Perhaps all what I&#39;m saying makes no sense or you already thought about this, anyway, if you want me to try different things, just let me know.<br><font color="#888888">
<br>
Sylvain</font><div><div></div><div class="h5"><br>
<br>
On Wed, 10 Jun 2009, Ralph Castain wrote:<br>
<br>
<blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
Hi Ashley<br>
<br>
Thanks! I would definitely be interested and will look at the tool. Meantime, I have filed a bunch of data on this in<br>
ticket #1944, so perhaps you might take a glance at that and offer some thoughts?<br>
<br>
<a href="https://svn.open-mpi.org/trac/ompi/ticket/1944" target="_blank">https://svn.open-mpi.org/trac/ompi/ticket/1944</a><br>
<br>
Will be back after I look at the tool.<br>
<br>
Thanks again<br>
Ralph<br>
<br>
<br>
On Wed, Jun 10, 2009 at 8:51 AM, Ashley Pittman &lt;<a href="mailto:ashley@pittman.co.uk" target="_blank">ashley@pittman.co.uk</a>&gt; wrote:<br>
<br>
      Ralph,<br>
<br>
      If I may say this is exactly the type of problem the tool I have been<br>
      working on recently aims to help with and I&#39;d be happy to help you<br>
      through it.<br>
<br>
      Firstly I&#39;d say of the three collectives you mention, MPI_Allgather,<br>
      MPI_Reduce and MPI_Bcast one exhibit a many-to-many, one a many-to-one<br>
      and the last a many-to-one communication pattern.  The scenario of a<br>
      root process falling behind and getting swamped in comms is a plausible<br>
      one for MPI_Reduce only but doesn&#39;t hold water with the other two.  You<br>
      also don&#39;t mention if the loop is over a single collective or if you<br>
      have loop calling a number of different collectives each iteration.<br>
<br>
      padb, the tool I&#39;ve been working on has the ability to look at parallel<br>
      jobs and report on the state of collective comms and should help narrow<br>
      you down on erroneous processes and those simply blocked waiting for<br>
      comms.  I&#39;d recommend using it to look at maybe four or five instances<br>
      where the application has hung and look for any common features between<br>
      them.<br>
<br>
      Let me know if you are willing to try this route and I&#39;ll talk, the code<br>
      is downloadable from <a href="http://padb.pittman.org.uk" target="_blank">http://padb.pittman.org.uk</a> and if you want the full<br>
      collective functionality you&#39;ll need to patch openmp with the patch from<br>
      <a href="http://padb.pittman.org.uk/extensions.html" target="_blank">http://padb.pittman.org.uk/extensions.html</a><br>
<br>
      Ashley,<br>
<br>
      --<br>
<br>
      Ashley Pittman, Bath, UK.<br>
<br>
      Padb - A parallel job inspection tool for cluster computing<br>
      <a href="http://padb.pittman.org.uk" target="_blank">http://padb.pittman.org.uk</a><br>
<br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
<br>
<br>
<br>
</blockquote>
</div></div><br>_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br></blockquote></div><br>

