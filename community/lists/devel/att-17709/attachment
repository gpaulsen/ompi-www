<div dir="ltr">Gilles,<div><br></div><div>MOST of the automated tests I run when there is a new RC, are run on just the login nodes of cluster systems, or on workstations (no network).  So, many of my tests pass &quot;-mca btl sm,self&quot;.  Keep in mind that I am mainly focused on compile/link testing.  So, I run &quot;make check&quot; and build the examples directory, but I only run the ring_c test (which is hardly a stress test of any btl or mtl component).</div><div><br></div><div>The login nodes of the cluster systems have the headers and libs which match the compute nodes, and usually at least have the same network hardware.<br></div><div><br></div><div>This particular problem showed up when I tried to run tests manually on the compute nodes of one cluster.</div><div><br></div><div>In the case of the one specific system with the older (&quot;ConnectX XRC&quot;) OFED, the login nodes do NOT have the hardware fully configured for use (probably on purpose), resulting the openib blt component being rejected:</div><blockquote style="margin:0 0 0 40px;border:none;padding:0px"><font face="monospace, monospace">libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs2<br></font><font face="monospace, monospace">libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs1<br></font><font face="monospace, monospace">[cvrsvc04][[2535,1],1][/global/homes/h/hargrove/GSCRATCH/OMPI/openmpi-1.10.0rc2-linux-x86_64-icc-11.1/openmpi-1.10.0rc2/ompi/mca/btl/openib/btl_openib_component.c:1586:init_one_device] openib: RC QPs not supported -- skipping mlx4_0<br></font><font face="monospace, monospace">[cvrsvc04:00940] select: init of component openib returned failure</font></blockquote><div><br></div>







<div><br></div><div>-Paul<br><div class="gmail_extra"><br><div class="gmail_quote">On Sat, Jul 25, 2015 at 3:06 AM, Gilles Gouaillardet <span dir="ltr">&lt;<a href="mailto:gilles.gouaillardet@gmail.com" target="_blank">gilles.gouaillardet@gmail.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-color:rgb(204,204,204);border-left-style:solid;padding-left:1ex">Paul,<div><br></div><div>where do you run mpirun ?</div><div>on a compute node ?</div><div>on a login node with no infiniband interface ?</div><div>if on a login node, are the infiniband libraries at least available ?</div><div><br></div><div>Cheers,</div><div><br></div><div><span class="">Gilles<br><br>On Saturday, July 25, 2015, Paul Hargrove &lt;<a href="mailto:phhargrove@lbl.gov" target="_blank">phhargrove@lbl.gov</a>&gt; wrote:<br></span><blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-color:rgb(204,204,204);border-left-style:solid;padding-left:1ex"><div dir="ltr"><div><div class="h5">I know Gilles and I went to a fair amount of effort to get configure detection of &quot;older&quot; XRC working again for 1.8.7 (having been broken in 1.8.5 and 1.8.6).</div></div><div><div><div class="h5">However, I had tested on configuring and building the XRC support, but had not *run* it (because my test scripts execute on the login node with no IB interfaces).<div><br></div><div>What I saw today when 1.10.0rc2 (and confirmed in 1.8.7) on the actual compute nodes is the following:</div><div><br></div></div></div><div><div><div class="h5"><div><font face="monospace, monospace">mpirun -np 2 examples/ring_c&#39;</font></div><div><font face="monospace, monospace">[c0869][[27518,1],1][/global/homes/h/hargrove/GSCRATCH/OMPI/openmpi-1.8.7-linux-x86_64-icc-11.1/openmpi-1.8.7/ompi/mca/btl/openib/btl_openib_proc.c:155:mca_btl_openib_proc_create] [/global/homes/h/hargrove/GSCRATCH/OMPI/openmpi-1.8.7-linux-x86_64-icc-11.1/openmpi-1.8.7/ompi/mca/btl/openib/btl_openib_proc.c:155] ompi_modex_recv failed for peer [[27518,1],0]</font></div><div><font face="monospace, monospace">Process 0 sending 10 to 1, tag 201 (2 processes in ring)</font></div><div><font face="monospace, monospace">Process 0 sent to 1</font></div><div><font face="monospace, monospace">Process 0 decremented value: 9</font></div><div><font face="monospace, monospace">Process 0 decremented value: 8</font></div><div><font face="monospace, monospace">Process 0 decremented value: 7</font></div><div><font face="monospace, monospace">Process 0 decremented value: 6</font></div><div><font face="monospace, monospace">Process 0 decremented value: 5</font></div><div><font face="monospace, monospace">Process 0 decremented value: 4</font></div><div><font face="monospace, monospace">Process 0 decremented value: 3</font></div><div><font face="monospace, monospace">Process 0 decremented value: 2</font></div><div><font face="monospace, monospace">Process 0 decremented value: 1</font></div><div><font face="monospace, monospace">Process 0 decremented value: 0</font></div><div><font face="monospace, monospace">Process 0 exiting</font></div><div><font face="monospace, monospace">Process 1 exiting</font></div><div><font face="monospace, monospace">[c0869][[27518,1],1][/global/homes/h/hargrove/GSCRATCH/OMPI/openmpi-1.8.7-linux-x86_64-icc-11.1/openmpi-1.8.7/ompi/mca/btl/openib/btl_openib_xrc.c:57:mca_btl_openib_xrc_check_api] XRC error: bad XRC API (require XRC from OFED pre 3.12).</font></div><div><br></div><div><br></div><div>There are TWO things in there:</div><div>+ the modex failure</div><div>+ the &quot;bad XRC API&quot; error</div><div><br></div><div>I don&#39;t know what the source of the modex failure may be, but the &quot;bad XRC API&quot; message is from the following:</div><div><br></div><div><div><font face="monospace, monospace">    if (NULL != dlsym(lib, &quot;ibv_create_xrc_rcv_qp&quot;)) {</font></div><div><font face="monospace, monospace">        BTL_ERROR((&quot;XRC error: bad XRC API (require XRC from OFED pre 3.12).&quot;));</font></div><div><font face="monospace, monospace">        return false;</font></div><div><font face="monospace, monospace">    }</font></div></div><div><br></div><div>Yet, the symbol *is* in /usr/lib64/libibverbs.so:</div><div><br></div><div><div><font face="monospace, monospace">$ objdump -T /usr/lib64/libibverbs.so | grep ibv_create_xrc_rcv_qp</font></div><div><font face="monospace, monospace">0000000000009bd0 g    DF .text  0000000000000033  IBVERBS_1.1 ibv_create_xrc_rcv_qp</font></div></div><div><br></div><div><br></div><div>HOWEVER, there are other OFED installs on this system which are NOT in LD_LIBRARY_PATH.</div><div>None of those contain ibv_create_xrc_rcv_qp.</div><div><br></div><div><div>I am hoping this is some weird environment problem, but don&#39;t know how to test that theory.</div></div><div><div>If I can determine that /usr/lib64/libibverbs.so is *not* the library being loaded, then at least I know this is not an Open MPI problem.</div></div><div>So, how can I actually determine which libibverbs is getting loaded at runtime?</div><div>Is there some mca parameter that would help?</div><div><br></div><div>-Paul</div><div><br></div><div><br></div></div></div><div><br clear="all"><span class="HOEnZb"><font color="#888888"><div><br></div>-- <br></font></span><div><div dir="ltr"><div><font face="courier new, monospace"><span class="HOEnZb"><font color="#888888"><div>Paul H. Hargrove                          <a>PHHargrove@lbl.gov</a></div></font></span><span class=""><div>Computer Languages &amp; Systems Software (CLaSS) Group</div><div>Computer Science Department               Tel: <a href="tel:%2B1-510-495-2352" value="+15104952352" target="_blank">+1-510-495-2352</a></div><div>Lawrence Berkeley National Laboratory     Fax: <a href="tel:%2B1-510-486-6900" value="+15104866900" target="_blank">+1-510-486-6900</a></div></span></font></div></div></div>
</div></div></div></div>
</blockquote></div>
<br>_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" rel="noreferrer" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/07/17708.php" rel="noreferrer" target="_blank">http://www.open-mpi.org/community/lists/devel/2015/07/17708.php</a><br></blockquote></div><br><br clear="all"><div><br></div>-- <br><div class="gmail_signature"><div dir="ltr"><div><font face="courier new, monospace"><div>Paul H. Hargrove                          <a href="mailto:PHHargrove@lbl.gov" target="_blank">PHHargrove@lbl.gov</a></div><div>Computer Languages &amp; Systems Software (CLaSS) Group</div><div>Computer Science Department               Tel: +1-510-495-2352</div><div>Lawrence Berkeley National Laboratory     Fax: +1-510-486-6900</div></font></div></div></div>
</div></div></div>

