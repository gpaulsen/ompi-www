<html><head></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; ">Hi Ralph,<div><br></div><div>Very interesting the "composite framework" idea. Regarding to the schema represented by the picture, I didn't understand the RecoS' behaviour in a node failure situation.</div><div><br></div><div>In this case, will mpirun consider the daemon failure as a normal proc failure? If it is correct, should mpirun update the global procs state for all jobs running under the failed daemon?</div><div><br></div><div>Best regards,</div><div>Leonardo</div><div><br><div><div>On Feb 25, 2010, at 7:05 AM, Ralph Castain wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><div style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; ">Hi George et al<div><br></div><div>I have begun documenting the RecoS operation on the OMPI wiki:</div><div><br></div><div><a href="https://svn.open-mpi.org/trac/ompi/wiki/RecoS">https://svn.open-mpi.org/trac/ompi/wiki/RecoS</a></div><div><br></div><div>I'll continue to work on this over the next few days by adding a section explaining what was changed outside of the new framework to make it all work. In addition, I am revising the recos.h API documentation.</div><div><br></div><div>Hope to have all that done over the weekend.</div><div><br></div><div><br><div><div>On Feb 23, 2010, at 4:00 PM, Ralph Castain wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><div style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; "><br><div><div>On Feb 23, 2010, at 3:32 PM, George Bosilca wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><div>Ralph, Josh,<br><br>We have some comments about the API of the new framework, mostly clarifications needed to better understand how this new framework is supposed to be used. And a request for a deadline extension, to delay the code merge from the Recos branch in the trunk by a week.<br><br>We have our own FT branch, with a totally different approach than what is described in your RFC. Unfortunately, it diverged from the trunk about a year ago, and merging back had proven to be a quite difficult task. Some of the functionality in the Recos framework is clearly beneficial for what we did, and has the potential to facilitate the porting of most of the features from our brach back in trunk. We would like the deadline extension in order to deeply analyze the impact of the Recos framework on our work, and see how we can fit everything together back in the trunk of Open MPI.<br></div></blockquote><div><br></div>No problem with the extension - feel free to suggest modifications to make the merge easier. This is by no means cast in stone, but rather a starting point.</div><div><br><blockquote type="cite"><div><br>Here are some comments about the code:<br><br>1. The documentation in recos.h is not very clear. Most of the functions use only IN arguments, and are not supposed to return any values. We don't see how the functions are supposed to be used, and what is supposed to be their impact on the ORTE framework data.<br></div></blockquote><div><br></div>I'll try to clarify the comments tonight (I know Josh is occupied right now). The recos APIs are called from two locations:</div><div><br></div><div>1. The errmgr calls recos whenever it receives a report of an aborted process (via the errmgr.proc_aborted API). The idea was for recos to determine what (if anything) to do about the failed process.&nbsp;</div><div><br></div><div>2. The rmaps modules can call the recos "suggest_map_targets" API to get a list of suggested nodes for the process that is to be restarted. At the moment, only the resilient mapper module does this. However, Josh and I are looking at reorganizing some functionality currently in that mapper module and making all of the existing mappers be "resilient".</div><div><br></div><div>So basically, the recos modules determine the recovery procedure and execute it. For example, in the "orcm" module, we actually update the various proc/job objects to prep them for restart and call plm.spawn from within that module. If instead you use the ignore module, it falls through to the recos base functions which call "abort" to kill the job. Again, the action is taken local to recos, so nothing need be returned.</div><div><br></div><div>The functions generally don't return values (other than success/error) because we couldn't think of anything useful to return to the errmgr. Whatever recos does about an aborted proc, the errmgr doesn't do anything further - if you look in that code, you'll see that if recos is enabled, all the errmgr does is call recos and return.</div><div><br></div><div>Again, this can be changed if desired.</div><div><br><blockquote type="cite"><div><br>2. Why do we have all the char***? Why are they only declared as IN arguments?<br></div></blockquote><div><br></div>I take it you mean in the predicted fault API? I believe Josh was including that strictly as a placeholder. As you undoubtedly recall, I removed the fddp framework from the trunk (devel continues off-line), so Josh wasn't sure what I might want to input here. If you look at the modules themselves, you will see the implementation is essentially empty at this time.</div><div><br></div><div>We had discussed simply removing that API for now until we determined if/when fault prediction would return to the OMPI trunk. It was kind of a tossup - so we left if for now. Could just as easily be removed until a later date - either way is fine with us.</div><div><br><blockquote type="cite"><div><br>3. The orte_recos_base_process_fault_fn_t function use the node_list as an IN/OUT argument. Why? If the list is modified, then we have a scalability problem, as the list will have to be rebuilt before each call.</div></blockquote><div><br></div>Looking...looking...hmm.</div><div><br></div><div><div style="margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; font: normal normal normal 11px/normal Menlo; color: rgb(10, 135, 0); "><span style="color: rgb(183, 14, 163); ">typedef</span>&nbsp;<span style="color: rgb(183, 14, 163); ">int</span>&nbsp;(*orte_recos_base_process_fault_fn_t)</div><div style="margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; font: normal normal normal 11px/normal Menlo; ">&nbsp; &nbsp;&nbsp;(orte_job_t *jdata, orte_process_name_t *proec_name, orte_proc_state_t state,&nbsp;<span style="color: rgb(183, 14, 163); ">int</span>&nbsp;*stack_state);</div><div><font class="Apple-style-span" face="Menlo" size="3"><span class="Apple-style-span" style="font-size: 11px; "><br></span></font></div><span class="Apple-style-span" style="font-family: Menlo; font-size: 11px; "></span></div><div>There is no node list, or list of any type, going in or out of that function.&nbsp;<span class="Apple-style-span" style="font-size: 12px; ">I suspect you meant the one below it:</span><div><font class="Apple-style-span" face="Menlo" size="3"><span class="Apple-style-span" style="font-size: 11px;"><br></span></font></div><div><font class="Apple-style-span" face="Menlo" size="3"><span class="Apple-style-span" style="font-size: 11px;"><div style="margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; font: normal normal normal 11px/normal Menlo; "><span style="color: #b70ea3">typedef</span> <span style="color: #b70ea3">int</span> (*orte_recos_base_suggest_map_targets_fn_t)</div><div style="margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; font: normal normal normal 11px/normal Menlo; ">&nbsp; &nbsp; (orte_proc_t *proc, orte_node_t *oldnode, opal_list_t *node_list);</div><div><br></div><div><font class="Apple-style-span" face="Helvetica" size="3"><span class="Apple-style-span" style="font-size: 12px;">I concur with your concern about scalability here. However, I believe the idea was that we would pass in the proc that failed and is to be restarted, a pointer to the node it was last on, and return a list of candidate nodes where it could be restarted. Essentially, this is the equivalent of building the target node list that we do in the mappers whenever we map a job.</span></font></div><div><font class="Apple-style-span" face="Helvetica" size="3"><span class="Apple-style-span" style="font-size: 12px;"><br></span></font></div><div><font class="Apple-style-span" face="Helvetica" size="3"><span class="Apple-style-span" style="font-size: 12px;">So in the implementation, we use the rmaps base function to assemble the target node list for the app, and then go through some logic (e.g., remove the old node, look at fault groups and load balancing) to prune the list down. We then pass the resulting list back to the caller.</span></font></div><div><font class="Apple-style-span" face="Helvetica" size="3"><span class="Apple-style-span" style="font-size: 12px;"><br></span></font></div><div><font class="Apple-style-span" face="Helvetica" size="3"><span class="Apple-style-span" style="font-size: 12px;">If we are going to have frequent process failures, then rebuilding the candidate node list every time would indeed be a problem. I suspect we'll have to revisit that implementation at some point.</span></font></div><div><font class="Apple-style-span" face="Helvetica" size="3"><span class="Apple-style-span" style="font-size: 12px;"><br></span></font></div><div><font class="Apple-style-span" face="Helvetica" size="3"><span class="Apple-style-span" style="font-size: 12px;">HTH</span></font></div><div><font class="Apple-style-span" face="Helvetica" size="3"><span class="Apple-style-span" style="font-size: 12px;">Ralph</span></font></div><div><font class="Apple-style-span" face="Helvetica" size="3"><span class="Apple-style-span" style="font-size: 12px;"><br></span></font></div></span></font></div><blockquote type="cite"><div><br> &nbsp;Thanks,<br> &nbsp;&nbsp;&nbsp;george.<br><br>On Feb 19, 2010, at 12:59 , Ralph Castain wrote:<br><br><blockquote type="cite">WHAT: Merge a tmp branch for fault recovery development into the OMPI trunk<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">WHY: Bring over work done by Josh and Ralph to extend OMPI's fault recovery capabilities<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">WHERE: Impacts a number of ORTE files and a small number of OMPI files<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">TIMEOUT: Barring objections and/or requests for delay, the weekend of Feb 27-28<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">REFERENCE BRANCH: <a href="http://bitbucket.org/rhc/ompi-recos/overview/">http://bitbucket.org/rhc/ompi-recos/overview/</a><br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">======================================================================<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">BACKGROUND:<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">Josh and Ralph have been working on a private branch off of the trunk on extended fault recovery procedures, mostly impacting ORTE. The new code optionally allows ORTE to recover from failed nodes, moving processes to other nodes in order to maintain operation. In addition, the code provides better support for recovering from individual process failures.<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">Not all of the work done on the private branch will be brought over in this commit. Some of the MPI-specific code that allows recovery from process failure on-the-fly will be committed separately at a later date.<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">This commit will include the infrastructure to support those advanced recovery operations. Among other things, this commit will introduce a new "RecoS" (Recovery Service/Strategy) framework to allow multiple strategies for responding to failures. The default module, called "ignore", will stabilize the runtime environment for other RecoS components. In the absence of other RecoS components it will trigger the default behavior (abort the job) to be executed.<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">This branch includes some configure modifications that allow a comma separated list of options to be passed to the '--with-ft' option. This allows us to enable any combination of 'cr' and 'recos' at build time, specifically so that the RecoS functionally can be enabled independently of the C/R functionality. Most of the changes outside of the ORTE layer are due to symbol cleanup resulting from this modification.<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">For example, C/R specific code paths were previously incorrectly marked with:<br></blockquote><blockquote type="cite">#if OPAL_ENABLE_FT == 1<br></blockquote><blockquote type="cite">They are now marked as, where appropriate:<br></blockquote><blockquote type="cite">#if OPAL_ENABLE_FT_CR == 1<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">Additionally, C/R specific components have modified configure.m4 files to change:<br></blockquote><blockquote type="cite">AS_IF([test "$ompi_want_ft" = "0"],<br></blockquote><blockquote type="cite">to:<br></blockquote><blockquote type="cite">AS_IF([test "$ompi_want_ft_cr" = "0"],<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">We have created a public repo (reference branch, above) with the code to be merged into the trunk. Please feel free to check it out and test it.<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">NOTE: the new recovery capability is only active if...<br></blockquote><blockquote type="cite"> &nbsp;(a) you configure --with-ft=recos, and<br></blockquote><blockquote type="cite"> &nbsp;(b) you set OMPI_MCA_recos_base_enable=1 to turn it on!<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">Comments, suggestions, and corrections are welcome!<br></blockquote><blockquote type="cite"><br></blockquote><blockquote type="cite">_______________________________________________<br></blockquote><blockquote type="cite">devel mailing list<br></blockquote><blockquote type="cite"><a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br></blockquote><blockquote type="cite"><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br></blockquote><br><br>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br></div></blockquote></div><br></div></blockquote></div><br></div></div>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>http://www.open-mpi.org/mailman/listinfo.cgi/devel</blockquote></div><br></div></body></html>
