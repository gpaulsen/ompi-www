<html><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; ">Hi folks<div><br></div><div>We aren't running a full MTT here (which is why I'm reporting these results to the list instead of into the MTT database), but we are running a subset of tests on the 1.3 beta and hitting a consistent set of errors involving five tests. For reference, we see all of these tests pass on 1.2.6, but fail in the identical way on 1.2.8 - so it appears that something systematic may have entered the system and gotten into the 1.2 series as well.</div><div><br></div><div>The tests are:</div><div>MPI_Pack_user_type</div><div>MPI_Type_hindexed_blklen</div><div>MPI_Type_vector_stride</div><div>MPI_Cart_get_c</div><div>MPI_Graph_neighbors_c</div><div><br></div><div>The tests are running under slurm on RHEL5 with 16-cores of Opteron processors on each node plus IB. The below results are with 40 nodes at 16ppn.</div><div><br></div><div>Any thoughts would be appreciated. Meantime, we are trying different ppn to see if that has an impact.</div><div><br></div><div>Thanks</div><div>Ralph</div><div><br></div><div>Here is what we see:</div><div><br></div><div><blockquote type="cite"><blockquote type="cite">MPITEST error (585): 1 errors in buffer (17, 5) len 1024 commsize 214<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">commtype -14 extent 64 root 194 MPITEST error (591): Received buffer<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">overflow, Expected buffer[65536]: -197, Actual buffer[65536]: 59<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">MPITEST<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">error (591): 1 errors in buffer (17, 5) len 1024 commsize 214<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">commtype -14<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">extent 64 root 196<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">MPITEST_results: MPI_Pack_user_type 60480 tests FAILED (of 21076704)<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">MPITEST error (597): Received buffer overflow, Expected<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">buffer[16384]: -199,<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Actual buffer[16384]: 57 MPITEST error (597): 1 errors in buffer<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">(17, 5) len<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">16 commsize 214 commtype<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">-14 extent 64 root 198<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">MPITEST error (585): Received buffer overflow, Expected<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">buffer[16384]: -195,<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Actual buffer[16384]: 61 MPITEST error (585): 1 errors in buffer<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">(17, 5) len<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">16 commsize 214 commtype<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">-14 extent 64 root 194<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">MPITEST_results: MPI_Type_hindexed_blklen 60480 tests FAILED (of<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">21076704)<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">MPITEST error (597): Received buffer overflow, Expected<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">buffer[65536]: -199,<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Actual buffer[65536]: 57 MPITEST error (597): 1 errors in buffer<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">(17, 5) len<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">512 commsize 214 commtype -14 extent 64 root 198 MPITEST error (615):<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">Received buffer overflow, Expected buffer[65536]: -205, Actual<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">buffer[65536]: 51 MPITEST error (615): 1 errors in buffer (17, 5)<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">len 512<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">commsize 214 commtype -14 extent 64 root 204<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">MPITEST_results: MPI_Type_vector_stride 60480 tests FAILED (of<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">21076704)<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">[lob097:32556] *** Process received signal *** mpirun noticed that<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">job rank<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">0 with PID 32556 on node lob097 exited on signal 11 (Segmentation<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">fault).<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">639 additional processes aborted (not shown)<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">make[1]: *** [MPI_Cart_get_c] Error 139<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">MPITEST fatal error (568): MPI_ERR_COMM: invalid communicator<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">MPITEST fatal<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">error (572): MPI_ERR_COMM: invalid communicator MPITEST fatal error<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">(574):<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">MPI_ERR_COMM: invalid communicator mpirun noticed that job rank 37<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">with PID<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">32074 on node lob099 exited on signal 1 (Hangup).<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">18 additional processes aborted (not shown)<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">make[1]: *** [MPI_Graph_neighbors_c] Error 1<br></blockquote><div><font class="Apple-style-span" color="#006312"><br></font></div></blockquote><br><blockquote type="cite"></blockquote></div><div>Here is how the different versions are built:</div><div><br></div><div>1.2.6 and 1.2.8</div><div><blockquote type="cite"><blockquote type="cite">oob_tcp_connect_timeout=600<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">pml_ob1_use_early_completion=0<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">mca_component_show_load_errors=0<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">btl_openib_ib_retry_count=7<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">btl_openib_ib_timeout=31<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">mpi_keep_peer_hostnames=1<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">RPMBUILD parameters<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">setenv CPPFLAGS -I/opt/panfs/include<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">setenv CFLAGS -I/opt/panfs/include<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">rpmbuild -bb ./SPECS/loboopenmpi128.spec \<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">--with gcc \<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">--with root=/opt/OpenMPI \<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">--with shared \<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">--with openib \<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">--with slurm \<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">--without pty_support \<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">--without dlopen \<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">--with io_romio_flags=--with-file-system=ufs+nfs+panfs<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite"><br></blockquote></blockquote><blockquote type="cite"></blockquote></div><div><br></div><div><br></div><div><br></div><div>1.3beta</div><div><div><br></div><div></div><blockquote type="cite"><blockquote type="cite"><div># Basic behavior to smooth startup</div><div>mca_component_show_load_errors = 0</div><div><span class="Apple-style-span" style="-webkit-text-stroke-width: -1; ">orte_abort_timeout = 10&nbsp;</span></div><div>opal_set_max_sys_limits = 1</div><div><br></div><div>## Protect the shared file systems</div><div>orte_no_session_dirs = /panfs,/scratch,/users,/usr/projects</div><div>orte_tmpdir_base = /tmp</div><div><br></div><div>## Require an allocation to run - protects the frontend</div><div>## from inadvertent job executions</div><div>orte_allocation_required = 1</div><div><br></div><div>## Add the interface for out-of-band communication</div><div>## and set it up</div><div>oob_tcp_if_include=ib0&nbsp;</div><div>oob_tcp_peer_retries = 10&nbsp;</div><div>oob_tcp_disable_family = IPv6&nbsp;</div><div>oob_tcp_listen_mode = listen_thread</div><div>oob_tcp_sndbuf = 32768</div><div>oob_tcp_rcvbuf = 32768</div><div><br></div><div>## Define the MPI interconnects</div><div>btl = sm,openib,self&nbsp;</div><div><br></div><div>## Setup OpenIB</div><div>btl_openib_want_fork_support = 0</div><div>btl_openib_cpc_include = oob&nbsp;</div><div>#btl_openib_receive_queues = P,128,256,64,32,32:S,2048,1024,128,32:S,12288,1024,128,32:S,65536,1024,128,32&nbsp;</div><div><br></div><div>## Enable cpu affinity&nbsp;</div><div>mpi_paffinity_alone = 1&nbsp;</div><div><br></div><div>## Setup MPI options</div><div>mpi_show_handle_leaks = 0</div><div>mpi_warn_on_fork = 1</div></blockquote></blockquote><div><br></div></div><div><blockquote type="cite"><blockquote type="cite">enable_dlopen=no<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">with_openib=/opt/ofed<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">with_openib_libdir=/opt/ofed/lib64<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_mem_debug=no<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_mem_profile=no<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_debug_symbols=no<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_binaries=yes<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">with_devel_headers=yes<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_heterogeneous=yes<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_debug=no<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_shared=yes<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_static=yes<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">with_slurm=yes<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_memchecker=no<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_ipv6=no<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_mpi_f77=yes<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_mpi_f90=yes<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_mpi_cxx=yes<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_mpi_cxx_seek=yes<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_cxx_exceptions=yes<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">enable_mca_no_build=pml-dr,pml-crcp2,crcp,filem<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">with_io_romio_flags=--with-file-system=ufs+nfs+panfs<br></blockquote></blockquote><blockquote type="cite"><blockquote type="cite">with_threads=posix</blockquote></blockquote><br></div></body></html>
