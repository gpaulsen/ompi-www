<html><head><meta http-equiv="Content-Type" content="text/html charset=us-ascii"></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;">How odd - can you run it with --display-devel-map and send that along? It will give us a detailed statement of where it thinks everything should run.<div><br></div><div><br><div><div>On Aug 21, 2014, at 2:49 PM, Andrej Prsa &lt;<a href="mailto:aprsa09@gmail.com">aprsa09@gmail.com</a>&gt; wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><div style="font-size: 12px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;">Hi Ralph,<br><br>Thanks for your reply!<br><br><blockquote type="cite">One thing you might want to try: add this to your mpirun cmd line:<br><br>--display-allocation<br><br>This will tell you how many slots we think we've been given on your<br>cluster.<br></blockquote><br>I tried that using 1.8.2rc4, this is what I get:<br><br>====================== &nbsp;&nbsp;ALLOCATED NODES &nbsp;&nbsp;======================<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;node2: slots=48 max_slots=48 slots_inuse=0 state=UNKNOWN<br>=================================================================<br><br>I forgot to mention previously that mpirun runs all cores on localhost,<br>it is only when running on another host (--hostfile hosts) that the 32<br>proc cap is observed. I'm attaching a snapshot of the most recent run.<br>The job was invoked by:<br><br>/usr/local/openmpi-1.8.2rc4/bin/mpirun -np 48 --hostfile hosts<br>&nbsp;--display-allocation ./test.py &gt; test.std 2&gt; test.ste<br><br>test.ste contains the hwloc error I mentioned in my previous post:<br><br>****************************************************************************<br>* hwloc has encountered what looks like an error from the operating system.<br>*<br>* object (L3 cpuset 0x000003f0) intersection without inclusion!<br>* Error occurred in topology.c line 760<br>*<br>* Please report this error message to the hwloc user's mailing list,<br>* along with the output from the hwloc-gather-topology.sh script.<br>****************************************************************************<br><br>Hope this helps,<br>Andrej<br><br><br><blockquote type="cite">On Aug 21, 2014, at 12:50 PM, Ralph Castain &lt;<a href="mailto:rhc@open-mpi.org">rhc@open-mpi.org</a>&gt; wrote:<br><br><blockquote type="cite">Starting early in the 1.7 series, we began to bind procs by default<br>to cores when -np &lt;= 2, and to sockets if np &gt; 2. Is it possible<br>this is what you are seeing?<br><br><br>On Aug 21, 2014, at 12:45 PM, Andrej Prsa &lt;<a href="mailto:aprsa09@gmail.com">aprsa09@gmail.com</a>&gt; wrote:<br><br><blockquote type="cite">Dear devels,<br><br>I have been trying out 1.8.2rcs recently and found a show-stopping<br>problem on our cluster. Running any job with any number of<br>processors larger than 32 will always employ only 32 cores per<br>node (our nodes have 48 cores). We are seeing identical behavior<br>with 1.8.2rc4, 1.8.2rc2, and 1.8.1. Running identical programs<br>shows no such issues with version 1.6.5, where all 48 cores per<br>node are working. While our system is running torque/maui, the<br>problem is evident by running mpirun directly.<br><br>I am attaching hwloc topology in case that helps -- I am aware of a<br>buggy bios code that trips hwloc, but I don't know if that might<br>be an issue or not. I am happy to help debugging if you can<br>provide me with guidance.<br><br>Thanks,<br>Andrej<br>&lt;cluster.output&gt;&lt;cluster.tar.bz2&gt;_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>Subscription: http://www.open-mpi.org/mailman/listinfo.cgi/devel<br>Link to this post:<br>http://www.open-mpi.org/community/lists/devel/2014/08/15676.php<br></blockquote><br></blockquote><br>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>Subscription:<span class="Apple-converted-space">&nbsp;</span><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>Link to this post:<br><a href="http://www.open-mpi.org/community/lists/devel/2014/08/15678.php">http://www.open-mpi.org/community/lists/devel/2014/08/15678.php</a><br></blockquote><span>&lt;htop.jpg&gt;</span>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>Subscription:<span class="Apple-converted-space">&nbsp;</span><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>Link to this post:<span class="Apple-converted-space">&nbsp;</span><a href="http://www.open-mpi.org/community/lists/devel/2014/08/15679.php">http://www.open-mpi.org/community/lists/devel/2014/08/15679.php</a></div></blockquote></div><br></div></body></html>
