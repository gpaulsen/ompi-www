<div dir="ltr">Do you have the same behavior when you disable the vader BTL ? (--mca btl ^vader).<div><br></div><div>  George.</div><div><br></div></div><div class="gmail_extra"><br><div class="gmail_quote">On Fri, Mar 13, 2015 at 2:20 PM, Orion Poplawski <span dir="ltr">&lt;<a href="mailto:orion@cora.nwra.com" target="_blank">orion@cora.nwra.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">We currently have openmpi-1.8.4-99-20150228 built in Fedora Rawhide.  I&#39;m now<br>
seeing crashes/hangs when running the netcdf test suite on i686.  Crashes include:<br>
<br>
<br>
[mock1:23702] *** An error occurred in MPI_Allreduce<br>
[mock1:23702] *** reported by process <a href="tel:%5B3653173249" value="+13653173249">[3653173249</a>,1]<br>
[mock1:23702] *** on communicator MPI COMMUNICATOR 7 DUP FROM 6<br>
[mock1:23702] *** MPI_ERR_IN_STATUS: error code in status<br>
[mock1:23702] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will<br>
now abort,<br>
[mock1:23702] ***    and potentially your MPI job)<br>
<br>
and a similar one in MPI_Bcast.<br>
<br>
Hangs (100%cpu) seem to be in opal_condition_wait() -&gt; opal_progress() calling<br>
both mca_pml_ob1_progress and mca_btl_vader_component_progress.<br>
<br>
#0  mca_btl_vader_check_fboxes () at btl_vader_fbox.h:192<br>
#1  mca_btl_vader_component_progress () at btl_vader_component.c:694<br>
#2  0xf3971b69 in opal_progress () at runtime/opal_progress.c:187<br>
#3  0xf40b4695 in opal_condition_wait (c=&lt;optimized out&gt;, m=&lt;optimized out&gt;)<br>
    at ../opal/threads/condition.h:78<br>
#4  ompi_request_default_wait_all (count=6, requests=&lt;optimized out&gt;,<br>
statuses=0x0)<br>
    at request/req_wait.c:281<br>
#5  0xf28bb5e7 in ompi_coll_tuned_alltoall_intra_basic_linear<br>
(sbuf=sbuf@entry=0xf7a2d328,<br>
    scount=scount@entry=1, sdtype=sdtype@entry=0xf4148240 &lt;ompi_mpi_int&gt;,<br>
    rbuf=rbuf@entry=0xf7af1920, rcount=rcount@entry=1,<br>
    rdtype=rdtype@entry=0xf4148240 &lt;ompi_mpi_int&gt;, comm=comm@entry=0xf7b051d8,<br>
    module=module@entry=0xf7a2b4d0) at coll_tuned_alltoall.c:700<br>
#6  0xf28b4d08 in ompi_coll_tuned_alltoall_intra_dec_fixed (sbuf=0xf7a2d328,<br>
scount=1,<br>
    sdtype=0xf4148240 &lt;ompi_mpi_int&gt;, rbuf=0xf7af1920, rcount=1,<br>
    rdtype=0xf4148240 &lt;ompi_mpi_int&gt;, comm=0xf7b051d8, module=0xf7a2b4d0)<br>
    at coll_tuned_decision_fixed.c:130<br>
#7  0xf40c7899 in PMPI_Alltoall (sendbuf=sendbuf@entry=0xf7a2d328,<br>
    sendcount=sendcount@entry=1, sendtype=sendtype@entry=0xf4148240<br>
&lt;ompi_mpi_int&gt;,<br>
    recvbuf=recvbuf@entry=0xf7af1920, recvcount=recvcount@entry=1,<br>
    recvtype=recvtype@entry=0xf4148240 &lt;ompi_mpi_int&gt;, comm=0xf7b051d8) at<br>
palltoall.c:111<br>
#8  0xe9780da0 in ADIOI_Calc_others_req (fd=fd@entry=0xf7b12640,<br>
count_my_req_procs=1,<br>
    count_my_req_per_proc=0xf7a2d328, my_req=0xf7b00750, nprocs=4, myrank=0,<br>
    count_others_req_procs_ptr=count_others_req_procs_ptr@entry=0xffbea6e8,<br>
    others_req_ptr=others_req_ptr@entry=0xffbea6cc) at<br>
adio/common/ad_aggregate.c:453<br>
#9  0xe9796a14 in ADIOI_GEN_WriteStridedColl (fd=0xf7b12640, buf=0xf7aa0148,<br>
count=2440,<br>
    datatype=0xf4148840 &lt;ompi_mpi_byte&gt;, file_ptr_type=100, offset=0,<br>
status=0xffbea8b8,<br>
    error_code=0xffbea790) at adio/common/ad_write_coll.c:192<br>
#10 0xe97779e0 in MPIOI_File_write_all (fh=fh@entry=0xf7b12640,<br>
offset=offset@entry=0,<br>
    file_ptr_type=file_ptr_type@entry=100, buf=buf@entry=0xf7aa0148,<br>
count=count@entry=2440,<br>
    datatype=datatype@entry=0xf4148840 &lt;ompi_mpi_byte&gt;,<br>
    myname=myname@entry=0xe97a9a1c &lt;myname.9354&gt; &quot;MPI_FILE_WRITE_AT_ALL&quot;,<br>
    status=status@entry=0xffbea8b8) at mpi-io/write_all.c:116<br>
#11 0xe9778176 in mca_io_romio_dist_MPI_File_write_at_all (fh=0xf7b12640,<br>
    offset=offset@entry=0, buf=buf@entry=0xf7aa0148, count=count@entry=2440,<br>
    datatype=datatype@entry=0xf4148840 &lt;ompi_mpi_byte&gt;,<br>
status=status@entry=0xffbea8b8)<br>
    at mpi-io/write_atall.c:55<br>
#12 0xe9770bcc in mca_io_romio_file_write_at_all (fh=0xf7aa27c8, offset=0,<br>
buf=0xf7aa0148,<br>
    count=2440, datatype=0xf4148840 &lt;ompi_mpi_byte&gt;, status=0xffbea8b8)<br>
    at src/io_romio_file_write.c:61<br>
#13 0xf40ff3ce in PMPI_File_write_at_all (fh=0xf7aa27c8, offset=0,<br>
buf=buf@entry=0xf7aa0148,<br>
    count=count@entry=2440, e=0xf4148840 &lt;ompi_mpi_byte&gt;,<br>
status=status@entry=0xffbea8b8)<br>
    at pfile_write_at_all.c:75<br>
#14 0xf437a43c in H5FD_mpio_write (_file=_file@entry=0xf7b074a8,<br>
    type=type@entry=H5FD_MEM_DRAW, dxpl_id=167772177, addr=31780,<br>
size=size@entry=2440,<br>
    buf=buf@entry=0xf7aa0148) at ../../src/H5FDmpio.c:1840<br>
#15 0xf4375cd5 in H5FD_write (file=0xf7b074a8, dxpl=0xf7a47d20,<br>
type=H5FD_MEM_DRAW,<br>
    addr=31780, size=size@entry=2440, buf=buf@entry=0xf7aa0148) at<br>
../../src/H5FDint.c:245<br>
#16 0xf4360932 in H5F__accum_write (fio_info=fio_info@entry=0xffbea9d4,<br>
    type=type@entry=H5FD_MEM_DRAW, addr=31780, size=size@entry=2440,<br>
buf=buf@entry=0xf7aa0148)<br>
    at ../../src/H5Faccum.c:824<br>
#17 0xf436430c in H5F_block_write (f=0xf7a31860,<br>
type=type@entry=H5FD_MEM_DRAW, addr=31780,<br>
    size=size@entry=2440, dxpl_id=167772177, buf=0xf7aa0148) at<br>
../../src/H5Fio.c:170<br>
#18 0xf43413ee in H5D__mpio_select_write (io_info=0xffbeab60,<br>
type_info=0xffbeab1c,<br>
    mpi_buf_count=2440, file_space=0x0, mem_space=0x0) at ../../src/H5Dmpio.c:296<br>
#19 0xf4341f33 in H5D__final_collective_io (mpi_buf_type=0xffbeaa7c,<br>
mpi_file_type=0xffbeaa78,<br>
    mpi_buf_count=&lt;optimized out&gt;, type_info=0xffbeab1c, io_info=0xffbeab60)<br>
    at ../../src/H5Dmpio.c:1444<br>
#20 H5D__inter_collective_io (mem_space=0xf7a38120, file_space=0xf7a55590,<br>
    type_info=0xffbeab1c, io_info=0xffbeab60) at ../../src/H5Dmpio.c:1400<br>
#21 H5D__contig_collective_write (io_info=0xffbeab60, type_info=0xffbeab1c,<br>
nelmts=610,<br>
    file_space=0xf7a55590, mem_space=0xf7a38120, fm=0xffbeace0) at<br>
../../src/H5Dmpio.c:528<br>
#22 0xf433ae8d in H5D__write (buf=0xf7aa0148, dxpl_id=167772177,<br>
file_space=0xf7a55590,<br>
    mem_space=0xf7a38120, mem_type_id=-140159600, dataset=0xf7a3eb40) at<br>
../../src/H5Dio.c:787<br>
#23 H5D__pre_write (dset=dset@entry=0xf7a3eb40, direct_write=&lt;optimized out&gt;,<br>
    mem_type_id=mem_type_id@entry=50331747, mem_space=mem_space@entry=0xf7a38120,<br>
    file_space=0xf7a55590, dxpl_id=dxpl_id@entry=167772177,<br>
buf=buf@entry=0xf7aa0148)<br>
    at ../../src/H5Dio.c:351<br>
#24 0xf433b74c in H5Dwrite (dset_id=83886085, mem_type_id=50331747,<br>
    mem_space_id=mem_space_id@entry=67108867,<br>
file_space_id=file_space_id@entry=67108866,<br>
    dxpl_id=dxpl_id@entry=167772177, buf=buf@entry=0xf7aa0148) at<br>
../../src/H5Dio.c:270<br>
#25 0xf466b603 in nc4_put_vara (nc=0xf7a05c58, ncid=ncid@entry=65536,<br>
varid=varid@entry=3,<br>
    startp=startp@entry=0xffbf6a08, countp=countp@entry=0xffbf6a10,<br>
    mem_nc_type=mem_nc_type@entry=5, is_long=is_long@entry=0,<br>
data=data@entry=0xf7a07c40)<br>
    at ../../libsrc4/nc4hdf.c:788<br>
#26 0xf4673c55 in nc4_put_vara_tc (mem_type_is_long=0, op=0xf7a07c40,<br>
countp=0xffbf6a10,<br>
    startp=0xffbf6a08, mem_type=5, varid=3, ncid=65536) at<br>
../../libsrc4/nc4var.c:1429<br>
#27 NC4_put_vara (ncid=65536, varid=3, startp=0xffbf6a08, countp=0xffbf6a10,<br>
op=0xf7a07c40,<br>
    memtype=5) at ../../libsrc4/nc4var.c:1565<br>
#28 0xf460a377 in NC_put_vara (ncid=ncid@entry=65536, varid=varid@entry=3,<br>
    start=start@entry=0xffbf6a08, edges=edges@entry=0xffbf6a10,<br>
value=value@entry=0xf7a07c40,<br>
    memtype=memtype@entry=5) at ../../libdispatch/dvarput.c:79<br>
#29 0xf460b541 in nc_put_vara_float (ncid=65536, varid=3, startp=0xffbf6a08,<br>
    countp=0xffbf6a10, op=0xf7a07c40) at ../../libdispatch/dvarput.c:655<br>
#30 0xf77d06ed in test_pio_2d (cache_size=67108864, facc_type=8192,<br>
access_flag=1,<br>
    comm=0xf414d800 &lt;ompi_mpi_comm_world&gt;, info=0xf4154240<br>
&lt;ompi_mpi_info_null&gt;, mpi_size=4,<br>
    mpi_rank=0, chunk_size=0xffbf76f4) at ../../nc_test4/tst_nc4perf.c:96<br>
#31 0xf77cfdb1 in main (argc=1, argv=0xffbf7804) at<br>
../../nc_test4/tst_nc4perf.c:299<br>
<br>
<br>
Any suggests as to where to look next would be greatly appreciated.<br>
<span class="HOEnZb"><font color="#888888"><br>
--<br>
Orion Poplawski<br>
Technical Manager                     <a href="tel:303-415-9701%20x222" value="+13034159701">303-415-9701 x222</a><br>
NWRA, Boulder/CoRA Office             FAX: <a href="tel:303-415-9702" value="+13034159702">303-415-9702</a><br>
3380 Mitchell Lane                       <a href="mailto:orion@nwra.com">orion@nwra.com</a><br>
Boulder, CO 80301                   <a href="http://www.nwra.com" target="_blank">http://www.nwra.com</a><br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/03/17131.php" target="_blank">http://www.open-mpi.org/community/lists/devel/2015/03/17131.php</a><br>
</font></span></blockquote></div><br></div>

