<div dir="ltr"><br><div class="gmail_extra"><br><div class="gmail_quote">On Wed, Apr 13, 2016 at 1:59 AM, Gilles Gouaillardet <span dir="ltr">&lt;<a href="mailto:gilles@rist.or.jp" target="_blank">gilles@rist.or.jp</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex">George,<br>
<br>
about the process binding part<span class=""><br>
<br>
On 4/13/2016 7:32 AM, George Bosilca wrote:<br>
<blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex">
Also my processes, despite the fact that I asked for 1 per node, are not bound to the first core. Shouldn’t we release the process binding when we know there is a single process per node (as in the above case) ?<br>
</blockquote></span>
did you expect the tasks are bound to the first *core* on each node ?<br>
<br>
i would expect the tasks are bound to the first *socket* on each node.<br></blockquote><div><br></div><div>In this particular instance, where it has been explicitly requested to have a single process per node, I would have expected the process to be unbound (we know there is only one per node). It is the responsibility of the application to bound itself or its thread if necessary. Why are we enforcing a particular binding policy?</div><div><br></div><blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex">
(since we do not know how many (OpenMP or other) threads will be used by the application, </blockquote><blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex">
--bind-to socket is a good policy imho. in this case (one task per node), no binding at all would mean<br>
the task can migrate from one socket to the other, and/or OpenMP threads are bound accross sockets.<br>
That would trigger some NUMA effects (better bandwidth if memory is locally accessed, but worst performance<br>
is memory is allocated only on one socket).<br>
so imho, --bind-to socket is still my preferred policy, even if there is only one MPI task per node.<br></blockquote><div><br></div><div>Open MPI is about MPI ranks/processes. I don&#39;t think it is our job to try to figure out how the user handle do with it&#39;s own threads.</div><div><br></div><div>Your justification make sense if the application only uses a single socket. It also make sense if one starts multiple ranks per node, and the internal threads of each MPI process inherit the MPI process binding. However, in the case where there is a single process per node, because there is a mismatch between the number of resources available (hardware threads) and the binding of the parent process, all the threads of the MPI application are [by default] bound on a single socket.</div><div><br></div><div> George.<br></div><div><br></div><div>PS: That being said I think I&#39;ll need to implement the binding code anyway in order to deal with the wide variety of behaviors in the different MPI implementations.</div><div><br></div><div> </div><blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex">
<br>
Cheers,<br>
<br>
Gilles<br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" rel="noreferrer" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2016/04/18758.php" rel="noreferrer" target="_blank">http://www.open-mpi.org/community/lists/devel/2016/04/18758.php</a></blockquote></div><br></div></div>

