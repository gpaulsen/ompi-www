<html>
  <head>
    <meta content="text/html; charset=ISO-8859-1"
      http-equiv="Content-Type">
  </head>
  <body bgcolor="#FFFFFF" text="#000000">
    IIRC, the first 16 or so messages over the openib btl uses the
    send/recv API as opposed to rdma which is significantly faster.&nbsp; I
    am not sure as to how 1.5.3 and multi-rail affects this but the
    preconnected I believe short circuits when one cuts over to use rdma
    for eager messages.<br>
    <br>
    --td<br>
    <br>
    <div class="moz-cite-prefix">On 10/31/2012 3:36 PM, Paul Kapinos
      wrote:<br>
    </div>
    <blockquote cite="mid:50917DDB.7010602@rz.rwth-aachen.de"
      type="cite">Hello all,
      <br>
      <br>
      Open MPI is clever and use by default multiple IB adapters, if
      available.
      <br>
      <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/faq/?category=openfabrics#ofa-port-wireup">http://www.open-mpi.org/faq/?category=openfabrics#ofa-port-wireup</a>
      <br>
      <br>
      Open MPI is lazy and establish connections only iff needed.
      <br>
      <br>
      Both is good.
      <br>
      <br>
      We have kinda special nodes: up to 16 sockets, 128 cores, 4
      boards, 4 IB cards. Multirail works!
      <br>
      <br>
      The crucial thing is, that starting with v1.6.1 the latency of the
      very first PingPong sample between two nodes take really a lot of
      time - some 100x - 200x of usual latency. You cannot see this
      using usual latency benchmark(*) because they tend to omit the
      first samples as "warmup phase", but we use a kinda self-written
      parallel test which clearly show this (and let me to muse some
      days).
      <br>
      If Miltirail is forbidden (-mca btl_openib_max_btls 1), or if
      v.1.5.3 used, or if the MPI processes are preconnected
      (<a class="moz-txt-link-freetext" href="http://www.open-mpi.org/faq/?category=running#mpi-preconnect">http://www.open-mpi.org/faq/?category=running#mpi-preconnect</a>)
      there is no such huge latency outliers for the first sample.
      <br>
      <br>
      Well, we know about the warm-up and lazy connections.
      <br>
      <br>
      But 200x ?!
      <br>
      <br>
      Any comments about that is OK so?
      <br>
      <br>
      Best,
      <br>
      <br>
      Paul Kapinos
      <br>
      <br>
      (*) E.g. HPCC explicitely say in
      <a class="moz-txt-link-freetext" href="http://icl.cs.utk.edu/hpcc/faq/index.html#132">http://icl.cs.utk.edu/hpcc/faq/index.html#132</a>
      <br>
      &gt; Additional startup latencies are masked out by starting the
      measurement after
      <br>
      &gt; one non-measured ping-pong.
      <br>
      <br>
      P.S. Sorry for cross-posting to both Users and Developers, but my
      last questions to Users have no reply until yet, so trying to
      broadcast...
      <br>
      <br>
      <br>
      <br>
      <fieldset class="mimeAttachmentHeader"></fieldset>
      <br>
      <pre wrap="">_______________________________________________
devel mailing list
<a class="moz-txt-link-abbreviated" href="mailto:devel@open-mpi.org">devel@open-mpi.org</a>
<a class="moz-txt-link-freetext" href="http://www.open-mpi.org/mailman/listinfo.cgi/devel">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a></pre>
    </blockquote>
    <br>
  </body>
</html>

