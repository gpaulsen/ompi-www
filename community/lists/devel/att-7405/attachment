<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
<HEAD>

<META NAME="Generator" CONTENT="MS Exchange Server version 6.5.7654.12">
<TITLE>Re: [OMPI devel] failure with zero-lengthReduce()andbothsbuf=rbuf=NULL</TITLE>
</HEAD>
<BODY><div><font size=2 color=navy face=Arial>
I misparsed your reply. Yes, bcast(1) *can* sync if it wants to. I don't have a spec handy to check if bcast(0) is defined or not (similar to reduce). If it is, then sure, it could sync as well. <br><br>My previous point was that barrier is the only collective that is *required* to synchronize. <br><br>-jms<br>Sent from my PDA.  No type good.</font></div>
<br><div><hr size=2 width="100%" align=center tabindex=-1>
<font face=Tahoma size=2>
<b>From</b>: devel-bounces@open-mpi.org &lt;devel-bounces@open-mpi.org&gt;<br><b>To</b>: devel@open-mpi.org &lt;devel@open-mpi.org&gt;<br><b>Sent</b>: Thu Feb 11 07:04:59 2010<br><b>Subject</b>: Re: [OMPI devel] failure withzero-lengthReduce()andbothsbuf=rbuf=NULL<br></font><br></div>

<!-- Converted from text/plain format -->

<P><FONT SIZE=2>Where does bcast(1) synchronize?<BR>
<BR>
(Oops on typo - if reduce(1) wasn't defined, that definitely would be bad :) )<BR>
<BR>
-jms<BR>
Sent from my PDA.&nbsp; No type good.<BR>
<BR>
----- Original Message -----<BR>
From: devel-bounces@open-mpi.org &lt;devel-bounces@open-mpi.org&gt;<BR>
To: Open MPI Developers &lt;devel@open-mpi.org&gt;<BR>
Sent: Wed Feb 10 12:50:03 2010<BR>
Subject: Re: [OMPI devel] failure with zero-lengthReduce()andbothsbuf=rbuf=NULL<BR>
<BR>
On 10 February 2010 14:19, Jeff Squyres &lt;jsquyres@cisco.com&gt; wrote:<BR>
&gt; On Feb 10, 2010, at 11:59 AM, Lisandro Dalcin wrote:<BR>
&gt;<BR>
&gt;&gt; &gt; If I remember correctly, the HPCC pingpong test synchronizes occasionally by<BR>
&gt;&gt; &gt; having one process send a zero-byte broadcast to all other processes.<BR>
&gt;&gt; &gt;  What's a zero-byte broadcast?  Well, some MPIs apparently send no data, but<BR>
&gt;&gt; &gt; do have synchronization semantics.  (No non-root process can exit before the<BR>
&gt;&gt; &gt; root process has entered.)  Other MPIs treat the zero-byte broadcasts as<BR>
&gt;&gt; &gt; no-ops;  there is no synchronization and then timing results from the HPCC<BR>
&gt;&gt; &gt; pingpong test are very misleading.  So far as I can tell, the MPI standard<BR>
&gt;&gt; &gt; doesn't address which behavior is correct.<BR>
&gt;&gt;<BR>
&gt;&gt; Yep... for p2p communication things are more clear (and behavior more<BR>
&gt;&gt; consistens in the MPI's out there) regarding zero-length messages...<BR>
&gt;&gt; IMHO, collectives should be non-op only in the sense that no actual<BR>
&gt;&gt; reduction is made because there are no elements to operate on. I mean,<BR>
&gt;&gt; if Reduce(count=1) implies a sync, Reduce(count=0) should also imply a<BR>
&gt;&gt; sync...<BR>
&gt;<BR>
&gt; Sorry to disagree again.  :-)<BR>
&gt;<BR>
&gt; The *only* MPI collective operation that guarantees a synchronization is barrier.  The lack of synchronization guarantee for all other collective operations is very explicit in the MPI spec.<BR>
<BR>
Of course.<BR>
<BR>
&gt; Hence, it is perfectly valid for an MPI implementation to do something like a no-op when no data transfer actually needs to take place<BR>
&gt;<BR>
<BR>
So you say that an MPI implementation is free to do make a sync in<BR>
case of Bcast(count=1), but not in the case of Bcast(count=0) ? I<BR>
could agree that such behavior is technically correct regarding the<BR>
MPI standard... But it makes me feel a bit uncomfortable... OK, in the<BR>
end, the change on semantic depending on message sizes is comparable<BR>
to the blocking/nonblocking one for&nbsp; MPI_Send(count=10^8) versus<BR>
Send(count=1).<BR>
<BR>
&gt;<BR>
&gt; (except, of course, the fact that Reduce(count=1) isn't defined ;-) ).<BR>
&gt;<BR>
<BR>
You likely meant Reduce(count=0) ... Good catch ;-)<BR>
<BR>
<BR>
PS: The following question is unrelated to this thread, but my<BR>
curiosity+laziness cannot resist... Does Open MPI has some MCA<BR>
parameter to add a synchronization at every collective call?<BR>
<BR>
--<BR>
Lisandro Dalcin<BR>
---------------<BR>
Centro Internacional de Métodos Computacionales en Ingeniería (CIMEC)<BR>
Instituto de Desarrollo Tecnológico para la Industria Química (INTEC)<BR>
Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET)<BR>
PTLC - Güemes 3450, (3000) Santa Fe, Argentina<BR>
Tel/Fax: +54-(0)342-451.1594<BR>
<BR>
_______________________________________________<BR>
devel mailing list<BR>
devel@open-mpi.org<BR>
<A HREF="http://www.open-mpi.org/mailman/listinfo.cgi/devel">http://www.open-mpi.org/mailman/listinfo.cgi/devel</A><BR>
</FONT>
</P>

</BODY>
</HTML>