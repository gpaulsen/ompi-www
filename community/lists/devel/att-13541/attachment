<div dir="ltr">And the FreeBSD backtraces again, this time configured with --enable-debug and for all threads:<div><br></div><div>The 100%-cpu ring_c process:</div><div><br></div><div><div>(gdb) thread apply all where</div>
<div><br></div><div>Thread 2 (Thread 802007400 (LWP 182916/ring_c)):</div><div>#0  0x0000000800de7aac in sched_yield () from /lib/libc.so.7</div><div>#1  0x00000008013c7a5a in opal_progress ()</div><div>    at /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/openmpi-1.7-latest/opal/runtime/opal_progress.c:199</div>
<div>#2  0x00000008008670ec in ompi_mpi_init (argc=1, argv=0x7fffffffd3e0, requested=0, provided=0x7fffffffd328)</div><div>    at /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/openmpi-1.7-latest/ompi/runtime/ompi_mpi_init.c:618</div>
<div>#3  0x000000080089aefe in PMPI_Init (argc=0x7fffffffd36c, argv=0x7fffffffd360) at pinit.c:84</div><div>#4  0x0000000000400963 in main (argc=1, argv=0x7fffffffd3e0) at ring_c.c:19</div><div><br></div><div>Thread 1 (Thread 802007800 (LWP 186415/ring_c)):</div>
<div>#0  0x0000000800e2711c in poll () from /lib/libc.so.7</div><div>#1  0x0000000800b727fe in poll () from /lib/libthr.so.3</div><div>#2  0x000000080142edc1 in poll_dispatch (base=0x8020cd900, tv=0x0)</div><div>    at /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/openmpi-1.7-latest/opal/mca/event/libevent2021/libevent/poll.c:165</div>
<div>#3  0x0000000801422ca1 in opal_libevent2021_event_base_loop (base=0x8020cd900, flags=1)</div><div>    at /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/openmpi-1.7-latest/opal/mca/event/libevent2021/libevent/event.c:1631</div>
<div>#4  0x00000008010f2c22 in orte_progress_thread_engine (obj=0x80139b160)</div><div>    at /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/openmpi-1.7-latest/orte/runtime/orte_init.c:180</div><div>#5  0x0000000800b700a4 in pthread_getprio () from /lib/libthr.so.3</div>
<div>#6  0x0000000000000000 in ?? ()</div><div>Error accessing memory address 0x7fffffbfe000: Bad address.</div></div><div><br></div><div><br></div><div>The idle ring_c process:</div><div><br></div><div><div>(gdb) thread apply all where</div>
<div><br></div><div>Thread 2 (Thread 802007400 (LWP 183983/ring_c)):</div><div>#0  0x0000000800e6c44c in nanosleep () from /lib/libc.so.7</div><div>#1  0x0000000800b729d5 in nanosleep () from /lib/libthr.so.3</div><div>#2  0x0000000801161618 in orte_routed_base_register_sync (setup=true)</div>
<div>    at /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/openmpi-1.7-latest/orte/mca/routed/base/routed_base_fns.c:344</div><div>#3  0x0000000802a0a0a2 in init_routes (job=2628321281, ndat=0x0)</div><div>    at /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/openmpi-1.7-latest/orte/mca/routed/binomial/routed_binomial.c:705</div>
<div>#4  0x00000008011272ce in orte_ess_base_app_setup (db_restrict_local=true)</div><div>    at /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/openmpi-1.7-latest/orte/mca/ess/base/ess_base_std_app.c:233</div><div>
#5  0x0000000802401408 in rte_init ()</div><div>    at /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/openmpi-1.7-latest/orte/mca/ess/env/ess_env_module.c:146</div><div>#6  0x00000008010f2b28 in orte_init (pargc=0x0, pargv=0x0, flags=32)</div>
<div>    at /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/openmpi-1.7-latest/orte/runtime/orte_init.c:158</div><div>#7  0x0000000800866bde in ompi_mpi_init (argc=1, argv=0x7fffffffd3e0, requested=0, provided=0x7fffffffd328)</div>
<div>    at /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/openmpi-1.7-latest/ompi/runtime/ompi_mpi_init.c:451</div><div>#8  0x000000080089aefe in PMPI_Init (argc=0x7fffffffd36c, argv=0x7fffffffd360) at pinit.c:84</div>
<div>#9  0x0000000000400963 in main (argc=1, argv=0x7fffffffd3e0) at ring_c.c:19</div><div><br></div><div>Thread 1 (Thread 802007800 (LWP 186412/ring_c)):</div><div>#0  0x0000000800e2711c in poll () from /lib/libc.so.7</div>
<div>#1  0x0000000800b727fe in poll () from /lib/libthr.so.3</div><div>#2  0x000000080142edc1 in poll_dispatch (base=0x8020cd900, tv=0x0)</div><div>    at /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/openmpi-1.7-latest/opal/mca/event/libevent2021/libevent/poll.c:165</div>
<div>#3  0x0000000801422ca1 in opal_libevent2021_event_base_loop (base=0x8020cd900, flags=1)</div><div>    at /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/openmpi-1.7-latest/opal/mca/event/libevent2021/libevent/event.c:1631</div>
<div>#4  0x00000008010f2c22 in orte_progress_thread_engine (obj=0x80139b160)</div><div>    at /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/openmpi-1.7-latest/orte/runtime/orte_init.c:180</div><div>#5  0x0000000800b700a4 in pthread_getprio () from /lib/libthr.so.3</div>
<div>#6  0x0000000000000000 in ?? ()</div><div>Error accessing memory address 0x7fffffbfe000: Bad address.</div></div><div><br></div><div><br></div><div>-Paul</div><div class="gmail_extra"><br><br><div class="gmail_quote">
On Fri, Dec 20, 2013 at 2:59 PM, Paul Hargrove <span dir="ltr">&lt;<a href="mailto:phhargrove@lbl.gov" target="_blank">phhargrove@lbl.gov</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
<div dir="ltr">This case is not quite like my OpenBSD-5 report.<div>On FreeBSD-9 I *can* run singletons, but &quot;-np 2&quot; hangs.</div><div><br></div><div>The following hangs:</div><div>$ mpirun -np 2 examples/ring_c<br>

</div><div><br></div><div>The following complains about the &quot;bogus&quot; btl selection.</div><div>So this is not the same as my problem with OpenBSD-5:</div><div><div><font face="courier new, monospace" size="1">$ mpirun -mca btl bogus -np 2 examples/ring_c</font></div>

<div><font face="courier new, monospace" size="1">[freebsd9-amd64.qemu:05926] mca: base: components_open: component pml / bfo open function failed</font></div><div><font face="courier new, monospace" size="1">[freebsd9-amd64.qemu:05926] mca: base: components_open: component pml / ob1 open function failed</font></div>

<div><font face="courier new, monospace" size="1">[freebsd9-amd64.qemu:05926] PML ob1 cannot be selected</font></div><div><font face="courier new, monospace" size="1">--------------------------------------------------------------------------</font></div>

<div><font face="courier new, monospace" size="1">A requested component was not found, or was unable to be opened.  This</font></div><div><font face="courier new, monospace" size="1">means that this component is either not installed or is unable to be</font></div>

<div><font face="courier new, monospace" size="1">used on your system (e.g., sometimes this means that shared libraries</font></div><div><font face="courier new, monospace" size="1">that the component requires are unable to be found/loaded).  Note that</font></div>

<div><font face="courier new, monospace" size="1">Open MPI stopped checking at the first component that it did not find.</font></div><div><font face="courier new, monospace" size="1"><br></font></div><div><font face="courier new, monospace" size="1">Host:      freebsd9-amd64.qemu</font></div>

<div><font face="courier new, monospace" size="1">Framework: btl</font></div><div><font face="courier new, monospace" size="1">Component: bogus</font></div><div><font face="courier new, monospace" size="1">--------------------------------------------------------------------------</font></div>

<div><font face="courier new, monospace" size="1">--------------------------------------------------------------------------</font></div><div><font face="courier new, monospace" size="1">No available pml components were found!</font></div>

<div><font face="courier new, monospace" size="1"><br></font></div><div><font face="courier new, monospace" size="1">This means that there are no components of this type installed on your</font></div><div><font face="courier new, monospace" size="1">system or all the components reported that they could not be used.</font></div>

<div><font face="courier new, monospace" size="1"><br></font></div><div><font face="courier new, monospace" size="1">This is a fatal error; your MPI process is likely to abort.  Check the</font></div><div><font face="courier new, monospace" size="1">output of the &quot;ompi_info&quot; command and ensure that components of this</font></div>

<div><font face="courier new, monospace" size="1">type are available on your system.  You may also wish to check the</font></div><div><font face="courier new, monospace" size="1">value of the &quot;component_path&quot; MCA parameter and ensure that it has at</font></div>

<div><font face="courier new, monospace" size="1">least one directory that contains valid MCA components.</font></div><div><font face="courier new, monospace" size="1">--------------------------------------------------------------------------</font></div>

</div><div><br></div><div><br></div><div>For the non-bogus case, &quot;top&quot; show one idle and one active ring_c process:</div><div><div><font face="courier new, monospace" size="1">  PID USERNAME  THR PRI NICE   SIZE    RES STATE   C   TIME   WCPU COMMAND</font></div>

<div><font face="courier new, monospace" size="1"> 5933 phargrov    2  29    0    98M  6384K select  1   0:32 100.00% ring_c</font></div><div><font face="courier new, monospace" size="1"> 5931 phargrov    2  20    0 77844K  4856K select  0   0:00  0.00% orterun</font></div>

<div><font face="courier new, monospace" size="1"> 5932 phargrov    2  24    0 51652K  4960K select  0   0:00  0.00% ring_c</font></div></div><div><br></div><div>A backtrace for the 100%-cpu ring_c process:</div><div><div>

(gdb) where</div><div>#0  0x0000000800d9811c in poll () from /lib/libc.so.7</div><div>#1  0x0000000800ae37fe in poll () from /lib/libthr.so.3</div><div>#2  0x00000008013259aa in poll_dispatch ()</div><div>   from /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/INST/lib/libopen-pal.so.7</div>

<div>#3  0x000000080131eb50 in opal_libevent2021_event_base_loop ()</div><div>   from /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/INST/lib/libopen-pal.so.7</div><div>#4  0x000000080106395d in orte_progress_thread_engine ()</div>

<div>   from /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/INST/lib/libopen-rte.so.7</div><div>#5  0x0000000800ae10a4 in pthread_getprio () from /lib/libthr.so.3</div><div>#6  0x0000000000000000 in ?? ()</div><div>

Error accessing memory address 0x7fffffbfe000: Bad address.</div></div><div><br></div><div><br></div><div>And for the idle ring_c process:</div><div><div>(gdb) where</div><div>#0  0x0000000800d9811c in poll () from /lib/libc.so.7</div>

<div>#1  0x0000000800ae37fe in poll () from /lib/libthr.so.3</div><div>#2  0x00000008013259aa in poll_dispatch ()</div><div>   from /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/INST/lib/libopen-pal.so.7</div><div>

#3  0x000000080131eb50 in opal_libevent2021_event_base_loop ()</div><div>   from /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/INST/lib/libopen-pal.so.7</div><div>#4  0x000000080106395d in orte_progress_thread_engine ()</div>

<div>   from /home/phargrov/OMPI/openmpi-1.7-latest-freebsd9-amd64/INST/lib/libopen-rte.so.7</div><div>#5  0x0000000800ae10a4 in pthread_getprio () from /lib/libthr.so.3</div><div>#6  0x0000000000000000 in ?? ()</div><div>

Error accessing memory address 0x7fffffbfe000: Bad address.</div></div><div><br></div><div><br></div><div>They look to be the same, but I double checked that these are correct.</div><span class="HOEnZb"><font color="#888888"><div>
<br></div><div>-Paul</div><div><br clear="all">
<div><br></div>-- <br><font face="courier new, monospace"><div>Paul H. Hargrove                          <a href="mailto:PHHargrove@lbl.gov" target="_blank">PHHargrove@lbl.gov</a></div><div>Future Technologies Group</div>

<div>Computer and Data Sciences Department     Tel: <a href="tel:%2B1-510-495-2352" value="+15104952352" target="_blank">+1-510-495-2352</a></div><div>Lawrence Berkeley National Laboratory     Fax: <a href="tel:%2B1-510-486-6900" value="+15104866900" target="_blank">+1-510-486-6900</a></div>
</font>
</div></font></span></div>
</blockquote></div><br><br clear="all"><div><br></div>-- <br><font face="courier new, monospace"><div>Paul H. Hargrove                          <a href="mailto:PHHargrove@lbl.gov" target="_blank">PHHargrove@lbl.gov</a></div>
<div>Future Technologies Group</div><div>Computer and Data Sciences Department     Tel: +1-510-495-2352</div><div>Lawrence Berkeley National Laboratory     Fax: +1-510-486-6900</div></font>
</div></div>

