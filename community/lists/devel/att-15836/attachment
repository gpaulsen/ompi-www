<div dir="ltr">Ralph,<div><br></div><div>here is the full description of a race condition in oob/tcp i very briefly mentionned in a previous post :</div><div><br></div><div>the race condition can occur when two not connected orted try to send a message to each other for the first time and at the same time.</div><div><br></div><div>that can occur when running mpi helloworld on 4 nodes with the grpcomm/rcd module.</div><div><br></div><div>here is a scenario in which the race condition occurs :<br></div><div><br></div><div>orted vpid 2 and 3 enter the allgather</div><div>/* they are not orte yet oob/tcp connected*/</div><div>and they call orte.send_buffer_nb each other.</div><div>from a libevent point of view, vpid 2 and 3 will call mca_oob_tcp_peer_try_connect</div><div><br></div><div>vpid 2 calls mca_oob_tcp_send_handler</div><div><br></div><div>vpid 3 calls connection_event_handler</div><div><br></div><div>depending on the value returned by random() in libevent, vpid 3 will</div><div>either call mca_oob_tcp_send_handler (likely) or recv_handler (unlikely)</div><div>if vpid 3 calls recv_handler, it will close the two sockets to vpid 2</div><div><br></div><div>then vpid 2 will call mca_oob_tcp_recv_handler</div><div>(peer-&gt;state is MCA_OOB_TCP_CONNECT_ACK)</div><div>that will invoke mca_oob_tcp_recv_connect_ack<br></div><div>tcp_peer_recv_blocking will failÂ </div><div>/* zero bytes are recv&#39;ed since vpid 3 previously closed the socket before writing a header */</div><div>and this is handled by mca_oob_tcp_recv_handler as a fatal error</div><div>/* ORTE_FORCED_TERMINATE(1) */</div><div><br></div><div>could you please have a look at it ?</div><div><br></div><div>if you are too busy, could you please advise where this scenario should be handled differently ?</div><div>- should vpid 3 keep one socket instead of closing both and retrying ?</div><div>- should vpid 2 handle the failure as a non fatal error ?</div><div><br></div><div>Cheers,</div><div><br></div><div>Gilles</div></div>

