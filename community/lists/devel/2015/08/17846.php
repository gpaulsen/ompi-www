<?
$subject_val = "Re: [OMPI devel] [OMPI commits] Git: open-mpi/ompi branch master updated. dev-2362-ge2124c6";
include("../../include/msg-header.inc");
?>
<!-- received="Tue Aug 25 10:09:38 2015" -->
<!-- isoreceived="20150825140938" -->
<!-- sent="Tue, 25 Aug 2015 08:09:36 -0600" -->
<!-- isosent="20150825140936" -->
<!-- name="Howard Pritchard" -->
<!-- email="hppritcha_at_[hidden]" -->
<!-- subject="Re: [OMPI devel] [OMPI commits] Git: open-mpi/ompi branch master updated. dev-2362-ge2124c6" -->
<!-- id="CAF1Cqj7H9rPRsT+NQW_dk+8bHQbyBJgYPG-ouQZtW8g+LsZQ_g_at_mail.gmail.com" -->
<!-- charset="UTF-8" -->
<!-- inreplyto="20150825135348.E44B625F61A_at_lion.crest.iu.edu" -->
<!-- expires="-1" -->
<div class="center">
<table border="2" width="100%" class="links">
<tr>
<th><a href="date.php">Date view</a></th>
<th><a href="index.php">Thread view</a></th>
<th><a href="subject.php">Subject view</a></th>
<th><a href="author.php">Author view</a></th>
</tr>
</table>
</div>
<p class="headers">
<strong>Subject:</strong> Re: [OMPI devel] [OMPI commits] Git: open-mpi/ompi branch master updated. dev-2362-ge2124c6<br>
<strong>From:</strong> Howard Pritchard (<em>hppritcha_at_[hidden]</em>)<br>
<strong>Date:</strong> 2015-08-25 10:09:36
</p>
<ul class="links">
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17847.php">Jeff Squyres (jsquyres): "Re: [OMPI devel] mca_mtl_psm and java"</a>
<li><strong>Previous message:</strong> <a href="17845.php">Howard Pritchard: "Re: [OMPI devel] mca_mtl_psm and java"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<hr>
<!-- body="start" -->
<p>
is this going in to v2.x?
<br>
<p>----------
<br>
<p>sent from my smart phonr so no good type.
<br>
<p>Howard
<br>
On Aug 25, 2015 7:54 AM, &lt;gitdub_at_[hidden]&gt; wrote:
<br>
<p><span class="quotelev1">&gt; This is an automated email from the git hooks/post-receive script. It was
</span><br>
<span class="quotelev1">&gt; generated because a ref change was pushed to the repository containing
</span><br>
<span class="quotelev1">&gt; the project &quot;open-mpi/ompi&quot;.
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt; The branch, master has been updated
</span><br>
<span class="quotelev1">&gt;        via  e2124c61fee7bd5a156c90d559ba15f6ded34d53 (commit)
</span><br>
<span class="quotelev1">&gt;       from  6f2e8d20737907b474a401d041b5c0b1059e7d3f (commit)
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt; Those revisions listed above that are new to this repository have
</span><br>
<span class="quotelev1">&gt; not appeared on any other notification email; so we list those
</span><br>
<span class="quotelev1">&gt; revisions in full, below.
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt; - Log -----------------------------------------------------------------
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt; <a href="https://github.com/open-mpi/ompi/commit/e2124c61fee7bd5a156c90d559ba15f6ded34d53">https://github.com/open-mpi/ompi/commit/e2124c61fee7bd5a156c90d559ba15f6ded34d53</a>
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt; commit e2124c61fee7bd5a156c90d559ba15f6ded34d53
</span><br>
<span class="quotelev1">&gt; Author: Jeff Squyres &lt;jsquyres_at_[hidden]&gt;
</span><br>
<span class="quotelev1">&gt; Date:   Tue Aug 25 09:53:25 2015 -0400
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;     README: minor re-flowing on extra-long lines
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;     No other content changes; just re-flowing of long lines.
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt; diff --git a/README b/README
</span><br>
<span class="quotelev1">&gt; index 70f251d..6883d1f 100644
</span><br>
<span class="quotelev1">&gt; --- a/README
</span><br>
<span class="quotelev1">&gt; +++ b/README
</span><br>
<span class="quotelev1">&gt; @@ -436,8 +436,8 @@ General Run-Time Support Notes
</span><br>
<span class="quotelev1">&gt;  MPI Functionality and Features
</span><br>
<span class="quotelev1">&gt;  ------------------------------
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt; -- Rank reordering support is available using the TreeMatch library. It is
</span><br>
<span class="quotelev1">&gt; activated
</span><br>
<span class="quotelev1">&gt; -  for the graph and dist_graph topologies.
</span><br>
<span class="quotelev1">&gt; +- Rank reordering support is available using the TreeMatch library. It
</span><br>
<span class="quotelev1">&gt; +  is activated for the graph and dist_graph topologies.
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;  - All MPI-3 functionality is supported.
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt; @@ -532,37 +532,39 @@ MPI Collectives
</span><br>
<span class="quotelev1">&gt;    MPI process onto Mellanox QDR InfiniBand switch CPUs and HCAs.
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;  - The &quot;ML&quot; coll component is an implementation of MPI collective
</span><br>
<span class="quotelev1">&gt; -  operations that takes advantage of communication hierarchies
</span><br>
<span class="quotelev1">&gt; -  in modern systems. A ML collective operation is implemented by
</span><br>
<span class="quotelev1">&gt; +  operations that takes advantage of communication hierarchies in
</span><br>
<span class="quotelev1">&gt; +  modern systems. A ML collective operation is implemented by
</span><br>
<span class="quotelev1">&gt;    combining multiple independently progressing collective primitives
</span><br>
<span class="quotelev1">&gt;    implemented over different communication hierarchies, hence a ML
</span><br>
<span class="quotelev1">&gt; -  collective operation is also referred to as a hierarchical collective
</span><br>
<span class="quotelev1">&gt; -  operation. The number of collective primitives that are included in a
</span><br>
<span class="quotelev1">&gt; -  ML collective operation is a function of subgroups(hierarchies).
</span><br>
<span class="quotelev1">&gt; -  Typically, MPI processes in a single communication hierarchy such as
</span><br>
<span class="quotelev1">&gt; -  CPU socket, node, or subnet are grouped together into a single subgroup
</span><br>
<span class="quotelev1">&gt; -  (hierarchy). The number of subgroups are configurable at runtime,
</span><br>
<span class="quotelev1">&gt; -  and each different collective operation could be configured to have
</span><br>
<span class="quotelev1">&gt; -  a different of number of subgroups.
</span><br>
<span class="quotelev1">&gt; +  collective operation is also referred to as a hierarchical
</span><br>
<span class="quotelev1">&gt; +  collective operation. The number of collective primitives that are
</span><br>
<span class="quotelev1">&gt; +  included in a ML collective operation is a function of
</span><br>
<span class="quotelev1">&gt; +  subgroups(hierarchies).  Typically, MPI processes in a single
</span><br>
<span class="quotelev1">&gt; +  communication hierarchy such as CPU socket, node, or subnet are
</span><br>
<span class="quotelev1">&gt; +  grouped together into a single subgroup (hierarchy). The number of
</span><br>
<span class="quotelev1">&gt; +  subgroups are configurable at runtime, and each different collective
</span><br>
<span class="quotelev1">&gt; +  operation could be configured to have a different of number of
</span><br>
<span class="quotelev1">&gt; +  subgroups.
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;    The component frameworks and components used by/required for a
</span><br>
<span class="quotelev1">&gt;    &quot;ML&quot; collective operation.
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;    Frameworks:
</span><br>
<span class="quotelev1">&gt; -  * &quot;sbgp&quot; - Provides functionality for grouping processes into subgroups
</span><br>
<span class="quotelev1">&gt; +  * &quot;sbgp&quot; - Provides functionality for grouping processes into
</span><br>
<span class="quotelev1">&gt; +             subgroups
</span><br>
<span class="quotelev1">&gt;    * &quot;bcol&quot; - Provides collective primitives optimized for a particular
</span><br>
<span class="quotelev1">&gt;               communication hierarchy
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;    Components:
</span><br>
<span class="quotelev1">&gt; -  * sbgp components     - Provides grouping functionality over a CPU
</span><br>
<span class="quotelev1">&gt; socket
</span><br>
<span class="quotelev1">&gt; -                          (&quot;basesocket&quot;), shared memory (&quot;basesmuma&quot;),
</span><br>
<span class="quotelev1">&gt; -                          Mellanox's ConnectX HCA (&quot;ibnet&quot;), and other
</span><br>
<span class="quotelev1">&gt; -                          interconnects supported by PML (&quot;p2p&quot;)
</span><br>
<span class="quotelev1">&gt; -
</span><br>
<span class="quotelev1">&gt; -  * BCOL components     - Provides optimized collective primitives for
</span><br>
<span class="quotelev1">&gt; -                          shared memory (&quot;basesmuma&quot;), Mellanox's ConnectX
</span><br>
<span class="quotelev1">&gt; -                          HCA (&quot;iboffload&quot;), and other interconnects
</span><br>
<span class="quotelev1">&gt; supported
</span><br>
<span class="quotelev1">&gt; -                          by PML (&quot;ptpcoll&quot;)
</span><br>
<span class="quotelev1">&gt; +  * sbgp components - Provides grouping functionality over a CPU
</span><br>
<span class="quotelev1">&gt; +                      socket (&quot;basesocket&quot;), shared memory
</span><br>
<span class="quotelev1">&gt; +                      (&quot;basesmuma&quot;), Mellanox's ConnectX HCA
</span><br>
<span class="quotelev1">&gt; +                      (&quot;ibnet&quot;), and other interconnects supported by
</span><br>
<span class="quotelev1">&gt; +                      PML (&quot;p2p&quot;)
</span><br>
<span class="quotelev1">&gt; +  * BCOL components - Provides optimized collective primitives for
</span><br>
<span class="quotelev1">&gt; +                      shared memory (&quot;basesmuma&quot;), Mellanox's ConnectX
</span><br>
<span class="quotelev1">&gt; +                      HCA (&quot;iboffload&quot;), and other interconnects
</span><br>
<span class="quotelev1">&gt; +                      supported by PML (&quot;ptpcoll&quot;)
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;  - The &quot;cuda&quot; coll component provides CUDA-aware support for the
</span><br>
<span class="quotelev1">&gt;    reduction type collectives with GPU buffers. This component is only
</span><br>
<span class="quotelev1">&gt; @@ -1002,10 +1004,11 @@ RUN-TIME SYSTEM SUPPORT
</span><br>
<span class="quotelev1">&gt;    most cases.  This option is only needed for special configurations.
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;  --with-pmi
</span><br>
<span class="quotelev1">&gt; -  Build PMI support (by default on non-Cray XE/XC systems, it is not
</span><br>
<span class="quotelev1">&gt; built).
</span><br>
<span class="quotelev1">&gt; -  On Cray XE/XC systems, the location of pmi is detected automatically as
</span><br>
<span class="quotelev1">&gt; -  part of the configure process.  For non-Cray systems, if the pmi2.h
</span><br>
<span class="quotelev1">&gt; header
</span><br>
<span class="quotelev1">&gt; -  is found in addition to pmi.h, then support for PMI2 will be built.
</span><br>
<span class="quotelev1">&gt; +  Build PMI support (by default on non-Cray XE/XC systems, it is not
</span><br>
<span class="quotelev1">&gt; +  built).  On Cray XE/XC systems, the location of pmi is detected
</span><br>
<span class="quotelev1">&gt; +  automatically as part of the configure process.  For non-Cray
</span><br>
<span class="quotelev1">&gt; +  systems, if the pmi2.h header is found in addition to pmi.h, then
</span><br>
<span class="quotelev1">&gt; +  support for PMI2 will be built.
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;  --with-slurm
</span><br>
<span class="quotelev1">&gt;    Force the building of SLURM scheduler support.
</span><br>
<span class="quotelev1">&gt; @@ -1635,9 +1638,9 @@ Open MPI API Extensions
</span><br>
<span class="quotelev1">&gt;  -----------------------
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;  Open MPI contains a framework for extending the MPI API that is
</span><br>
<span class="quotelev1">&gt; -available to applications.  Each extension is usually a standalone set of
</span><br>
<span class="quotelev1">&gt; -functionality that is distinct from other extensions (similar to how
</span><br>
<span class="quotelev1">&gt; -Open MPI's plugins are usually unrelated to each other).  These
</span><br>
<span class="quotelev1">&gt; +available to applications.  Each extension is usually a standalone set
</span><br>
<span class="quotelev1">&gt; +of functionality that is distinct from other extensions (similar to
</span><br>
<span class="quotelev1">&gt; +how Open MPI's plugins are usually unrelated to each other).  These
</span><br>
<span class="quotelev1">&gt;  extensions provide new functions and/or constants that are available
</span><br>
<span class="quotelev1">&gt;  to MPI applications.
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt; @@ -1955,9 +1958,9 @@ Here's how the three sub-groups are defined:
</span><br>
<span class="quotelev1">&gt;      get their MPI/OSHMEM application to run correctly.
</span><br>
<span class="quotelev1">&gt;   2. Application tuner: Generally, these are parameters that can be
</span><br>
<span class="quotelev1">&gt;      used to tweak MPI application performance.
</span><br>
<span class="quotelev1">&gt; - 3. MPI/OSHMEM developer: Parameters that either don't fit in the other
</span><br>
<span class="quotelev1">&gt; two,
</span><br>
<span class="quotelev1">&gt; -    or are specifically intended for debugging / development of Open
</span><br>
<span class="quotelev1">&gt; -    MPI itself.
</span><br>
<span class="quotelev1">&gt; + 3. MPI/OSHMEM developer: Parameters that either don't fit in the
</span><br>
<span class="quotelev1">&gt; +    other two, or are specifically intended for debugging /
</span><br>
<span class="quotelev1">&gt; +    development of Open MPI itself.
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;  Each sub-group is broken down into three classifications:
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt; -----------------------------------------------------------------------
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt; Summary of changes:
</span><br>
<span class="quotelev1">&gt;  README | 67
</span><br>
<span class="quotelev1">&gt; ++++++++++++++++++++++++++++++++++--------------------------------
</span><br>
<span class="quotelev1">&gt;  1 file changed, 35 insertions(+), 32 deletions(-)
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt;
</span><br>
<span class="quotelev1">&gt; hooks/post-receive
</span><br>
<span class="quotelev1">&gt; --
</span><br>
<span class="quotelev1">&gt; open-mpi/ompi
</span><br>
<span class="quotelev1">&gt; _______________________________________________
</span><br>
<span class="quotelev1">&gt; ompi-commits mailing list
</span><br>
<span class="quotelev1">&gt; ompi-commits_at_[hidden]
</span><br>
<span class="quotelev1">&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/ompi-commits">http://www.open-mpi.org/mailman/listinfo.cgi/ompi-commits</a>
</span><br>
<span class="quotelev1">&gt;
</span><br>
<p><hr>
<ul>
<li>text/html attachment: <a href="http://www.open-mpi.org/community/lists/devel/att-17846/attachment">attachment</a>
</ul>
<!-- attachment="attachment" -->
<!-- body="end" -->
<hr>
<ul class="links">
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17847.php">Jeff Squyres (jsquyres): "Re: [OMPI devel] mca_mtl_psm and java"</a>
<li><strong>Previous message:</strong> <a href="17845.php">Howard Pritchard: "Re: [OMPI devel] mca_mtl_psm and java"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
</ul>
<div class="center">
<table border="2" width="100%" class="links">
<tr>
<th><a href="date.php">Date view</a></th>
<th><a href="index.php">Thread view</a></th>
<th><a href="subject.php">Subject view</a></th>
<th><a href="author.php">Author view</a></th>
</tr>
</table>
</div>
<!-- trailer="footer" -->
<? include("../../include/msg-footer.inc") ?>
