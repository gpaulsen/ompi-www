<html><head><meta http-equiv="Content-Type" content="text/html charset=utf-8"></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;" class="">The —map-by node option should now be fixed on master, and PRs waiting for 1.10 and 2.0<div class=""><br class=""></div><div class="">Thx!</div><div class=""><br class=""><div><blockquote type="cite" class=""><div class="">On Apr 12, 2016, at 6:45 PM, Ralph Castain &lt;<a href="mailto:rhc@open-mpi.org" class="">rhc@open-mpi.org</a>&gt; wrote:</div><br class="Apple-interchange-newline"><div class=""><meta http-equiv="Content-Type" content="text/html charset=utf-8" class=""><div style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;" class="">FWIW: speaking just to the —map-by node issue, Josh Ladd reported the problem on master as well yesterday. I’ll be looking into it on Wed.<div class=""><br class=""><div class=""><blockquote type="cite" class=""><div class="">On Apr 12, 2016, at 5:53 PM, George Bosilca &lt;<a href="mailto:bosilca@icl.utk.edu" class="">bosilca@icl.utk.edu</a>&gt; wrote:</div><br class="Apple-interchange-newline"><div class=""><div dir="ltr" class=""><br class=""><div class="gmail_extra"><br class=""><div class="gmail_quote">On Wed, Apr 13, 2016 at 1:59 AM, Gilles Gouaillardet <span dir="ltr" class="">&lt;<a href="mailto:gilles@rist.or.jp" target="_blank" class="">gilles@rist.or.jp</a>&gt;</span> wrote:<br class=""><blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex">George,<br class="">
<br class="">
about the process binding part<span class=""><br class="">
<br class="">
On 4/13/2016 7:32 AM, George Bosilca wrote:<br class="">
<blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex">
Also my processes, despite the fact that I asked for 1 per node, are not bound to the first core. Shouldn’t we release the process binding when we know there is a single process per node (as in the above case) ?<br class="">
</blockquote></span>
did you expect the tasks are bound to the first *core* on each node ?<br class="">
<br class="">
i would expect the tasks are bound to the first *socket* on each node.<br class=""></blockquote><div class=""><br class=""></div><div class="">In this particular instance, where it has been explicitly requested to have a single process per node, I would have expected the process to be unbound (we know there is only one per node). It is the responsibility of the application to bound itself or its thread if necessary. Why are we enforcing a particular binding policy?</div><div class=""><br class=""></div><blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex">
(since we do not know how many (OpenMP or other) threads will be used by the application,&nbsp;</blockquote><blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex">
--bind-to socket is a good policy imho. in this case (one task per node), no binding at all would mean<br class="">
the task can migrate from one socket to the other, and/or OpenMP threads are bound accross sockets.<br class="">
That would trigger some NUMA effects (better bandwidth if memory is locally accessed, but worst performance<br class="">
is memory is allocated only on one socket).<br class="">
so imho, --bind-to socket is still my preferred policy, even if there is only one MPI task per node.<br class=""></blockquote><div class=""><br class=""></div><div class="">Open MPI is about MPI ranks/processes. I don't think it is our job to try to figure out how the user handle do with it's own threads.</div><div class=""><br class=""></div><div class="">Your justification make sense if the application only uses a single socket. It also make sense if one starts multiple ranks per node, and the internal threads of each MPI process inherit the MPI process binding. However, in the case where there is a single process per node, because there is a mismatch between the number of resources available (hardware threads) and the binding of the parent process, all the threads of the MPI application are [by default] bound on a single socket.</div><div class=""><br class=""></div><div class="">&nbsp;George.<br class=""></div><div class=""><br class=""></div><div class="">PS: That being said I think I'll need to implement the binding code anyway in order to deal with the wide variety of behaviors in the different MPI implementations.</div><div class=""><br class=""></div><div class="">&nbsp;</div><blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex">
<br class="">
Cheers,<br class="">
<br class="">
Gilles<br class="">
_______________________________________________<br class="">
devel mailing list<br class="">
<a href="mailto:devel@open-mpi.org" target="_blank" class="">devel@open-mpi.org</a><br class="">
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br class="">
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2016/04/18758.php" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2016/04/18758.php</a></blockquote></div><br class=""></div></div>
_______________________________________________<br class="">devel mailing list<br class=""><a href="mailto:devel@open-mpi.org" class="">devel@open-mpi.org</a><br class="">Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br class="">Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2016/04/18759.php" class="">http://www.open-mpi.org/community/lists/devel/2016/04/18759.php</a></div></blockquote></div><br class=""></div></div></div></blockquote></div><br class=""></div></body></html>
