<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" xmlns="http://www.w3.org/TR/REC-html40"><head><META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=us-ascii"><meta name=Generator content="Microsoft Word 14 (filtered medium)"><style><!--
/* Font Definitions */
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0cm;
	margin-bottom:.0001pt;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-priority:99;
	color:purple;
	text-decoration:underline;}
span.E-MailFormatvorlage17
	{mso-style-type:personal-compose;
	font-family:"Calibri","sans-serif";
	color:windowtext;}
.MsoChpDefault
	{mso-style-type:export-only;
	font-family:"Calibri","sans-serif";}
@page WordSection1
	{size:612.0pt 792.0pt;
	margin:70.85pt 70.85pt 2.0cm 70.85pt;}
div.WordSection1
	{page:WordSection1;}
--></style><!--[if gte mso 9]><xml>
<o:shapedefaults v:ext="edit" spidmax="1026" />
</xml><![endif]--><!--[if gte mso 9]><xml>
<o:shapelayout v:ext="edit">
<o:idmap v:ext="edit" data="1" />
</o:shapelayout></xml><![endif]--></head><body lang=EN-US link=blue vlink=purple><div class=WordSection1><p class=MsoNormal>Hi,<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>It looks like the rmda OSC component does not progress passive RMA operations at the target during calls to MPI_WIN_(UN)LOCK. As a sample case take a master-worker program where each worker writes to an entry in an array exposed in the master&#8217;s window:<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>MPI_Comm_size(MPI_COMM_WORLD, &amp;size);<o:p></o:p></p><p class=MsoNormal>MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>If (rank == 0)<o:p></o:p></p><p class=MsoNormal>{<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; // Master code<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; MPI_Alloc_mem(size * sizeof(int), MPI_INFO_NULL, &amp;array);<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; MPI_Win_create(array, size * sizeof(int), sizeof(int), MPI_INFO_NULL, MPI_COMM_WORLD, &amp;win);<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; do<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; {<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;MPI_Win_lock(MPI_LOCK_EXCLUSIVE, 0, 0, win);<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;nonzeros = count non-zero elements of array<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;MPI_Win_unlock(0, win);<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; } while(nonzeros &lt; size-1);<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; MPI_Win_free(&amp;win);<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; MPI_Free_mem(array);<o:p></o:p></p><p class=MsoNormal>}<o:p></o:p></p><p class=MsoNormal>else<o:p></o:p></p><p class=MsoNormal>{<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; // Worker code<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; int one = 1;<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; MPI_Win_create(NULL, 0, 1, MPI_INFO_NULL, MPI_COMM_WORLD, &amp;win);<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; // Postpone the RMA with a rank-specific time<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; sleep(rank);<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; MPI_Win_lock(MPI_LOCK_EXCLUSIVE, 0, 0, win);<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; MPI_Put(&amp;one, 1, MPI_INT, 0, rank, 1, MPI_INT, win);<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; MPI_Win_unlock(0, win);<o:p></o:p></p><p class=MsoNormal>&nbsp;&nbsp; MPI_Win_free(&amp;win);<o:p></o:p></p><p class=MsoNormal>}<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>Attached is a complete sample program. The program hangs when run with the default MCA settings:<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>$ mpirun -n 3 ./rma.x<o:p></o:p></p><p class=MsoNormal>[1379003818.571960] 0 workers checked in<o:p></o:p></p><p class=MsoNormal>[1379003819.571317] Worker 1 acquired lock<o:p></o:p></p><p class=MsoNormal>[1379003819.571374] Worker 1 unlocking the window<o:p></o:p></p><p class=MsoNormal>[1379003820.571342] Worker 2 acquired lock<o:p></o:p></p><p class=MsoNormal>[1379003820.571384] Worker 2 unlocking the window<o:p></o:p></p><p class=MsoNormal>&lt;hangs&gt;<o:p></o:p></p><p class=MsoNormal> <o:p></o:p></p><p class=MsoNormal>On the other hand, it works as expected if pt2pt is forced:<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>$ mpirun --mca osc pt2pt -n 3 ./rma.x | sort<o:p></o:p></p><p class=MsoNormal>[1379003926.000442] 0 workers checked in<o:p></o:p></p><p class=MsoNormal>[1379003926.998981] Worker 1 acquired lock<o:p></o:p></p><p class=MsoNormal>[1379003926.999027] Worker 1 unlocking the window<o:p></o:p></p><p class=MsoNormal>[1379003926.999076] Worker 1 synched<o:p></o:p></p><p class=MsoNormal>[1379003926.999078] 1 workers checked in<o:p></o:p></p><p class=MsoNormal>[1379003927.998917] Worker 2 acquired lock<o:p></o:p></p><p class=MsoNormal>[1379003927.998940] Worker 2 unlocking the window<o:p></o:p></p><p class=MsoNormal>[1379003927.998962] Worker 2 synched<o:p></o:p></p><p class=MsoNormal>[1379003927.998964] 2 workers checked in<o:p></o:p></p><p class=MsoNormal>[1379003927.998973] All workers checked in<o:p></o:p></p><p class=MsoNormal>[1379003927.998996] Worker 1 done<o:p></o:p></p><p class=MsoNormal>[1379003927.998996] Worker 2 done<o:p></o:p></p><p class=MsoNormal>[1379003927.999099] Master finished<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>All processes are started on the same host. Open MPI is 1.6.4 without progression thread. The output from ompi_info is attached. The same behaviour (hang with rdma, success with pt2pt) is observed when the tcp BTL is used and when all processes run on separate cluster nodes and talk via the openib BTL.<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>Is this a bug in the rdma OSC component or does the sample program violate the MPI correctness requirements for RMA operations?<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal>Kind regards,<o:p></o:p></p><p class=MsoNormal>Hristo<o:p></o:p></p><p class=MsoNormal><o:p>&nbsp;</o:p></p><p class=MsoNormal><span lang=EN-GB>--<o:p></o:p></span></p><p class=MsoNormal><span lang=EN-GB>Hristo Iliev, PhD &#8211; High Performance Computing Team<o:p></o:p></span></p><p class=MsoNormal><span lang=EN-GB>RWTH Aachen University, Center for Computing and Communication<o:p></o:p></span></p><p class=MsoNormal><span lang=DE>Rechen- und Kommunikationszentrum der RWTH Aachen<o:p></o:p></span></p><p class=MsoNormal><span lang=DE>Seffenter Weg 23, D 52074 Aachen (Germany)<o:p></o:p></span></p></div></body></html>
