<div dir="ltr">Ralph,<div><br></div><div>This is the front end of a production cluster at NERSC.</div><div>So, I would not be surprised if there is a fairly restrictive firewall configuration in place.</div><div>However, I could&#39;t find a way to query the configuration.</div>
<div><br></div><div>The verbose output with (only) <span style="color:rgb(0,0,0);font-family:arial,sans-serif;font-size:13px">&quot;-mca oob_base_verbose 10&quot; is attached.</span></div><div><br></div><div>On a hunch, I tried adding &quot;-mca oob_tcp_if_include lo&quot; and IT WORKS!</div>
<div>Is there some reason why the loopback interface is not being used automatically for the single-host case?</div><div>That would seem to be a straight-forward solution to this issue.</div><div><br></div><div>-Paul</div>
</div><div class="gmail_extra"><br><br><div class="gmail_quote">On Fri, Jan 10, 2014 at 12:43 PM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div style="word-wrap:break-word">Bingo - the proc can&#39;t send a message to the daemon to tell it &quot;i&#39;m alive and need my nidmap data&quot;. I suspect we&#39;ll find that your headnode isn&#39;t allowing us to open a socket for communication between two processes on it, and we don&#39;t have (yet) a pipe-like mechanism to replace it.<div>
<br></div><div>Can verify that by putting &quot;-mca oob_base_verbose 10&quot; on the cmd line - should see the oob indicate that it fails to make the connection back to the daemon</div><div><br></div><div><br><div><div>On Jan 10, 2014, at 12:33 PM, Paul Hargrove &lt;<a href="mailto:phhargrove@lbl.gov" target="_blank">phhargrove@lbl.gov</a>&gt; wrote:</div>
<br><blockquote type="cite"><div dir="ltr">Ralph,<div><br></div><div>Configuring using a proper --with-tm=... I find that I *can* run a singleton in an allocation (&quot;qsub -I -l nodes=1 ....&quot;).</div><div>The case of a singleton on the front end is still failing.</div>

<div><br></div><div>The verbose output using &quot;<span style="font-family:arial,sans-serif;font-size:13px">-mca state_base_verbose 5 -mca plm_base_verbose 5 -mca odls_base_verbose 5&quot; is attached.</span></div>
<div><span style="font-family:arial,sans-serif;font-size:13px"><br></span></div><div><span style="font-family:arial,sans-serif;font-size:13px">-Paul</span></div></div><div class="gmail_extra">
<br><br><div class="gmail_quote">On Fri, Jan 10, 2014 at 12:12 PM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">

<div style="word-wrap:break-word"><br><div><div>On Jan 10, 2014, at 11:04 AM, Paul Hargrove &lt;<a href="mailto:phhargrove@lbl.gov" target="_blank">phhargrove@lbl.gov</a>&gt; wrote:</div><br><blockquote type="cite"><div dir="ltr">

<div class="gmail_extra"><div class="gmail_quote">On Fri, Jan 10, 2014 at 10:41 AM, Paul Hargrove <span dir="ltr">&lt;<a href="mailto:phhargrove@lbl.gov" target="_blank">phhargrove@lbl.gov</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-color:rgb(204,204,204);border-left-style:solid;padding-left:1ex"><div dir="ltr"><div class="gmail_extra"><br><div class="gmail_quote">


On Fri, Jan 10, 2014 at 10:08 AM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-color:rgb(204,204,204);border-left-style:solid;padding-left:1ex">??? that was it? Was this built with --enable-debug?</blockquote>


</div><br>Nope, I missed --enable-debug.  Will try again.</div><span><font color="#888888">
<div class="gmail_extra"><br></div></font></span></div></blockquote><div><br></div><div>OK, Take-2 below.</div><div>There is an obvious &quot;<span style="font-family:&#39;courier new&#39;,monospace">recipient list is empty!</span>&quot; in the output.</div>

</div></div></div></blockquote><div><br></div>That one is correct and expected - all it means is that you are running on only one node, so mpirun doesn&#39;t need to relay messages to another daemon</div><div><br><blockquote type="cite">

<div dir="ltr"><div class="gmail_extra"><div class="gmail_quote">
<div><br></div><div>-Paul</div><div><br></div><div><div><font face="courier new, monospace">$ mpirun -mca btl sm,self -np 2 -mca grpcomm_base_verbose 5 -mca orte_nidmap_verbose 10 examples/ring_c&#39;</font></div><div><font face="courier new, monospace">[cvrsvc01:21200] mca:base:select:(grpcomm) Querying component [bad]</font></div>


<div><font face="courier new, monospace">[cvrsvc01:21200] mca:base:select:(grpcomm) Query of component [bad] set priority to 10</font></div><div><font face="courier new, monospace">[cvrsvc01:21200] mca:base:select:(grpcomm) Selected component [bad]</font></div>


<div><font face="courier new, monospace">[cvrsvc01:21200] [[45961,0],0] grpcomm:base:receive start comm</font></div><div><font face="courier new, monospace">[cvrsvc01:21200] [[45961,0],0] orte:util:encode_nidmap</font></div>


<div><font face="courier new, monospace">[cvrsvc01:21200] [[45961,0],0] grpcomm:bad:xcast sent to job [45961,0] tag 1</font></div><div><font face="courier new, monospace">[cvrsvc01:21200] [[45961,0],0] grpcomm:xcast:recv: with 1135 bytes</font></div>


<div><font face="courier new, monospace">[cvrsvc01:21200] [[45961,0],0] orte:daemon:send_relay - recipient list is empty!</font></div><div><font face="courier new, monospace">[cvrsvc01:21200] [[45961,0],0] orte:util:encode_nidmap</font></div>


<div><font face="courier new, monospace">[cvrsvc01:21200] [[45961,0],0] orte:util:build:daemon:nidmap packed 55 bytes</font></div><div><font face="courier new, monospace">[cvrsvc01:21200] [[45961,0],0] PROGRESSING COLL id 0</font></div>


<div><font face="courier new, monospace">[cvrsvc01:21200] [[45961,0],0] ALL LOCAL PROCS FOR JOB [45961,1] CONTRIBUTE 2</font></div><div><font face="courier new, monospace">[cvrsvc01:21200] [[45961,0],0] PROGRESSING COLL id 1</font></div>


<div><font face="courier new, monospace">[cvrsvc01:21200] [[45961,0],0] ALL LOCAL PROCS FOR JOB [45961,1] CONTRIBUTE 2</font></div><div><font face="courier new, monospace">[cvrsvc01:21200] [[45961,0],0] PROGRESSING COLL id 2</font></div>


<div><font face="courier new, monospace">[cvrsvc01:21200] [[45961,0],0] ALL LOCAL PROCS FOR JOB [45961,1] CONTRIBUTE 2</font></div><div><font face="courier new, monospace">[cvrsvc01:21202] mca:base:select:(grpcomm) Querying component [bad]</font></div>


<div><font face="courier new, monospace">[cvrsvc01:21202] mca:base:select:(grpcomm) Query of component [bad] set priority to 10</font></div><div><font face="courier new, monospace">[cvrsvc01:21202] mca:base:select:(grpcomm) Selected component [bad]</font></div>


<div><font face="courier new, monospace">[cvrsvc01:21202] [[45961,1],0] grpcomm:base:receive start comm</font></div><div><font face="courier new, monospace">[cvrsvc01:21202] [[45961,1],0] ORTE_ERROR_LOG: Data for specified key not found in file /global/homes/h/hargrove/GSCRATCH/OMPI/openmpi-trunk-linux-x86_64-gcc/openmpi-1.9a1r30215/orte/runtime/orte_globals.c at line 503</font></div>


<div><font face="courier new, monospace">[cvrsvc01:21203] mca:base:select:(grpcomm) Querying component [bad]</font></div><div><font face="courier new, monospace">[cvrsvc01:21203] mca:base:select:(grpcomm) Query of component [bad] set priority to 10</font></div>


<div><font face="courier new, monospace">[cvrsvc01:21203] mca:base:select:(grpcomm) Selected component [bad]</font></div><div><font face="courier new, monospace">[cvrsvc01:21203] [[45961,1],1] grpcomm:base:receive start comm</font></div>


<div><font face="courier new, monospace">[cvrsvc01:21203] [[45961,1],1] ORTE_ERROR_LOG: Data for specified key not found in file /global/homes/h/hargrove/GSCRATCH/OMPI/openmpi-trunk-linux-x86_64-gcc/openmpi-1.9a1r30215/orte/runtime/orte_globals.c at line 503</font></div>

</div></div></div></div></blockquote><div><br></div><div><br></div>This is very weird - it appears that your procs are looking for hostname data prior to receiving the necessary data. Let&#39;s try jacking up the debug, I guess - add &quot;-mca state_base_verbose 5 -mca plm_base_verbose 5 -mca odls_base_verbose 5&quot;</div>

<div><br></div><div>Sorry that will be rather wordy, but I don&#39;t understand the ordering you show above. It&#39;s like your procs are skipping a bunch of steps in the startup procedure.</div><div><br></div><div>Out of curiosity, if you do have an allocation on run on it, does it work?</div>

<div><br><blockquote type="cite"><div dir="ltr"><div class="gmail_extra"><div class="gmail_quote"><div>
</div><div><br></div><div> </div></div><span><font color="#888888">-- <br><font face="courier new, monospace"><div>Paul H. Hargrove                          <a href="mailto:PHHargrove@lbl.gov" target="_blank">PHHargrove@lbl.gov</a></div>

<div>Future Technologies Group</div>
<div>Computer and Data Sciences Department     Tel: <a href="tel:%2B1-510-495-2352" value="+15104952352" target="_blank">+1-510-495-2352</a></div><div>Lawrence Berkeley National Laboratory     Fax: <a href="tel:%2B1-510-486-6900" value="+15104866900" target="_blank">+1-510-486-6900</a></div>

</font>
</font></span></div></div><span><font color="#888888">
_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a></font></span></blockquote>

</div><br></div><br>_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br></blockquote></div><br><br clear="all"><span class="HOEnZb"><font color="#888888"><div>
<br></div>-- <br><font face="courier new, monospace"><div>
Paul H. Hargrove                          <a href="mailto:PHHargrove@lbl.gov" target="_blank">PHHargrove@lbl.gov</a></div><div>Future Technologies Group</div><div>Computer and Data Sciences Department     Tel: <a href="tel:%2B1-510-495-2352" value="+15104952352" target="_blank">+1-510-495-2352</a></div>

<div>Lawrence Berkeley National Laboratory     Fax: <a href="tel:%2B1-510-486-6900" value="+15104866900" target="_blank">+1-510-486-6900</a></div></font>
</font></span></div><span class="HOEnZb"><font color="#888888">
<span>&lt;log-fe.bz2&gt;</span>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a></font></span></blockquote>
</div><br></div></div><br>_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br></blockquote></div><br><br clear="all"><div><br></div>-- <br><font face="courier new, monospace"><div>
Paul H. Hargrove                          <a href="mailto:PHHargrove@lbl.gov" target="_blank">PHHargrove@lbl.gov</a></div><div>Future Technologies Group</div><div>Computer and Data Sciences Department     Tel: +1-510-495-2352</div>
<div>Lawrence Berkeley National Laboratory     Fax: +1-510-486-6900</div></font>
</div>

