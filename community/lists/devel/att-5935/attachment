I&#39;m not entirely sure if David is going to be in today, so I will answer for him (and let him correct me later!).<br><br>This code is indeed representative of what the app is doing. Basically, the user repeatedly splits the communicator so he can run mini test cases before going on to the larger computation. So it is always the base communicator being repeatedly split and freed.<br>
<br>I would suspect, therefore, that the quick fix would serve us just fine while the worst case is later resolved.<br><br>Thanks<br>Ralph<br><br><div class="gmail_quote">On Fri, May 1, 2009 at 6:08 AM, Edgar Gabriel <span dir="ltr">&lt;<a href="mailto:gabriel@cs.uh.edu">gabriel@cs.uh.edu</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">David,<br>
<br>
is this code representative for what your app is doing? E.g. you have a base communicator (e.g. MPI_COMM_WORLD) which is being &#39;split&#39;, freed again, split, freed again etc. ? i.e. the important aspect is that the same &#39;base&#39; communicator is being used for deriving new communicators again and again?<br>

<br>
The reason I ask is two-fold: one, you would in that case be one of the ideal beneficiaries of the block cid algorithm :-) (even if it fails you right now);  two, a fix for this scenario which basically tries to reuse the last block used (and which would fix your case if the condition is true) is roughly five lines of code. This would give us the possibility to have a fix quickly in the trunk and v1.3 (keep in mind that the block-cid code is in the trunk since two years and this is the first problem that we have) and give us more time to develop a profound solution for the worst case - a chain of communicators being created, e.g. communicator 1 is basis to derive a new comm 2, comm 2 is being used to derive comm 3 etc.<br>

<br>
Thanks<br>
Edgar<br>
<br>
David Gunter wrote:<br>
<blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
Here is the test code reproducer:<br>
<br>
      program test2<br>
      implicit none<br>
      include &#39;mpif.h&#39;<br>
      integer ierr, myid, numprocs,i1,i2,n,local_comm,<br>
     $     icolor,ikey,rank,root<br>
<br>
c<br>
c...  MPI set-up<br>
      ierr = 0<br>
      call MPI_INIT(IERR)<br>
      ierr = 1<br>
      CALL MPI_COMM_SIZE(MPI_COMM_WORLD, numprocs, ierr)<br>
      print *, ierr<br>
<br>
      ierr = -1<br>
<br>
      CALL MPI_COMM_RANK(MPI_COMM_WORLD, myid, ierr)<br>
<br>
      ierr = -5<br>
      i1 = ierr<br>
      if (myid.eq.0) i1 = 1<br>
      call mpi_allreduce(i1, i2, 1,MPI_integer,MPI_MIN,<br>
     $     MPI_COMM_WORLD,ierr)<br>
<br>
      ikey = myid<br>
      if (mod(myid,2).eq.0) then<br>
         icolor = 0<br>
      else<br>
         icolor = MPI_UNDEFINED<br>
      end if<br>
<br>
      root = 0<br>
      do n = 1, 100000<br>
<br>
         call MPI_COMM_SPLIT(MPI_COMM_WORLD, icolor,<br>
     $        ikey, local_comm, ierr)<br>
<br>
         if (mod(myid,2).eq.0) then<br>
            CALL MPI_COMM_RANK(local_comm, rank, ierr)<br>
            i2 = i1<br>
            call mpi_reduce(i1, i2, 1,MPI_integer,MPI_MIN,<br>
     $           root, local_comm,ierr)<br>
<br>
            if (myid.eq.0.and.mod(n,10).eq.0)<br>
     $           print *, n, i1, i2,icolor,ikey<br>
<br>
            call mpi_comm_free(local_comm, ierr)<br>
         end if<br>
<br>
      end do<br>
c      if (icolor.eq.0) call mpi_comm_free(local_comm, ierr)<br>
<br>
<br>
<br>
      call MPI_barrier(MPi_COMM_WORLD,ierr)<br>
<br>
      call MPI_FINALIZE(IERR)<br>
<br>
      print *, myid, ierr<br>
<br>
      end<br>
<br>
<br>
<br>
-david<br>
-- <br>
David Gunter<br>
HPC-3: Parallel Tools Team<br>
Los Alamos National Laboratory<br>
<br>
<br>
<br>
On Apr 30, 2009, at 12:43 PM, David Gunter wrote:<br>
<br>
<blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
Just to throw out more info on this, the test code runs fine on previous versions of OMPI.  It only hangs on the 1.3 line when the cid reaches 65536.<br>
<br>
-david<br>
-- <br>
David Gunter<br>
HPC-3: Parallel Tools Team<br>
Los Alamos National Laboratory<br>
<br>
<br>
<br>
On Apr 30, 2009, at 12:28 PM, Edgar Gabriel wrote:<br>
<br>
<blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
cid&#39;s are in fact not recycled in the block algorithm. The problem is that comm_free is not collective, so you can not make any assumptions whether other procs have also released that communicator.<br>
<br>
<br>
But nevertheless, a cid in the communicator structure is a uint32_t, so it should not hit the 16k limit there yet. this is not new, so if there is a discrepancy between what the comm structure assumes that a cid is and what the pml assumes, than this was in the code since the very first days of Open MPI...<br>

<br>
Thanks<br>
Edgar<br>
<br>
Brian W. Barrett wrote:<br>
<blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
On Thu, 30 Apr 2009, Ralph Castain wrote:<br>
<blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
We seem to have hit a problem here - it looks like we are seeing a<br>
built-in limit on the number of communicators one can create in a<br>
program. The program basically does a loop, calling MPI_Comm_split each<br>
time through the loop to create a sub-communicator, does a reduce<br>
operation on the members of the sub-communicator, and then calls<br>
MPI_Comm_free to release it (this is a minimized reproducer for the real<br>
code). After 64k times through the loop, the program fails.<br>
<br>
This looks remarkably like a 16-bit index that hits a max value and then<br>
blocks.<br>
<br>
I have looked at the communicator code, but I don&#39;t immediately see such<br>
a field. Is anyone aware of some other place where we would have a limit<br>
that would cause this problem?<br>
</blockquote>
There&#39;s a maximum of 32768 communicator ids when using OB1 (each PML can set the max contextid, although the communicator code is the part that actually assigns a cid).  Assuming that comm_free is actually properly called, there should be plenty of cids available for that pattern. However, I&#39;m not sure I understand the block algorithm someone added to cid allocation - I&#39;d have to guess that there&#39;s something funny with that routine and cids aren&#39;t being recycled properly.<br>

Brian<br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote>
<br>
-- <br>
Edgar Gabriel<br>
Assistant Professor<br>
Parallel Software Technologies Lab      <a href="http://pstl.cs.uh.edu" target="_blank">http://pstl.cs.uh.edu</a><br>
Department of Computer Science          University of Houston<br>
Philip G. Hoffman Hall, Room 524        Houston, TX-77204, USA<br>
Tel: +1 (713) 743-3857                  Fax: +1 (713) 743-3335<br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote>
<br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote>
<br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote>
<br>
-- <br>
Edgar Gabriel<br>
Assistant Professor<br>
Parallel Software Technologies Lab      <a href="http://pstl.cs.uh.edu" target="_blank">http://pstl.cs.uh.edu</a><br>
Department of Computer Science          University of Houston<br>
Philip G. Hoffman Hall, Room 524        Houston, TX-77204, USA<br>
Tel: +1 (713) 743-3857                  Fax: +1 (713) 743-3335<br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote></div><br>

