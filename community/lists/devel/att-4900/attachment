<html><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; "><br><div><div>On Nov 14, 2008, at 7:41 AM, Richard Graham wrote:</div><br class="Apple-interchange-newline"><blockquote type="cite"><div> <font face="Calibri, Verdana, Helvetica, Arial"><span style="font-size:11pt">Just a few comments:<br> &nbsp;&nbsp;- not sure what sort of alternative memory approach is being considered. &nbsp;The current approach was selected for two reasons:<br> &nbsp;&nbsp;&nbsp;&nbsp;- If something like anonymous memory is being used, one can only inherit access to the shared files, so one process needs<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;set up the shared memory regions, and then fork() the procs that will use it. &nbsp;This usually implies that to do this portably,<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;this needs to happen inside of MPI_Init(), so up to that stage only one process runs on each host. &nbsp;Also, unrelated procs can’t<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;access this memory – can’t use this in the context of Fault Tolerance.<br> &nbsp;&nbsp;- The approach used here is very efficient for small systems, so alternatives should be added to what is in place here, so we<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;don’t loose the performance potential on small SMP’s, which still describes the vast majority of systems.</span></font></div></blockquote><div><br></div>I concur - however, note that the segv occurred on a 4ppn system, which I think we would all agree constitutes a small SMP. I believe that the alternative memory approach needs to be a separate component, but I also believe that we need to modify the existing component so it doesn't segv if adequate memory isn't found.</div><div><br></div><div>Just my $.002</div><div><br><blockquote type="cite"><div><font face="Calibri, Verdana, Helvetica, Arial"><span style="font-size:11pt"><br> <br> Rich<br> <br> <br> On 11/14/08 9:22 AM, "Jeff Squyres" &lt;<a href="jsquyres@cisco.com">jsquyres@cisco.com</a>> wrote:<br> <br> </span></font><blockquote type="cite"><font face="Calibri, Verdana, Helvetica, Arial"><span style="font-size:11pt">Ok. &nbsp;Should be pretty easy to test/simulate to figure out what's going <br> on -- e.g., whether it's segv'ing in MPI_INIT or the first MPI_SEND.<br> <br> <br> On Nov 14, 2008, at 9:19 AM, Ralph Castain wrote:<br> <br> > Until we do complete the switch, and for systems that do not support <br> > the alternate type of shared memory (I believe it is only Linux?), I <br> > truly believe we should do something nicer than segv.<br> ><br> > Just to clarify: I know the segv case was done with paffinity set, <br> > and believe both cases were done that way. In the first case, I was <br> > told that the segv hit when they did MPI_Send, but I did not <br> > personally verify that claim - it could be that it hit during <br> > maffinity binding if, as you suggest, we actually touch the page at <br> > that time.<br> ><br> > Ralph<br> ><br> ><br> ><br> > On Nov 14, 2008, at 7:07 AM, Jeff Squyres wrote:<br> ><br> >> It's been a looooong time since I've looked at the sm code; Eugene <br> >> has looked at it much more in-depth recently than I have. &nbsp;But I'm <br> >> guessing we *haven't* checked this stuff to abort nicely in such <br> >> error conditions. &nbsp;We might very well succeed in the mmap but then <br> >> segv later when the memory isn't actually available. &nbsp;Perhaps we <br> >> should try to touch every page first to ensure that it's actually <br> >> there...? &nbsp;(I'm pretty sure we do this when using paffinity to <br> >> ensure to maffinity bind memory to processors -- perhaps we're not <br> >> doing that in the !paffinity case?)<br> >><br> >> Additionally, another solution might well be what Tim has long <br> >> advocated: switch to the other type of shared memory on systems <br> >> that support auto-pruning it when all processes die, and/or have <br> >> the orted kill it when all processes die. &nbsp;Then a) we're not <br> >> dependent on the filesystem free space, and b) we're not writing <br> >> all the dirty pages to disk when the processes exit.<br> >><br> >><br> >><br> >> On Nov 14, 2008, at 8:42 AM, Ralph Castain wrote:<br> >><br> >>> Hi Eugene<br> >>><br> >>> I too am interested - I think we need to do something about the sm <br> >>> backing file situation as larger core machines are slated to <br> >>> become more prevalent shortly.<br> >>><br> >>> I appreciate your info on the sizes and controls. One other <br> >>> question: what happens when there isn't enough memory to support <br> >>> all this? Are we smart enough to detect this situation? Does the <br> >>> sm subsystem quietly shut down? Warn and shut down? Segfault?<br> >>><br> >>> I have two examples so far:<br> >>><br> >>> 1. using a ramdisk, /tmp was set to 10MB. OMPI was run on a single <br> >>> node, 2ppn, with btl=openib,sm,self. The program started, but <br> >>> segfaulted on the first MPI_Send. No warnings were printed.<br> >>><br> >>> 2. again with a ramdisk, /tmp was reportedly set to 16MB <br> >>> (unverified - some uncertainty, could be have been much larger). <br> >>> OMPI was run on multiple nodes, 16ppn, with btl=openib,sm,self. <br> >>> The program ran to completion without errors or warning. I don't <br> >>> know the communication pattern - could be no local comm was <br> >>> performed, though that sounds doubtful.<br> >>><br> >>> If someone doesn't know, I'll have to dig into the code and figure <br> >>> out the response - just hoping that someone can spare me the pain.<br> >>><br> >>> Thanks<br> >>> Ralph<br> >>><br> >>><br> >>> On Nov 13, 2008, at 3:21 PM, Eugene Loh wrote:<br> >>><br> >>>> Ralph Castain wrote:<br> >>>><br> >>>>> As has frequently been commented upon at one time or another, <br> >>>>> the &nbsp;shared memory backing file can be quite huge. There used to <br> >>>>> be a param &nbsp;for controlling this size, but I can't find it in <br> >>>>> 1.3 - or at least, &nbsp;the name or method for controlling file size <br> >>>>> has morphed into &nbsp;something I don't recognize.<br> >>>>><br> >>>>> Can someone more familiar with that subsystem point me to one or <br> >>>>> more &nbsp;params that will allow us to control the size of that <br> >>>>> file? It is &nbsp;swamping our systems and causing OMPI to segfault.<br> >>>><br> >>>> Sounds like you've already gotten your answers, but I'll add my <br> >>>> $0.02 anyhow.<br> >>>><br> >>>> The file size is the number of local processes (call it n) times <br> >>>> mpool_sm_per_peer_size (default 32M), but with a minimum of <br> >>>> mpool_sm_min_size (default 128M) and a maximum of <br> >>>> mpool_sm_max_size (default 2G? &nbsp;256M?). &nbsp;So, you can tweak those <br> >>>> parameters to control file size.<br> >>>><br> >>>> Another issue is possibly how small a backing file you can get <br> >>>> away with. &nbsp;That is, just forcing the file to be smaller may not <br> >>>> be enough since your job may no longer run. &nbsp;The backing file <br> >>>> seems to be used mainly by:<br> >>>><br> >>>> *) eager-fragment free lists: &nbsp;We start with enough eager <br> >>>> fragments so that we could have two per connection. &nbsp;So, you <br> >>>> could bump the sm eager size down if you need to shoehorn a job <br> >>>> into a very small backing file.<br> >>>><br> >>>> *) large-fragment free lists: &nbsp;We start with 8*n large <br> >>>> fragments. &nbsp;If this term plagues you, you can bump the sm chunk <br> >>>> size down or reduce the value of 8 (using btl_sm_free_list_num, I <br> >>>> think).<br> >>>><br> >>>> *) FIFOs: &nbsp;The code tries to align a number of things on pagesize <br> >>>> boundaries, so you end up with about 3*n*n*pagesize overhead <br> >>>> here. &nbsp;If this term is causing you problems, you're stuck (unless <br> >>>> you modify OMPI).<br> >>>><br> >>>> I'm interested in this subject! &nbsp;:^)<br> >>>> _______________________________________________<br> >>>> devel mailing list<br> >>>> <a href="devel@open-mpi.org">devel@open-mpi.org</a><br> >>>> <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br> >>><br> >>> _______________________________________________<br> >>> devel mailing list<br> >>> <a href="devel@open-mpi.org">devel@open-mpi.org</a><br> >>> <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br> >><br> >><br> >> --<br> >> Jeff Squyres<br> >> Cisco Systems<br> >><br> >> _______________________________________________<br> >> devel mailing list<br> >> <a href="devel@open-mpi.org">devel@open-mpi.org</a><br> >> <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br> ><br> > _______________________________________________<br> > devel mailing list<br> > <a href="devel@open-mpi.org">devel@open-mpi.org</a><br> > <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br> <br> <br> --<br> Jeff Squyres<br> Cisco Systems<br> <br> _______________________________________________<br> devel mailing list<br> <a href="devel@open-mpi.org">devel@open-mpi.org</a><br> <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br> <br> </span></font></blockquote> </div>  _______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>http://www.open-mpi.org/mailman/listinfo.cgi/devel</blockquote></div><br></body></html>
