<html><head><meta http-equiv="Content-Type" content="text/html charset=utf-8"></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;" class="">George was looking into it, but I don’t know if he has had time recently to continue the investigation. We understand “what” is happening (accept sometimes ignores the connection), but we don’t yet know “why”. I’ve done some digging around the web, and found that sometimes you can try to talk to a Unix Domain Socket too quickly - i.e., you open it and then send to it, but the OS hasn’t yet set it up. In those cases, you can hang the socket. However, I’ve tried adding some artificial delay, and while it helped, it didn’t completely solve the problem.<div class=""><div class=""><br class=""></div><div class="">I have an idea for a workaround (set a timer and retry after awhile), but would obviously prefer a real solution. I’m not even sure it will work as it is unclear that the server (who is the one hung in accept) will break free if the client closes the socket and retries.</div><div class=""><br class=""></div><div class=""><br class=""><div><blockquote type="cite" class=""><div class="">On Nov 6, 2015, at 10:53 PM, Artem Polyakov &lt;<a href="mailto:artpol84@gmail.com" class="">artpol84@gmail.com</a>&gt; wrote:</div><br class="Apple-interchange-newline"><div class=""><div dir="ltr" class="">Hello, is there any progress on this topic? This affects our PMIx measurements.</div><div class="gmail_extra"><br class=""><div class="gmail_quote">2015-10-30 21:21 GMT+06:00 Ralph Castain <span dir="ltr" class="">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank" class="">rhc@open-mpi.org</a>&gt;</span>:<br class=""><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div style="word-wrap:break-word" class="">I’ve verified that the orte/util/listener thread is not being started, so I don’t think it should be involved in this problem.<div class=""><br class=""></div><div class="">HTH</div><span class="HOEnZb"><font color="#888888" class=""><div class="">Ralph</div></font></span><div class=""><div class="h5"><div class=""><br class=""><div class=""><blockquote type="cite" class=""><div class="">On Oct 30, 2015, at 8:07 AM, Ralph Castain &lt;<a href="mailto:rhc@open-mpi.org" target="_blank" class="">rhc@open-mpi.org</a>&gt; wrote:</div><br class=""><div class=""><div style="word-wrap:break-word" class="">Hmmm…there is a hook that would allow the PMIx server to utilize that listener thread, but we aren’t currently using it. Each daemon plus mpirun will call orte_start_listener, but nothing is currently registering and so the listener in that code is supposed to just return without starting the thread.<div class=""><br class=""></div><div class="">So the only listener thread that should exist is the one inside the PMIx server itself. If something else is happening, then that would be a bug. I can look at the orte listener code to ensure that the thread isn’t incorrectly starting.</div><div class=""><br class=""></div><div class=""><br class=""><div class=""><blockquote type="cite" class=""><div class="">On Oct 29, 2015, at 10:03 PM, George Bosilca &lt;<a href="mailto:bosilca@icl.utk.edu" target="_blank" class="">bosilca@icl.utk.edu</a>&gt; wrote:</div><br class=""><div class=""><div dir="ltr" class="">Some progress, that puzzles me but might help you understand. Once the deadlock appears, if I manually kill the MPI process on the node where the deadlock was created, the local orte daemon doesn't notice and will just keep waiting.<div class=""><br class=""></div><div class="">Quick question: I am under the impression that the issue is not in the PMIX server but somewhere around the listener_thread_fn in orte/util/listener.c. Possible ?</div><div class=""><br class=""></div><div class="">&nbsp; George.</div><div class=""><br class=""></div></div><div class="gmail_extra"><br class=""><div class="gmail_quote">On Wed, Oct 28, 2015 at 3:56 AM, Ralph Castain <span dir="ltr" class="">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank" class="">rhc@open-mpi.org</a>&gt;</span> wrote:<br class=""><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div style="word-wrap:break-word" class="">Should have also clarified: the prior fixes are indeed in the current master.<div class=""><div class=""><div class=""><br class=""><div class=""><blockquote type="cite" class=""><div class="">On Oct 28, 2015, at 12:42 AM, Ralph Castain &lt;<a href="mailto:rhc@open-mpi.org" target="_blank" class="">rhc@open-mpi.org</a>&gt; wrote:</div><br class=""><div class=""><div style="word-wrap:break-word" class="">Nope - I was wrong. The correction on the client side consisted of attempting to timeout if the blocking recv failed. We then modified the blocking send/recv so they would handle errors.<div class=""><br class=""></div><div class="">So that problem occurred -after- the server had correctly called accept. The listener code is in opal/mca/pmix/pmix1xx/pmix/src/server/pmix_server_listener.c</div><div class=""><br class=""></div><div class="">It looks to me like the only way we could drop the accept (assuming the OS doesn’t lose it) is if the file descriptor lies outside the expected range once we fall out of select:<br class=""><div class=""><div class=""><br class=""></div><div class=""><br class=""></div><div class=""><div class="">&nbsp; &nbsp; &nbsp; &nbsp; /* Spin accepting connections until all active listen sockets</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* do not have any incoming connections, pushing each connection</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* onto the event queue for processing</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*/</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; do {</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; accepted_connections = 0;</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* according to the man pages, select replaces the given descriptor</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* set with a subset consisting of those descriptors that are ready</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* for the specified operation - in this case, a read. So we need to</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* first check to see if this file descriptor is included in the</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* returned subset</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*/</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (0 == FD_ISSET(pmix_server_globals.listen_socket, &amp;readfds)) {</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* this descriptor is not included */</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue;</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }</div><div class=""><br class=""></div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* this descriptor is ready to be read, which means a connection</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* request has been received - so harvest it. All we want to do</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* here is accept the connection and push the info onto the event</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* library for subsequent processing - we don't want to actually</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* process the connection here as it takes too long, and so the</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* OS might start rejecting connections due to timeout.</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*/</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pending_connection = PMIX_NEW(pmix_pending_connection_t);</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; event_assign(&amp;pending_connection-&gt;ev, pmix_globals.evbase, -1,</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;EV_WRITE, connection_handler, pending_connection);</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pending_connection-&gt;sd = accept(pmix_server_globals.listen_socket,</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (struct sockaddr*)&amp;(pending_connection-&gt;addr),</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;addrlen);</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (pending_connection-&gt;sd &lt; 0) {</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PMIX_RELEASE(pending_connection);</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (pmix_socket_errno != EAGAIN ||</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pmix_socket_errno != EWOULDBLOCK) {</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (EMFILE == pmix_socket_errno) {</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PMIX_ERROR_LOG(PMIX_ERR_OUT_OF_RESOURCE);</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; } else {</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pmix_output(0, "listen_thread: accept() failed: %s (%d).",</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; strerror(pmix_socket_errno), pmix_socket_errno);</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; goto done;</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue;</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }</div><div class=""><br class=""></div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pmix_output_verbose(8, pmix_globals.debug_output,</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "listen_thread: new connection: (%d, %d)",</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pending_connection-&gt;sd, pmix_socket_errno);</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* activate the event */</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; event_active(&amp;pending_connection-&gt;ev, EV_WRITE, 1);</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; accepted_connections++;</div><div class="">&nbsp; &nbsp; &nbsp; &nbsp; } while (accepted_connections &gt; 0);</div></div><div class=""><br class=""></div><div class=""><br class=""></div><div class=""><blockquote type="cite" class=""><div class="">On Oct 28, 2015, at 12:25 AM, Ralph Castain &lt;<a href="mailto:rhc@open-mpi.org" target="_blank" class="">rhc@open-mpi.org</a>&gt; wrote:</div><br class=""><div class=""><div style="word-wrap:break-word" class="">Looking at the code, it appears that a fix was committed for this problem, and that we correctly resolved the issue found by Paul. The problem is that the fix didn’t get upstreamed, and so it was lost the next time we refreshed PMIx. Sigh.<div class=""><br class=""></div><div class="">Let me try to recreate the fix and have you take a gander at it.</div><div class=""><br class=""></div><div class=""><br class=""><div class=""><blockquote type="cite" class=""><div class="">On Oct 28, 2015, at 12:22 AM, Ralph Castain &lt;<a href="mailto:rhc@open-mpi.org" target="_blank" class="">rhc@open-mpi.org</a>&gt; wrote:</div><br class=""><div class=""><div style="word-wrap:break-word" class="">Here is the discussion - afraid it is fairly lengthy. Ignore the hwloc references in it as that was a separate issue:<div class=""><br class=""></div><div class=""><a href="http://www.open-mpi.org/community/lists/devel/2015/09/18074.php" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2015/09/18074.php</a></div><div class=""><br class=""></div><div class="">It definitely sounds like the same issue creeping in again. I’d appreciate any thoughts on how to correct it. If it helps, you could look at the PMIx master - there are standalone tests in the test/simple directory that fork/exec a child and just do the connection.</div><div class=""><br class=""></div><div class=""><a href="https://github.com/pmix/master" target="_blank" class="">https://github.com/pmix/master</a></div><div class=""><br class=""></div><div class="">The test server is simptest.c - it will spawn a single copy of simpclient.c by default.</div><div class=""><br class=""></div><div class=""><br class=""><div class=""><blockquote type="cite" class=""><div class="">On Oct 27, 2015, at 10:14 PM, George Bosilca &lt;<a href="mailto:bosilca@icl.utk.edu" target="_blank" class="">bosilca@icl.utk.edu</a>&gt; wrote:</div><br class=""><div class=""><div dir="ltr" class="">Interesting. Do you have a pointer to the commit (or/and to the discussion)?<div class=""><br class=""></div><div class="">I looked at the PMIX code, and I have identified few issues, but unfortunately none of them seem to fix the problem for good. However, now I need more than 1000 runs to get a deadlock (instead of few tens).</div><div class=""><br class=""></div><div class="">Looking with "netstat -ax" at the status of the UDS while the processes are deadlocked, I see 2 UDS with the same name: one from the server which is in LISTEN state, and one for the client which is being in CONNECTING state (while the client already sent a message in the socket and is now waiting in a blocking receive). This somehow suggest that the server has not yet called accept on the UDS. Unfortunately, there are 3 threads all doing different flavors of even_base and select, so I have a hard time tracking the path of the UDS on the server side.</div><div class=""><br class=""></div><div class="">So in order to validate my assumption I wrote a minimalistic UDS client and server application and tried different scenarios. The conclusion is that in order to see the same type of output from "netstat -ax" I have to call listen on the server, connect on the client and do not call accept on the server.</div><div class=""><br class=""></div><div class="">With the same occasion I also confirmed that the UDS are holding the data sent so there is no need for further synchronization for the case where the data is sent first. We only need to find out how the server forgets to call accept.</div><div class=""><br class=""></div><div class="">&nbsp; George.</div><div class=""><br class=""></div><div class=""><br class=""></div><div class="gmail_extra"><br class=""><div class="gmail_quote">On Tue, Oct 27, 2015 at 7:52 PM, Ralph Castain <span dir="ltr" class="">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank" class="">rhc@open-mpi.org</a>&gt;</span> wrote:<br class=""><blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-color:rgb(204,204,204);border-left-style:solid;padding-left:1ex"><div style="word-wrap:break-word" class="">Hmmm…this looks like it might be that problem we previously saw where the blocking recv hangs in a proc when the blocking send tries to send before the domain socket is actually ready, and so the send fails on the other end. As I recall, it was something to do with the socketoptions - and then Paul had a problem on some of his machines, and we backed it out?<div class=""><br class=""></div><div class="">I wonder if that’s what is biting us here again, and what we need is to either remove the blocking send/recv’s altogether, or figure out a way to wait until the socket is really ready.</div><div class=""><br class=""></div><div class="">Any thoughts?</div><div class=""><br class=""></div><div class=""><br class=""><div class=""><blockquote type="cite" class=""><div class=""><div class=""><div class="">On Oct 27, 2015, at 4:11 PM, George Bosilca &lt;<a href="mailto:bosilca@icl.utk.edu" target="_blank" class="">bosilca@icl.utk.edu</a>&gt; wrote:</div><br class=""></div></div><div class=""><div class=""><div class=""><div dir="ltr" class="">It appear the branch solve the problem at least partially. I asked one of my students to hammer it pretty badly, and he reported that the deadlocks still occur. He also graciously provided some stacktraces:<div class=""><br class=""></div><div class=""><div class="">#0 &nbsp;0x00007f4bd5274aed in nanosleep () from /lib64/libc.so.6</div><div class="">#1 &nbsp;0x00007f4bd52a9c94 in usleep () from /lib64/libc.so.6</div><div class="">#2 &nbsp;0x00007f4bd2e42b00 in OPAL_PMIX_PMIX1XX_PMIx_Fence (procs=0x0, nprocs=0, info=0x7fff3c561960,&nbsp;</div><div class="">&nbsp; &nbsp; ninfo=1) at src/client/pmix_client_fence.c:100</div><div class="">#3 &nbsp;0x00007f4bd306e6d2 in pmix1_fence (procs=0x0, collect_data=1) at pmix1_client.c:306</div><div class="">#4 &nbsp;0x00007f4bd57d5cc3 in ompi_mpi_init (argc=3, argv=0x7fff3c561ea8, requested=3,&nbsp;</div><div class="">&nbsp; &nbsp; provided=0x7fff3c561d84) at runtime/ompi_mpi_init.c:644</div><div class="">#5 &nbsp;0x00007f4bd5813399 in PMPI_Init_thread (argc=0x7fff3c561d7c, argv=0x7fff3c561d70, required=3,&nbsp;</div><div class="">&nbsp; &nbsp; provided=0x7fff3c561d84) at pinit_thread.c:69</div><div class="">#6 &nbsp;0x0000000000401516 in main (argc=3, argv=0x7fff3c561ea8) at osu_mbw_mr.c:86</div></div><div class=""><br class=""></div><div class="">And another process:</div><div class=""><br class=""></div><div class=""><div class="">#0 &nbsp;0x00007f7b9d7d8bdc in recv () from /lib64/libpthread.so.0</div><div class="">#1 &nbsp;0x00007f7b9b0aa42d in opal_pmix_pmix1xx_pmix_usock_recv_blocking (sd=13, data=0x7ffd62139004 "",&nbsp;</div><div class="">&nbsp; &nbsp; size=4) at src/usock/usock.c:168</div><div class="">#2 &nbsp;0x00007f7b9b0af5d9 in recv_connect_ack (sd=13) at src/client/pmix_client.c:844</div><div class="">#3 &nbsp;0x00007f7b9b0b085e in usock_connect (addr=0x7ffd62139330) at src/client/pmix_client.c:1110</div><div class="">#4 &nbsp;0x00007f7b9b0acc24 in connect_to_server (address=0x7ffd62139330, cbdata=0x7ffd621390e0)</div><div class="">&nbsp; &nbsp; at src/client/pmix_client.c:181</div><div class="">#5 &nbsp;0x00007f7b9b0ad569 in OPAL_PMIX_PMIX1XX_PMIx_Init (proc=0x7f7b9b4e9b60)</div><div class="">&nbsp; &nbsp; at src/client/pmix_client.c:362</div><div class="">#6 &nbsp;0x00007f7b9b2dbd9d in pmix1_client_init () at pmix1_client.c:99</div><div class="">#7 &nbsp;0x00007f7b9b4eb95f in pmi_component_query (module=0x7ffd62139490, priority=0x7ffd6213948c)</div><div class="">&nbsp; &nbsp; at ess_pmi_component.c:90</div><div class="">#8 &nbsp;0x00007f7b9ce70ec5 in mca_base_select (type_name=0x7f7b9d20e059 "ess", output_id=-1,&nbsp;</div><div class="">&nbsp; &nbsp; components_available=0x7f7b9d431eb0, best_module=0x7ffd621394d0, best_component=0x7ffd621394d8,&nbsp;</div><div class="">&nbsp; &nbsp; priority_out=0x0) at mca_base_components_select.c:77</div><div class="">#9 &nbsp;0x00007f7b9d1a956b in orte_ess_base_select () at base/ess_base_select.c:40</div><div class="">#10 0x00007f7b9d160449 in orte_init (pargc=0x0, pargv=0x0, flags=32) at runtime/orte_init.c:219</div><div class="">#11 0x00007f7b9da4377a in ompi_mpi_init (argc=3, argv=0x7ffd621397f8, requested=3,&nbsp;</div><div class="">&nbsp; &nbsp; provided=0x7ffd621396d4) at runtime/ompi_mpi_init.c:488</div><div class="">#12 0x00007f7b9da81399 in PMPI_Init_thread (argc=0x7ffd621396cc, argv=0x7ffd621396c0, required=3,&nbsp;</div><div class="">&nbsp; &nbsp; provided=0x7ffd621396d4) at pinit_thread.c:69</div><div class="">#13 0x0000000000401516 in main (argc=3, argv=0x7ffd621397f8) at osu_mbw_mr.c:86</div></div><div class=""><br class=""></div><div class="">&nbsp; George.</div><div class=""><br class=""></div><div class=""><br class=""></div></div><div class="gmail_extra"><br class=""><div class="gmail_quote">On Tue, Oct 27, 2015 at 2:36 PM, Ralph Castain <span dir="ltr" class="">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank" class="">rhc@open-mpi.org</a>&gt;</span> wrote:<br class=""><blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-color:rgb(204,204,204);border-left-style:solid;padding-left:1ex"><div style="word-wrap:break-word" class="">I haven’t been able to replicate this when using the branch in this PR:<div class=""><br class=""></div><div class=""><a href="https://github.com/open-mpi/ompi/pull/1073" target="_blank" class="">https://github.com/open-mpi/ompi/pull/1073</a></div><div class=""><br class=""></div><div class="">Would you mind giving it a try? It fixes some other race conditions and might pick this one up too.</div><div class=""><div class=""><div class=""><br class=""></div><div class=""><br class=""><div class=""><blockquote type="cite" class=""><div class="">On Oct 27, 2015, at 10:04 AM, Ralph Castain &lt;<a href="mailto:rhc@open-mpi.org" target="_blank" class="">rhc@open-mpi.org</a>&gt; wrote:</div><br class=""><div class=""><div style="word-wrap:break-word" class="">Okay, I’ll take a look - I’ve been chasing a race condition that might be related<div class=""><br class=""><div class=""><blockquote type="cite" class=""><div class="">On Oct 27, 2015, at 9:54 AM, George Bosilca &lt;<a href="mailto:bosilca@icl.utk.edu" target="_blank" class="">bosilca@icl.utk.edu</a>&gt; wrote:</div><br class=""><div class=""><div dir="ltr" class="">No, it's using 2 nodes.<div class="">&nbsp; George.</div><div class=""><br class=""></div></div><div class="gmail_extra"><br class=""><div class="gmail_quote">On Tue, Oct 27, 2015 at 12:35 PM, Ralph Castain <span dir="ltr" class="">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank" class="">rhc@open-mpi.org</a>&gt;</span> wrote:<br class=""><blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-color:rgb(204,204,204);border-left-style:solid;padding-left:1ex"><div style="word-wrap:break-word" class="">Is this on a single node?<div class=""><br class=""><div class=""><blockquote type="cite" class=""><div class=""><div class=""><div class="">On Oct 27, 2015, at 9:25 AM, George Bosilca &lt;<a href="mailto:bosilca@icl.utk.edu" target="_blank" class="">bosilca@icl.utk.edu</a>&gt; wrote:</div><br class=""></div></div><div class=""><div class=""><div class=""><div dir="ltr" class="">I get intermittent deadlocks wit the latest trunk. The smallest reproducer is a shell for loop around a small (2 processes) short (20 seconds) MPI application. After few tens of iterations the MPI_Init will deadlock with the following backtrace:<div class=""><br class=""></div><div class=""><div style="font-size:12.8px" class="">#0&nbsp; 0x00007fa94b5d9aed in nanosleep () from /lib64/libc.so.6</div><div style="font-size:12.8px" class="">#1&nbsp; 0x00007fa94b60ec94 in usleep () from /lib64/libc.so.6</div><div style="font-size:12.8px" class="">#2&nbsp; 0x00007fa94960ba08 in OPAL_PMIX_PMIX1XX_PMIx_Fence (procs=0x0, nprocs=0, info=0x7ffd7934fb90,&nbsp;</div><div style="font-size:12.8px" class="">&nbsp; &nbsp; ninfo=1) at src/client/pmix_client_fence.c:100</div><div style="font-size:12.8px" class="">#3&nbsp; 0x00007fa9498376a2 in pmix1_fence (procs=0x0, collect_data=1) at pmix1_client.c:305</div><div style="font-size:12.8px" class="">#4&nbsp; 0x00007fa94bb39ba4 in ompi_mpi_init (argc=3, argv=0x7ffd793500a8, requested=3,&nbsp;</div><div style="font-size:12.8px" class="">&nbsp; &nbsp; provided=0x7ffd7934ff94) at runtime/ompi_mpi_init.c:645</div><div style="font-size:12.8px" class="">#5&nbsp; 0x00007fa94bb77281 in PMPI_Init_thread (argc=0x7ffd7934ff8c, argv=0x7ffd7934ff80, required=3,&nbsp;</div><div style="font-size:12.8px" class="">&nbsp; &nbsp; provided=0x7ffd7934ff94) at pinit_thread.c:69</div><div style="font-size:12.8px" class="">#6&nbsp; 0x000000000040150f in main (argc=3, argv=0x7ffd793500a8) at osu_mbw_mr.c:86</div></div><div style="font-size:12.8px" class=""><br class=""></div><div style="font-size:12.8px" class="">On my machines this is reproducible at 100% after anywhere between 50 and 100 iterations.</div><div style="font-size:12.8px" class=""><br class=""></div><div style="font-size:12.8px" class="">&nbsp; Thanks,</div><div style="font-size:12.8px" class="">&nbsp; &nbsp; George.</div><div style="font-size:12.8px" class=""><br class=""></div></div></div></div>
_______________________________________________<br class="">devel mailing list<br class=""><a href="mailto:devel@open-mpi.org" target="_blank" class="">devel@open-mpi.org</a><br class="">Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br class="">Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/10/18280.php" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2015/10/18280.php</a></div></blockquote></div><br class=""></div></div><br class="">_______________________________________________<br class="">
devel mailing list<br class="">
<a href="mailto:devel@open-mpi.org" target="_blank" class="">devel@open-mpi.org</a><br class="">
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br class="">
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/10/18281.php" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2015/10/18281.php</a><br class=""></blockquote></div><br class=""></div>
_______________________________________________<br class="">devel mailing list<br class=""><a href="mailto:devel@open-mpi.org" target="_blank" class="">devel@open-mpi.org</a><br class="">Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br class="">Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/10/18282.php" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2015/10/18282.php</a></div></blockquote></div><br class=""></div></div></div></blockquote></div><br class=""></div></div></div></div><br class="">_______________________________________________<br class="">
devel mailing list<br class="">
<a href="mailto:devel@open-mpi.org" target="_blank" class="">devel@open-mpi.org</a><br class="">
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br class="">
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/10/18284.php" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2015/10/18284.php</a><br class=""></blockquote></div><br class=""></div>
_______________________________________________<br class="">devel mailing list<br class=""><a href="mailto:devel@open-mpi.org" target="_blank" class="">devel@open-mpi.org</a><br class="">Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br class=""></div></div>Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/10/18292.php" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2015/10/18292.php</a></div></blockquote></div><br class=""></div></div><br class="">_______________________________________________<br class="">
devel mailing list<br class="">
<a href="mailto:devel@open-mpi.org" target="_blank" class="">devel@open-mpi.org</a><br class="">
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br class="">
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/10/18294.php" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2015/10/18294.php</a><br class=""></blockquote></div><br class=""></div></div>
_______________________________________________<br class="">devel mailing list<br class=""><a href="mailto:devel@open-mpi.org" target="_blank" class="">devel@open-mpi.org</a><br class="">Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br class="">Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/10/18302.php" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2015/10/18302.php</a></div></blockquote></div><br class=""></div></div></div></blockquote></div><br class=""></div></div></div></blockquote></div><br class=""></div></div></div></div></blockquote></div><br class=""></div></div></div></div><br class="">_______________________________________________<br class="">
devel mailing list<br class="">
<a href="mailto:devel@open-mpi.org" target="_blank" class="">devel@open-mpi.org</a><br class="">
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br class="">
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/10/18309.php" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2015/10/18309.php</a><br class=""></blockquote></div><br class=""></div>
_______________________________________________<br class="">devel mailing list<br class=""><a href="mailto:devel@open-mpi.org" target="_blank" class="">devel@open-mpi.org</a><br class="">Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br class="">Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/10/18320.php" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2015/10/18320.php</a></div></blockquote></div><br class=""></div></div></div></blockquote></div><br class=""></div></div></div></div><br class="">_______________________________________________<br class="">
devel mailing list<br class="">
<a href="mailto:devel@open-mpi.org" class="">devel@open-mpi.org</a><br class="">
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br class="">
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/10/18323.php" rel="noreferrer" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2015/10/18323.php</a><br class=""></blockquote></div><br class=""><br clear="all" class=""><div class=""><br class=""></div>-- <br class=""><div class="gmail_signature">С Уважением, Поляков Артем Юрьевич<br class="">Best regards, Artem Y. Polyakov</div>
</div>
_______________________________________________<br class="">devel mailing list<br class=""><a href="mailto:devel@open-mpi.org" class="">devel@open-mpi.org</a><br class="">Subscription: http://www.open-mpi.org/mailman/listinfo.cgi/devel<br class="">Link to this post: http://www.open-mpi.org/community/lists/devel/2015/11/18334.php</div></blockquote></div><br class=""></div></div></body></html>
