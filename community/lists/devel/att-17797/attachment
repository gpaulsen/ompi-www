Paul,<div><br></div><div>if ompi is built statically or with --disable-dlopen, I do not think --mca coll ^ml can prevent the crash (assuming this is the same issue we discussed before).</div><div>note if you build dynamically and without --disable-dlopen, it might or might not crash, depending on how modules are enumerated, and this is specific to each system.</div><div><br></div><div>so at this stage, I cannot suspect this is a different issue or not.</div><div>if the crash still occurs with .ompi_ignore in coll ml, then I could conclude this is a different issue.</div><div><br></div><div>Cheers,</div><div><br></div><div>Gilles<br><br>On Sunday, August 23, 2015, Paul Hargrove &lt;<a href="mailto:phhargrove@lbl.gov">phhargrove@lbl.gov</a>&gt; wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir="ltr">Gilles,<div><br></div><div>This is on Mellanox&#39;s own system where /opt/mellanox/hcoll was updates Aug 2.</div><div>This problem also did not occur unless I build libmpi statically.</div><div>A run of &quot;mpirun -mca coll ^ml -np 2 examples/ring_c&quot; still crashes.</div><div>So, I really don&#39;t know if this is the same issue, but suspect that it is not.</div><div><br></div><div>-Paul</div></div><div class="gmail_extra"><br><div class="gmail_quote">On Sat, Aug 22, 2015 at 6:00 PM, Gilles Gouaillardet <span dir="ltr">&lt;<a href="javascript:_e(%7B%7D,&#39;cvml&#39;,&#39;gilles.gouaillardet@gmail.com&#39;);" target="_blank">gilles.gouaillardet@gmail.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Paul,<div><br></div><div>isn t this an issue that was already discussed ?</div><div>mellanox proprietary hcoll library includes its own coll ml module that conflicts with the ompi one.</div><div>mellanox folks fixed this internally but I am not sure this has been released.</div><div>you can run</div><div>nm libhcoll.so</div><div>if there are some symbols starting with coll_ml, then the issue is still there.</div><div>if you have time and recent autotools, you can</div><div>touch ompi/mca/coll/ml/.ompi_ignore</div><div>./<a href="http://autogen.pl" target="_blank">autogen.pl</a></div><div>make ...</div><div>and that should be fine</div><div><br></div><div>if you configure&#39;d with dynamic libraries and no --disable_dlopen, then</div><div>mpirun --mca coll ^ml ...</div><div>is enough to work around the issue.</div><div><br></div><div>Cheers,</div><div><br></div><div>Gilles</div><div><div><div><br>On Sunday, August 23, 2015, Paul Hargrove &lt;<a href="javascript:_e(%7B%7D,&#39;cvml&#39;,&#39;phhargrove@lbl.gov&#39;);" target="_blank">phhargrove@lbl.gov</a>&gt; wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir="ltr">Having seen problems with mtl:ofi with &quot;--enable-static --disable-shared&quot;, I tried mtl:psm and mtl:mxm with those options as well.<div><br></div><div>The good news is that mtl:psm was fine, but the bad news is when testing mtl:mxm I encountered a new problem involving coll:hcol.</div><div>Ralph probably wants to strangle me right now...</div><div><br></div><div><br></div><div>I am configuring the 1.10.0rc4 tarball with</div><div><font face="monospace, monospace">   --prefix=[...] --enable-debug --with-verbs --enable-openib-connectx-xrc \</font></div><div><font face="monospace, monospace">   --with-mxm=/opt/mellanox/mxm --with-hcoll=/opt/mellanox/hcoll \</font></div><div><font face="monospace, monospace">   --enable-static --disable-shared</font><br clear="all"><div><br></div><div>Everything was fine without those last two arguments.</div><div>When I add them the build is fine, and I can compile the examples.</div><div>However, I get a SEGV when running an example:</div><div><br></div><div><div><font face="monospace, monospace">$mpirun -np 2 examples/ring_c</font></div><div><font face="monospace, monospace">[mir13:12444:0] Caught signal 11 (Segmentation fault)</font></div><div><font face="monospace, monospace">[mir13:12445:0] Caught signal 11 (Segmentation fault)</font></div><div><font face="monospace, monospace">==== backtrace ====</font></div><div><font face="monospace, monospace">==== backtrace ====</font></div><div><font face="monospace, monospace"> 2 0x0000000000059d9c mxm_handle_error()  /hpc/local/benchmarks/hpc-stack-gcc-Saturday/src/install/mxm-master/</font></div><div><font face="monospace, monospace">src/mxm/util/debug/debug.c:641</font></div><div><font face="monospace, monospace"> 3 0x0000000000059f0c mxm_error_signal_handler()  /hpc/local/benchmarks/hpc-stack-gcc-Saturday/src/install/mxm</font></div><div><font face="monospace, monospace">-master/src/mxm/util/debug/debug.c:616</font></div><div><font face="monospace, monospace"> 4 0x0000003c2e0329a0 killpg()  ??:0</font></div><div><font face="monospace, monospace"> 5 0x0000000000528b51 opal_list_remove_last()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux</font></div><div><font face="monospace, monospace">-x86_64-mxm-static/openmpi-1.10.0rc4/opal/class/opal_list.h:721</font></div><div><font face="monospace, monospace"> 6 0x0000000000529872 base_bcol_basesmuma_setup_library_buffers()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/ope</font></div><div><font face="monospace, monospace">nmpi-1.10.0rc4-linux-x86_64-mxm-static/openmpi-1.10.0rc4/ompi/mca/bcol/basesmuma/bcol_basesmuma_setup.c:537</font></div><div><font face="monospace, monospace"> 7 0x000000000009e983 hmca_bcol_basesmuma_comm_query()  ??:0</font></div><div><font face="monospace, monospace"> 8 0x00000000000348e3 hmca_coll_ml_tree_hierarchy_discovery()  coll_ml_module.c:0</font></div><div><font face="monospace, monospace"> 9 0x00000000000317a2 hmca_coll_ml_comm_query()  ??:0</font></div><div><font face="monospace, monospace">10 0x000000000006c929 hcoll_create_context()  ??:0</font></div><div><font face="monospace, monospace">11 0x00000000004a248f mca_coll_hcoll_comm_query()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-l</font></div><div><font face="monospace, monospace">inux-x86_64-mxm-static/openmpi-1.10.0rc4/ompi/mca/coll/hcoll/coll_hcoll_module.c:290</font></div><div><font face="monospace, monospace">12 0x000000000047c82f query_2_0_0()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mx</font></div><div><font face="monospace, monospace">m-static/openmpi-1.10.0rc4/ompi/mca/coll/base/coll_base_comm_select.c:392</font></div><div><font face="monospace, monospace">13 0x000000000047c7ee query()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mxm-stat</font></div><div><font face="monospace, monospace">ic/openmpi-1.10.0rc4/ompi/mca/coll/base/coll_base_comm_select.c:375</font></div><div><font face="monospace, monospace">14 0x000000000047c704 check_one_component()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x</font></div><div><font face="monospace, monospace">86_64-mxm-static/openmpi-1.10.0rc4/ompi/mca/coll/base/coll_base_comm_select.c:337</font></div><div><font face="monospace, monospace">15 0x000000000047c567 check_components()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_</font></div><div><font face="monospace, monospace">64-mxm-static/openmpi-1.10.0rc4/ompi/mca/coll/base/coll_base_comm_select.c:301</font></div><div><font face="monospace, monospace">16 0x000000000047552a mca_coll_base_comm_select()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-l</font></div><div><font face="monospace, monospace">inux-x86_64-mxm-static/openmpi-1.10.0rc4/ompi/mca/coll/base/coll_base_comm_select.c:131</font></div><div><font face="monospace, monospace">17 0x0000000000428476 ompi_mpi_init()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-</font></div><div><font face="monospace, monospace">mxm-static/openmpi-1.10.0rc4/ompi/runtime/ompi_mpi_init.c:894</font></div><div><font face="monospace, monospace">18 0x0000000000431ba5 PMPI_Init()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mxm-</font></div><div><font face="monospace, monospace">static/BLD/ompi/mpi/c/profile/pinit.c:84</font></div><div><font face="monospace, monospace">19 0x000000000040abce main()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mxm-stati</font></div><div><font face="monospace, monospace">c/BLD/examples/ring_c.c:19</font></div><div><font face="monospace, monospace">20 0x0000003c2e01ed1d __libc_start_main()  ??:0</font></div><div><font face="monospace, monospace">21 0x000000000040aae9 _start()  ??:0</font></div></div><div><div><div><font face="monospace, monospace">===================</font></div><div><font face="monospace, monospace"> 2 0x0000000000059d9c mxm_handle_error()  /hpc/local/benchmarks/hpc-stack-gcc-Saturday/src/install/mxm-master/src/mxm/util/debug/debug.c:641</font></div><div><font face="monospace, monospace"> 3 0x0000000000059f0c mxm_error_signal_handler()  /hpc/local/benchmarks/hpc-stack-gcc-Saturday/src/install/mxm-master/src/mxm/util/debug/debug.c:616</font></div><div><font face="monospace, monospace"> 4 0x0000003c2e0329a0 killpg()  ??:0</font></div><div><font face="monospace, monospace"> 5 0x0000000000528b51 opal_list_remove_last()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mxm-static/openmpi-1.10.0rc4/opal/class/opal_list.h:721</font></div><div><font face="monospace, monospace"> 6 0x0000000000529872 base_bcol_basesmuma_setup_library_buffers()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mxm-static/openmpi-1.10.0rc4/ompi/mca/bcol/basesmuma/bcol_basesmuma_setup.c:537</font></div><div><font face="monospace, monospace"> 7 0x000000000009e983 hmca_bcol_basesmuma_comm_query()  ??:0</font></div><div><font face="monospace, monospace"> 8 0x00000000000348e3 hmca_coll_ml_tree_hierarchy_discovery()  coll_ml_module.c:0</font></div><div><font face="monospace, monospace"> 9 0x00000000000317a2 hmca_coll_ml_comm_query()  ??:0</font></div><div><font face="monospace, monospace">10 0x000000000006c929 hcoll_create_context()  ??:0</font></div><div><font face="monospace, monospace">11 0x00000000004a248f mca_coll_hcoll_comm_query()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mxm-static/openmpi-1.10.0rc4/ompi/mca/coll/hcoll/coll_hcoll_module.c:290</font></div><div><font face="monospace, monospace">12 0x000000000047c82f query_2_0_0()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mxm-static/openmpi-1.10.0rc4/ompi/mca/coll/base/coll_base_comm_select.c:392</font></div><div><font face="monospace, monospace">13 0x000000000047c7ee query()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mxm-static/openmpi-1.10.0rc4/ompi/mca/coll/base/coll_base_comm_select.c:375</font></div><div><font face="monospace, monospace">14 0x000000000047c704 check_one_component()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mxm-static/openmpi-1.10.0rc4/ompi/mca/coll/base/coll_base_comm_select.c:337</font></div><div><font face="monospace, monospace">15 0x000000000047c567 check_components()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mxm-static/openmpi-1.10.0rc4/ompi/mca/coll/base/coll_base_comm_select.c:301</font></div><div><font face="monospace, monospace">16 0x000000000047552a mca_coll_base_comm_select()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mxm-static/openmpi-1.10.0rc4/ompi/mca/coll/base/coll_base_comm_select.c:131</font></div><div><font face="monospace, monospace">17 0x0000000000428476 ompi_mpi_init()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mxm-static/openmpi-1.10.0rc4/ompi/runtime/ompi_mpi_init.c:894</font></div><div><font face="monospace, monospace">18 0x0000000000431ba5 PMPI_Init()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mxm-static/BLD/ompi/mpi/c/profile/pinit.c:84</font></div><div><font face="monospace, monospace">19 0x000000000040abce main()  /hpc/home/USERS/phhargrove/SCRATCH/OMPI/openmpi-1.10.0rc4-linux-x86_64-mxm-static/BLD/examples/ring_c.c:19</font></div><div><font face="monospace, monospace">20 0x0000003c2e01ed1d __libc_start_main()  ??:0</font></div><div><font face="monospace, monospace">21 0x000000000040aae9 _start()  ??:0</font></div><div><font face="monospace, monospace">===================</font></div><div><font face="monospace, monospace">--------------------------------------------------------------------------</font></div><div><font face="monospace, monospace">mpirun noticed that process rank 1 with PID 12445 on node mir13 exited on signal 13 (Broken pipe).</font></div><div><font face="monospace, monospace">--------------------------------------------------------------------------</font></div></div></div><div><br></div><div>This is reproducible.</div><div>A run with &quot;-np 1&quot; is fine.</div><div><br></div><div>-Paul</div><div><br></div>-- <br><div><div dir="ltr"><div><font face="courier new, monospace"><div>Paul H. Hargrove                          <a>PHHargrove@lbl.gov</a></div><div>Computer Languages &amp; Systems Software (CLaSS) Group</div><div>Computer Science Department               Tel: <a href="tel:%2B1-510-495-2352" value="+15104952352" target="_blank">+1-510-495-2352</a></div><div>Lawrence Berkeley National Laboratory     Fax: <a href="tel:%2B1-510-486-6900" value="+15104866900" target="_blank">+1-510-486-6900</a></div></font></div></div></div>
</div></div>
</blockquote></div>
</div></div><br>_______________________________________________<br>
devel mailing list<br>
<a href="javascript:_e(%7B%7D,&#39;cvml&#39;,&#39;devel@open-mpi.org&#39;);" target="_blank">devel@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" rel="noreferrer" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/08/17795.php" rel="noreferrer" target="_blank">http://www.open-mpi.org/community/lists/devel/2015/08/17795.php</a><br></blockquote></div><br><br clear="all"><div><br></div>-- <br><div><div dir="ltr"><div><font face="courier new, monospace"><div>Paul H. Hargrove                          <a href="javascript:_e(%7B%7D,&#39;cvml&#39;,&#39;PHHargrove@lbl.gov&#39;);" target="_blank">PHHargrove@lbl.gov</a></div><div>Computer Languages &amp; Systems Software (CLaSS) Group</div><div>Computer Science Department               Tel: +1-510-495-2352</div><div>Lawrence Berkeley National Laboratory     Fax: +1-510-486-6900</div></font></div></div></div>
</div>
</blockquote></div>

