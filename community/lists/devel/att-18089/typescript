Script started on Sun Sep 20 15:51:32 2015
$ export PATH=/export/home/phargrov/OMPI/openmpi-master-solaris11-x64-ss12u3/INST/bin:$PATH
$ export LD_LIBRARY_PATH=/export/home/phargrov/OMPI/openmpi-master-solaris11-x64-ss12u3/INST/lib:$LD_LIBRARY_PATH
$ mpirun -mca btl sm,self -mca pmix_base_verbose 10 -np 2 examples/ring_c
Error opening /devices/pci@0,0:reg: Permission denied
[pcp-d-3:19753] mca: base: components_register: registering framework pmix components
[pcp-d-3:19753] mca: base: components_register: found loaded component pmix1xx
[pcp-d-3:19753] mca: base: components_register: component pmix1xx has no register or open function
[pcp-d-3:19753] mca: base: components_open: opening pmix components
[pcp-d-3:19753] mca: base: components_open: found loaded component pmix1xx
[pcp-d-3:19753] mca: base: components_open: component pmix1xx open function successful
[pcp-d-3:19753] mca:base:select: Auto-selecting pmix components
[pcp-d-3:19753] mca:base:select:( pmix) Querying component [pmix1xx]
[pcp-d-3:19753] mca:base:select:( pmix) Query of component [pmix1xx] set priority to 5
[pcp-d-3:19753] mca:base:select:( pmix) Selected component [pmix1xx]
[pcp-d-3:19753] pmix:server init called
[pcp-d-3:19753] sec: native init
[pcp-d-3:19753] sec: SPC native active
[pcp-d-3:19753] pmix:server constructed uri pmix-server:19753:/tmp/openmpi-sessions-19214@pcp-d-3_0/1159/0/0/pmix-19753
[pcp-d-3:19753] listen_thread: active
[pcp-d-3:19753] pmix:server register client 75956225:0
[pcp-d-3:19753] pmix:server register client 75956225:1
[pcp-d-3:19753] pmix:server _register_client for nspace 75956225 rank 0
[pcp-d-3:19753] pmix:server setup_fork for nspace 75956225 rank 0
[pcp-d-3:19753] pmix:server _register_client for nspace 75956225 rank 1
[pcp-d-3:19753] pmix:server _register_nspace
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.ltopo
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.jobid
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.offset
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.nmap
[pcp-d-3:19753] pmix:extract:nodes: checking list: pcp-d-3
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.pmap
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.nodeid
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.node.size
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.lpeers
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.lcpus
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.lldr
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.univ.size
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.job.size
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.local.size
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.max.size
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.pdata
[pcp-d-3:19753] pmix:server _register_nspace recording pmix.pdata
[pcp-d-3:19753] pmix:server setup_fork for nspace 75956225 rank 1
[pcp-d-3:19754] mca: base: components_register: registering framework pmix components
[pcp-d-3:19754] mca: base: components_register: found loaded component pmix1xx
[pcp-d-3:19754] mca: base: components_register: component pmix1xx has no register or open function
[pcp-d-3:19754] mca: base: components_open: opening pmix components
[pcp-d-3:19754] mca: base: components_open: found loaded component pmix1xx
[pcp-d-3:19754] mca: base: components_open: component pmix1xx open function successful
[pcp-d-3:19754] mca:base:select: Auto-selecting pmix components
[pcp-d-3:19754] mca:base:select:( pmix) Querying component [pmix1xx]
[pcp-d-3:19754] mca:base:select:( pmix) Query of component [pmix1xx] set priority to 100
[pcp-d-3:19754] mca:base:select:( pmix) Selected component [pmix1xx]
[pcp-d-3:19754] PMIx_client init
[pcp-d-3:19754] pmix: init called
[pcp-d-3:19754] posting notification recv on tag 0
[pcp-d-3:19754] sec: native init
[pcp-d-3:19754] sec: SPC native active
[pcp-d-3:19754] usock_peer_try_connect: attempting to connect to server
[pcp-d-3:19754] usock_peer_try_connect: attempting to connect to server on socket 15
[pcp-d-3:19754] pmix: SEND CONNECT ACK
[pcp-d-3:19754] sec: native create_cred
[pcp-d-3:19754] sec: using credential 19214:5513
[pcp-d-3:19754] send blocking of 48 bytes to socket 15
[pcp-d-3:19754] blocking send complete to socket 15
[pcp-d-3:19754] pmix: RECV CONNECT ACK FROM SERVER
[pcp-d-3:19754] PMIX ERROR: ERROR in file /export/home/phargrov/OMPI/openmpi-master-solaris11-x64-ss12u3/openmpi-dev-2559-g567c9e3/opal/mca/pmix/pmix1xx/pmix/src/client/pmix_client.c at line 181
[pcp-d-3:19754] mca: base: close: component pmix1xx closed
[pcp-d-3:19754] mca: base: close: unloading component pmix1xx
[pcp-d-3:19753] listen_thread: new connection: (32, 0)
[pcp-d-3:19753] connection_handler: new connection: 32
[pcp-d-3:19753] RECV CONNECT ACK FROM PEER ON SOCKET 32
[pcp-d-3:19753] waiting for blocking recv of 16 bytes
[pcp-d-3:19753] blocking receive complete from remote
[pcp-d-3:19753] waiting for blocking recv of 32 bytes
[pcp-d-3:19753] blocking receive complete from remote
[pcp-d-3:19753] connect-ack recvd from peer 75956225:0
[pcp-d-3:19753] sec: native validate_cred 19214:5513
[pcp-d-3:19753] sec: native credential valid
[pcp-d-3:19753] client credential validated
[pcp-d-3:19753] send blocking of 4 bytes to socket 32
--------------------------------------------------------------------------
It looks like MPI_INIT failed for some reason; your parallel process is
likely to abort.  There are many reasons that a parallel process can
fail during MPI_INIT; some of which are due to configuration or environment
problems.  This failure appears to be an internal failure; here's some
additional information (which may only be relevant to an Open MPI
developer):

  ompi_mpi_init: ompi_rte_init failed
  --> Returned "(null)" (-43) instead of "Success" (0)
--------------------------------------------------------------------------
[pcp-d-3:19753] PMIX ERROR: UNREACHABLE in file /export/home/phargrov/OMPI/openmpi-master-solaris11-x64-ss12u3/openmpi-dev-2559-g567c9e3/opal/mca/pmix/pmix1xx/pmix/src/server/pmix_server_listener.c at line 463
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
***    and potentially your MPI job)
[pcp-d-3:19754] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!
-------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code.. Per user-direction, the job has been aborted.
-------------------------------------------------------
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[1159,1],0]
  Exit code:    1
--------------------------------------------------------------------------
[pcp-d-3:19753] pmix:server finalize called
[pcp-d-3:19753] listen_thread: shutdown
[pcp-d-3:19753] sec: native finalize
[pcp-d-3:19753] pmix:server finalize complete
[pcp-d-3:19753] mca: base: close: component pmix1xx closed
[pcp-d-3:19753] mca: base: close: unloading component pmix1xx
$ exit

script done on Sun Sep 20 15:54:20 2015
