<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
<HEAD>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="Generator" CONTENT="MS Exchange Server version 6.5.7654.12">
<TITLE>Re: [OMPI devel] Open MPI 2009 released</TITLE>
</HEAD>
<BODY>
<!-- Converted from text/plain format -->

<P><FONT SIZE=2>My wife thought it was frackin' brilliant.&nbsp; :)<BR>
<BR>
-jms<BR>
Sent from my PDA.&nbsp; No type good.<BR>
<BR>
----- Original Message -----<BR>
From: devel-bounces@open-mpi.org &lt;devel-bounces@open-mpi.org&gt;<BR>
To: Open MPI Developers &lt;devel@open-mpi.org&gt;<BR>
Sent: Wed Apr 01 18:58:55 2009<BR>
Subject: Re: [OMPI devel] Open MPI 2009 released<BR>
<BR>
Bravo!! This is beautiful.<BR>
By far my favorite part is &quot;Cobol (so say we all!)&quot;.<BR>
However, I question why ARM6 was targeted as opposed to ARM7 ;-)<BR>
<BR>
-Paul<BR>
<BR>
George Bosilca wrote:<BR>
&gt; The Open MPI Team, representing a consortium of bailed-out banks, car<BR>
&gt; manufacturers, and insurance companies, is pleased to announce the<BR>
&gt; release of the &quot;unbreakable&quot; / bug-free version Open MPI 2009,<BR>
&gt; (expected to be available by mid-2011).&nbsp; This release is essentially a<BR>
&gt; complete rewrite of Open MPI based on new technologies such as C#,<BR>
&gt; Java, and object-oriented Cobol (so say we all!).&nbsp; Buffer overflows<BR>
&gt; and memory leaks are now things of the past.&nbsp; We strongly recommend<BR>
&gt; that all users upgrade to Windows 7 to fully take advantage of the new<BR>
&gt; powers embedded in Open MPI.<BR>
&gt;<BR>
&gt; This version can be downloaded from the The Onion web site or from<BR>
&gt; many BitTorrent networks (seeding now; the Open MPI ISO is<BR>
&gt; approximately 3.97GB -- please wait for the full upload).<BR>
&gt;<BR>
&gt; Here is an abbreviated list of changes in Open MPI 2009 as compared to<BR>
&gt; the previous version:<BR>
&gt;<BR>
&gt; - Dropped support for MPI 2 in favor of the newly enhanced MPI 11.7<BR>
&gt;&nbsp; standard.&nbsp; MPI_COOK_DINNER support is only available with additional<BR>
&gt;&nbsp; equipment (some assembly may be required).&nbsp; An experimental PVM-like<BR>
&gt;&nbsp; API has been introduced to deal with the current limitations of the<BR>
&gt;&nbsp; MPI 11.7 API.<BR>
&gt; - Added a Twitter network transport capable of achieving peta-scale<BR>
&gt;&nbsp; per second bandwidth (but only on useless data).<BR>
&gt; - Dropped support for the barely-used x86 and x86_64 architectures in<BR>
&gt;&nbsp; favor of the most recent ARM6 architecture.&nbsp; As a direct result,<BR>
&gt;&nbsp; several Top500 sites are planning to convert from their now obsolete<BR>
&gt;&nbsp; peta-scale machines to high-reliability iPhone clusters using the<BR>
&gt;&nbsp; low-latency AT&amp;T 3G network.<BR>
&gt; - The iPhone iMPI app (powered by iOpen MPI) is now downloadable from<BR>
&gt;&nbsp; the iTunes Store.&nbsp; Blackberry support will be included in a future<BR>
&gt;&nbsp; release.<BR>
&gt; - Fix all compiler errors related to the PGI 8.0 compiler by<BR>
&gt;&nbsp; completely dropping support.<BR>
&gt; - Add some &quot;green&quot; features for energy savings.&nbsp; The new &quot;--bike&quot;<BR>
&gt;&nbsp; mpirun option will only run your parallel jobs only during the<BR>
&gt;&nbsp; operation hours of the official Open MPI biking team.&nbsp; The<BR>
&gt;&nbsp; &quot;--preload-result&quot; option will directly embed the final result in<BR>
&gt;&nbsp; the parallel execution, leading to more scalable and reliable runs<BR>
&gt;&nbsp; and decreasing the execution time of any parallel application under<BR>
&gt;&nbsp; the real-time limit of 1 second.&nbsp; Open MPI is therefore EnergyStar<BR>
&gt;&nbsp; compliant when used with these options.<BR>
&gt; - In addition to moving Open MPI's lowest point-to-point transports to<BR>
&gt;&nbsp; be an external project, limited support will be offered for<BR>
&gt;&nbsp; industry-standard platforms.&nbsp; Our focus will now be to develop<BR>
&gt;&nbsp; highly scalable transports based on widely distributed technologies<BR>
&gt;&nbsp; such as SMTP, High Performance Gopher (v3.8 and later), OLE COMM,<BR>
&gt;&nbsp; RSS/Atom, DNS, and Bonjour.<BR>
&gt; - Opportunistic integration with Conflicker in order to utilize free<BR>
&gt;&nbsp; resources distributed world-wide.<BR>
&gt; - Support for all Fortran versions prior to Fortran 2020 has been<BR>
&gt;&nbsp; dropped.<BR>
&gt;<BR>
&gt; Make today an Open MPI day!<BR>
&gt;<BR>
&gt;<BR>
&gt; _______________________________________________<BR>
&gt; devel mailing list<BR>
&gt; devel@open-mpi.org<BR>
&gt; <A HREF="http://www.open-mpi.org/mailman/listinfo.cgi/devel">http://www.open-mpi.org/mailman/listinfo.cgi/devel</A><BR>
<BR>
<BR>
--<BR>
Paul H. Hargrove&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PHHargrove@lbl.gov<BR>
Future Technologies Group&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Tel: +1-510-495-2352<BR>
HPC Research Department&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Fax: +1-510-486-6900<BR>
Lawrence Berkeley National Laboratory&nbsp;&nbsp;&nbsp;&nbsp;<BR>
<BR>
_______________________________________________<BR>
devel mailing list<BR>
devel@open-mpi.org<BR>
<A HREF="http://www.open-mpi.org/mailman/listinfo.cgi/devel">http://www.open-mpi.org/mailman/listinfo.cgi/devel</A><BR>
</FONT>
</P>

</BODY>
</HTML>