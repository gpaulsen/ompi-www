<div dir="ltr"><br><div>     I&#39;ve downloaded the OpenMPI master as suggested and rerun all my aggregate tests</div><div>across my system with QDR IB and 10 Gbps RoCE.  </div><div><br></div><div>     The attached unidirectional.pdf graph is the ping-pong performance for 1 core</div><div>on 1 machine to 1 core on the 2nd.  The red curve for OpenMPI 1.8.3 shows lower</div><div>performance for small and also medium message sizes for the base test without</div><div>using any tuning parameters.  The green line from the OpenMPI master shows lower </div><div>performance only for small messages, but great for medium size.  Turning off the</div><div>10 Gbps card entirely produces great performance for all message sizes.  So the</div><div>fixes in the master at least help, but it still seems to be choosing to use RoCE for</div><div>small messages rather than QDR IB.  They both use the openib btl so I assume it</div><div>just chooses one at random so this is probably not that surprising.  Since there are</div><div>no tunable parameters for multiple openib btl&#39;s, this cannot be manually tuned.</div><div><br></div><div>     The bi-directional ping-pong tests show basically the same thing with lower</div><div>performance for small message sizes for 1.8.3 and the master.  However, I&#39;m </div><div>also seeing the max bandwidth being limited to 44 Gbps instead of 60 Gbps</div><div>for the master for some reason.</div><div><br></div><div>     The aggregate tests in the 3rd graph are for 20 cores on one machine</div><div>yelling at 20 cores on the 2nd machine (bi-directional too).  They likewise show</div><div>the lower 10 Gbps RoCE performance for small messages, and also show </div><div>the max bandwidth being limited to 45 Gbps for the master.</div><div><br></div><div>     Our solution for now is to simply exclude mlx4_1 which is the 10 Gbps card</div><div>which will give us QDR performance but not allow us to use the extra 10 Gbps</div><div>to channel bond for large messages.  It is more worrisome that max bandwidth</div><div>on the bi-directional and aggregate tests using the master are slower than they</div><div>should be.</div><div><br></div><div>                       Dave</div></div><div class="gmail_extra"><br><div class="gmail_quote">On Wed, Feb 11, 2015 at 11:00 AM,  <span dir="ltr">&lt;<a href="mailto:devel-request@open-mpi.org" target="_blank">devel-request@open-mpi.org</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Send devel mailing list submissions to<br>
        <a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
<br>
To subscribe or unsubscribe via the World Wide Web, visit<br>
        <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
or, via email, send a message with subject or body &#39;help&#39; to<br>
        <a href="mailto:devel-request@open-mpi.org">devel-request@open-mpi.org</a><br>
<br>
You can reach the person managing the list at<br>
        <a href="mailto:devel-owner@open-mpi.org">devel-owner@open-mpi.org</a><br>
<br>
When replying, please edit your Subject line so it is more specific<br>
than &quot;Re: Contents of devel digest...&quot;<br>
<br>
<br>
Today&#39;s Topics:<br>
<br>
   1. Re: OMPI devel] RoCE plus QDR IB tunable parameters<br>
      (George Bosilca)<br>
   2. Re: OMPI devel] RoCE plus QDR IB tunable parameters<br>
      (Howard Pritchard)<br>
<br>
<br>
----------------------------------------------------------------------<br>
<br>
Message: 1<br>
Date: Tue, 10 Feb 2015 20:41:30 -0500<br>
From: George Bosilca &lt;<a href="mailto:bosilca@icl.utk.edu">bosilca@icl.utk.edu</a>&gt;<br>
To: <a href="mailto:DrDaveTurner@gmail.com">DrDaveTurner@gmail.com</a>, Open MPI Developers &lt;<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a>&gt;<br>
Subject: Re: [OMPI devel] OMPI devel] RoCE plus QDR IB tunable<br>
        parameters<br>
Message-ID:<br>
        &lt;<a href="mailto:CAMJJpkXC6e_y34fU5VeJ0uHrrJ2z4CA89mN7WfWa5dSfx52s7A@mail.gmail.com">CAMJJpkXC6e_y34fU5VeJ0uHrrJ2z4CA89mN7WfWa5dSfx52s7A@mail.gmail.com</a>&gt;<br>
Content-Type: text/plain; charset=&quot;utf-8&quot;<br>
<br>
Somehow one of the most basic information about the capabilities of the<br>
BTLs (bandwidth) disappeared from the MCA parameters and the one left<br>
(latency) was mislabeled. This mishap not only prevented the communication<br>
engine from correctly ordering the BTL for small messages (the latency<br>
bound part), but also introduced undesirable bias on the load-balance<br>
between multiple devices logic (the bandwidth part).<br>
<br>
I just pushed a fix  in master<br>
<a href="https://github.com/open-mpi/ompi/commit/e173f9b0c0c63c3ea24b8d8bc0ebafe1f1736acb" target="_blank">https://github.com/open-mpi/ompi/commit/e173f9b0c0c63c3ea24b8d8bc0ebafe1f1736acb</a>.<br>
Once validated this should be moved over the 1.8 branch.<br>
<br>
Dave do you think it is possible to renew your experiment with the current<br>
master ?<br>
<br>
  Thanks,<br>
    George.<br>
<br>
<br>
<br>
On Mon, Feb 9, 2015 at 2:57 PM, Dave Turner &lt;<a href="mailto:drdaveturner@gmail.com">drdaveturner@gmail.com</a>&gt; wrote:<br>
<br>
&gt; Gilles,<br>
&gt;<br>
&gt;      I tried running with btl_openib_cpc_include rdmacm and saw no change.<br>
&gt;<br>
&gt;       Let&#39;s simplify the problem by forgetting about the channel bonding.<br>
&gt; If I just do an aggregate test of 16 cores on one machine talking to 16 on<br>
&gt; a second machine without any settings changed from the default install<br>
&gt; of OpenMPI, I see that RoCE over the 10 Gbps link is used for small<br>
&gt; messages<br>
&gt; then it switches over to QDR IB for large messages.  I don&#39;t see channel<br>
&gt; bonding<br>
&gt; for large messages, but can turn this on with the btl_tcp_exclusivity<br>
&gt; parameter.<br>
&gt;<br>
&gt;      I think there are 2 problems here, both related to the fact that QDR<br>
&gt; IB link and RoCE<br>
&gt; both use the same openib btl.  The first problem is that the slower RoCE<br>
&gt; link is being chosen<br>
&gt; for small messages, which does lower performance significantly.  The<br>
&gt; second problem<br>
&gt; is that I don&#39;t think there are parameters to allow for tuning of multiple<br>
&gt; openib btl&#39;s<br>
&gt; to manually select one over the other.<br>
&gt;<br>
&gt;                        Dave<br>
&gt;<br>
&gt; On Fri, Feb 6, 2015 at 8:24 PM, Gilles Gouaillardet &lt;<br>
&gt; <a href="mailto:gilles.gouaillardet@gmail.com">gilles.gouaillardet@gmail.com</a>&gt; wrote:<br>
&gt;<br>
&gt;&gt; Dave,<br>
&gt;&gt;<br>
&gt;&gt; These settings tell ompi to use native infiniband on the ib qdr port and<br>
&gt;&gt; tcpo/ip on the other port.<br>
&gt;&gt;<br>
&gt;&gt; From the faq, roce is implemented in the openib btl<br>
&gt;&gt; <a href="http://www.open-mpi.org/faq/?category=openfabrics#ompi-over-roce" target="_blank">http://www.open-mpi.org/faq/?category=openfabrics#ompi-over-roce</a><br>
&gt;&gt;<br>
&gt;&gt; Did you use<br>
&gt;&gt; --mca btl_openib_cpc_include rdmacm<br>
&gt;&gt; in your first tests ?<br>
&gt;&gt;<br>
&gt;&gt; I had some second thougths about the bandwidth values, and imho they<br>
&gt;&gt; should be 327680 and 81920 because of the 8/10 encoding<br>
&gt;&gt; (And that being said, that should not change the measured performance)<br>
&gt;&gt;<br>
&gt;&gt; Also, could you try again by forcing the same btl_tcp_latency and<br>
&gt;&gt; btl_openib_latency ?<br>
&gt;&gt;<br>
&gt;&gt; Cheers,<br>
&gt;&gt;<br>
&gt;&gt; Gilles<br>
&gt;&gt;<br>
&gt;&gt; Dave Turner &lt;<a href="mailto:drdaveturner@gmail.com">drdaveturner@gmail.com</a>&gt; wrote:<br>
&gt;&gt; George,<br>
&gt;&gt;<br>
&gt;&gt;      I can check with my guys on Monday but I think the bandwidth<br>
&gt;&gt; parameters<br>
&gt;&gt; are the defaults.  I did alter these to 40960 and 10240 as someone else<br>
&gt;&gt; suggested to me.  The attached graph shows the base red line, along with<br>
&gt;&gt; the manual balanced blue line and auto balanced green line (0&#39;s for both).<br>
&gt;&gt; This shift lower suggests to me that the higher TCP latency is being<br>
&gt;&gt; pulled in.<br>
&gt;&gt; I&#39;m not sure why the curves are shifted right.<br>
&gt;&gt;<br>
&gt;&gt;                         Dave<br>
&gt;&gt;<br>
&gt;&gt; On Fri, Feb 6, 2015 at 5:32 PM, George Bosilca &lt;<a href="mailto:bosilca@icl.utk.edu">bosilca@icl.utk.edu</a>&gt;<br>
&gt;&gt; wrote:<br>
&gt;&gt;<br>
&gt;&gt;&gt; Dave,<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; Based on your ompi_info.all the following bandwidth are reported on your<br>
&gt;&gt;&gt; system:<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;                 MCA btl: parameter &quot;btl_openib_bandwidth&quot; (current<br>
&gt;&gt;&gt; value: &quot;4&quot;, data source: default, level: 5 tuner/detail, type: unsigned)<br>
&gt;&gt;&gt;                           Approximate maximum bandwidth of interconnect<br>
&gt;&gt;&gt; (0 = auto-detect value at run-time [not supported in all BTL modules], &gt;= 1<br>
&gt;&gt;&gt; = bandwidth in Mbps)<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;                  MCA btl: parameter &quot;btl_tcp_bandwidth&quot; (current value:<br>
&gt;&gt;&gt; &quot;100&quot;, data source: default, level: 5 tuner/detail, type: unsigned)<br>
&gt;&gt;&gt;                           Approximate maximum bandwidth of interconnect<br>
&gt;&gt;&gt; (0 = auto-detect value at run-time [not supported in all BTL modules], &gt;= 1<br>
&gt;&gt;&gt; = bandwidth in Mbps)<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; This basically states that on your system the default values for these<br>
&gt;&gt;&gt; parameters are wrong, your TCP network being much faster than the IB. This<br>
&gt;&gt;&gt; explains the somewhat unexpected decision of OMPI.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; As a possible solution I suggest you set these bandwidth values to<br>
&gt;&gt;&gt; something more meaningful (directly in your configuration file). As an<br>
&gt;&gt;&gt; example,<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; btl_openib_bandwidth = 40000<br>
&gt;&gt;&gt; btl_tcp_bandwidth = 10000<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; make more sense based on your HPC system description.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;   George.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; On Fri, Feb 6, 2015 at 5:37 PM, Dave Turner &lt;<a href="mailto:drdaveturner@gmail.com">drdaveturner@gmail.com</a>&gt;<br>
&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;      We have nodes in our HPC system that have 2 NIC&#39;s,<br>
&gt;&gt;&gt;&gt; one being QDR IB and the second being a slower 10 Gbps card<br>
&gt;&gt;&gt;&gt; configured for both RoCE and TCP.  Aggregate bandwidth<br>
&gt;&gt;&gt;&gt; tests with 20 cores on one node yelling at 20 cores on a second<br>
&gt;&gt;&gt;&gt; node (attached roce.ib.aggregate.pdf) show that without tuning<br>
&gt;&gt;&gt;&gt; the slower RoCE interface is being used for small messages<br>
&gt;&gt;&gt;&gt; then QDR IB is used for larger messages (red line).  Tuning<br>
&gt;&gt;&gt;&gt; the tcp_exclusivity to 1024 to match the openib_exclusivity<br>
&gt;&gt;&gt;&gt; adds another 20 Gbps of bidirectional bandwidth to the high end (green<br>
&gt;&gt;&gt;&gt; line),<br>
&gt;&gt;&gt;&gt; and I&#39;m guessing this is TCP traffic and not RoCE.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;      So by default the slower interface is being chosen on the low end,<br>
&gt;&gt;&gt;&gt; and<br>
&gt;&gt;&gt;&gt; I don&#39;t think there are tunable parameters to allow me to choose the<br>
&gt;&gt;&gt;&gt; QDR interface as the default.  Going forward we&#39;ll probably just<br>
&gt;&gt;&gt;&gt; disable<br>
&gt;&gt;&gt;&gt; RoCE on these nodes and go with QDR IB plus 10 Gbps TCP for large<br>
&gt;&gt;&gt;&gt; messages.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;       However, I do think these issues will come up more in the future.<br>
&gt;&gt;&gt;&gt; With the low latency of RoCE matching IB, there are more opportunities<br>
&gt;&gt;&gt;&gt; to do channel bonding or allowing multiple interfaces for aggregate<br>
&gt;&gt;&gt;&gt; traffic<br>
&gt;&gt;&gt;&gt; for even smaller message sizes.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;                 Dave Turner<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt; Work:     <a href="mailto:DaveTurner@ksu.edu">DaveTurner@ksu.edu</a>     <a href="tel:%28785%29%20532-7791" value="+17855327791">(785) 532-7791</a><br>
&gt;&gt;&gt;&gt;              118 Nichols Hall, Manhattan KS  66502<br>
&gt;&gt;&gt;&gt; Home:    <a href="mailto:DrDaveTurner@gmail.com">DrDaveTurner@gmail.com</a><br>
&gt;&gt;&gt;&gt;               cell: <a href="tel:%28785%29%20770-5929" value="+17857705929">(785) 770-5929</a><br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; _______________________________________________<br>
&gt;&gt;&gt;&gt; devel mailing list<br>
&gt;&gt;&gt;&gt; <a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt;&gt;&gt;&gt; Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
&gt;&gt;&gt;&gt; Link to this post:<br>
&gt;&gt;&gt;&gt; <a href="http://www.open-mpi.org/community/lists/devel/2015/02/16951.php" target="_blank">http://www.open-mpi.org/community/lists/devel/2015/02/16951.php</a><br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt; --<br>
&gt;&gt; Work:     <a href="mailto:DaveTurner@ksu.edu">DaveTurner@ksu.edu</a>     <a href="tel:%28785%29%20532-7791" value="+17855327791">(785) 532-7791</a><br>
&gt;&gt;              118 Nichols Hall, Manhattan KS  66502<br>
&gt;&gt; Home:    <a href="mailto:DrDaveTurner@gmail.com">DrDaveTurner@gmail.com</a><br>
&gt;&gt;               cell: <a href="tel:%28785%29%20770-5929" value="+17857705929">(785) 770-5929</a><br>
&gt;&gt;<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; --<br>
&gt; Work:     <a href="mailto:DaveTurner@ksu.edu">DaveTurner@ksu.edu</a>     <a href="tel:%28785%29%20532-7791" value="+17855327791">(785) 532-7791</a><br>
&gt;              118 Nichols Hall, Manhattan KS  66502<br>
&gt; Home:    <a href="mailto:DrDaveTurner@gmail.com">DrDaveTurner@gmail.com</a><br>
&gt;               cell: <a href="tel:%28785%29%20770-5929" value="+17857705929">(785) 770-5929</a><br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; devel mailing list<br>
&gt; <a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt; Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
&gt; Link to this post:<br>
&gt; <a href="http://www.open-mpi.org/community/lists/devel/2015/02/16963.php" target="_blank">http://www.open-mpi.org/community/lists/devel/2015/02/16963.php</a><br>
&gt;<br>
-------------- next part --------------<br>
HTML attachment scrubbed and removed<br>
<br>
------------------------------<br>
<br>
Message: 2<br>
Date: Tue, 10 Feb 2015 20:34:59 -0700<br>
From: Howard Pritchard &lt;<a href="mailto:hppritcha@gmail.com">hppritcha@gmail.com</a>&gt;<br>
To: Open MPI Developers &lt;<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a>&gt;<br>
Subject: Re: [OMPI devel] OMPI devel] RoCE plus QDR IB tunable<br>
        parameters<br>
Message-ID:<br>
        &lt;CAF1Cqj5=GPfi=t8Jw6SSUBKjqut0ChgntTyXfU0diM=<a href="mailto:MXs%2B9Yw@mail.gmail.com">MXs+9Yw@mail.gmail.com</a>&gt;<br>
Content-Type: text/plain; charset=&quot;utf-8&quot;<br>
<br>
HI George,<br>
<br>
I&#39;d say commit cf377db82 explains the vanishing of the bandwidth metric as<br>
well as the mis-labeling of the latency metric.<br>
<br>
Howard<br>
<br>
<br>
2015-02-10 18:41 GMT-07:00 George Bosilca &lt;<a href="mailto:bosilca@icl.utk.edu">bosilca@icl.utk.edu</a>&gt;:<br>
<br>
&gt; Somehow one of the most basic information about the capabilities of the<br>
&gt; BTLs (bandwidth) disappeared from the MCA parameters and the one left<br>
&gt; (latency) was mislabeled. This mishap not only prevented the communication<br>
&gt; engine from correctly ordering the BTL for small messages (the latency<br>
&gt; bound part), but also introduced undesirable bias on the load-balance<br>
&gt; between multiple devices logic (the bandwidth part).<br>
&gt;<br>
&gt; I just pushed a fix  in master<br>
&gt; <a href="https://github.com/open-mpi/ompi/commit/e173f9b0c0c63c3ea24b8d8bc0ebafe1f1736acb" target="_blank">https://github.com/open-mpi/ompi/commit/e173f9b0c0c63c3ea24b8d8bc0ebafe1f1736acb</a>.<br>
&gt; Once validated this should be moved over the 1.8 branch.<br>
&gt;<br>
&gt; Dave do you think it is possible to renew your experiment with the current<br>
&gt; master ?<br>
&gt;<br>
&gt;   Thanks,<br>
&gt;     George.<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; On Mon, Feb 9, 2015 at 2:57 PM, Dave Turner &lt;<a href="mailto:drdaveturner@gmail.com">drdaveturner@gmail.com</a>&gt;<br>
&gt; wrote:<br>
&gt;<br>
&gt;&gt; Gilles,<br>
&gt;&gt;<br>
&gt;&gt;      I tried running with btl_openib_cpc_include rdmacm and saw no<br>
&gt;&gt; change.<br>
&gt;&gt;<br>
&gt;&gt;       Let&#39;s simplify the problem by forgetting about the channel bonding.<br>
&gt;&gt;<br>
&gt;&gt; If I just do an aggregate test of 16 cores on one machine talking to 16 on<br>
&gt;&gt; a second machine without any settings changed from the default install<br>
&gt;&gt; of OpenMPI, I see that RoCE over the 10 Gbps link is used for small<br>
&gt;&gt; messages<br>
&gt;&gt; then it switches over to QDR IB for large messages.  I don&#39;t see channel<br>
&gt;&gt; bonding<br>
&gt;&gt; for large messages, but can turn this on with the btl_tcp_exclusivity<br>
&gt;&gt; parameter.<br>
&gt;&gt;<br>
&gt;&gt;      I think there are 2 problems here, both related to the fact that QDR<br>
&gt;&gt; IB link and RoCE<br>
&gt;&gt; both use the same openib btl.  The first problem is that the slower RoCE<br>
&gt;&gt; link is being chosen<br>
&gt;&gt; for small messages, which does lower performance significantly.  The<br>
&gt;&gt; second problem<br>
&gt;&gt; is that I don&#39;t think there are parameters to allow for tuning of<br>
&gt;&gt; multiple openib btl&#39;s<br>
&gt;&gt; to manually select one over the other.<br>
&gt;&gt;<br>
&gt;&gt;                        Dave<br>
&gt;&gt;<br>
&gt;&gt; On Fri, Feb 6, 2015 at 8:24 PM, Gilles Gouaillardet &lt;<br>
&gt;&gt; <a href="mailto:gilles.gouaillardet@gmail.com">gilles.gouaillardet@gmail.com</a>&gt; wrote:<br>
&gt;&gt;<br>
&gt;&gt;&gt; Dave,<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; These settings tell ompi to use native infiniband on the ib qdr port and<br>
&gt;&gt;&gt; tcpo/ip on the other port.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; From the faq, roce is implemented in the openib btl<br>
&gt;&gt;&gt; <a href="http://www.open-mpi.org/faq/?category=openfabrics#ompi-over-roce" target="_blank">http://www.open-mpi.org/faq/?category=openfabrics#ompi-over-roce</a><br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; Did you use<br>
&gt;&gt;&gt; --mca btl_openib_cpc_include rdmacm<br>
&gt;&gt;&gt; in your first tests ?<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; I had some second thougths about the bandwidth values, and imho they<br>
&gt;&gt;&gt; should be 327680 and 81920 because of the 8/10 encoding<br>
&gt;&gt;&gt; (And that being said, that should not change the measured performance)<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; Also, could you try again by forcing the same btl_tcp_latency and<br>
&gt;&gt;&gt; btl_openib_latency ?<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; Cheers,<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; Gilles<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; Dave Turner &lt;<a href="mailto:drdaveturner@gmail.com">drdaveturner@gmail.com</a>&gt; wrote:<br>
&gt;&gt;&gt; George,<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;      I can check with my guys on Monday but I think the bandwidth<br>
&gt;&gt;&gt; parameters<br>
&gt;&gt;&gt; are the defaults.  I did alter these to 40960 and 10240 as someone else<br>
&gt;&gt;&gt; suggested to me.  The attached graph shows the base red line, along with<br>
&gt;&gt;&gt; the manual balanced blue line and auto balanced green line (0&#39;s for<br>
&gt;&gt;&gt; both).<br>
&gt;&gt;&gt; This shift lower suggests to me that the higher TCP latency is being<br>
&gt;&gt;&gt; pulled in.<br>
&gt;&gt;&gt; I&#39;m not sure why the curves are shifted right.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;                         Dave<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; On Fri, Feb 6, 2015 at 5:32 PM, George Bosilca &lt;<a href="mailto:bosilca@icl.utk.edu">bosilca@icl.utk.edu</a>&gt;<br>
&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Dave,<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Based on your ompi_info.all the following bandwidth are reported on<br>
&gt;&gt;&gt;&gt; your system:<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;                 MCA btl: parameter &quot;btl_openib_bandwidth&quot; (current<br>
&gt;&gt;&gt;&gt; value: &quot;4&quot;, data source: default, level: 5 tuner/detail, type: unsigned)<br>
&gt;&gt;&gt;&gt;                           Approximate maximum bandwidth of interconnect<br>
&gt;&gt;&gt;&gt; (0 = auto-detect value at run-time [not supported in all BTL modules], &gt;= 1<br>
&gt;&gt;&gt;&gt; = bandwidth in Mbps)<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;                  MCA btl: parameter &quot;btl_tcp_bandwidth&quot; (current value:<br>
&gt;&gt;&gt;&gt; &quot;100&quot;, data source: default, level: 5 tuner/detail, type: unsigned)<br>
&gt;&gt;&gt;&gt;                           Approximate maximum bandwidth of interconnect<br>
&gt;&gt;&gt;&gt; (0 = auto-detect value at run-time [not supported in all BTL modules], &gt;= 1<br>
&gt;&gt;&gt;&gt; = bandwidth in Mbps)<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; This basically states that on your system the default values for these<br>
&gt;&gt;&gt;&gt; parameters are wrong, your TCP network being much faster than the IB. This<br>
&gt;&gt;&gt;&gt; explains the somewhat unexpected decision of OMPI.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; As a possible solution I suggest you set these bandwidth values to<br>
&gt;&gt;&gt;&gt; something more meaningful (directly in your configuration file). As an<br>
&gt;&gt;&gt;&gt; example,<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; btl_openib_bandwidth = 40000<br>
&gt;&gt;&gt;&gt; btl_tcp_bandwidth = 10000<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; make more sense based on your HPC system description.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;   George.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; On Fri, Feb 6, 2015 at 5:37 PM, Dave Turner &lt;<a href="mailto:drdaveturner@gmail.com">drdaveturner@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;      We have nodes in our HPC system that have 2 NIC&#39;s,<br>
&gt;&gt;&gt;&gt;&gt; one being QDR IB and the second being a slower 10 Gbps card<br>
&gt;&gt;&gt;&gt;&gt; configured for both RoCE and TCP.  Aggregate bandwidth<br>
&gt;&gt;&gt;&gt;&gt; tests with 20 cores on one node yelling at 20 cores on a second<br>
&gt;&gt;&gt;&gt;&gt; node (attached roce.ib.aggregate.pdf) show that without tuning<br>
&gt;&gt;&gt;&gt;&gt; the slower RoCE interface is being used for small messages<br>
&gt;&gt;&gt;&gt;&gt; then QDR IB is used for larger messages (red line).  Tuning<br>
&gt;&gt;&gt;&gt;&gt; the tcp_exclusivity to 1024 to match the openib_exclusivity<br>
&gt;&gt;&gt;&gt;&gt; adds another 20 Gbps of bidirectional bandwidth to the high end (green<br>
&gt;&gt;&gt;&gt;&gt; line),<br>
&gt;&gt;&gt;&gt;&gt; and I&#39;m guessing this is TCP traffic and not RoCE.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;      So by default the slower interface is being chosen on the low<br>
&gt;&gt;&gt;&gt;&gt; end, and<br>
&gt;&gt;&gt;&gt;&gt; I don&#39;t think there are tunable parameters to allow me to choose the<br>
&gt;&gt;&gt;&gt;&gt; QDR interface as the default.  Going forward we&#39;ll probably just<br>
&gt;&gt;&gt;&gt;&gt; disable<br>
&gt;&gt;&gt;&gt;&gt; RoCE on these nodes and go with QDR IB plus 10 Gbps TCP for large<br>
&gt;&gt;&gt;&gt;&gt; messages.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;       However, I do think these issues will come up more in the future.<br>
&gt;&gt;&gt;&gt;&gt; With the low latency of RoCE matching IB, there are more opportunities<br>
&gt;&gt;&gt;&gt;&gt; to do channel bonding or allowing multiple interfaces for aggregate<br>
&gt;&gt;&gt;&gt;&gt; traffic<br>
&gt;&gt;&gt;&gt;&gt; for even smaller message sizes.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;                 Dave Turner<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; Work:     <a href="mailto:DaveTurner@ksu.edu">DaveTurner@ksu.edu</a>     <a href="tel:%28785%29%20532-7791" value="+17855327791">(785) 532-7791</a><br>
&gt;&gt;&gt;&gt;&gt;              118 Nichols Hall, Manhattan KS  66502<br>
&gt;&gt;&gt;&gt;&gt; Home:    <a href="mailto:DrDaveTurner@gmail.com">DrDaveTurner@gmail.com</a><br>
&gt;&gt;&gt;&gt;&gt;               cell: <a href="tel:%28785%29%20770-5929" value="+17857705929">(785) 770-5929</a><br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; _______________________________________________<br>
&gt;&gt;&gt;&gt;&gt; devel mailing list<br>
&gt;&gt;&gt;&gt;&gt; <a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt;&gt;&gt;&gt;&gt; Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
&gt;&gt;&gt;&gt;&gt; Link to this post:<br>
&gt;&gt;&gt;&gt;&gt; <a href="http://www.open-mpi.org/community/lists/devel/2015/02/16951.php" target="_blank">http://www.open-mpi.org/community/lists/devel/2015/02/16951.php</a><br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; --<br>
&gt;&gt;&gt; Work:     <a href="mailto:DaveTurner@ksu.edu">DaveTurner@ksu.edu</a>     <a href="tel:%28785%29%20532-7791" value="+17855327791">(785) 532-7791</a><br>
&gt;&gt;&gt;              118 Nichols Hall, Manhattan KS  66502<br>
&gt;&gt;&gt; Home:    <a href="mailto:DrDaveTurner@gmail.com">DrDaveTurner@gmail.com</a><br>
&gt;&gt;&gt;               cell: <a href="tel:%28785%29%20770-5929" value="+17857705929">(785) 770-5929</a><br>
&gt;&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt; --<br>
&gt;&gt; Work:     <a href="mailto:DaveTurner@ksu.edu">DaveTurner@ksu.edu</a>     <a href="tel:%28785%29%20532-7791" value="+17855327791">(785) 532-7791</a><br>
&gt;&gt;              118 Nichols Hall, Manhattan KS  66502<br>
&gt;&gt; Home:    <a href="mailto:DrDaveTurner@gmail.com">DrDaveTurner@gmail.com</a><br>
&gt;&gt;               cell: <a href="tel:%28785%29%20770-5929" value="+17857705929">(785) 770-5929</a><br>
&gt;&gt;<br>
&gt;&gt; _______________________________________________<br>
&gt;&gt; devel mailing list<br>
&gt;&gt; <a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt;&gt; Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
&gt;&gt; Link to this post:<br>
&gt;&gt; <a href="http://www.open-mpi.org/community/lists/devel/2015/02/16963.php" target="_blank">http://www.open-mpi.org/community/lists/devel/2015/02/16963.php</a><br>
&gt;&gt;<br>
&gt;<br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; devel mailing list<br>
&gt; <a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt; Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
&gt; Link to this post:<br>
&gt; <a href="http://www.open-mpi.org/community/lists/devel/2015/02/16965.php" target="_blank">http://www.open-mpi.org/community/lists/devel/2015/02/16965.php</a><br>
&gt;<br>
-------------- next part --------------<br>
HTML attachment scrubbed and removed<br>
<br>
------------------------------<br>
<br>
Subject: Digest Footer<br>
<br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
<br>
------------------------------<br>
<br>
End of devel Digest, Vol 2917, Issue 1<br>
**************************************<br>
</blockquote></div><br><br clear="all"><div><br></div>-- <br><div class="gmail_signature"><div dir="ltr">Work:     <a href="mailto:DaveTurner@ksu.edu" target="_blank">DaveTurner@ksu.edu</a>     (785) 532-7791<div>             118 Nichols Hall, Manhattan KS  66502<br>Home:    <a href="mailto:DrDaveTurner@gmail.com" target="_blank">DrDaveTurner@gmail.com</a><br>              cell: (785) 770-5929<br></div></div></div>
</div>

