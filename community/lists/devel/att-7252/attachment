<div dir="ltr"><div>Hi,<br></div><div>can you provide $cat /proc/cpuinfo </div><div>I am not optimistic that it will help, but still...</div><div></div><div>thanks</div><div>Lenny.</div><br><div class="gmail_quote">On Wed, Dec 16, 2009 at 6:01 PM, Daan van Rossum <span dir="ltr">&lt;<a href="mailto:daan@flash.uchicago.edu">daan@flash.uchicago.edu</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;">Hi Terry,<br>
<br>
Thanks for your hint. I tried configure --enable-debug and even compiled it with all kind of manual debug flags turned on, but it doesn&#39;t help to get rid of this problem. So it definitively is not an optimization flaw.<br>

One more interesting test would be to try an older version of the Intel compiler. But the next older version that I have is 10.0.015, which is too old for the operating system (must be &gt;10.1).<br>
<br>
<br>
A good thing is that this bug is very easy to test. You only need one line of MPI code and one process in the execution.<br>
<br>
A few more test cases:<br>
 rank 0=node01 slot=1-7<br>
and<br>
 rank 0=node01 slot=0,2-7<br>
and<br>
 rank 0=node01 slot=0-1,3-7<br>
work WELL.<br>
But<br>
 rank 0=node01 slot=0-2,4-7<br>
FAILS.<br>
<br>
As long as either slot 0, 1, OR 2 is excluded from the list it&#39;s allright. Excluding a different slot, like slot 3, does not help.<br>
<br>
<br>
I&#39;ll try to get hold of an Intel v10.1 compiler version.<br>
<br>
Best,<br>
<font color="#888888">Daan<br>
</font><div><div class="h5"><br>
* on Monday, 14.12.09 at 14:57, Terry Dontje &lt;Terry.Dontje@Sun.COM&gt; wrote:<br>
<br>
&gt; I don&#39;t really want to throw fud on this list but we&#39;ve seen all<br>
&gt; sorts of oddities with OMPI 1.3.4 being built with Intel&#39;s 11.1<br>
&gt; compiler versus their 11.0 or other compilers (gcc, Sun Studio, pgi,<br>
&gt; and pathscale).  I have not tested your specific failing case but<br>
&gt; considering your issue doesn&#39;t show up with gcc I am wondering if<br>
&gt; there is some sort of optimization issue with the 11.1 compiler.<br>
&gt;<br>
&gt; It might be interesting to see if using certain optimization levels<br>
&gt; with the Intel 11.1 compiler produces a working OMPI library.<br>
&gt;<br>
&gt; --td<br>
&gt;<br>
&gt; Daan van Rossum wrote:<br>
&gt; &gt;Hi Ralph,<br>
&gt; &gt;<br>
&gt; &gt;I took the Dec 10th snapshot, but got exactly the same behavior as with version 1.3.4.<br>
&gt; &gt;<br>
&gt; &gt;I just noticed that even this rankfile doesn&#39;t work, with a single process:<br>
&gt; &gt; rank 0=node01 slot=0-3<br>
&gt; &gt;<br>
&gt; &gt;------------<br>
&gt; &gt;[node01:31105] mca:base:select:(paffinity) Querying component [linux]<br>
&gt; &gt;[node01:31105] mca:base:select:(paffinity) Query of component [linux] set priority to 10<br>
&gt; &gt;[node01:31105] mca:base:select:(paffinity) Selected component [linux]<br>
&gt; &gt;[node01:31105] paffinity slot assignment: slot_list == 0-3<br>
&gt; &gt;[node01:31105] paffinity slot assignment: rank 0 runs on cpu #0 (#0)<br>
&gt; &gt;[node01:31105] paffinity slot assignment: rank 0 runs on cpu #1 (#1)<br>
&gt; &gt;[node01:31105] paffinity slot assignment: rank 0 runs on cpu #2 (#2)<br>
&gt; &gt;[node01:31105] paffinity slot assignment: rank 0 runs on cpu #3 (#3)<br>
&gt; &gt;[node01:31106] mca:base:select:(paffinity) Querying component [linux]<br>
&gt; &gt;[node01:31106] mca:base:select:(paffinity) Query of component [linux] set priority to 10<br>
&gt; &gt;[node01:31106] mca:base:select:(paffinity) Selected component [linux]<br>
&gt; &gt;[node01:31106] paffinity slot assignment: slot_list == 0-3<br>
&gt; &gt;[node01:31106] paffinity slot assignment: rank 0 runs on cpu #0 (#0)<br>
&gt; &gt;[node01:31106] paffinity slot assignment: rank 0 runs on cpu #1 (#1)<br>
&gt; &gt;[node01:31106] paffinity slot assignment: rank 0 runs on cpu #2 (#2)<br>
&gt; &gt;[node01:31106] paffinity slot assignment: rank 0 runs on cpu #3 (#3)<br>
&gt; &gt;[node01:31106] *** An error occurred in MPI_Comm_rank<br>
&gt; &gt;[node01:31106] *** on a NULL communicator<br>
&gt; &gt;[node01:31106] *** Unknown error<br>
&gt; &gt;[node01:31106] *** MPI_ERRORS_ARE_FATAL (your MPI job will now abort)<br>
&gt; &gt;forrtl: severe (174): SIGSEGV, segmentation fault occurred<br>
&gt; &gt;------------<br>
&gt; &gt;<br>
&gt; &gt;The spawned compute process doesn&#39;t sense that it should skip the setting paffinity...<br>
&gt; &gt;<br>
&gt; &gt;<br>
&gt; &gt;I saw the posting from last July about a similar problem (the problem that I mentioned on the bottom, with the slot=0:* notation not working). But that is a different problem (besides, that is still not working as it seems).<br>

&gt; &gt;<br>
&gt; &gt;Best,<br>
&gt; &gt;Daan<br>
&gt; &gt;<br>
&gt; &gt;* on Saturday, 12.12.09 at 18:48, Ralph Castain &lt;<a href="mailto:rhc@open-mpi.org">rhc@open-mpi.org</a>&gt; wrote:<br>
&gt; &gt;<br>
&gt; &gt;&gt;This looks like an uninitialized variable that gnu c handles one way and intel another. Someone recently contributed a patch to the ompi trunk to fix just such a  thing in this code area - don&#39;t know if it addresses this problem or not.<br>

&gt; &gt;&gt;<br>
&gt; &gt;&gt;Can you try the ompi trunk (a nightly tarball from the last day or so forward) and see if this still occurs?<br>
&gt; &gt;&gt;<br>
&gt; &gt;&gt;Thanks<br>
&gt; &gt;&gt;Ralph<br>
&gt; &gt;&gt;<br>
&gt; &gt;&gt;On Dec 11, 2009, at 4:06 PM, Daan van Rossum wrote:<br>
&gt; &gt;&gt;<br>
&gt; &gt;&gt;&gt;Hi all,<br>
&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;There&#39;s a problem with ompi 1.3.4 when compiled with the intel 11.1.059 c compiler, related with the built in processor binding functionallity. The problem does not occur when ompi is compiled with the gnu c compiler.<br>

&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;A mpi program execution fails (segfault) on mpi_init() when the following rank file is used:<br>
&gt; &gt;&gt;&gt;rank 0=node01 slot=0-3<br>
&gt; &gt;&gt;&gt;rank 1=node01 slot=0-3<br>
&gt; &gt;&gt;&gt;but runs fine with:<br>
&gt; &gt;&gt;&gt;rank 0=node01 slot=0<br>
&gt; &gt;&gt;&gt;rank 1=node01 slot=1-3<br>
&gt; &gt;&gt;&gt;and fine with:<br>
&gt; &gt;&gt;&gt;rank 0=node01 slot=0-1<br>
&gt; &gt;&gt;&gt;rank 1=node01 slot=1-3<br>
&gt; &gt;&gt;&gt;but segfaults with:<br>
&gt; &gt;&gt;&gt;rank 0=node01 slot=0-2<br>
&gt; &gt;&gt;&gt;rank 1=node01 slot=1-3<br>
&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;This is on a two-processor quad-core opteron machine (occurs on all nodes of the cluster) with Ubuntu 8.10, kernel 2.6.27-16.<br>
&gt; &gt;&gt;&gt;This is the siplest case that fails. Generally, I would like to bind processors to physical procs but always allow any core, like<br>
&gt; &gt;&gt;&gt;rank 0=node01 slot=p0:0-3<br>
&gt; &gt;&gt;&gt;rank 1=node01 slot=p0:0-3<br>
&gt; &gt;&gt;&gt;rank 2=node01 slot=p0:0-3<br>
&gt; &gt;&gt;&gt;rank 3=node01 slot=p0:0-3<br>
&gt; &gt;&gt;&gt;rank 4=node01 slot=p1:0-3<br>
&gt; &gt;&gt;&gt;rank 5=node01 slot=p1:0-3<br>
&gt; &gt;&gt;&gt;rank 6=node01 slot=p1:0-3<br>
&gt; &gt;&gt;&gt;rank 7=node01 slot=p1:0-3<br>
&gt; &gt;&gt;&gt;which fails too.<br>
&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;This happens with a test code that contains only two lines of code, calling mpi_init and mpi_finalize subsequently, and happens in both fortran and in c.<br>
&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;One more interesting thing is, that the problem with setting the process affinity does not occur on our four-processor quad-core opteron nodes, with exactly the same OS etc.<br>
&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;Setting &quot;--mca paffinity_base_verbose 5&quot; shows what is going wrong for this rankfile:<br>
&gt; &gt;&gt;&gt;rank 0=node01 slot=0-3<br>
&gt; &gt;&gt;&gt;rank 1=node01 slot=0-3<br>
&gt; &gt;&gt;&gt;------------- WRONG -----------------<br>
&gt; &gt;&gt;&gt;[node01:23174] mca:base:select:(paffinity) Querying component [linux]<br>
&gt; &gt;&gt;&gt;[node01:23174] mca:base:select:(paffinity) Query of component [linux] set priority to 10<br>
&gt; &gt;&gt;&gt;[node01:23174] mca:base:select:(paffinity) Selected component [linux]<br>
&gt; &gt;&gt;&gt;[node01:23174] paffinity slot assignment: slot_list == 0-3<br>
&gt; &gt;&gt;&gt;[node01:23174] paffinity slot assignment: rank 0 runs on cpu #0 (#0)<br>
&gt; &gt;&gt;&gt;[node01:23174] paffinity slot assignment: rank 0 runs on cpu #1 (#1)<br>
&gt; &gt;&gt;&gt;[node01:23174] paffinity slot assignment: rank 0 runs on cpu #2 (#2)<br>
&gt; &gt;&gt;&gt;[node01:23174] paffinity slot assignment: rank 0 runs on cpu #3 (#3)<br>
&gt; &gt;&gt;&gt;[node01:23174] paffinity slot assignment: slot_list == 0-3<br>
&gt; &gt;&gt;&gt;[node01:23174] paffinity slot assignment: rank 1 runs on cpu #0 (#0)<br>
&gt; &gt;&gt;&gt;[node01:23174] paffinity slot assignment: rank 1 runs on cpu #1 (#1)<br>
&gt; &gt;&gt;&gt;[node01:23174] paffinity slot assignment: rank 1 runs on cpu #2 (#2)<br>
&gt; &gt;&gt;&gt;[node01:23174] paffinity slot assignment: rank 1 runs on cpu #3 (#3)<br>
&gt; &gt;&gt;&gt;[node01:23175] mca:base:select:(paffinity) Querying component [linux]<br>
&gt; &gt;&gt;&gt;[node01:23175] mca:base:select:(paffinity) Query of component [linux] set priority to 10<br>
&gt; &gt;&gt;&gt;[node01:23175] mca:base:select:(paffinity) Selected component [linux]<br>
&gt; &gt;&gt;&gt;[node01:23176] mca:base:select:(paffinity) Querying component [linux]<br>
&gt; &gt;&gt;&gt;[node01:23176] mca:base:select:(paffinity) Query of component [linux] set priority to 10<br>
&gt; &gt;&gt;&gt;[node01:23176] mca:base:select:(paffinity) Selected component [linux]<br>
&gt; &gt;&gt;&gt;[node01:23175] paffinity slot assignment: slot_list == 0-3<br>
&gt; &gt;&gt;&gt;[node01:23175] paffinity slot assignment: rank 0 runs on cpu #0 (#0)<br>
&gt; &gt;&gt;&gt;[node01:23175] paffinity slot assignment: rank 0 runs on cpu #1 (#1)<br>
&gt; &gt;&gt;&gt;[node01:23175] paffinity slot assignment: rank 0 runs on cpu #2 (#2)<br>
&gt; &gt;&gt;&gt;[node01:23175] paffinity slot assignment: rank 0 runs on cpu #3 (#3)<br>
&gt; &gt;&gt;&gt;[node01:23176] paffinity slot assignment: slot_list == 0-3<br>
&gt; &gt;&gt;&gt;[node01:23176] paffinity slot assignment: rank 1 runs on cpu #0 (#0)<br>
&gt; &gt;&gt;&gt;[node01:23176] paffinity slot assignment: rank 1 runs on cpu #1 (#1)<br>
&gt; &gt;&gt;&gt;[node01:23176] paffinity slot assignment: rank 1 runs on cpu #2 (#2)<br>
&gt; &gt;&gt;&gt;[node01:23176] paffinity slot assignment: rank 1 runs on cpu #3 (#3)<br>
&gt; &gt;&gt;&gt;[node01:23175] *** Process received signal ***<br>
&gt; &gt;&gt;&gt;[node01:23176] *** Process received signal ***<br>
&gt; &gt;&gt;&gt;[node01:23175] Signal: Segmentation fault (11)<br>
&gt; &gt;&gt;&gt;[node01:23175] Signal code: Address not mapped (1)<br>
&gt; &gt;&gt;&gt;[node01:23175] Failing at address: 0x30<br>
&gt; &gt;&gt;&gt;[node01:23176] Signal: Segmentation fault (11)<br>
&gt; &gt;&gt;&gt;[node01:23176] Signal code: Address not mapped (1)<br>
&gt; &gt;&gt;&gt;[node01:23176] Failing at address: 0x30<br>
&gt; &gt;&gt;&gt;------------- WRONG -----------------<br>
&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;------------- RIGHT -----------------<br>
&gt; &gt;&gt;&gt;[node25:23241] mca:base:select:(paffinity) Querying component [linux]<br>
&gt; &gt;&gt;&gt;[node25:23241] mca:base:select:(paffinity) Query of component [linux] set priority to 10<br>
&gt; &gt;&gt;&gt;[node25:23241] mca:base:select:(paffinity) Selected component [linux]<br>
&gt; &gt;&gt;&gt;[node25:23241] paffinity slot assignment: slot_list == 0-3<br>
&gt; &gt;&gt;&gt;[node25:23241] paffinity slot assignment: rank 0 runs on cpu #0 (#0)<br>
&gt; &gt;&gt;&gt;[node25:23241] paffinity slot assignment: rank 0 runs on cpu #1 (#1)<br>
&gt; &gt;&gt;&gt;[node25:23241] paffinity slot assignment: rank 0 runs on cpu #2 (#2)<br>
&gt; &gt;&gt;&gt;[node25:23241] paffinity slot assignment: rank 0 runs on cpu #3 (#3)<br>
&gt; &gt;&gt;&gt;[node25:23241] paffinity slot assignment: slot_list == 0-3<br>
&gt; &gt;&gt;&gt;[node25:23241] paffinity slot assignment: rank 1 runs on cpu #0 (#0)<br>
&gt; &gt;&gt;&gt;[node25:23241] paffinity slot assignment: rank 1 runs on cpu #1 (#1)<br>
&gt; &gt;&gt;&gt;[node25:23241] paffinity slot assignment: rank 1 runs on cpu #2 (#2)<br>
&gt; &gt;&gt;&gt;[node25:23241] paffinity slot assignment: rank 1 runs on cpu #3 (#3)<br>
&gt; &gt;&gt;&gt;[node25:23242] mca:base:select:(paffinity) Querying component [linux]<br>
&gt; &gt;&gt;&gt;[node25:23242] mca:base:select:(paffinity) Query of component [linux] set priority to 10<br>
&gt; &gt;&gt;&gt;[node25:23242] mca:base:select:(paffinity) Selected component [linux]<br>
&gt; &gt;&gt;&gt;[node25:23243] mca:base:select:(paffinity) Querying component [linux]<br>
&gt; &gt;&gt;&gt;[node25:23243] mca:base:select:(paffinity) Query of component [linux] set priority to 10<br>
&gt; &gt;&gt;&gt;[node25:23243] mca:base:select:(paffinity) Selected component [linux]<br>
&gt; &gt;&gt;&gt;------------- RIGHT -----------------<br>
&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;Apparently, only a master process (ID [node01:23174] and [node25:23241]) set the paffinity in the RIGHT case, but in the WRONG case, also the compute processes ([node01:23175] and [node01:23176], rank0 and rank1) try to set the their own paffinity properties.<br>

&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;Note that for the rankfile also the notation does not work. But that seems to have a different origin, as it tries to bind to a core# 4, whereas there are just 0-3.<br>
&gt; &gt;&gt;&gt;rank 0=node01 slot=0:*<br>
&gt; &gt;&gt;&gt;rank 1=node01 slot=0:*<br>
&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;Thanks for your help on this!<br>
&gt; &gt;&gt;&gt;<br>
&gt; &gt;&gt;&gt;--<br>
&gt; &gt;&gt;&gt;Daan van Rossum<br>
&gt; &gt;&gt;&gt;_______________________________________________<br>
&gt; &gt;&gt;&gt;devel mailing list<br>
&gt; &gt;&gt;&gt;<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt; &gt;&gt;&gt;<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
&gt; &gt;&gt;_______________________________________________<br>
&gt; &gt;&gt;devel mailing list<br>
&gt; &gt;&gt;<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt; &gt;&gt;<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
&gt; &gt;<br>
&gt; &gt;--<br>
&gt; &gt;Daan van Rossum<br>
&gt; &gt;<br>
&gt; &gt;University of Chicago<br>
&gt; &gt;Department of Astronomy and Astrophysics<br>
&gt; &gt;5640 S. Ellis Ave<br>
&gt; &gt;Chicago, IL 60637<br>
&gt; &gt;phone: 773-7020624<br>
&gt; &gt;_______________________________________________<br>
&gt; &gt;devel mailing list<br>
&gt; &gt;<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt; &gt;<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; devel mailing list<br>
&gt; <a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
<br>
--<br>
Daan van Rossum<br>
<br>
University of Chicago<br>
Department of Astronomy and Astrophysics<br>
5640 S. Ellis Ave<br>
Chicago, IL 60637<br>
phone: 773-7020624<br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</div></div></blockquote></div><br></div>

