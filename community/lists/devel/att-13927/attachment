<div dir="ltr">Nathan,<div><br></div><div>To encourage you to focus on 1.7.4, I will delay testing vader on the SGI UV until I&#39;ve tested the next 1.7.4 release candidate (or final).</div><div><br></div><div>-Paul</div>
</div><div class="gmail_extra"><br><br><div class="gmail_quote">On Mon, Jan 27, 2014 at 12:55 PM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Just FWIW: I believe that problem did indeed make it over to 1.7.4, and that release is on &quot;hold&quot; pending your fix. So while I&#39;m happy to hear about xpmem on SGI, please do let us release 1.7.4!<br>

<br>
<br>
On Jan 27, 2014, at 8:19 AM, Nathan Hjelm &lt;<a href="mailto:hjelmn@lanl.gov">hjelmn@lanl.gov</a>&gt; wrote:<br>
<br>
&gt; Yup. Has to do with not having 64-bit atomic math. The fix is complete<br>
&gt; but I am working on another update to enable using xpmem on SGI<br>
&gt; systems. I will push the changes once that is complete.<br>
&gt;<br>
&gt; -Nathan<br>
&gt;<br>
&gt; On Mon, Jan 27, 2014 at 04:00:08PM +0000, Jeff Squyres (jsquyres) wrote:<br>
&gt;&gt; Is this the same issue Absoft is seeing in 32 bit builds on the trunk?  (i.e., 100% failure rate)<br>
&gt;&gt;<br>
&gt;&gt;    <a href="http://mtt.open-mpi.org/index.php?do_redir=2142" target="_blank">http://mtt.open-mpi.org/index.php?do_redir=2142</a><br>
&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt; On Jan 27, 2014, at 10:38 AM, Nathan Hjelm &lt;<a href="mailto:hjelmn@lanl.gov">hjelmn@lanl.gov</a>&gt; wrote:<br>
&gt;&gt;<br>
&gt;&gt;&gt; This shouldn&#39;t be affecting 1.7.4 since neither the vader or coll/ml<br>
&gt;&gt;&gt; updates have been moved yet. As for trunk I am working on a 32-bit fix<br>
&gt;&gt;&gt; for vader and it should be in later today. I will have to track down<br>
&gt;&gt;&gt; what is going wrong the basesmuma initialization.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; -Nathan<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; On Sun, Jan 26, 2014 at 04:10:29PM +0100, George Bosilca wrote:<br>
&gt;&gt;&gt;&gt; I noticed two major issues on 32 bits machines. The first one is with the vader BTL and the second with the selection logic in basesmuma (bcol_basesmuma_bank_init_opti). Both versions are impacted: trunk and 1.7.<br>

&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; If I turn off vader and boll via the MCA parameters everything runs just fine.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; George.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; ../trunk/configure --enable-debug --disable-mpi-cxx --disable-mpi-fortran --disable-io-romio --enable-contrib-no-build=vt,libtrace --enable-mpirun-prefix-by-default<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; - Vader generates a segfault for any application even with only 2 processes, so this should be pretty easy to track.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Program received signal SIGSEGV, Segmentation fault.<br>
&gt;&gt;&gt;&gt; (gdb) bt<br>
&gt;&gt;&gt;&gt; #0  0x00000000 in ?? ()<br>
&gt;&gt;&gt;&gt; #1  0x00ae43b3 in mca_btl_vader_poll_fifo ()<br>
&gt;&gt;&gt;&gt;   at ../../../../../trunk/ompi/mca/btl/vader/btl_vader_component.c:394<br>
&gt;&gt;&gt;&gt; #2  0x00ae444a in mca_btl_vader_component_progress ()<br>
&gt;&gt;&gt;&gt;   at ../../../../../trunk/ompi/mca/btl/vader/btl_vader_component.c:421<br>
&gt;&gt;&gt;&gt; #3  0x008fdb95 in opal_progress ()<br>
&gt;&gt;&gt;&gt;   at ../../trunk/opal/runtime/opal_progress.c:186<br>
&gt;&gt;&gt;&gt; #4  0x001961bc in ompi_request_default_test_some (count=13,<br>
&gt;&gt;&gt;&gt;   requests=0xb1f01d48, outcount=0xb2afb2d0, indices=0xb1f01f60,<br>
&gt;&gt;&gt;&gt;   statuses=0xb1f02178) at ../../trunk/ompi/request/req_test.c:316<br>
&gt;&gt;&gt;&gt; #5  0x001def9a in PMPI_Testsome (incount=13, requests=0xb1f01d48,<br>
&gt;&gt;&gt;&gt;   outcount=0xb2afb2d0, indices=0xb1f01f60, statuses=0xb1f02178)<br>
&gt;&gt;&gt;&gt;   at ptestsome.c:81<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; - basesmuma overwrite the memory. The results_array can’t be released as the memory is corrupted. I did not have time to investigate too much but it looks like the pload_mgmt-&gt;data_bffs either too small or somehow data is stored outside its boundaries.<br>

&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; *** glib detected *** /home/bosilca/unstable/dplasma/trunk/build/debug/dplasma/testing/testing_dpotrf: free(): invalid next size (fast): 0x081f0798 ***<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; (gdb) bt<br>
&gt;&gt;&gt;&gt; #0  0x00130424 in __kernel_vsyscall ()<br>
&gt;&gt;&gt;&gt; #1  0x006bfb11 in raise () from /lib/libc.so.6<br>
&gt;&gt;&gt;&gt; #2  0x006c13ea in abort () from /lib/libc.so.6<br>
&gt;&gt;&gt;&gt; #3  0x006ff9d5 in __libc_message () from /lib/libc.so.6<br>
&gt;&gt;&gt;&gt; #4  0x00705e31 in malloc_printerr () from /lib/libc.so.6<br>
&gt;&gt;&gt;&gt; #5  0x00708571 in _int_free () from /lib/libc.so.6<br>
&gt;&gt;&gt;&gt; #6  0x00c02d0e in bcol_basesmuma_bank_init_opti (ml_module=0x81dfe60,<br>
&gt;&gt;&gt;&gt;   bcol_module=0xb30b3008, reg_data=0x81e6698)<br>
&gt;&gt;&gt;&gt;   at ../../../../../trunk/ompi/mca/bcol/basesmuma/bcol_basesmuma_buf_mgmt.c:472<br>
&gt;&gt;&gt;&gt; #7  0x00b7035f in mca_coll_ml_register_bcols (ml_module=0x81dfe60)<br>
&gt;&gt;&gt;&gt;   at ../../../../../trunk/ompi/mca/coll/ml/coll_ml_module.c:513<br>
&gt;&gt;&gt;&gt; #8  0x00b70651 in ml_module_memory_initialization (ml_module=0x81dfe60)<br>
&gt;&gt;&gt;&gt;   at ../../../../../trunk/ompi/mca/coll/ml/coll_ml_module.c:560<br>
&gt;&gt;&gt;&gt; #9  0x00b733fd in ml_discover_hierarchy (ml_module=0x81dfe60)<br>
&gt;&gt;&gt;&gt;   at ../../../../../trunk/ompi/mca/coll/ml/coll_ml_module.c:1585<br>
&gt;&gt;&gt;&gt; #10 0x00b7786e in mca_coll_ml_comm_query (comm=0x8127da0, priority=0xbfffe558)<br>
&gt;&gt;&gt;&gt;   at ../../../../../trunk/ompi/mca/coll/ml/coll_ml_module.c:2998<br>
&gt;&gt;&gt;&gt; #11 0x00202ea6 in query_2_0_0 (component=0xbc6500, comm=0x8127da0,<br>
&gt;&gt;&gt;&gt;   priority=0xbfffe558, module=0xbfffe580)<br>
&gt;&gt;&gt;&gt;   at ../../../../trunk/ompi/mca/coll/base/coll_base_comm_select.c:375<br>
&gt;&gt;&gt;&gt; #12 0x00202e7f in query (component=0xbc6500, comm=0x8127da0,<br>
&gt;&gt;&gt;&gt;   priority=0xbfffe558, module=0xbfffe580)<br>
&gt;&gt;&gt;&gt; ---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---<br>
&gt;&gt;&gt;&gt;   at ../../../../trunk/ompi/mca/coll/base/coll_base_comm_select.c:358<br>
&gt;&gt;&gt;&gt; #13 0x00202d9e in check_one_component (comm=0x8127da0, component=0xbc6500,<br>
&gt;&gt;&gt;&gt;   module=0xbfffe580)<br>
&gt;&gt;&gt;&gt;   at ../../../../trunk/ompi/mca/coll/base/coll_base_comm_select.c:320<br>
&gt;&gt;&gt;&gt; #14 0x00202bce in check_components (components=0x253d70, comm=0x8127da0)<br>
&gt;&gt;&gt;&gt;   at ../../../../trunk/ompi/mca/coll/base/coll_base_comm_select.c:284<br>
&gt;&gt;&gt;&gt; #15 0x001fbbe1 in mca_coll_base_comm_select (comm=0x8127da0)<br>
&gt;&gt;&gt;&gt;   at ../../../../trunk/ompi/mca/coll/base/coll_base_comm_select.c:117<br>
&gt;&gt;&gt;&gt; #16 0x0019872f in ompi_mpi_init (argc=7, argv=0xbfffee74, requested=0,<br>
&gt;&gt;&gt;&gt;   provided=0xbfffe970) at ../../trunk/ompi/runtime/ompi_mpi_init.c:894<br>
&gt;&gt;&gt;&gt; #17 0x001c9509 in PMPI_Init (argc=0xbfffe9c0, argv=0xbfffe9c4) at pinit.c:84<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; _______________________________________________<br>
&gt;&gt;&gt;&gt; devel mailing list<br>
&gt;&gt;&gt;&gt; <a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt;&gt;&gt;&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
&gt;&gt;&gt; _______________________________________________<br>
&gt;&gt;&gt; devel mailing list<br>
&gt;&gt;&gt; <a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt;&gt;&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt; --<br>
&gt;&gt; Jeff Squyres<br>
&gt;&gt; <a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a><br>
&gt;&gt; For corporate legal information go to: <a href="http://www.cisco.com/web/about/doing_business/legal/cri/" target="_blank">http://www.cisco.com/web/about/doing_business/legal/cri/</a><br>
&gt;&gt;<br>
&gt;&gt; _______________________________________________<br>
&gt;&gt; devel mailing list<br>
&gt;&gt; <a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt;&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
&gt; _______________________________________________<br>
&gt; devel mailing list<br>
&gt; <a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt; <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
<br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote></div><br><br clear="all"><div><br></div>-- <br><font face="courier new, monospace"><div>Paul H. Hargrove                          <a href="mailto:PHHargrove@lbl.gov" target="_blank">PHHargrove@lbl.gov</a></div>
<div>Future Technologies Group</div><div>Computer and Data Sciences Department     Tel: +1-510-495-2352</div><div>Lawrence Berkeley National Laboratory     Fax: +1-510-486-6900</div></font>
</div>

