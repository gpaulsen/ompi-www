<div dir="ltr"><div>I will take a look,<br></div><div>originally it supposed to bind process to CPU#1 and CPU #3.</div><div></div><div></div><br><div class="gmail_quote">On Fri, Sep 25, 2009 at 4:57 PM, Eugene Loh <span dir="ltr">&lt;<a href="mailto:Eugene.Loh@sun.com">Eugene.Loh@sun.com</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;">Thanks, filed as <a href="https://svn.open-mpi.org/trac/ompi/ticket/2030" target="_blank">https://svn.open-mpi.org/trac/ompi/ticket/2030</a><div>
<div class="h5"><br>
<br>
Ralph Castain wrote:<br>
<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
Circling some off-list comments back to the list...while we could and  should error-out easier, this really isn&#39;t a supportable operation.  What the cmd<br>
<br>
mpirun -n 2 -slot-list 1,3 foo<br>
<br>
appears to do is cause us to launch a 2-process job consisting of  vpid=1 and vpid=3, as opposed to the normal vpid=0 and 1.<br>
<br>
Not only is ORTE not prepared to handle this scenario, I believe it  will cause problems in some areas within OMPI.<br>
<br>
I can try to make it fail nicer - someone with more knowledge of the  intended slot-list behavior would have to make it do what they  actually intended, or at least explain what is supposed o happen.<br>
<br>
Ralph<br>
<br>
On Sep 24, 2009, at 7:03 PM, Eugene Loh wrote:<br>
<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
mpirun -V<br>
mpirun (Open MPI) 1.4a1-1<br>
<br>
Ralph Castain wrote:<br>
<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
Sigh - you really need to remember to tell us what version you&#39;re   talking about.<br>
<br>
On Sep 24, 2009, at 5:39 PM, Eugene Loh wrote:<br>
<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
I assume this is a bug?<br>
<br>
% mpirun -np 2 -slot-list 1,3 hostname<br>
[saem9:10337] [[455,0],0] ORTE_ERROR_LOG: Not found in file base/  odls_base_default_fns.c at line 875<br>
[saem9:10337] *** Process received signal ***<br>
[saem9:10337] Signal: Segmentation fault (11)<br>
[saem9:10337] Signal code: Address not mapped (1)<br>
[saem9:10337] Failing at address: 0x4c<br>
[saem9:10337] [ 0] [0xffffe600]<br>
[saem9:10337] [ 1] /home/eugene/CTperf/test-CT821/paff_bug2/src/  myopt/lib/libopen-rte.so.0(orte_plm_base_launch_apps+0x78a)   [0xf7f8c206]<br>
[saem9:10337] [ 2] /home/eugene/CTperf/test-CT821/paff_bug2/src/  myopt/lib/openmpi/mca_plm_rsh.so [0xf7d13564]<br>
[saem9:10337] [ 3] mpirun [0x804b49d]<br>
[saem9:10337] [ 4] mpirun [0x804a456]<br>
[saem9:10337] [ 5] /lib/libc.so.6(__libc_start_main+0xdc)  [0xf7d348ac]<br>
[saem9:10337] [ 6] mpirun(orte_daemon_recv+0x201) [0x804a3b1]<br>
[saem9:10337] *** End of error message ***<br>
Segmentation fault<br>
</blockquote>
<br>
<br>
</blockquote>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote>
<br>
<br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote>
<br>
<br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</div></div></blockquote></div><br></div>

