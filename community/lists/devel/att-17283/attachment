<div dir="ltr">Also, was this with HT&#39;s enabled? I&#39;m wondering if the print code is incorrectly computing the core because it isn&#39;t correctly accounting for HT cpus.<div><br></div></div><div class="gmail_extra"><br><div class="gmail_quote">On Mon, Apr 20, 2015 at 3:49 PM, Jeff Squyres (jsquyres) <span dir="ltr">&lt;<a href="mailto:jsquyres@cisco.com" target="_blank">jsquyres@cisco.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Ralph&#39;s the authority on this one, but just to be sure: are all nodes the same topology? E.g., does adding &quot;--hetero-nodes&quot; to the mpirun command line fix the problem?<br>
<div><div class="h5"><br>
<br>
&gt; On Apr 20, 2015, at 9:29 AM, Elena Elkina &lt;<a href="mailto:elena.elkina@itseez.com">elena.elkina@itseez.com</a>&gt; wrote:<br>
&gt;<br>
&gt; Hi guys,<br>
&gt;<br>
&gt; I faced with an issue on our cluster related to mapping &amp; binding policies on 1.8.5.<br>
&gt;<br>
&gt; The matter is that --report-bindings output doesn&#39;t correspond to the locale. It looks like there is a mistake on the output itself, because it just puts serial core number while that core can be on another socket. For example,<br>
&gt;<br>
&gt; mpirun -np 2 --display-devel-map --report-bindings --map-by socket hostname<br>
&gt;  Data for JOB [43064,1] offset 0<br>
&gt;<br>
&gt;  Mapper requested: NULL  Last mapper: round_robin  Mapping policy: BYSOCKET  Ranking policy: SOCKET<br>
&gt;  Binding policy: CORE  Cpu set: NULL  PPR: NULL  Cpus-per-rank: 1<br>
&gt;       Num new daemons: 0      New daemon starting vpid INVALID<br>
&gt;       Num nodes: 1<br>
&gt;<br>
&gt;  Data for node: clx-orion-001         Launch id: -1   State: 2<br>
&gt;       Daemon: [[43064,0],0]   Daemon launched: True<br>
&gt;       Num slots: 28   Slots in use: 2 Oversubscribed: FALSE<br>
&gt;       Num slots allocated: 28 Max slots: 0<br>
&gt;       Username on node: NULL<br>
&gt;       Num procs: 2    Next node_rank: 2<br>
&gt;       Data for proc: [[43064,1],0]<br>
&gt;               Pid: 0  Local rank: 0   Node rank: 0    App rank: 0<br>
&gt;               State: INITIALIZED      Restarts: 0     App_context: 0  Locale: 0-6,14-20       Bind location: 0        Binding: 0<br>
&gt;       Data for proc: [[43064,1],1]<br>
&gt;               Pid: 0  Local rank: 1   Node rank: 1    App rank: 1<br>
&gt;               State: INITIALIZED      Restarts: 0     App_context: 0  Locale: 7-13,21-27      Bind location: 7        Binding: 7<br>
&gt; [clx-orion-001:26951] MCW rank 0 bound to socket 0[core 0[hwt 0]]: [B/././././././././././././.][./././././././././././././.]<br>
&gt; [clx-orion-001:26951] MCW rank 1 bound to socket 1[core 14[hwt 0]]: [./././././././././././././.][B/././././././././././././.]<br>
&gt;<br>
&gt; The second process should be bound at core 7 (not core 14).<br>
&gt;<br>
&gt;<br>
&gt; Another example:<br>
&gt; mpirun -np 8 --display-devel-map --report-bindings --map-by core hostname<br>
&gt;  Data for JOB [43202,1] offset 0<br>
&gt;<br>
&gt;  Mapper requested: NULL  Last mapper: round_robin  Mapping policy: BYCORE  Ranking policy: CORE<br>
&gt;  Binding policy: CORE  Cpu set: NULL  PPR: NULL  Cpus-per-rank: 1<br>
&gt;       Num new daemons: 0      New daemon starting vpid INVALID<br>
&gt;       Num nodes: 1<br>
&gt;<br>
&gt;  Data for node: clx-orion-001         Launch id: -1   State: 2<br>
&gt;       Daemon: [[43202,0],0]   Daemon launched: True<br>
&gt;       Num slots: 28   Slots in use: 8 Oversubscribed: FALSE<br>
&gt;       Num slots allocated: 28 Max slots: 0<br>
&gt;       Username on node: NULL<br>
&gt;       Num procs: 8    Next node_rank: 8<br>
&gt;       Data for proc: [[43202,1],0]<br>
&gt;               Pid: 0  Local rank: 0   Node rank: 0    App rank: 0<br>
&gt;               State: INITIALIZED      Restarts: 0     App_context: 0  Locale: 0       Bind location: 0        Binding: 0<br>
&gt;       Data for proc: [[43202,1],1]<br>
&gt;               Pid: 0  Local rank: 1   Node rank: 1    App rank: 1<br>
&gt;               State: INITIALIZED      Restarts: 0     App_context: 0  Locale: 1       Bind location: 1        Binding: 1<br>
&gt;       Data for proc: [[43202,1],2]<br>
&gt;               Pid: 0  Local rank: 2   Node rank: 2    App rank: 2<br>
&gt;               State: INITIALIZED      Restarts: 0     App_context: 0  Locale: 2       Bind location: 2        Binding: 2<br>
&gt;       Data for proc: [[43202,1],3]<br>
&gt;               Pid: 0  Local rank: 3   Node rank: 3    App rank: 3<br>
&gt;               State: INITIALIZED      Restarts: 0     App_context: 0  Locale: 3       Bind location: 3        Binding: 3<br>
&gt;       Data for proc: [[43202,1],4]<br>
&gt;               Pid: 0  Local rank: 4   Node rank: 4    App rank: 4<br>
&gt;               State: INITIALIZED      Restarts: 0     App_context: 0  Locale: 4       Bind location: 4        Binding: 4<br>
&gt;       Data for proc: [[43202,1],5]<br>
&gt;               Pid: 0  Local rank: 5   Node rank: 5    App rank: 5<br>
&gt;               State: INITIALIZED      Restarts: 0     App_context: 0  Locale: 5       Bind location: 5        Binding: 5<br>
&gt;       Data for proc: [[43202,1],6]<br>
&gt;               Pid: 0  Local rank: 6   Node rank: 6    App rank: 6<br>
&gt;               State: INITIALIZED      Restarts: 0     App_context: 0  Locale: 6       Bind location: 6        Binding: 6<br>
&gt;       Data for proc: [[43202,1],7]<br>
&gt;               Pid: 0  Local rank: 7   Node rank: 7    App rank: 7<br>
&gt;               State: INITIALIZED      Restarts: 0     App_context: 0  Locale: 14      Bind location: 14       Binding: 14<br>
&gt; [clx-orion-001:27069] MCW rank 0 bound to socket 0[core 0[hwt 0]]: [B/././././././././././././.][./././././././././././././.]<br>
&gt; [clx-orion-001:27069] MCW rank 1 bound to socket 0[core 1[hwt 0]]: [./B/./././././././././././.][./././././././././././././.]<br>
&gt; [clx-orion-001:27069] MCW rank 2 bound to socket 0[core 2[hwt 0]]: [././B/././././././././././.][./././././././././././././.]<br>
&gt; [clx-orion-001:27069] MCW rank 3 bound to socket 0[core 3[hwt 0]]: [./././B/./././././././././.][./././././././././././././.]<br>
&gt; [clx-orion-001:27069] MCW rank 4 bound to socket 0[core 4[hwt 0]]: [././././B/././././././././.][./././././././././././././.]<br>
&gt; [clx-orion-001:27069] MCW rank 5 bound to socket 0[core 5[hwt 0]]: [./././././B/./././././././.][./././././././././././././.]<br>
&gt; [clx-orion-001:27069] MCW rank 6 bound to socket 0[core 6[hwt 0]]: [././././././B/././././././.][./././././././././././././.]<br>
&gt; [clx-orion-001:27069] MCW rank 7 bound to socket 0[core 7[hwt 0]]: [./././././././B/./././././.][./././././././././././././.]<br>
&gt;<br>
&gt; Rank 7 should be bound at core 14 instead of core 7 since core 7 is at another socket.<br>
&gt;<br>
&gt; Best regards,<br>
&gt; Elena<br>
&gt;<br>
&gt;<br>
</div></div><span class="">&gt; _______________________________________________<br>
&gt; devel mailing list<br>
&gt; <a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt; Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
&gt; Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/04/17273.php" target="_blank">http://www.open-mpi.org/community/lists/devel/2015/04/17273.php</a><br>
<br>
<br>
--<br>
Jeff Squyres<br>
<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a><br>
For corporate legal information go to: <a href="http://www.cisco.com/web/about/doing_business/legal/cri/" target="_blank">http://www.cisco.com/web/about/doing_business/legal/cri/</a><br>
<br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</span>Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2015/04/17282.php" target="_blank">http://www.open-mpi.org/community/lists/devel/2015/04/17282.php</a><br>
</blockquote></div><br></div>

