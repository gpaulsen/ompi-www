<html><head><meta http-equiv="Content-Type" content="text/html charset=windows-1252"></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;" class="">Kewl - thanks to both of you for the explanation. I’ll make the adjustment.<div class=""><br class=""><div><blockquote type="cite" class=""><div class="">On Dec 11, 2014, at 9:10 PM, Paul Hargrove &lt;<a href="mailto:phhargrove@lbl.gov" class="">phhargrove@lbl.gov</a>&gt; wrote:</div><br class="Apple-interchange-newline"><div class=""><div dir="ltr" class="">Ralph,<div class=""><br class=""></div><div class="">The "understanding" Gilles just expresses matches my own.</div><div class=""><br class=""></div><div class="">The issue that the OP observed on an ARM/Linux system (and I was able to reproduce on Linux w/ any arch) is that when the LO interface is missing Linux is unable to pass loopback messages sent on ANY interface.&nbsp; The oob_tcp code was trying to connect to a 172.18.0.x address when I reproduced it.</div><div class=""><br class=""></div><div class="">In summary:</div><div class=""><br class=""></div><div class="">For LINUX the lack of a loopback interface (selected or not) prevents local connection.</div><div class="">For NON-LINUX the lack of a loopback interface MAKES NO DIFFERENCE.</div><div class=""><br class=""></div><div class="">So, I think Gilles's version is correct, but that making the logic (at least the reporting) conditional on Linux might be an improvement.</div><div class=""><br class=""></div><div class="">Since this is a warning, it might be better to remove from 1.8 until we have more certainty about where/when it matters.&nbsp; I don't think users will appreciate a "cry wolf" release.</div><div class=""><br class=""></div><div class="">-Paul</div></div><div class="gmail_extra"><br class=""><div class="gmail_quote">On Thu, Dec 11, 2014 at 9:01 PM, Gilles Gouaillardet <span dir="ltr" class="">&lt;<a href="mailto:gilles.gouaillardet@iferc.org" target="_blank" class="">gilles.gouaillardet@iferc.org</a>&gt;</span> wrote:<br class=""><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
  
    
  
  <div text="#000000" bgcolor="#FFFFFF" class="">
    <div class="">Ralph,<br class="">
      <br class="">
      here is my understanding of what happens on Linux :<br class="">
      <br class="">
      lo: <a href="http://127.0.0.1/8" target="_blank" class="">127.0.0.1/8</a><br class="">
      eth0: <a href="http://192.168.122.101/24" target="_blank" class="">192.168.122.101/24</a><br class="">
      <br class="">
      mpirun --mca orte_oob_tcp_if_include eth0 ...<br class="">
      <br class="">
      so the mpi task tries to contact orted/mpirun on <a href="http://192.168.0.1/24" target="_blank" class="">192.168.0.1/24</a><br class="">
      <br class="">
      that works just fine if the loopback interface is active,<br class="">
      and that hangs if there is no loopback interface.<br class="">
      <br class="">
      <br class="">
      imho that is a linux oddity, and OMPI has nothing to do with it<br class="">
      <br class="">
      Cheers,<br class="">
      <br class="">
      Gilles<br class="">
      <br class="">
      [root@slurm1 ~]# ping -c 3 192.168.122.101<br class="">
      PING 192.168.122.101 (192.168.122.101) 56(84) bytes of data.<br class="">
      64 bytes from <a href="http://192.168.122.101/" target="_blank" class="">192.168.122.101</a>: icmp_seq=1 ttl=64 time=0.013 ms<br class="">
      64 bytes from <a href="http://192.168.122.101/" target="_blank" class="">192.168.122.101</a>: icmp_seq=2 ttl=64 time=0.009 ms<br class="">
      64 bytes from <a href="http://192.168.122.101/" target="_blank" class="">192.168.122.101</a>: icmp_seq=3 ttl=64 time=0.011 ms<br class="">
      <br class="">
      --- 192.168.122.101 ping statistics ---<br class="">
      3 packets transmitted, 3 received, 0% packet loss, time 1999ms<br class="">
      rtt min/avg/max/mdev = 0.009/0.011/0.013/0.001 ms<br class="">
      <br class="">
      <br class="">
      <br class="">
      [root@slurm1 ~]# ifdown lo<br class="">
      [root@slurm1 ~]# ping -c 3 192.168.122.101<br class="">
      PING 192.168.122.101 (192.168.122.101) 56(84) bytes of data.<br class="">
      <br class="">
      --- 192.168.122.101 ping statistics ---<br class="">
      3 packets transmitted, 0 received, 100% packet loss, time 11999ms<div class=""><div class="h5"><br class="">
      <br class="">
      <br class="">
      On 2014/12/12 13:54, Ralph Castain wrote:<br class="">
    </div></div></div>
    <blockquote type="cite" class=""><div class=""><div class="h5">
      <pre class="">I honestly think it has to be a selected interface, Gilles, else we will fail to connect.

</pre>
      </div></div><blockquote type="cite" class=""><div class=""><div class="h5">
        <pre class="">On Dec 11, 2014, at 8:26 PM, Gilles Gouaillardet <a href="mailto:gilles.gouaillardet@iferc.org" target="_blank" class="">&lt;gilles.gouaillardet@iferc.org&gt;</a> wrote:

Paul,

about the five warnings :
can you confirm you are running mpirun *not* on n15 nor n16 ?
if my guess is correct, then you can get up to 5 warnings : mpirun + 2 orted + 2 mpi tasks

do you have any oob_tcp_if_include or oob_tcp_if_exclude settings in your openmpi-mca-params.conf ?

here is attached a patch to fix this issue.
what we really want is test there is a loopback interface, period.
the current code (my bad for not having reviewed in a timely manner) seems to check
there is a *selected* loopback interface.

Cheers,

Gilles

On 2014/12/12 13:15, Paul Hargrove wrote:
</pre>
        </div></div><blockquote type="cite" class="">
          <pre class=""><div class=""><div class="h5">Ralph,

Sorry to be the bearer of more bad news.
The "good" news is I've seen the new warning regarding the lack of a
loopback interface.
The BAD news is that it is occurring on a Linux cluster that I'ver verified
DOES have 'lo' configured on the front-end and compute nodes (UP and
RUNNING according to ifconfig).

Though run with "-np 2" the warning appears FIVE times.
ADDITIONALLY, there is a SEGV at exit!

Unfortunately, despite configuring with --enable-debug, I didn't get line
numbers from the core (and there was no backtrace printed).

All of this appears below (and no, "-mca mtl psm" is not a typo or a joke).

Let me know what tracing flags to apply to gather the info needed to debug
this.

-Paul


$ mpirun -mca btl sm,self -np 2 -host n15,n16 -mca mtl psm examples/ring_c
--------------------------------------------------------------------------
WARNING: No loopback interface was found. This can cause problems
when we spawn processes as they are likely to be unable to connect
back to their host daemon. Sadly, it may take awhile for the connect
attempt to fail, so you may experience a significant hang time.

You may wish to ctrl-c out of your job and activate loopback support
on at least one interface before trying again.

--------------------------------------------------------------------------
[... above message FOUR more times ...]
Process 1 exiting
Process 0 sending 10 to 1, tag 201 (2 processes in ring)
Process 0 sent to 1
Process 0 decremented value: 9
Process 0 decremented value: 8
Process 0 decremented value: 7
Process 0 decremented value: 6
Process 0 decremented value: 5
Process 0 decremented value: 4
Process 0 decremented value: 3
Process 0 decremented value: 2
Process 0 decremented value: 1
Process 0 decremented value: 0
Process 0 exiting
--------------------------------------------------------------------------
mpirun noticed that process rank 0 with PID 0 on node n15 exited on signal
11 (Segmentation fault).
--------------------------------------------------------------------------

$ /sbin/ifconfig lo
lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:16436  Metric:1
          RX packets:481228 errors:0 dropped:0 overruns:0 frame:0
          TX packets:481228 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:81039065 (77.2 MiB)  TX bytes:81039065 (77.2 MiB)

$ ssh n15 /sbin/ifconfig lo
lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:16436  Metric:1
          RX packets:24885 errors:0 dropped:0 overruns:0 frame:0
          TX packets:24885 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:1509940 (1.4 MiB)  TX bytes:1509940 (1.4 MiB)

$ ssh n16 /sbin/ifconfig lo
lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:16436  Metric:1
          RX packets:24938 errors:0 dropped:0 overruns:0 frame:0
          TX packets:24938 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:1543408 (1.4 MiB)  TX bytes:1543408 (1.4 MiB)

$ gdb examples/ring_c core.29728
[...]
(gdb) where
#0  0x0000002a97a19980 in ?? ()
#1  &lt;signal handler called&gt;
#2  0x0000003a6d40607c in _Unwind_FindEnclosingFunction () from
/lib64/libgcc_s.so.1
#3  0x0000003a6d406b57 in _Unwind_RaiseException () from
/lib64/libgcc_s.so.1
#4  0x0000003a6d406c4c in _Unwind_ForcedUnwind () from /lib64/libgcc_s.so.1
#5  0x0000003a6c30ac50 in __pthread_unwind () from
/lib64/tls/libpthread.so.0
#6  0x0000003a6c305202 in sigcancel_handler () from
/lib64/tls/libpthread.so.0
#7  &lt;signal handler called&gt;
#8  0x0000003a6b6bd9a2 in poll () from /lib64/tls/libc.so.6
#9  0x0000002a978f8f7d in ?? ()
#10 0x002000010000000e in ?? ()
#11 0x0000000000000000 in ?? ()



_______________________________________________
devel mailing list
</div></div><a href="mailto:devel@open-mpi.org" target="_blank" class="">devel@open-mpi.org</a> <a href="mailto:devel@open-mpi.org" target="_blank" class="">&lt;mailto:devel@open-mpi.org&gt;</a>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a> <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank" class="">&lt;http://www.open-mpi.org/mailman/listinfo.cgi/devel&gt;</a>
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2014/12/16525.php" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2014/12/16525.php</a> <a href="http://www.open-mpi.org/community/lists/devel/2014/12/16525.php" target="_blank" class="">&lt;http://www.open-mpi.org/community/lists/devel/2014/12/16525.php&gt;</a>
</pre>
        </blockquote><span class="">
        <pre class="">&lt;loopback.diff&gt;_______________________________________________
devel mailing list
<a href="mailto:devel@open-mpi.org" target="_blank" class="">devel@open-mpi.org</a>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a>
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2014/12/16526.php" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2014/12/16526.php</a>
</pre>
      </span></blockquote>
      <pre class=""></pre>
      <br class="">
      <fieldset class=""></fieldset>
      <br class="">
      <pre class=""><span class="">_______________________________________________
devel mailing list
<a href="mailto:devel@open-mpi.org" target="_blank" class="">devel@open-mpi.org</a>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a></span>
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2014/12/16527.php" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2014/12/16527.php</a></pre>
    </blockquote>
    <br class="">
  </div>

<br class="">_______________________________________________<br class="">
devel mailing list<br class="">
<a href="mailto:devel@open-mpi.org" class="">devel@open-mpi.org</a><br class="">
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank" class="">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br class="">
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2014/12/16529.php" target="_blank" class="">http://www.open-mpi.org/community/lists/devel/2014/12/16529.php</a><br class=""></blockquote></div><br class=""><br clear="all" class=""><div class=""><br class=""></div>-- <br class=""><div class="gmail_signature"><div dir="ltr" class=""><div class=""><font face="courier new, monospace" class=""><div class="">Paul H. Hargrove &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<a href="mailto:PHHargrove@lbl.gov" target="_blank" class="">PHHargrove@lbl.gov</a></div><div class="">Computer Languages &amp; Systems Software (CLaSS) Group</div><div class="">Computer Science Department &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Tel: +1-510-495-2352</div><div class="">Lawrence Berkeley National Laboratory &nbsp; &nbsp; Fax: +1-510-486-6900</div></font></div></div></div>
</div>
_______________________________________________<br class="">devel mailing list<br class=""><a href="mailto:devel@open-mpi.org" class="">devel@open-mpi.org</a><br class="">Subscription: http://www.open-mpi.org/mailman/listinfo.cgi/devel<br class="">Link to this post: http://www.open-mpi.org/community/lists/devel/2014/12/16531.php</div></blockquote></div><br class=""></div></body></html>
