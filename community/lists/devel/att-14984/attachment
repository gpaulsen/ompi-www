<div dir="ltr"><div><div><div><div>Ralph,<br><br>sorry for my poor understanding ...<br><br></div>i tried r31956 and it solved both issues :<br></div>- MPI_Abort does not hang any more if nodes are on different eth0 subnets<br>
</div>- MPI_Init does not hang any more if hosts have different number of IB ports<br><br></div><div>this likely explains why you are having trouble replicating it ;-)<br><br></div>Thanks a lot !<br><br>Gilles<br></div><div class="gmail_extra">
<br><br><div class="gmail_quote">On Fri, Jun 6, 2014 at 11:45 AM, Ralph Castain <span dir="ltr">&lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
I keep explaining that we don&#39;t &quot;discard&quot; anything, but there really isn&#39;t any point to continuing trying to explain the system. With the announced intention of completing the move of the BTLs to OPAL, I no longer need the multi-module complexity in the OOB/TCP. So I have removed it and gone back to the single module that connects to everything.<br>

<br>
Try r31956 - hopefully will resolve your connectivity issues.<br>
<br>
Still looking at the MPI_Abort hang as I&#39;m having trouble replicating it.<br>
<div><div class="h5"><br>
<br>
On Jun 5, 2014, at 7:16 PM, Gilles Gouaillardet &lt;<a href="mailto:gilles.gouaillardet@iferc.org">gilles.gouaillardet@iferc.org</a>&gt; wrote:<br>
<br>
&gt; Jeff,<br>
&gt;<br>
&gt; as pointed by Ralph, i do wish using eth0 for oob messages.<br>
&gt;<br>
&gt; i work on a 4k+ nodes cluster with a very decent gigabit ethernet<br>
&gt; network (reasonable oversubscription + switches<br>
&gt; from a reputable vendor you are familiar with ;-) )<br>
&gt; my experience is that IPoIB can be very slow at establishing a<br>
&gt; connection, especially if the arp table is not populated<br>
&gt; (as far as i understand, this involves the subnet manager and<br>
&gt; performance can be very random especially if all nodes issue<br>
&gt; arp requests at the same time)<br>
&gt; on the other hand, performance is much more stable when using the<br>
&gt; subnetted IP network.<br>
&gt;<br>
&gt; as Ralf also pointed, i can imagine some architects neglect their<br>
&gt; ethernet network (e.g. highly oversubscribed + low end switches)<br>
&gt; and in this case ib0 is a best fit for oob messages.<br>
&gt;<br>
&gt;&gt; As a simple solution, there could be an TCP oob MCA param that says &quot;regardless of peer IP address, I can connect to them&quot; (i.e., assume IP routing will make everything work out ok).<br>
&gt; +1 and/or an option to tell oob mca &quot;do not discard the interface simply<br>
&gt; because the peer IP is not in the same subnet&quot;<br>
&gt;<br>
&gt; Cheers,<br>
&gt;<br>
&gt; Gilles<br>
&gt;<br>
&gt; On 2014/06/05 23:01, Ralph Castain wrote:<br>
&gt;&gt; Because Gilles wants to avoid using IB for TCP messages, and using eth0 also solves the problem (the messages just route)<br>
&gt;&gt;<br>
&gt;&gt; On Jun 5, 2014, at 5:00 AM, Jeff Squyres (jsquyres) &lt;<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a>&gt; wrote:<br>
&gt;&gt;<br>
&gt;&gt;&gt; Another random thought for Gilles situation: why not oob-TCP-if-include ib0? Â (And not eth0)<br>
&gt;&gt;&gt;<br>
&gt;<br>
&gt; _______________________________________________<br>
&gt; devel mailing list<br>
&gt; <a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
&gt; Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
&gt; Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2014/06/14982.php" target="_blank">http://www.open-mpi.org/community/lists/devel/2014/06/14982.php</a><br>
<br>
_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
Subscription: <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</div></div>Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2014/06/14983.php" target="_blank">http://www.open-mpi.org/community/lists/devel/2014/06/14983.php</a><br>
</blockquote></div><br></div>

