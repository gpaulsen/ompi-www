<div dir="ltr">The timeout never triggers and when I attach to the mpirun process I see an extremely strange stack:<div><br></div><div><div>(lldb) bt</div><div>* thread #1: tid = 0x272b40e, 0x00007fff93306de6 libsystem_kernel.dylib`__psynch_mutexwait + 10, queue = &#39;com.apple.main-thread&#39;, stop reason = signal SIGSTOP</div><div>  * frame #0: 0x00007fff93306de6 libsystem_kernel.dylib`__psynch_mutexwait + 10</div><div>    frame #1: 0x00007fff9a000e4a libsystem_pthread.dylib`_pthread_mutex_lock_wait + 89</div><div>    frame #2: 0x00007fff99ffe5f5 libsystem_pthread.dylib`_pthread_mutex_lock_slow + 300</div><div>    frame #3: 0x00007fff8c2a00f8 libdyld.dylib`dyldGlobalLockAcquire() + 16</div><div>    frame #4: 0x00007fff6ca8e177 dyld`ImageLoaderMachOCompressed::doBindFastLazySymbol(unsigned int, ImageLoader::LinkContext const&amp;, void (*)(), void (*)()) + 55</div><div>    frame #5: 0x00007fff6ca78063 dyld`dyld::fastBindLazySymbol(ImageLoader**, unsigned long) + 90</div><div>    frame #6: 0x00007fff8c2a0262 libdyld.dylib`dyld_stub_binder + 282</div><div>    frame #7: 0x000000010a5b29b0 libopen-pal.0.dylib`obj_order_type + 3776</div></div><div><br></div><div>This seems to indicate that we are trying to access a function from a dylib that has been or is in the process of being unloaded.</div><div><br></div><div>  George.</div><div><br></div></div><div class="gmail_extra"><br><div class="gmail_quote">On Thu, Jun 2, 2016 at 8:34 AM, Nathan Hjelm <span dir="ltr">&lt;<a href="mailto:hjelmn@me.com" target="_blank">hjelmn@me.com</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir="auto"><div></div><div>The osc hang is fixed by a PR to fix bugs in start in cm and ob1. See #1729.</div><div><br></div><div>-Nathan</div><div><div class="h5"><div><br>On Jun 2, 2016, at 5:17 AM, Gilles Gouaillardet &lt;<a href="mailto:gilles.gouaillardet@gmail.com" target="_blank">gilles.gouaillardet@gmail.com</a>&gt; wrote:<br><br></div><blockquote type="cite"><div><p style="color:rgb(34,34,34);line-height:22px">fwiw,</p><p style="color:rgb(34,34,34);line-height:22px">the onsided/c_fence_lock test from the ibm test suite hangs<br></p><p style="color:rgb(34,34,34);line-height:22px">(mpirun -np 2 ./c_fence_lock)</p><p style="color:rgb(34,34,34);line-height:22px">i ran a git bisect and it incriminates commit b90c83840f472de3219b87cd7e1a364eec5c5a29</p><p style="color:rgb(34,34,34);line-height:22px">commit b90c83840f472de3219b87cd7e1a364eec5c5a29<br>Author: bosilca <a style="color:rgb(17,85,204)">&lt;bosilca@users.noreply.github.com&gt;</a><br>Date:   Tue May 24 18:20:51 2016 -0500<br><br>    Refactor the request completion (#1422)<br>    <br>    * Remodel the request.<br>    Added the wait sync primitive and integrate it into the PML and MTL<br>    infrastructure. The multi-threaded requests are now significantly<br>    less heavy and less noisy (only the threads associated with completed<br>    requests are signaled).<br>    <br>    * Fix the condition to release the request.<br><br></p><p style="color:rgb(34,34,34);line-height:22px"><br></p><p style="color:rgb(34,34,34);line-height:22px">I also noted a warning is emitted when running only one task</p><p style="color:rgb(34,34,34);line-height:22px">./c_fence_lock</p><p style="color:rgb(34,34,34);line-height:22px">but I did not git bisect, so that might not be related</p><p style="color:rgb(34,34,34);line-height:22px">Cheers,</p><p style="color:rgb(34,34,34);line-height:22px"><br></p><p style="color:rgb(34,34,34);line-height:22px">Gilles</p><br>On Thursday, June 2, 2016, Ralph Castain &lt;<a href="mailto:rhc@open-mpi.org" target="_blank">rhc@open-mpi.org</a>&gt; wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div style="word-wrap:break-word">Yes, please! I’d like to know what mpirun thinks is happening - if you like, just set the —timeout N —report-state-on-timeout flags and tell me what comes out<div><br><div><blockquote type="cite"><div>On Jun 1, 2016, at 7:57 PM, George Bosilca &lt;<a>bosilca@icl.utk.edu</a>&gt; wrote:</div><br><div><div dir="ltr">I don&#39;t think it matters. I was running the IBM collective and pt2pt tests, but each time it deadlocked was in a different test. If you are interested in some particular values, I would be happy to attach a debugger next time it happens.<div><br></div><div>  George.</div><div><br></div></div><div class="gmail_extra"><br><div class="gmail_quote">On Wed, Jun 1, 2016 at 10:47 PM, Ralph Castain <span dir="ltr">&lt;<a>rhc@open-mpi.org</a>&gt;</span> wrote:<br><blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">What kind of apps are they? Or does it matter what you are running?<br>
<div><div><br>
<br>
&gt; On Jun 1, 2016, at 7:37 PM, George Bosilca &lt;<a>bosilca@icl.utk.edu</a>&gt; wrote:<br>
&gt;<br>
&gt; I have a seldomly occurring deadlock on a OS X laptop if I use more than 2 processes). It is coming up once every 200 runs or so.<br>
&gt;<br>
&gt; Here is what I could gather from my experiments: All the MPI processes seem to have correctly completed (I get all the expected output and the MPI processes are in a waiting state), but somehow the mpirun does not detect their completion. As a result, mpirun never returns.<br>
&gt;<br>
&gt;   George.<br>
&gt;<br>
</div></div>&gt; _______________________________________________<br>
&gt; devel mailing list<br>
&gt; <a>devel@open-mpi.org</a><br>
&gt; Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/devel" rel="noreferrer" target="_blank">https://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
&gt; Searchable archives: <a href="http://www.open-mpi.org/community/lists/devel/2016/06/19054.php" rel="noreferrer" target="_blank">http://www.open-mpi.org/community/lists/devel/2016/06/19054.php</a><br>
<br>
_______________________________________________<br>
devel mailing list<br>
<a>devel@open-mpi.org</a><br>
Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/devel" rel="noreferrer" target="_blank">https://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2016/06/19054.php" rel="noreferrer" target="_blank">http://www.open-mpi.org/community/lists/devel/2016/06/19054.php</a><br>
</blockquote></div><br></div>
_______________________________________________<br>devel mailing list<br><a>devel@open-mpi.org</a><br>Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">https://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2016/06/19055.php" target="_blank">http://www.open-mpi.org/community/lists/devel/2016/06/19055.php</a></div></blockquote></div><br></div></div></blockquote>
</div></blockquote></div></div><blockquote type="cite"><div><div><div class="h5"><span>_______________________________________________</span><br><span>devel mailing list</span><br><span><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a></span><br><span>Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">https://www.open-mpi.org/mailman/listinfo.cgi/devel</a></span><br></div></div><span>Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2016/06/19059.php" target="_blank">http://www.open-mpi.org/community/lists/devel/2016/06/19059.php</a></span></div></blockquote></div><br>_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
Subscription: <a href="https://www.open-mpi.org/mailman/listinfo.cgi/devel" rel="noreferrer" target="_blank">https://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
Link to this post: <a href="http://www.open-mpi.org/community/lists/devel/2016/06/19060.php" rel="noreferrer" target="_blank">http://www.open-mpi.org/community/lists/devel/2016/06/19060.php</a><br></blockquote></div><br></div>

