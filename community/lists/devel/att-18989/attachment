<html><head><meta http-equiv="Content-Type" content="text/html charset=windows-1252"></head><body style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;" class="">You are welcome to raise the question of default mapping behavior on master yet again, but please do so on a separate thread so we can make sense of it.<div class=""><br class=""></div><div class="">Note that I will not be making more modifications of that behavior, so if someone feels strongly that they want it to change, please go ahead and do so. I’m tired of chasing this tiger’s tail.</div><div class=""><br class=""></div><div class=""><br class=""><div><blockquote type="cite" class=""><div class="">On May 16, 2016, at 5:59 PM, Gilles Gouaillardet &lt;<a href="mailto:gilles@rist.or.jp" class="">gilles@rist.or.jp</a>&gt; wrote:</div><br class="Apple-interchange-newline"><div class="">
  
    <meta content="text/html; charset=windows-1252" http-equiv="Content-Type" class="">
  
  <div bgcolor="#FFFFFF" text="#000000" class=""><p class="">Thanks Nathan,</p><p class=""><br class="">
    </p><p class="">sorry for the confusion, what i observed was a consequence of
      something else ...</p><p class="">mpirun --host n0,n1 -np 4 a.out</p><p class="">/* n0 and n1 have 16 cores each */<br class="">
    </p>
    runs 4 instances of a.out on n0 (and nothing on n1)<br class="">
    <br class="">
    if i run with -np 32, then 16 tasks run on each node.<br class="">
    <br class="">
    <br class="">
    with v2.x, the --oversubscribe option is needed and 2 tasks run on
    each node<br class="">
    <br class="">
    <br class="">
    is this really the intended behavior on master ?<br class="">
    i mean, i am fine with detecting the number of slots automatically
    so --oversubscribe is not needed up to 32 tasks. my point is,
    shouldn't we have a different mapping policy in this case ? for
    example, allocate the tasks round robin, or allocate &lt;total
    number of slots&gt; / &lt;number of slots per node&gt; consecutive
    tasks per node ?<br class="">
    <br class="">
    Cheers,<br class="">
    <br class="">
    Gilles<br class="">
    <br class="">
    <div class="moz-cite-prefix">On 5/17/2016 1:13 AM, Nathan Hjelm
      wrote:<br class="">
    </div>
    <blockquote cite="mid:20160516161317.GA80855@mordor.lanl.gov" type="cite" class="">
      <pre wrap="" class="">add_procs is always called at least once. This is how we set up shared
memory communication. It will then be invoked on-demand for non-local
peers with the reachability argument set to NULL (because the bitmask
doesn't provide any benefit when adding only 1 peer).

-Nathan

On Tue, May 17, 2016 at 12:00:38AM +0900, Gilles Gouaillardet wrote:
</pre>
      <blockquote type="cite" class="">
        <pre wrap="" class="">   Jeff,
   this is not what I observed
   (tcp btl, 2 to 4 nodes with one task per node, cutoff=0)
   the add_procs of the tcp btl is invoked once with the 4 tasks.
   I checked the sources and found cutoff only controls if the modex is
   invoked once for all at init, or on demand.
   Cheers,
   Gilles

   On Monday, May 16, 2016, Jeff Squyres (jsquyres) <a class="moz-txt-link-rfc2396E" href="mailto:jsquyres@cisco.com">&lt;jsquyres@cisco.com&gt;</a>
   wrote:

     We changed the way BTL add_procs is invoked on master and v2.x for
     scalability reasons.

     In short: add_procs is only invoked the first time you talk to a given
     peer.  The cutoff switch is an override to that -- if the sizeof
     COMM_WORLD is less than the cutoff, we revert to the old behavior of
     calling add_procs for all procs.

     As for why one BTL would be chosen over another, be sure to look at not
     only the priority of the component/module, but also the exclusivity
     level.  In short, only BTLs with the same exclusivity level will be
     considered (e.g., this is how we exclude TCP when using HPC-class
     networks), and then the BTL modules with the highest priority will be
     used for a given peer.

     &gt; On May 16, 2016, at 7:19 AM, Gilles Gouaillardet
     <a class="moz-txt-link-rfc2396E" href="mailto:gilles.gouaillardet@gmail.com">&lt;gilles.gouaillardet@gmail.com&gt;</a> wrote:
     &gt;
     &gt; it seems I misunderstood some things ...
     &gt;
     &gt; add_procs is always invoked, regardless the cutoff value.
     &gt; cutoff is used to retrieve processes info via the modex "on demand" vs
     at init time.
     &gt;
     &gt; Please someone correct me and/or elaborate if needed
     &gt;
     &gt; Cheers,
     &gt;
     &gt; Gilles
     &gt;
     &gt; On Monday, May 16, 2016, Gilles Gouaillardet <a class="moz-txt-link-rfc2396E" href="mailto:gilles@rist.or.jp">&lt;gilles@rist.or.jp&gt;</a>
     wrote:
     &gt; i cannot reproduce this behavior.
     &gt;
     &gt; note mca_btl_tcp_add_procs is invoked once per tcp component (e.g.
     once per physical NIC)
     &gt;
     &gt; so you might want to explicitly select one nic
     &gt;
     &gt; mpirun --mca btl_tcp_if_include xxx ...
     &gt;
     &gt; my printf output are the same and regardless the mpi_add_procs_cutoff
     value
     &gt;
     &gt;
     &gt; Cheers,
     &gt;
     &gt;
     &gt; Gilles
     &gt; On 5/16/2016 12:22 AM, dpchoudh . wrote:
     &gt;&gt; Sorry, I accidentally pressed 'Send' before I was done writing the
     last mail. What I wanted to ask was what is the parameter
     mpi_add_procs_cutoff and why adding it seems to make a difference in the
     code path but not in the end result of the program? How would it help me
     debug my problem?
     &gt;&gt;
     &gt;&gt; Thank you
     &gt;&gt; Durga
     &gt;&gt;
     &gt;&gt; The surgeon general advises you to eat right, exercise regularly and
     quit ageing.
     &gt;&gt;
     &gt;&gt; On Sun, May 15, 2016 at 11:17 AM, dpchoudh . <a class="moz-txt-link-rfc2396E" href="mailto:dpchoudh@gmail.com">&lt;dpchoudh@gmail.com&gt;</a>
     wrote:
     &gt;&gt; Hello Gilles
     &gt;&gt;
     &gt;&gt; Setting -mca mpi_add_procs_cutoff 1024 indeed makes a difference to
     the output, as follows:
     &gt;&gt;
     &gt;&gt; With -mca mpi_add_procs_cutoff 1024:
     &gt;&gt; reachable =     0x1
     &gt;&gt; (Note that add_procs was called once and the value of 'reachable is
     correct')
     &gt;&gt;
     &gt;&gt; Without -mca mpi_add_procs_cutoff 1024
     &gt;&gt; reachable =     0x0
     &gt;&gt; reachable = NULL
     &gt;&gt; reachable = NULL
     &gt;&gt; (Note that add_procs() was caklled three times and the value of
     'reachable' seems wrong.
     &gt;&gt;
     &gt;&gt; The program does run correctly in either case. The program listing is
     as below (note that I have removed output from the program itself in the
     above reporting.)
     &gt;&gt;
     &gt;&gt; The code that prints 'reachable' is as follows:
     &gt;&gt;
     &gt;&gt; if (reachable == NULL)
     &gt;&gt;     printf("reachable = NULL\n");
     &gt;&gt; else
     &gt;&gt; {
     &gt;&gt;     int i;
     &gt;&gt;     printf("reachable = ");
     &gt;&gt;     for (i = 0; i &lt; reachable-&gt;array_size; i++)
     &gt;&gt;     printf("\t0x%llu", reachable-&gt;bitmap[i]);
     &gt;&gt;     printf("\n\n");
     &gt;&gt; }
     &gt;&gt; return OPAL_SUCCESS;
     &gt;&gt;
     &gt;&gt; And the code for the test program is as follows:
     &gt;&gt;
     &gt;&gt; #include &lt;mpi.h&gt;
     &gt;&gt; #include &lt;stdio.h&gt;
     &gt;&gt; #include &lt;string.h&gt;
     &gt;&gt; #include &lt;stdlib.h&gt;
     &gt;&gt;
     &gt;&gt; int main(int argc, char *argv[])
     &gt;&gt; {
     &gt;&gt;     int world_size, world_rank, name_len;
     &gt;&gt;     char hostname[MPI_MAX_PROCESSOR_NAME], buf[8];
     &gt;&gt;
     &gt;&gt;     MPI_Init(&amp;argc, &amp;argv);
     &gt;&gt;     MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size);
     &gt;&gt;     MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank);
     &gt;&gt;     MPI_Get_processor_name(hostname, &amp;name_len);
     &gt;&gt;     printf("Hello world from processor %s, rank %d out of %d
     processors\n", hostname, world_rank, world_size);
     &gt;&gt;     if (world_rank == 1)
     &gt;&gt;     {
     &gt;&gt;     MPI_Recv(buf, 6, MPI_CHAR, 0, 99, MPI_COMM_WORLD,
     MPI_STATUS_IGNORE);
     &gt;&gt;     printf("%s received %s, rank %d\n", hostname, buf, world_rank);
     &gt;&gt;     }
     &gt;&gt;     else
     &gt;&gt;     {
     &gt;&gt;     strcpy(buf, "haha!");
     &gt;&gt;     MPI_Send(buf, 6, MPI_CHAR, 1, 99, MPI_COMM_WORLD);
     &gt;&gt;     printf("%s sent %s, rank %d\n", hostname, buf, world_rank);
     &gt;&gt;     }
     &gt;&gt;     MPI_Barrier(MPI_COMM_WORLD);
     &gt;&gt;     MPI_Finalize();
     &gt;&gt;     return 0;
     &gt;&gt; }
     &gt;&gt;
     &gt;&gt;
     &gt;&gt;
     &gt;&gt; The surgeon general advises you to eat right, exercise regularly and
     quit ageing.
     &gt;&gt;
     &gt;&gt; On Sun, May 15, 2016 at 10:49 AM, Gilles Gouaillardet
     <a class="moz-txt-link-rfc2396E" href="mailto:gilles.gouaillardet@gmail.com">&lt;gilles.gouaillardet@gmail.com&gt;</a> wrote:
     &gt;&gt; At first glance, that seems a bit odd...
     &gt;&gt; are you sure you correctly print the reachable bitmap ?
     &gt;&gt; I would suggest you add some instrumentation to understand what
     happens
     &gt;&gt; (e.g., printf before opal_bitmap_set_bit() and other places that
     prevent this from happening)
     &gt;&gt;
     &gt;&gt; one more thing ...
     &gt;&gt; now, master default behavior is
     &gt;&gt; mpirun --mca mpi_add_procs_cutoff 0 ...
     &gt;&gt; you might want to try
     &gt;&gt; mpirun --mca mpi_add_procs_cutoff 1024 ...
     &gt;&gt; and see if things make more sense.
     &gt;&gt; if it helps, and iirc, there is a parameter so a btl can report it
     does not support cutoff.
     &gt;&gt;
     &gt;&gt;
     &gt;&gt; Cheers,
     &gt;&gt;
     &gt;&gt; Gilles
     &gt;&gt;
     &gt;&gt; On Sunday, May 15, 2016, dpchoudh . <a class="moz-txt-link-rfc2396E" href="mailto:dpchoudh@gmail.com">&lt;dpchoudh@gmail.com&gt;</a> wrote:
     &gt;&gt; Hello Gilles
     &gt;&gt;
     &gt;&gt; Thanks for jumping in to help again. Actually, I had already tried
     some of your suggestions before asking for help.
     &gt;&gt;
     &gt;&gt; I have several interconnects that can run both openib and tcp BTL. To
     simplify things, I explicitly mentioned TCP:
     &gt;&gt;
     &gt;&gt; mpirun -np 2 -hostfile ~/hostfile -mca pml ob1 -mca btl self.tcp
     ./mpitest
     &gt;&gt;
     &gt;&gt; where mpitest is a small program that does MPI_Send()/MPI_Recv() on a
     small string, and then does an MPI_Barrier(). The program does work as
     expected.
     &gt;&gt;
     &gt;&gt; I put a printf on the last line of mca_tcp_add_procs() to print the
     value of 'reachable'. What I saw was that the value was always 0 when it
     was invoked for Send()/Recv() and the pointer itself was NULL when
     invoked for Barrier()
     &gt;&gt;
     &gt;&gt; Next I looked at pml_ob1_add_procs(), where the call chain starts,
     and found that it initializes and passes an opal_bitmap_t reachable down
     the call chain, but the resulting value is not used later in the code
     (the memory is simply freed later).
     &gt;&gt;
     &gt;&gt; That, coupled with the fact that I am trying to imitate what the
     other BTL implementations are doing, yet in
     mca_bml_r2_endpoint_add_btl() by BTL is not being picked up, left me
     puzzled. Please note that the interconnect that I am developing for is
     on a different cluster (than where I ran the above test for TCP BTL.)
     &gt;&gt;
     &gt;&gt; Thanks again
     &gt;&gt; Durga
     &gt;&gt;
     &gt;&gt; The surgeon general advises you to eat right, exercise regularly and
     quit ageing.
     &gt;&gt;
     &gt;&gt; On Sun, May 15, 2016 at 10:20 AM, Gilles Gouaillardet
     <a class="moz-txt-link-rfc2396E" href="mailto:gilles.gouaillardet@gmail.com">&lt;gilles.gouaillardet@gmail.com&gt;</a> wrote:
     &gt;&gt; did you check the add_procs callbacks ?
     &gt;&gt; (e.g. mca_btl_tcp_add_procs() for the tcp btl)
     &gt;&gt; this is where the reachable bitmap is set, and I guess this is what
     you are looking for.
     &gt;&gt;
     &gt;&gt; keep in mind that if several btl can be used, the one with the higher
     exclusivity is used
     &gt;&gt; (e.g. tcp is never used if openib is available)
     &gt;&gt; you can simply force your btl and self, and the ob1 pml, so you do
     not have to worry about other btl exclusivity.
     &gt;&gt;
     &gt;&gt; Cheers,
     &gt;&gt;
     &gt;&gt; Gilles
     &gt;&gt;
     &gt;&gt;
     &gt;&gt; On Sunday, May 15, 2016, dpchoudh . <a class="moz-txt-link-rfc2396E" href="mailto:dpchoudh@gmail.com">&lt;dpchoudh@gmail.com&gt;</a> wrote:
     &gt;&gt; Hello all
     &gt;&gt;
     &gt;&gt; I have been struggling with this issue for a while and figured it
     might be a good idea to ask for help.
     &gt;&gt;
     &gt;&gt; Where (in the code path) is the connectivity map created?
     &gt;&gt;
     &gt;&gt; I can see that it is *used* in mca_bml_r2_endpoint_add_btl(), but
     obviously I am not setting it up right, because this routine is not
     finding the BTL corresponding to my interconnect.
     &gt;&gt;
     &gt;&gt; Thanks in advance
     &gt;&gt; Durga
     &gt;&gt;
     &gt;&gt; The surgeon general advises you to eat right, exercise regularly and
     quit ageing.
     &gt;&gt;
     &gt;&gt; _______________________________________________
     &gt;&gt; devel mailing list
     &gt;&gt; <a class="moz-txt-link-abbreviated" href="mailto:devel@open-mpi.org">devel@open-mpi.org</a>
     &gt;&gt; Subscription: <a class="moz-txt-link-freetext" href="https://www.open-mpi.org/mailman/listinfo.cgi/devel">https://www.open-mpi.org/mailman/listinfo.cgi/devel</a>
     &gt;&gt; Link to this post:
     <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/devel/2016/05/18975.php">http://www.open-mpi.org/community/lists/devel/2016/05/18975.php</a>
     &gt;&gt;
     &gt;&gt;
     &gt;&gt; _______________________________________________
     &gt;&gt; devel mailing list
     &gt;&gt; <a class="moz-txt-link-abbreviated" href="mailto:devel@open-mpi.org">devel@open-mpi.org</a>
     &gt;&gt; Subscription: <a class="moz-txt-link-freetext" href="https://www.open-mpi.org/mailman/listinfo.cgi/devel">https://www.open-mpi.org/mailman/listinfo.cgi/devel</a>
     &gt;&gt; Link to this post:
     <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/devel/2016/05/18977.php">http://www.open-mpi.org/community/lists/devel/2016/05/18977.php</a>
     &gt;&gt;
     &gt;&gt;
     &gt;&gt;
     &gt;&gt;
     &gt;&gt; _______________________________________________
     &gt;&gt; devel mailing list
     &gt;&gt;
     &gt;&gt; <a class="moz-txt-link-abbreviated" href="mailto:devel@open-mpi.org">devel@open-mpi.org</a>
     &gt;&gt;
     &gt;&gt; Subscription:
     &gt;&gt; <a class="moz-txt-link-freetext" href="https://www.open-mpi.org/mailman/listinfo.cgi/devel">https://www.open-mpi.org/mailman/listinfo.cgi/devel</a>
     &gt;&gt;
     &gt;&gt; Link to this post:
     &gt;&gt; <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/devel/2016/05/18979.php">http://www.open-mpi.org/community/lists/devel/2016/05/18979.php</a>
     &gt;
     &gt; _______________________________________________
     &gt; devel mailing list
     &gt; <a class="moz-txt-link-abbreviated" href="mailto:devel@open-mpi.org">devel@open-mpi.org</a>
     &gt; Subscription: <a class="moz-txt-link-freetext" href="https://www.open-mpi.org/mailman/listinfo.cgi/devel">https://www.open-mpi.org/mailman/listinfo.cgi/devel</a>
     &gt; Link to this post:
     <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/devel/2016/05/18981.php">http://www.open-mpi.org/community/lists/devel/2016/05/18981.php</a>

     --
     Jeff Squyres
     <a class="moz-txt-link-abbreviated" href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a>
     For corporate legal information go to:
     <a class="moz-txt-link-freetext" href="http://www.cisco.com/web/about/doing_business/legal/cri/">http://www.cisco.com/web/about/doing_business/legal/cri/</a>

     _______________________________________________
     devel mailing list
     <a class="moz-txt-link-abbreviated" href="mailto:devel@open-mpi.org">devel@open-mpi.org</a>
     Subscription: <a class="moz-txt-link-freetext" href="https://www.open-mpi.org/mailman/listinfo.cgi/devel">https://www.open-mpi.org/mailman/listinfo.cgi/devel</a>
     Link to this post:
     <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/devel/2016/05/18982.php">http://www.open-mpi.org/community/lists/devel/2016/05/18982.php</a>
</pre>
      </blockquote>
      <pre wrap="" class=""></pre>
      <blockquote type="cite" class="">
        <pre wrap="" class="">_______________________________________________
devel mailing list
<a class="moz-txt-link-abbreviated" href="mailto:devel@open-mpi.org">devel@open-mpi.org</a>
Subscription: <a class="moz-txt-link-freetext" href="https://www.open-mpi.org/mailman/listinfo.cgi/devel">https://www.open-mpi.org/mailman/listinfo.cgi/devel</a>
Link to this post: <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/devel/2016/05/18983.php">http://www.open-mpi.org/community/lists/devel/2016/05/18983.php</a>
</pre>
      </blockquote>
      <pre wrap="" class=""></pre>
      <br class="">
      <fieldset class="mimeAttachmentHeader"></fieldset>
      <br class="">
      <pre wrap="" class="">_______________________________________________
devel mailing list
<a class="moz-txt-link-abbreviated" href="mailto:devel@open-mpi.org">devel@open-mpi.org</a>
Subscription: <a class="moz-txt-link-freetext" href="https://www.open-mpi.org/mailman/listinfo.cgi/devel">https://www.open-mpi.org/mailman/listinfo.cgi/devel</a>
Link to this post: <a class="moz-txt-link-freetext" href="http://www.open-mpi.org/community/lists/devel/2016/05/18986.php">http://www.open-mpi.org/community/lists/devel/2016/05/18986.php</a></pre>
    </blockquote>
    <br class="">
  </div>

_______________________________________________<br class="">devel mailing list<br class=""><a href="mailto:devel@open-mpi.org" class="">devel@open-mpi.org</a><br class="">Subscription: https://www.open-mpi.org/mailman/listinfo.cgi/devel<br class="">Link to this post: http://www.open-mpi.org/community/lists/devel/2016/05/18988.php</div></blockquote></div><br class=""></div></body></html>
