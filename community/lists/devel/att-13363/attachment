<div dir="ltr"><div>We had committers at HLRS, but they are not as active any more (some people left, funding priorities changed, etc.), and the VampirTrace folks are in the general area. We could point you to them if that would be of help.<br>
<br></div>We also have a couple of folks in Spain who wrote the Java bindings, a few folks who regularly contribute to the user and devel lists (but aren&#39;t formal committers), and some folks in France that don&#39;t directly contribute to OMPI, but are very familiar with it.<br>
<br></div><div class="gmail_extra"><br><br><div class="gmail_quote">On Wed, Dec 4, 2013 at 5:47 AM, &quot;Isaías A. Comprés Ureña&quot; <span dir="ltr">&lt;<a href="mailto:compresu@in.tum.de" target="_blank">compresu@in.tum.de</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
  
    
  
  <div bgcolor="#FFFFFF" text="#000000">
    Dear Ralph,<br>
    <br>
    do you know if Open MPI already have commiters in Munich? Any
    contact in the Technical University of Munich or the LRZ compute
    center could be easily reachable by us.  <br>
    <br>
    In any case, I will need to get familiar with the internals of the
    library first.  I am happy to say that the communication here has so
    far left a good impression.  Thanks.<div><div class="h5"><br>
    <br>
    <br>
    <div>On 12/04/2013 01:55 PM, Ralph Castain
      wrote:<br>
    </div>
    <blockquote type="cite">
      <div dir="ltr">
        <div>
          <div>I&#39;m not sure how many apps would benefit, but we are
            always interested in taking back patches that extend the
            ability for researchers to explore new capabilities provided
            they don&#39;t impact performance (or can be configured out if
            they do) and are self-maintained (i.e., either the
            researcher agrees to maintain them, or - as in this case -
            they involve a change that essentially requires no ongoing
            maintenance).<br>
            <br>
          </div>
          So if you want to take a crack at this, I&#39;d suggest taking one
          or two of most interest and sending us the required patch for
          review. If it looks like things fit well, then we (a) can
          absorb the patches, and (b) it would probably be worth your
          time to submit a contributor agreement and join the team as
          full committers.<br>
          <br>
        </div>
        <div>HTH<br>
        </div>
        Ralph<br>
        <br>
      </div>
      <div class="gmail_extra"><br>
        <br>
        <div class="gmail_quote">On Wed, Dec 4, 2013 at 3:25 AM, &quot;Isaías
          A. Comprés Ureña&quot; <span dir="ltr">&lt;<a href="mailto:compresu@in.tum.de" target="_blank">compresu@in.tum.de</a>&gt;</span> wrote:<br>
          <blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Dear Jeff
            Squyres,
            <div><br>
              <br>
              On 12/03/2013 11:27 PM, Jeff Squyres (jsquyres) wrote:<br>
              <blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
                I&#39;m sorry; I really wasn&#39;t paying attention to my email
                the week of SC, and then I was on vacation for the
                Thanksgiving holiday.  :-\<br>
                <br>
                More below.<br>
                <br>
                On Nov 20, 2013, at 4:13 PM, Compres &lt;<a href="mailto:compresu@in.tum.de" target="_blank">compresu@in.tum.de</a>&gt;
                wrote:<br>
                <br>
                <blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
                  I was at the birds of a feather and wanted to talk to
                  the Open MPI developers, but unfortunately had to
                  leave early.  In particular, I would like to discuss
                  about your implementation of the MPI tools interface
                  and possibly contribute to it later on.<br>
                </blockquote>
                Sorry we missed you.<br>
              </blockquote>
              <br>
            </div>
            No problem; I had to be at a booth during times that
            overlapped with your session.
            <div><br>
              <br>
              <blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
                What did you want to discuss?  We actually have a full
                implementation of the MPI_T interface -- meaning that we
                have all the infrastructure in place for MPI_T control
                and performance variables.<br>
                <br>
                1. The MPI_T control variables map directly to OMPI&#39;s
                MCA params, so we automatically expose oodles of cvars
                through MPI_T.  They&#39;re all read-only after MPI_INIT,
                however -- many things are setup during MPI_INIT and it
                would be quite a Big Deal if they were to change.
                 However, we pretty much *assumed* all cvars shouldn&#39;t
                change after INIT -- we didn&#39;t really audit to see if
                there were actually some cvars that could change after
                INIT. So there&#39;s work that could be done there (i.e.,
                find cvars that could change after INIT, and/or evaluate
                the amount of work/change it would be to change some
                read-only cvars to be read-write, etc.).<br>
                <br>
                2. The MPI_T performance variables are new.  There&#39;s
                only a few created right now (e.g., in the Cisco usnic
                BTL).  But the field is pretty wide open here -- the
                infrastructure is there, but we&#39;re really not exposing
                much information yet.  There&#39;s lots that can be done
                here.<br>
                <br>
                What did you have in mind?<br>
              </blockquote>
              <br>
            </div>
            I think you made a good guess on what we would like to do
            here.  We are working on automatic tuning based on both
            modeling and empirical data.  One of our aims is to
            accelerate the data collection part (in this case related to
            MPI settings), by doing it online without the need of full
            application runs or restarts.<br>
            <br>
            Right now we can modify MPI runtime parameters with IBM-MPI
            or Open MPI.  These require full restarts, since they are
            set as environment variables and are not modifiable after
            MPI_INIT.  With your MPIT implementation, we can do the same
            programmatically but cannot avoid the restarts or full runs.<br>
            <br>
            We already did what you describe at the end of 1., but with
            a (1 year old) snapshot of MPICH.  The idea was to identify
            which variables could be made modifiable at runtime, and
            whether there was any attainable performance as a result of
            tuning them.  We only explored point to point and collective
            communication parameters, and the results are encouraging.
             There was no technical reason when picking MPICH for the
            first prototype.<br>
            <br>
            With MPICH, we had to examine the code for things that were
            configurable.  It seems to me that in the case of Open MPI,
            most of the work is done and, as you point out, it may just
            be necessary to identify which ones can be made modifiable
            at runtime and at what development cost.<br>
            <br>
            My main intention here is to see if other people are
            interested and will benefit from this.  Additionally, if the
            changes (patches) are taken by the project, we avoid running
            out of sync (which is what ended up happening with our MPICH
            modifications).<span><font color="#888888"><br>
                <br>
                - Isaías A. Comprés</font></span>
            <div>
              <div><br>
                <br>
                _______________________________________________<br>
                devel mailing list<br>
                <a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br>
                <a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
              </div>
            </div>
          </blockquote>
        </div>
        <br>
      </div>
      <br>
      <fieldset></fieldset>
      <br>
      <pre>_______________________________________________
devel mailing list
<a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a></pre>
    </blockquote>
    <br>
  </div></div></div>

<br>_______________________________________________<br>
devel mailing list<br>
<a href="mailto:devel@open-mpi.org">devel@open-mpi.org</a><br>
<a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br></blockquote></div><br></div>

